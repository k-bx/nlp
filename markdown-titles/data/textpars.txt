This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular/angular.js"></script> ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngAnimate). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-animate ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular-animate/angular-animate.js"></script> ```
And add `ngAnimate` as a dependency for your app:
```javascript angular.module('myApp', ['ngAnimate']); ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/api/ngAnimate).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngCookies). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-cookies ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular-cookies/angular-cookies.js"></script> ```
And add `ngCookies` as a dependency for your app:
```javascript angular.module('myApp', ['ngCookies']); ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/api/ngCookies).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Angular Dialog Service ======================
>**Please use one of the release versions rather than the Master Branch**.  The Master Branch has untested merges and changes and is a work in progress.  I urge you to always use a release version rather than linking directly to the Master Branch, as the Master Branch may change and may not always be backward compatible.
**v4.x.x + is not backward compatible with versions 1,2,3,3.1  Please refer to the changes section to view what is different in v4.0**
A complete AngularJS service with controllers and templates for generating application modals and dialogs for use with Angular-UI-Bootstrap and Twitter Bootstrap.  Supports, i18n, language translations for dialog headers, messages and buttons via angular-translate.
Demos -----  - v1.0 : [Codepen: http://codepen.io/m-e-conroy/pen/ALsdF](http://codepen.io/m-e-conroy/pen/ALsdF)  - v2.0 : [Codepen: http://codepen.io/m-e-conroy/pen/AmBpL](http://codepen.io/m-e-conroy/pen/AmBpL)  - v4.2 : [Codepen: http://codepen.io/m-e-conroy/pen/rkIqv](http://codepen.io/m-e-conroy/pen/rkIqv)  - v4.2 : [Codepen: with UI-Bootstrap Date Picker directive](http://codepen.io/m-e-conroy/pen/DAxzs)
Release Versions ---------------- - v1.0 : supports AngularJS 1.1.5 and below. - v2.0 : supports AngularJS 1.2 + - v3.0 : supports AngularJS 1.2 +, Angular UI Bootstrap 0.10.0 - v4.0.0 - v4.1.0 : supports AngularJS 1.2 +, Angular UI Bootstrap 0.10.0, Bootstrap 3 + - v4.2.0 - v5.x.x+ : supports AngularJS 1.2 +, Angular UI Bootstrap 0.11.0, Bootstrap 3.1 +
v5.1.0 ------ 1. Fixed Wait dialog template, header should now display a passed parameter header to the wait service.  Prior to this it would always display the default header whether or not a passed header parameter was used or not. 2. Default translations have been removed from the dialogs.main module to their own module, in order to support applications that were already using Angular-Translate and had already defined translation lists for 'en-US.'  Previously including dialogs.main would have overwritten those translation lists supplied elsewhere in an application.  To use the default translations: 	- Include the dialogs-default-translations.min.js file in your HTML file and add 'dialogs.default-translations' to your application's dependency list along with 'dialogs.main' 	- OR If you already had a translation list setup elsewhere in your application just copy the $translationProvider translation list in the dialogs-default-translations module to where-ever it is that you have your list configured
v5.0.0 ------ Re-introduction of the [opts] parameter to dialogs methods.  I had many complaints about removing method level options in favor of wholly using the provider instead.
1. dialogs.error(header,msg[,opts]) 2. dialogs.wait(header,msg,progress[,opts]) 3. dialogs.notify(header,msg[,opts]) 4. dialogs.confirm(header,msg[,opts]) 5. dialogs.create(url,ctrlr,data[,opts])
v4.2.0 ------ Bootstrap 3.1.1 / Angular UI Bootstrap 0.11.0 introduced a size property for dialogs.  This can be controlled via the provider or by the optional *sz* parameter to the dialog methods.
1. dialogs.error(header,msg[,sz]) 2. dialogs.wait(header,msg,progress[,sz]) 3. dialogs.notify(header,msg[,sz]) 4. dialogs.confirm(header,msg[,sz]) 5. dialogs.create(url,ctrlr,data[,sz])
v4.0.0 - 4.1.0 -------------- Removed *opts* and *static* parameters from dialog methods in favor of provider settings.  The dialogs service is now longer **$dialogs**, the *\$* has be removed as this is reserved for Angular core services.
1. dialogs.error(header,msg) 2. dialogs.wait(header,msg,progress) 3. dialogs.notify(header,msg) 4. dialogs.confirm(header,msg) 5. dialogs.create(url,ctrlr,data)
v1.0 - v3.1.0 ------------- Predefined dialogs/modals.
1. $dialogs.error(header,msg,[static]) 2. $dialogs.wait(header,msg,progess,[static]) 3. $dialogs.notify(header,msg,[static]) 4. $dialogs.confirm(header,msg,[static]) 5. $dialogs.create(url,ctrlr,data,opts)
Dependencies ------------
v1.0 ----
1.  [Angular JS](http://www.angularjs.org) (version 1.1.5 and less)  2.  [Angular UI Bootstrap](http://angular-ui.github.io/bootstrap/#/modal) (version <= 0.6.0, Non-Bootstrap 3 Branch) with embedded templates. 3.  [Twitter Bootstrap CSS](http://getbootstrap.com) (version 2)
v2.0 Additional Dependencies ---------------------------- 1.  All version 1.0 dependencies. 2.  [Angular JS ngSanitize](http://code.angularjs.org/1.2.1/angular-sanitize.min.js) 	- [ngSanitize](http://docs.angularjs.org/api/ngSanitize) (needed for ng-bind-html)
v3.0 ----
1.  AngularJS 1.2 + 2.  Angular UI Bootstrap 0.10.0 3.  Twitter Bootstrap CSS 3.0.3 4.  AngularJS ngSanitize
v4.0.0 - v4.1.0 ---------------
1. AngularJS 1.2 + 2. [Angular UI Bootstrap Modal 0.10.0, with templates](http://angular-ui.github.io/bootstrap/#/modal) 3. Twitter Bootstrap CSS 3 + (includes 3.1.1) 4. Angular ngSanitize 5. [Angular Translate](https://github.com/angular-translate)
v4.2.0 & v5.x.x --------------- Same as v4.0.0 with the exception of the following:
1. [Angular UI Bootstrap Modal 0.11.0, with templates](http://angular-ui.github.io/bootstrap/#/modal) 2. [Twitter Bootstrap CSS 3.1.x](http://getbootstrap.com)
CSS --- Included a css file that has a .modal class fix for Bootstrap and also has some predefined styles for the various modals described in the service.
**v3.0 css file has the .modal class removed that had been a fix for a Bootstrap 3 display problem.  This has since been rectified by Angular UI and Bootstrap.**
Changes -------
- v3.0
1.  Added support for Angular UI Bootstrap 0.10.0. 2.  Added the ability to customize the header on the error and wait dialogs. 3.  Added example files.
- v4.0.0 - v4.1.0
1.  Removed *\$* from the *\$dialogs* service as this is reserved for core AngularJS naming.  The service is now just *dialogs.*  Include **dialogs.main** in your application module in order to use the the *dialogs* service 2.  Changed *dialogs* service from factory to provider, you can now use **dialogsProvider** to set various options of the modals that were previously passed as parameters to the dialogs' service methods. 	- **dialogsProvider.useBackdrop([true,false,'static'])** - True or false to use a backdrop for the modal, 'static' to use a backdrop and disallow closing on mouse click of the backdrop. 	- **dialogsProvider.useEscClose([true,false])** - Whether or not to allow the use of the 'ESC' key to close the modal 	- **dialogsProvider.useClass([string])** - Sets an additional CSS class to the modal window 	- **dialogsProvider.useCopy([true,false])** - Determines whether to use angular.copy or not when passing a data object to the custom dialog service.  Setting this to false will allow the modal to retain the two-way binding with the calling controller - thus changing data in the modal will automatically change it in the calling controller's scope.  The default is setting is true, so if you want the two-way binding you need to set this to false.  3.  Main module is no longer *dialogs* as this would conflict with the new naming of the service.  It is now *dialogs.main,* include that in your application's module definition to use the *dialogs* service. 4.  Added i18n support via [Angular-Translate](https://github.com/angular-translate), use the *$translateProvider* to set language specific defaults.  Default language is currently *en-US.*  An example is provided in the example folder that will show you how to change the defaults from English to Spanish.  Translations can be set on the following: 	- DIALOGS_ERROR (modal header) 	- DIALOGS_ERROR_MSG 	- DIALOGS_CLOSE (modal button) 	- DIALOGS_PLEASE_WAIT (modal header) 	- DIALOGS_PLEASE_WAIT_ELIPS (modal header) 	- DIALOGS_PLEASE_WAIT_MSG 	- DIALOGS_PERCENT_COMPLETE (modal message partial) 	- DIALOGS_NOTIFICATION (modal header) 	- DIALOGS_NOTIFICATION_MSG 	- DIALOGS_CONFIRMATION (modal header) 	- DIALOGS_CONFIRMATION_MSG 	- DIALOGS_OK (modal button) 	- DIALOGS_YES (modal button) 	- DIALOGS_NO (modal button)
- v4.2.0
1. Supports everything described above in v4.0.0 - v4.1.0 and added the following
2. dialogsProvider.setSize(['sm','lg']) - This will set modal size application wide, but can be overridden using the *sz* parameter added to each dialog method call.
- v5.0.0
1. Optionally pass in options object, possible overrides are as follows
```    opts = {         'keyboard': true or false         'backdrop': 'static' or true or false         'size': 'sm' or 'lg' //small or large modal size         'windowClass': 'dialogs-default' // additional CSS class(es) to be added to a modal window         'copy': true or false // used only with create custom dialog     }     ```
- v5.1.0
1. Separated out the default translations into their own module: **dialogs-default-translations.js**  Include this or the "min" version in your application if you are not already using $translationProvider elsewhere, otherwise just copy the translation list within the module to your translation list for 'en-US.'
Notes -----
- Angular Translate: v4.0 requires [Angular-Translate](https://github.com/angular-translate) be included. - Bootstrap 3: There's a problem with the actual modal being displayed even though it appears in the HTML code to be present.  I found that adding a "display: block" to Bootstrap 3's .modal class solved the problem. *(v3.0 of this service no longer requires this fix)* - It should not rely on including the Bootstrap JS. - For version 2.0 + of this service module do not forget to include the *ngSanitize* Angular module.
> Written with [StackEdit](https://stackedit.io/).
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngMock). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-mocks ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/guide/dev_guide.unit-testing).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngResource). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-resource ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular-resource/angular-resource.js"></script> ```
And add `ngResource` as a dependency for your app:
```javascript angular.module('myApp', ['ngResource']); ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/api/ngResource).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngSanitize). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-sanitize ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular-sanitize/angular-sanitize.js"></script> ```
And add `ngSanitize` as a dependency for your app:
```javascript angular.module('myApp', ['ngSanitize']); ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/api/ngSanitize).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- **accordion:**    - support `is-disabled` state ([9c43ae7c](http://github.com/angular-ui/bootstrap/commit/9c43ae7c))   - **alert:**    - add WAI-ARIA markup ([9a2638bf](http://github.com/angular-ui/bootstrap/commit/9a2638bf))   - **button:**    - allow uncheckable radio button ([82df4fb1](http://github.com/angular-ui/bootstrap/commit/82df4fb1))   - **carousel:**    - Support swipe for touchscreen devices ([85140f84](http://github.com/angular-ui/bootstrap/commit/85140f84))   - **dateParser:**    - add `dateParser` service ([bd2ae0ee](http://github.com/angular-ui/bootstrap/commit/bd2ae0ee))   - **datepicker:**    - add `datepicker-mode`, `init-date` & today hint ([7f4b40eb](http://github.com/angular-ui/bootstrap/commit/7f4b40eb))     - make widget accessible ([2423f6d4](http://github.com/angular-ui/bootstrap/commit/2423f6d4))     - full six-week calendar ([b0b14343](http://github.com/angular-ui/bootstrap/commit/b0b14343))   - **dropdown:**    - add WAI-ARIA attributes ([22ebd230](http://github.com/angular-ui/bootstrap/commit/22ebd230))     - focus toggle element when opening or closing with Esc` ([f715d052](http://github.com/angular-ui/bootstrap/commit/f715d052))   - **dropdownToggle:**    - support programmatic trigger & toggle callback ([ae31079c](http://github.com/angular-ui/bootstrap/commit/ae31079c))     - add support for `escape` key ([1417c548](http://github.com/angular-ui/bootstrap/commit/1417c548))   - **modal:**    - support custom template for modal window ([96def3d6](http://github.com/angular-ui/bootstrap/commit/96def3d6))     - support modal window sizes ([976f6083](http://github.com/angular-ui/bootstrap/commit/976f6083))     - improve accessibility - add role='dialog' ([60cee9dc](http://github.com/angular-ui/bootstrap/commit/60cee9dc))   - **pagination:**    - plug into `ngModel` controller ([d65901cf](http://github.com/angular-ui/bootstrap/commit/d65901cf))   - **progressbar:**    - make widget accessible ([9dfe3157](http://github.com/angular-ui/bootstrap/commit/9dfe3157))   - **rating:**    - plug into `ngModel` controller ([47e227f6](http://github.com/angular-ui/bootstrap/commit/47e227f6))     - make widget accessible ([4f56e60e](http://github.com/angular-ui/bootstrap/commit/4f56e60e))   - **tooltip:**    - support more positioning options ([3704db9a](http://github.com/angular-ui/bootstrap/commit/3704db9a))   - **typeahead:**    - add WAI-ARIA markup ([5ca23e97](http://github.com/angular-ui/bootstrap/commit/5ca23e97))     - add `aria-owns` & `aria-activedescendant` roles ([4c76a858](http://github.com/angular-ui/bootstrap/commit/4c76a858))
- **alert:**    - use interpolation for type attribute ([f0a129ad](http://github.com/angular-ui/bootstrap/commit/f0a129ad))     - add `alert-dismissable` class ([794954af](http://github.com/angular-ui/bootstrap/commit/794954af))   - **carousel:**    - correct glyphicon ([3b6ab25b](http://github.com/angular-ui/bootstrap/commit/3b6ab25b))   - **datepicker:**    - remove unneeded date creation ([68cb2e5a](http://github.com/angular-ui/bootstrap/commit/68cb2e5a))     - `Today` button should not set time ([e1993491](http://github.com/angular-ui/bootstrap/commit/e1993491))     - mark input field as invalid if the date is invalid ([467dd159](http://github.com/angular-ui/bootstrap/commit/467dd159))     - rename `dateFormat` to `datepickerPopup` in datepickerPopupConfig ([93da30d5](http://github.com/angular-ui/bootstrap/commit/93da30d5))     - parse input using dateParser ([e0eb1bce](http://github.com/angular-ui/bootstrap/commit/e0eb1bce))   - **dropdown:**   - use $animate for adding and removing classes ([e8d5fefc](http://github.com/angular-ui/bootstrap/commit/e8d5fefc))     - unbind toggle element event on scope destroy ([890e2d37](http://github.com/angular-ui/bootstrap/commit/890e2d37))     - do not call `on-toggle` initially ([004dd1de](http://github.com/angular-ui/bootstrap/commit/004dd1de))     - ensure `on-toggle` works when `is-open` is not used ([06ad3bd5](http://github.com/angular-ui/bootstrap/commit/06ad3bd5))   - **modal:**   - destroy modal scope after animation end ([dfc36fd9](http://github.com/angular-ui/bootstrap/commit/dfc36fd9))     - backdrop z-index when stacking modals ([94a7f593](http://github.com/angular-ui/bootstrap/commit/94a7f593))     - give a reason of rejection when escape key pressed ([cb31b875](http://github.com/angular-ui/bootstrap/commit/cb31b875))     - prevent default event when closing via escape key ([da951222](http://github.com/angular-ui/bootstrap/commit/da951222))   - toggle 'modal-open' class after animation ([4d641ca7](http://github.com/angular-ui/bootstrap/commit/4d641ca7)) - **pagination:**    - take maxSize defaults into account ([a294c87f](http://github.com/angular-ui/bootstrap/commit/a294c87f))   - **position:**    - remove deprecated body scrollTop and scrollLeft ([1ba07c1b](http://github.com/angular-ui/bootstrap/commit/1ba07c1b))   - **progressbar:**    - allow fractional values for bar width ([0daa7a74](http://github.com/angular-ui/bootstrap/commit/0daa7a74))     - number filter in bar template and only for percent ([378a9337](http://github.com/angular-ui/bootstrap/commit/378a9337))   - **tabs:**    - fire deselect before select callback ([7474c47b](http://github.com/angular-ui/bootstrap/commit/7474c47b))     - use interpolation for type attribute ([83ceb78a](http://github.com/angular-ui/bootstrap/commit/83ceb78a))     - remove `tabbable` class required for left/right tabs ([19468331](http://github.com/angular-ui/bootstrap/commit/19468331))   - **timepicker:**    - evaluate correctly the `readonly-input` attribute ([f9b6c496](http://github.com/angular-ui/bootstrap/commit/f9b6c496))   - **tooltip:**    - animation causes tooltip to hide on show ([2b429f5d](http://github.com/angular-ui/bootstrap/commit/2b429f5d))   - **typeahead:**    - correctly handle append to body attribute ([10785736](http://github.com/angular-ui/bootstrap/commit/10785736))     - correctly higlight numeric matches ([09678b12](http://github.com/angular-ui/bootstrap/commit/09678b12))     - loading callback updates after blur ([6a830116](http://github.com/angular-ui/bootstrap/commit/6a830116))     - incompatibility with ng-focus ([d0024931](http://github.com/angular-ui/bootstrap/commit/d0024931))
- **alert:**   Use interpolation for type attribute.
Before:
```html   <alert type="'info'" ...></alert >   ```   or   ```html   <alert type="alert.type" ...></alert >   ```
After:
```html   <alert type="info" ...></alert >   ```   or   ```html   <alert type="{{alert.type}}" ...></alert >   ```
- **datepicker:**
`show-weeks` is no longer a watched attribute `*-format` attributes have been renamed to `format-*` `min` attribute has been renamed to `min-date` `max` attribute has been renamed to `max-date`
- **pagination:**
Both `pagination` and `pager` are now integrated with `ngModelController`.  * `page` is replaced from `ng-model`.  * `on-select-page` is removed since `ng-change` can now be used.
Before:
<pagination page="current" on-select-page="changed(page)" ...></pagination>
After:
<pagination ng-model="current" ng-change="changed()" ...></pagination>
- **rating:**   `rating` is now integrated with `ngModelController`.  * `value` is replaced from `ng-model`.
Before:
<rating value="rate" ...></rating>
After:
<rating ng-model="rate" ...></rating>
- **tabs:**
Use interpolation for type attribute.
Before:
<tabset type="'pills'" ...></tabset >   or   <tabset type="navtype" ...></tabset>
After:
<tabset type="pills" ...></tabset>   or   <tabset type="{{navtype}}" ...></tabset>   # 0.10.0 (2014-01-13)
_This release adds AngularJS 1.2 support_
- **modal:**    - expose dismissAll on $modalStack ([bc8d21c1](http://github.com/angular-ui/bootstrap/commit/bc8d21c1))
- **datepicker:**    - evaluate `show-weeks` from `datepicker-options` ([92c1715f](http://github.com/angular-ui/bootstrap/commit/92c1715f))   - **modal:**    - leaking watchers due to scope re-use ([0754ad7b](http://github.com/angular-ui/bootstrap/commit/0754ad7b))     - support close animation ([1933488c](http://github.com/angular-ui/bootstrap/commit/1933488c))   - **timepicker:**    - add correct type for meridian button ([bcf39efe](http://github.com/angular-ui/bootstrap/commit/bcf39efe))   - **tooltip:**    - performance and scope fixes ([c0df3201](http://github.com/angular-ui/bootstrap/commit/c0df3201))
_This release adds Bootstrap3 support_
- **accordion:**    - convert to bootstrap3 panel styling ([458a9bd3](http://github.com/angular-ui/bootstrap/commit/458a9bd3))   - **carousel:**    - some changes for Bootstrap3 ([1f632b65](http://github.com/angular-ui/bootstrap/commit/1f632b65))   - **collapse:**    - make collapse work with bootstrap3 ([517dff6e](http://github.com/angular-ui/bootstrap/commit/517dff6e))   - **datepicker:**    - update to Bootstrap 3 ([37684330](http://github.com/angular-ui/bootstrap/commit/37684330))   - **modal:**    - added bootstrap3 support ([444c488d](http://github.com/angular-ui/bootstrap/commit/444c488d))   - **pagination:**    - support bootstrap3 ([3db699d7](http://github.com/angular-ui/bootstrap/commit/3db699d7))   - **progressbar:**    - update to bootstrap3 ([5bcff623](http://github.com/angular-ui/bootstrap/commit/5bcff623))   - **rating:**    - update rating to bootstrap3 ([7e60284e](http://github.com/angular-ui/bootstrap/commit/7e60284e))   - **tabs:**    - add nav-justified ([3199dd88](http://github.com/angular-ui/bootstrap/commit/3199dd88))   - **timepicker:**    - restyled for bootstrap 3 ([6724a721](http://github.com/angular-ui/bootstrap/commit/6724a721))   - **typeahead:**    - update to Bootstrap 3 ([eadf934a](http://github.com/angular-ui/bootstrap/commit/eadf934a))
- **alert:**    - update template to Bootstrap 3 ([dfc3b0bd](http://github.com/angular-ui/bootstrap/commit/dfc3b0bd))   - **collapse:**    - Prevent consecutive transitions & tidy up code ([b0032d68](http://github.com/angular-ui/bootstrap/commit/b0032d68))     - fixes after rebase ([dc02ad1d](http://github.com/angular-ui/bootstrap/commit/dc02ad1d))   - **rating:**    - user glyhicon classes ([d221d517](http://github.com/angular-ui/bootstrap/commit/d221d517))   - **timepicker:**    - fix look with bootstrap3 ([9613b61b](http://github.com/angular-ui/bootstrap/commit/9613b61b))   - **tooltip:**    - re-position tooltip after draw ([a99b3608](http://github.com/angular-ui/bootstrap/commit/a99b3608))
- **datepicker:**    - option whether to display button bar in popup ([4d158e0d](http://github.com/angular-ui/bootstrap/commit/4d158e0d))   - **modal:**    - add modal-open class to body on modal open ([e76512fa](http://github.com/angular-ui/bootstrap/commit/e76512fa))   - **progressbar:**    - add `max` attribute & support transclusion ([365573ab](http://github.com/angular-ui/bootstrap/commit/365573ab))   - **timepicker:**    - default meridian labels based on locale ([8b1ab79a](http://github.com/angular-ui/bootstrap/commit/8b1ab79a))   - **typeahead:**    - add typeahead-append-to-body option ([dd8eac22](http://github.com/angular-ui/bootstrap/commit/dd8eac22))
- **accordion:**    - correct `is-open` handling for dynamic groups ([9ec21286](http://github.com/angular-ui/bootstrap/commit/9ec21286))   - **carousel:**    - cancel timer on scope destruction ([5b9d929c](http://github.com/angular-ui/bootstrap/commit/5b9d929c))     - cancel goNext on scope destruction ([7515df45](http://github.com/angular-ui/bootstrap/commit/7515df45))   - **collapse:**    - dont animate height changes from 0 to 0 ([81e014a8](http://github.com/angular-ui/bootstrap/commit/81e014a8))   - **datepicker:**    - set default zero time after no date selected ([93cd0df8](http://github.com/angular-ui/bootstrap/commit/93cd0df8))     - fire `ngChange` on today/clear button press ([6b1c68fb](http://github.com/angular-ui/bootstrap/commit/6b1c68fb))     - remove datepicker's popup on scope destroy ([48955d69](http://github.com/angular-ui/bootstrap/commit/48955d69))     - remove edge case position updates ([1fbcb5d6](http://github.com/angular-ui/bootstrap/commit/1fbcb5d6))   - **modal:**    - put backdrop in before window ([d64f4a97](http://github.com/angular-ui/bootstrap/commit/d64f4a97))     - grab reference to body when it is needed in lieu of when the factory is created ([dd415a98](http://github.com/angular-ui/bootstrap/commit/dd415a98))   - focus freshly opened modal ([709e679c](http://github.com/angular-ui/bootstrap/commit/709e679c))     - properly animate backdrops on each modal opening ([672a557a](http://github.com/angular-ui/bootstrap/commit/672a557a))   - **tabs:**    - make nested tabs work ([c9acebbe](http://github.com/angular-ui/bootstrap/commit/c9acebbe))   - **tooltip:**    - update tooltip content when empty ([60515ae1](http://github.com/angular-ui/bootstrap/commit/60515ae1))     - support IE8 ([5dd98238](http://github.com/angular-ui/bootstrap/commit/5dd98238))     - unbind element events on scope destroy ([3fe7aa8c](http://github.com/angular-ui/bootstrap/commit/3fe7aa8c))     - respect animate attribute ([54e614a8](http://github.com/angular-ui/bootstrap/commit/54e614a8))
- **progressbar:**   The onFull/onEmpty handlers & auto/stacked types have been removed.
To migrate your code change your markup like below.
Before:
```html   <progress percent="var" class="progress-warning"></progress> ```
After:
```html   <progressbar value="var" type="warning"></progressbar> ```
and for stacked instead of passing array/objects you can do:
```html   <progress><bar ng-repeat="obj in objs" value="obj.var" type="{{obj.type}}"></bar></progress> ```
- **datepicker:**    - add i18n support for bar buttons in popup ([c6ba8d7f](http://github.com/angular-ui/bootstrap/commit/c6ba8d7f))     - dynamic date format for popup ([aa3eaa91](http://github.com/angular-ui/bootstrap/commit/aa3eaa91))     - datepicker-append-to-body attribute ([0cdc4609](http://github.com/angular-ui/bootstrap/commit/0cdc4609))   - **dropdownToggle:**    - disable dropdown when it has the disabled class ([104bdd1b](http://github.com/angular-ui/bootstrap/commit/104bdd1b))   - **tooltip:**    - add ability to enable / disable tooltip ([5d9bd058](http://github.com/angular-ui/bootstrap/commit/5d9bd058))
- **accordion:**    - assign `is-open` to correct scope ([157f614a](http://github.com/angular-ui/bootstrap/commit/157f614a))   - **collapse:**    - remove element height watching ([a72c635c](http://github.com/angular-ui/bootstrap/commit/a72c635c))     - add the "in" class for expanded panels ([9eca35a8](http://github.com/angular-ui/bootstrap/commit/9eca35a8))   - **datepicker:**   - some IE8 compatibility improvements ([4540476f](http://github.com/angular-ui/bootstrap/commit/4540476f))     - set popup initial position in append-to-body case ([78a1e9d7](http://github.com/angular-ui/bootstrap/commit/78a1e9d7))   - properly handle showWeeks config option ([570dba90](http://github.com/angular-ui/bootstrap/commit/570dba90))   - **modal:**    - correctly close modals with no backdrop ([e55c2de3](http://github.com/angular-ui/bootstrap/commit/e55c2de3))   - **pagination:**    - fix altering of current page caused by totals change ([81164dae](http://github.com/angular-ui/bootstrap/commit/81164dae))     - handle extreme values for `total-items` ([8ecf93ed](http://github.com/angular-ui/bootstrap/commit/8ecf93ed))   - **position:**    - correct positioning for SVG elements ([968e5407](http://github.com/angular-ui/bootstrap/commit/968e5407))   - **tabs:**    - initial tab selection ([a08173ec](http://github.com/angular-ui/bootstrap/commit/a08173ec))   - **timepicker:**    - use html5 for input elements ([53709f0f](http://github.com/angular-ui/bootstrap/commit/53709f0f))   - **tooltip:**    - restore html-unsafe compatibility with AngularJS 1.2 ([08d8b21d](http://github.com/angular-ui/bootstrap/commit/08d8b21d))     - hide tooltips when content becomes empty ([cf5c27ae](http://github.com/angular-ui/bootstrap/commit/cf5c27ae))     - tackle DOM node and event handlers leak ([0d810acd](http://github.com/angular-ui/bootstrap/commit/0d810acd))   - **typeahead:**    - do not set editable error when input is empty ([006986db](http://github.com/angular-ui/bootstrap/commit/006986db))     - remove popup flickering ([dde804b6](http://github.com/angular-ui/bootstrap/commit/dde804b6))     - don't show matches if an element is not focused ([d1f94530](http://github.com/angular-ui/bootstrap/commit/d1f94530))     - fix loading callback when deleting characters ([0149eff6](http://github.com/angular-ui/bootstrap/commit/0149eff6))     - prevent accidental form submission on ENTER ([253c49ff](http://github.com/angular-ui/bootstrap/commit/253c49ff))     - evaluate matches source against a correct scope ([fd21214d](http://github.com/angular-ui/bootstrap/commit/fd21214d))     - support IE8 ([0e9f9980](http://github.com/angular-ui/bootstrap/commit/0e9f9980))
- **modal:**    - rewrite $dialog as $modal ([d7a48523](http://github.com/angular-ui/bootstrap/commit/d7a48523))     - add support for custom window settings ([015625d1](http://github.com/angular-ui/bootstrap/commit/015625d1))     - expose $close and $dismiss options on modal's scope ([8d153acb](http://github.com/angular-ui/bootstrap/commit/8d153acb))   - **pagination:**    - `total-items` & optional `items-per-page` API ([e55d9063](http://github.com/angular-ui/bootstrap/commit/e55d9063))   - **rating:**    - add support for custom icons per instance ([20ab01ad](http://github.com/angular-ui/bootstrap/commit/20ab01ad))   - **timepicker:**    - plug into `ngModel` controller ([b08e993f](http://github.com/angular-ui/bootstrap/commit/b08e993f))
- **carousel:**    - correct reflow triggering on FFox and Safari ([d34f2de1](http://github.com/angular-ui/bootstrap/commit/d34f2de1))   - **datepicker:**    - correctly manage focus without jQuery present ([d474824b](http://github.com/angular-ui/bootstrap/commit/d474824b))     - compatibility with angular 1.1.5 and no jquery ([bf30898d](http://github.com/angular-ui/bootstrap/commit/bf30898d))     - use $setViewValue for inner changes ([dd99f35d](http://github.com/angular-ui/bootstrap/commit/dd99f35d)) - **modal:**   - insert backdrop before modal window ([d870f212](http://github.com/angular-ui/bootstrap/commit/d870f212))   - ie8 fix after $modal rewrite ([ff9d969e](http://github.com/angular-ui/bootstrap/commit/ff9d969e))   - opening a modal should not change default options ([82532d1b](http://github.com/angular-ui/bootstrap/commit/82532d1b))   - backdrop should cover previously opened modals ([7fce2fe8](http://github.com/angular-ui/bootstrap/commit/7fce2fe8))   - allow replacing object with default options ([8e7fbf06](http://github.com/angular-ui/bootstrap/commit/8e7fbf06)) - **position:**   - fallback for IE8's scrollTop/Left for offset ([9aecd4ed](http://github.com/angular-ui/bootstrap/commit/9aecd4ed))   - **tabs:**    - add DI array-style annotations ([aac4a0dd](http://github.com/angular-ui/bootstrap/commit/aac4a0dd))     - evaluate `vertical` on parent scope ([9af6f96e](http://github.com/angular-ui/bootstrap/commit/9af6f96e))   - **timepicker:**    - add type attribute for meridian button ([1f89fd4b](http://github.com/angular-ui/bootstrap/commit/1f89fd4b))   - **tooltip:**    - remove placement='mouse' option ([17163c22](http://github.com/angular-ui/bootstrap/commit/17163c22))   - **typeahead:**    - fix label rendering for equal model and items names ([5de71216](http://github.com/angular-ui/bootstrap/commit/5de71216))     - set validity flag for non-editable inputs ([366e0c8a](http://github.com/angular-ui/bootstrap/commit/366e0c8a))     - plug in front of existing parsers ([80cef614](http://github.com/angular-ui/bootstrap/commit/80cef614))     - highlight return match if no query ([45dd9be1](http://github.com/angular-ui/bootstrap/commit/45dd9be1))     - keep pop-up on clicking input ([5f9e270d](http://github.com/angular-ui/bootstrap/commit/5f9e270d))     - remove dependency on ng-bind-html-unsafe ([75893393](http://github.com/angular-ui/bootstrap/commit/75893393))
- **modal:**
* `$dialog` service was refactored into `$modal` * `modal` directive was removed - use the `$modal` service instead
Check the documentation for the `$modal` service to migrate from `$dialog`
- **pagination:**   API has undergone some changes in order to be easier to use.  * `current-page` is replaced from `page`.  * Number of pages is not defined by `num-pages`, but from `total-items` &   `items-per-page` instead. If `items-per-page` is missing, default is 10.  * `num-pages` still exists but is just readonly.
Before:
```html   <pagination num-pages="10" ...></pagination> ```
After:
```html   <pagination total-items="100" ...></pagination> ```
- **tooltip:**
The placment='mouse' is gone with no equivalent   # 0.5.0 (2013-08-04)
- **buttons:**    - support dynamic true / false values in btn-checkbox ([3e30cd94](http://github.com/angular-ui/bootstrap/commit/3e30cd94))   - **datepicker:**    - `ngModelController` plug & new `datepickerPopup` ([dab18336](http://github.com/angular-ui/bootstrap/commit/dab18336))   - **rating:**    - added onHover and onLeave. ([5b1115e3](http://github.com/angular-ui/bootstrap/commit/5b1115e3))   - **tabs:**    - added onDeselect callback, used similarly as onSelect ([fe47c9bb](http://github.com/angular-ui/bootstrap/commit/fe47c9bb))     - add the ability to set the direction of the tabs ([220e7b60](http://github.com/angular-ui/bootstrap/commit/220e7b60))   - **typeahead:**    - support custom templates for matched items ([e2238174](http://github.com/angular-ui/bootstrap/commit/e2238174))     - expose index to custom templates ([5ffae83d](http://github.com/angular-ui/bootstrap/commit/5ffae83d))
- **datepicker:**    - handle correctly `min`/`max` when cleared ([566bdd16](http://github.com/angular-ui/bootstrap/commit/566bdd16))     - add type attribute for buttons ([25caf5fb](http://github.com/angular-ui/bootstrap/commit/25caf5fb))   - **pagination:**    - handle `currentPage` number as string ([b1fa7bb8](http://github.com/angular-ui/bootstrap/commit/b1fa7bb8))     - use interpolation for text attributes ([f45815cb](http://github.com/angular-ui/bootstrap/commit/f45815cb))   - **popover:**    - don't unbind event handlers created by other directives ([56f624a2](http://github.com/angular-ui/bootstrap/commit/56f624a2))     - correctly position popovers appended to body ([93a82af0](http://github.com/angular-ui/bootstrap/commit/93a82af0))   - **rating:**    - evaluate `max` attribute on parent scope ([60619d51](http://github.com/angular-ui/bootstrap/commit/60619d51))   - **tabs:**    - make tab contents be correctly connected to parent (#524) ([be7ecff0](http://github.com/angular-ui/bootstrap/commit/be7ecff0))     - Make tabset template correctly use tabset attributes (#584) ([8868f236](http://github.com/angular-ui/bootstrap/commit/8868f236))     - fix tab content compiling wrong (Closes #599, #631, #574) ([224bc2f5](http://github.com/angular-ui/bootstrap/commit/224bc2f5))     - make tabs added with active=true be selected ([360cd5ca](http://github.com/angular-ui/bootstrap/commit/360cd5ca))     - if tab is active at start, always select it ([ba1f741d](http://github.com/angular-ui/bootstrap/commit/ba1f741d))   - **timepicker:**    - prevent date change ([ee741707](http://github.com/angular-ui/bootstrap/commit/ee741707))     - added wheel event to enable mousewheel on Firefox ([8dc92afa](http://github.com/angular-ui/bootstrap/commit/8dc92afa))   - **tooltip:**    - fix positioning inside scrolling element ([63ae7e12](http://github.com/angular-ui/bootstrap/commit/63ae7e12))     - triggers should be local to tooltip instances ([58e8ef4f](http://github.com/angular-ui/bootstrap/commit/58e8ef4f))     - correctly handle initial events unbinding ([4fd5bf43](http://github.com/angular-ui/bootstrap/commit/4fd5bf43))     - bind correct 'hide' event handler ([d50b0547](http://github.com/angular-ui/bootstrap/commit/d50b0547))   - **typeahead:**    - play nicelly with existing formatters ([d2df0b35](http://github.com/angular-ui/bootstrap/commit/d2df0b35))     - properly render initial input value ([c4e169cb](http://github.com/angular-ui/bootstrap/commit/c4e169cb))     - separate text field rendering and drop down rendering ([ea1e858a](http://github.com/angular-ui/bootstrap/commit/ea1e858a))     - fixed waitTime functionality ([90a8aa79](http://github.com/angular-ui/bootstrap/commit/90a8aa79))     - correctly close popup on match selection ([624fd5f5](http://github.com/angular-ui/bootstrap/commit/624fd5f5))
- **pagination:**   The 'first-text', 'previous-text', 'next-text' and 'last-text'   attributes are now interpolated.
To migrate your code, remove quotes for constant attributes and/or   interpolate scope variables.
Before:
```html   <pagination first-text="'<<'" ...></pagination> ```   and/or
```html   $scope.var1 = '<<';   <pagination first-text="var1" ...></pagination> ```   After:
```html   <pagination first-text="<<" ...></pagination> ```   and/or
```html   $scope.var1 = '<<';   <pagination first-text="{{var1}}" ...></pagination> ```
- **buttons:**    - support dynamic values in btn-radio ([e8c5b548](http://github.com/angular-ui/bootstrap/commit/e8c5b548))   - **carousel:**    - add option to prevent pause ([5f895c13](http://github.com/angular-ui/bootstrap/commit/5f895c13))   - **datepicker:**    - add datepicker directive ([30a00a07](http://github.com/angular-ui/bootstrap/commit/30a00a07))   - **pagination:**    - option for different mode when maxSize ([a023d082](http://github.com/angular-ui/bootstrap/commit/a023d082))     - add pager directive ([d9526475](http://github.com/angular-ui/bootstrap/commit/d9526475))   - **tabs:**    - Change directive name, add features ([c5326595](http://github.com/angular-ui/bootstrap/commit/c5326595))     - support disabled state ([2b78dd16](http://github.com/angular-ui/bootstrap/commit/2b78dd16))     - add support for vertical option ([88d17a75](http://github.com/angular-ui/bootstrap/commit/88d17a75))     - add support for other navigation types, like 'pills' ([53e0a39f](http://github.com/angular-ui/bootstrap/commit/53e0a39f))   - **timepicker:**    - add timepicker directive ([9bc5207b](http://github.com/angular-ui/bootstrap/commit/9bc5207b))   - **tooltip:**    - add mouse placement option ([ace7bc60](http://github.com/angular-ui/bootstrap/commit/ace7bc60))   - add *-append-to-body attribute ([d0896263](http://github.com/angular-ui/bootstrap/commit/d0896263))     - add custom trigger support ([dfa53155](http://github.com/angular-ui/bootstrap/commit/dfa53155))   - **typeahead:**    - support typeahead-on-select callback ([91ac17c9](http://github.com/angular-ui/bootstrap/commit/91ac17c9))     - support wait-ms option ([7f35a3f2](http://github.com/angular-ui/bootstrap/commit/7f35a3f2))
- **accordion:**    - allow accordion heading directives as attributes. ([25f6e55c](http://github.com/angular-ui/bootstrap/commit/25f6e55c)) - **carousel:**    - do not allow user to change slide if transitioning ([1d19663f](http://github.com/angular-ui/bootstrap/commit/1d19663f))     - make slide 'active' binding optional ([17d6c3b5](http://github.com/angular-ui/bootstrap/commit/17d6c3b5))     - fix error with deleting multiple slides at once ([3fcb70f0](http://github.com/angular-ui/bootstrap/commit/3fcb70f0))   - **dialog:**    - remove dialogOpenClass to get in line with v2.3 ([f009b23f](http://github.com/angular-ui/bootstrap/commit/f009b23f))   - **pagination:**    - bind *-text attributes ([e1bff6b7](http://github.com/angular-ui/bootstrap/commit/e1bff6b7))   - **progressbar:**    - user `percent` attribute instead of `value`. ([58efec80](http://github.com/angular-ui/bootstrap/commit/58efec80))   - **tooltip:**    - fix positioning error when appendToBody is set to true ([76fee1f9](http://github.com/angular-ui/bootstrap/commit/76fee1f9))     - close tooltips appended to body on location change ([041261b5](http://github.com/angular-ui/bootstrap/commit/041261b5))     - tooltips will hide on scope.$destroy ([3e5a58e5](http://github.com/angular-ui/bootstrap/commit/3e5a58e5))     - support of custom $interpolate.startSymbol ([88c94ee6](http://github.com/angular-ui/bootstrap/commit/88c94ee6))     - make sure tooltip scope is evicted from cache ([9246905a](http://github.com/angular-ui/bootstrap/commit/9246905a))   - **typeahead:**    - return focus to the input after selecting a suggestion ([04a21e33](http://github.com/angular-ui/bootstrap/commit/04a21e33))
- **pagination:**   The 'first-text', 'previous-text', 'next-text' and 'last-text'   attributes are now binded to parent scope.
To migrate your code, surround the text of these attributes with quotes.
Before:            ```html     <pagination first-text="<<"></pagination>     ```
After:          ```html     <pagination first-text="'<<'"></pagination>     ```
- **progressbar:**   The 'value' is replaced by 'percent'.
Before:          ```html     <progress value="..."></progress>     ```
After:          ```html     <progress percent="..."></progress>     ```
- **tabs:**   The 'tabs' directive has been renamed to 'tabset', and  the 'pane' directive has been renamed to 'tab'.
To migrate your code, follow the example below.
Before:
```html     <tabs>       <pane heading="one">         First Content       </pane>       <pane ng-repeat="apple in basket" heading="{{apple.heading}}">         {{apple.content}}       </pane>     </tabs>     ```
After:
```html     <tabset>       <tab heading="one">         First Content       </tab>       <tab ng-repeat="apple in basket" heading="{{apple.heading}}">         {{apple.content}}       </tab>     </tabset>     ```
- **progressbar:**   - add progressbar directive ([261f2072](https://github.com/angular-ui/bootstrap/commit/261f2072)) - **rating:**   - add rating directive ([6b5e6369](https://github.com/angular-ui/bootstrap/commit/6b5e6369)) - **typeahead:**   - support the editable property ([a40c3fbe](https://github.com/angular-ui/bootstrap/commit/a40c3fbe))   - support typeahead-loading bindable expression ([b58c9c88](https://github.com/angular-ui/bootstrap/commit/b58c9c88)) - **tooltip:**   - added popup-delay option ([a79a2ba8](https://github.com/angular-ui/bootstrap/commit/a79a2ba8))   - added appendToBody to $tooltip ([1ee467f8](https://github.com/angular-ui/bootstrap/commit/1ee467f8))   - added tooltip-html-unsafe directive ([45ed2805](https://github.com/angular-ui/bootstrap/commit/45ed2805))   - support for custom triggers ([b1ba821b](https://github.com/angular-ui/bootstrap/commit/b1ba821b))
- **alert:**   - don't show close button if no close callback specified ([c2645f4a](https://github.com/angular-ui/bootstrap/commit/c2645f4a)) - **carousel:**   - Hide navigation indicators if only one slide ([aedc0565](https://github.com/angular-ui/bootstrap/commit/aedc0565)) - **collapse:**   - remove reference to msTransition for IE10 ([55437b16](https://github.com/angular-ui/bootstrap/commit/55437b16)) - **dialog:**   - set _open to false on init ([dcc9ef31](https://github.com/angular-ui/bootstrap/commit/dcc9ef31))   - close dialog on location change ([474ce52e](https://github.com/angular-ui/bootstrap/commit/474ce52e))   - IE8 fix to not set data() against text nodes ([a6c540e5](https://github.com/angular-ui/bootstrap/commit/a6c540e5))   - fix $apply in progres on $location change ([77e6acb9](https://github.com/angular-ui/bootstrap/commit/77e6acb9)) - **tabs:**   - remove superfluous href from tabs template ([38c1badd](https://github.com/angular-ui/bootstrap/commit/38c1badd)) - **tooltip:**   - fix positioning issues in tooltips and popovers ([6458f487](https://github.com/angular-ui/bootstrap/commit/6458f487)) - **typeahead:**   - close matches popup on click outside typeahead ([acca7dcd](https://github.com/angular-ui/bootstrap/commit/acca7dcd))   - stop keydown event propagation when ESC pressed to discard matches ([22a00cd0](https://github.com/angular-ui/bootstrap/commit/22a00cd0))   - correctly render initial model value ([929a46fa](https://github.com/angular-ui/bootstrap/commit/929a46fa))   - correctly higlight matches if query contains regexp-special chars ([467afcd6](https://github.com/angular-ui/bootstrap/commit/467afcd6))   - fix matches pop-up positioning issues ([74beecdb](https://github.com/angular-ui/bootstrap/commit/74beecdb))
- **dialog:**   - Make $dialog 'resolve' property to work the same way of $routeProvider.when ([739f86f](https://github.com/angular-ui/bootstrap/commit/739f86f)) - **modal:**   - allow global override of modal options ([acaf72b](https://github.com/angular-ui/bootstrap/commit/acaf72b)) - **buttons:**   - add checkbox and radio buttons ([571ccf4](https://github.com/angular-ui/bootstrap/commit/571ccf4)) - **carousel:**   - add slide indicators ([3b677ee](https://github.com/angular-ui/bootstrap/commit/3b677ee)) - **typeahead:**   - add typeahead directive ([6a97da2](https://github.com/angular-ui/bootstrap/commit/6a97da2)) - **accordion:**   - enable HTML in accordion headings ([3afcaa4](https://github.com/angular-ui/bootstrap/commit/3afcaa4)) - **pagination:**   - add first/last link & constant congif options ([0ff0454](https://github.com/angular-ui/bootstrap/commit/0ff0454))
- **dialog:**   - update resolve section to new syntax ([1f87486](https://github.com/angular-ui/bootstrap/commit/1f87486))   - $compile entire modal ([7575b3c](https://github.com/angular-ui/bootstrap/commit/7575b3c)) - **tooltip:**   - don't show tooltips if there is no content to show ([030901e](https://github.com/angular-ui/bootstrap/commit/030901e))   - fix placement issues ([a2bbf4d](https://github.com/angular-ui/bootstrap/commit/a2bbf4d)) - **collapse:**   - Avoids fixed height on collapse ([ff5d119](https://github.com/angular-ui/bootstrap/commit/ff5d119)) - **accordion:**   - fix minification issues ([f4da4d6](https://github.com/angular-ui/bootstrap/commit/f4da4d6)) - **typeahead:**   -  update inputs value on mapping where label is not derived from the model ([a5f64de](https://github.com/angular-ui/bootstrap/commit/a5f64de))
_Very first, initial release_.
Version `0.1.0` was released with the following directives:
* accordion * alert * carousel * dialog * dropdownToggle * modal * pagination * popover * tabs * tooltip
We are always looking for the quality contributions and will be happy to accept your Pull Requests as long as those adhere to some basic rules:
* Please make sure that your contribution fits well in the project's context:   * we are aiming at rebuilding bootstrap directives in pure AngularJS, without any dependencies on any external JavaScript library;   * the only dependency should be bootstrap CSS and its markup structure;   * directives should be html-agnostic as much as possible which in practice means:         * templates should be referred to using the `templateUrl` property         * it should be easy to change a default template to a custom one         * directives shouldn't manipulate DOM structure directly (when possible) * Please assure that you are submitting quality code, specifically make sure that:   * your directive has accompanying tests and all the tests are passing; don't hesitate to contact us (angular-ui@googlegroups.com) if you need any help with unit testing   * your PR doesn't break the build; check the Travis-CI build status after opening a PR and push corrective commits if anything goes wrong
***
[![Build Status](https://secure.travis-ci.org/angular-ui/bootstrap.png)](http://travis-ci.org/angular-ui/bootstrap) [![devDependency Status](https://david-dm.org/angular-ui/bootstrap/dev-status.png?branch=master)](https://david-dm.org/angular-ui/bootstrap#info=devDependencies) [![Bitdeli Badge](https://d2weczhvl823v0.cloudfront.net/angular-ui/bootstrap/trend.png)](https://bitdeli.com/free "Bitdeli Badge")
Do you want to see directives in action? Visit http://angular-ui.github.io/bootstrap/!
Installation is easy as angular-ui-bootstrap has minimal dependencies - only the AngularJS and Bootstrap's CSS are required. After downloading dependencies (or better yet, referencing them from your favourite CDN) you need to download build version of this project. All the files and their purposes are described here:  https://github.com/angular-ui/bootstrap/tree/gh-pages#build-files Don't worry, if you are not sure which file to take, opt for `ui-bootstrap-tpls-[version].min.js`.
When you are done downloading all the dependencies and project files the only remaining part is to add dependencies on the `ui.bootstrap` AngularJS module:
```javascript angular.module('myModule', ['ui.bootstrap']); ```
Project files are also available through your favourite package manager: * **Bower**: `bower install angular-bootstrap` * **NuGet**: https://nuget.org/packages/Angular.UI.Bootstrap/
Directives from this repository are automatically tested with the following browsers: * Chrome (stable and canary channel) * Firefox * IE 9 and 10 * Opera * Safari
Modern mobile browsers should work without problems.
**IE 8 is not officially supported at the moment**. This project is run by volunteers and with the current number of commiters we are not in the position to guarantee IE8 support. If you need support for IE8 we would welcome a contributor who would like to take care about IE8. Alternatively you could sponsor this project to guarantee IE8 support.
We believe that most of the directives would work OK after: * including relevant shims (for ES5 we recommend https://github.com/kriskowal/es5-shim) * taking care of the steps described in http://docs.angularjs.org/guide/ie
We are simply not regularly testing against IE8.
We are aiming at providing a set of AngularJS directives based on Bootstrap's markup and CSS. The goal is to provide **native AngularJS directives** without any dependency on jQuery or Bootstrap's JavaScript. It is often better to rewrite an existing JavaScript code and create a new, pure AngularJS directive. Most of the time the resulting directive is smaller as compared to the original JavaScript code size and better integrated into the AngularJS ecosystem.
All the directives in this repository should have their markup externalized as templates (loaded via `templateUrl`). In practice it means that you can **customize directive's markup at will**. One could even imagine providing a non-Bootstrap version of the templates!
Each directive has its own AngularJS module without any dependencies on other modules or third-party JavaScript code. In practice it means that you can **just grab the code for the directives you need** and you are not obliged to drag the whole repository.
Directives should work. All the time and in all browsers. This is why all the directives have a comprehensive suite of unit tests. All the automated tests are executed on each checkin in several browsers: Chrome, ChromeCanary, Firefox, Opera, Safari, IE9. In fact we are fortunate enough to **benefit from the same testing infrastructure as AngularJS**!
If you are having problems making some directives work, there are several ways to get help:
* Live help in the IRC (`#angularjs` channel at the `freenode` network). Use this [webchat](https://webchat.freenode.net/) or your own IRC client. * Ask a question in [stackoverflow](http://stackoverflow.com/) under the [angular-ui-bootstrap](http://stackoverflow.com/questions/tagged/angular-ui-bootstrap) tag. * Write your question in our [mailing list](https://groups.google.com/forum/#!categories/angular-ui/bootstrap).
Project's issue on GitHub should be used discuss bugs and features.
We are always looking for the quality contributions! Please check the [CONTRIBUTING.md](CONTRIBUTING.md) for the contribution guidelines.
You can generate a custom build, containing only needed modules, from the project's homepage. Alternatively you can run local Grunt build from the command line and list needed modules as shown below:
``` grunt build:modal:tabs:alert:popover:dropdownToggle:buttons:progressbar ```
Check the Grunt build file for other tasks that are defined for this project.
As mentioned directives from this repository have all the markup externalized in templates. You might want to customize default templates to match your desired look & feel, add new functionality etc.
The easiest way to override an individual template is to use the `<script>` directive:
```javascript <script id="template/alert/alert.html" type="text/ng-template">     <div class='alert' ng-class='type && "alert-" + type'>         <button ng-show='closeable' type='button' class='close' ng-click='close()'>Close</button>         <div ng-transclude></div>     </div> </script> ```
If you want to override more templates it makes sense to store them as individual files and feed the `$templateCache` from those partials. For people using Grunt as the build tool it can be easily done using the `grunt-html2js` plugin. You can also configure your own template url. Let's have a look:
Your own template url is `views/partials/ui-bootstrap-tpls/alert/alert.html`.
Add "html2js" task to your Gruntfile ``` html2js: {   options: {     base: '.',     module: 'ui-templates',     rename: function (modulePath) {       var moduleName = modulePath.replace('app/views/partials/ui-bootstrap-tpls/', '').replace('.html', '');       return 'template' + '/' + moduleName + '.html';     }   },   main: {     src: ['app/views/partials/ui-bootstrap-tpls/**/*.html'],     dest: '.tmp/ui-templates.js'   } } ```
Make sure to load your template.js file `<script src="/ui-templates.js"></script>`
Inject the `ui-templates` module in your `app.js` ``` angular.module('myApp', [   'ui.bootstrap',   'ui-templates' ]); ```
Then it will work fine!
For more information visit: https://github.com/karlgoldstein/grunt-html2js
Well done! (If you don't like repeating yourself open a PR with a grunt task taking care of the above!)
Who will take the lead regarding any pull requests or decisions for a a directive?
<table width="100%"> <th>Component</th><th>Maintainer</th> <tr>   <td>accordion</td><td>@ajoslin</td> </tr> <tr>   <td>alert</td><td>@pkozlowski</td> </tr> <tr>   <td>bindHtml</td><td>frozen, use $sce?</td> </tr> <tr>   <td>buttons</td><td> @pkozlowski</td> </tr> <tr>   <td>carousel</td><td>@ajoslin</td> </tr> <tr>   <td>collapse</td><td>$animate (@chrisirhc)</td> </tr> <tr>   <td>datepicker</td><td>@bekos</td> </tr> <tr>   <td>dropdownToggle</td><td>@bekos</td> </tr> <tr>   <td>modal</td><td>@pkozlowski</td> </tr> <tr>   <td>pagination</td><td>@bekos</td> </tr> <tr>   <td>popover/tooltip</td><td>@chrisirhc</td> </tr> <tr>   <td>position</td><td>@ajoslin</td> </tr> <tr>   <td>progressbar</td><td>@bekos</td> </tr> <tr>   <td>rating</td><td>@bekos</td> </tr> <tr>   <td>tabs</td><td>@ajoslin</td> </tr> <tr>   <td>timepicker</td><td>@bekos</td> </tr> <tr>   <td>transition</td><td>@frozen, remove (@chrisirhc)</td> </tr> <tr>   <td>typeahead</td><td>@pkozlowski, @chrisirhc</td> </tr> </table>
Each directive should make its own two-letter prefix
`<tab tb-active=true tb-select=doThis()>`
* @chrisirhc is leading this
* @ajoslin is leading this * Building everything on travis commit * Push to bower, nuget, cdnjs, etc
* http://github.com/petebacondarwin/angular-doc-gen
- Boolean attributes - Stick AngularJS conventions rather than Bootstrap conventions
The **accordion directive** builds on top of the collapse directive to provide a list of items, with collapsible bodies that are collapsed or expanded by clicking on the item's header.
We can control whether expanding an item will cause the other items to close, using the `close-others` attribute on accordion.
The body of each accordion group is transcluded in to the body of the collapsible element.
Alert is an AngularJS-version of bootstrap's alert.
This directive can be used to generate alerts from the dynamic model data (using the ng-repeat directive);
The presence of the "close" attribute determines if a close button is displayed
There are two directives that can make a group of buttons behave like a set of checkboxes, radio buttons, or a hybrid where radio buttons can be unchecked.
Carousel creates a carousel similar to bootstrap's image carousel.
The carousel also offers support for touchscreen devices in the form of swiping. To enable swiping, load the `ngTouch` module as a dependency.
Use a `<carousel>` element with `<slide>` elements inside it.  It will automatically cycle through the slides at a given rate, and a current-index variable will be kept in sync with the currently visible slide.
AngularJS version of Bootstrap's collapse plugin. Provides a simple way to hide and show an element with a css transition
A clean, flexible, and fully customizable date picker.
User can navigate through months and years. The datepicker shows dates that come from other than the main month being displayed. These other dates are also selectable.
Everything is formatted using the [date filter](http://docs.angularjs.org/api/ng.filter:date) and thus is also localized.
All settings can be provided as attributes in the `datepicker` or globally configured through the `datepickerConfig`.
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>  	:  	The date object.
* `datepicker-mode` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: 'day')_ :    Current mode of the datepicker _(day|month|year)_. Can be used to initialize datepicker to specific mode.
* `min-date` <i class="glyphicon glyphicon-eye-open"></i>  	_(Default: null)_ :  	Defines the minimum available date.
* `max-date` <i class="glyphicon glyphicon-eye-open"></i>  	_(Default: null)_ :  	Defines the maximum available date.
* `date-disabled (date, mode)`  	_(Default: null)_ :  	An optional expression to disable visible options based on passing date and current mode _(day|month|year)_.
* `show-weeks`  	_(Defaults: true)_ :  	Whether to display week numbers.
* `starting-day`  	_(Defaults: 0)_ :  	Starting day of the week from 0-6 (0=Sunday, ..., 6=Saturday).
* `init-date`  	:  	The initial date view when no model value is not specified.
* `min-mode`    _(Defaults: 'day')_ :    Set a lower limit for mode.
* `max-mode`    _(Defaults: 'year')_ :    Set an upper limit for mode.
* `format-day`  	_(Default: 'dd')_ :  	Format of day in month.
* `format-month`  	_(Default: 'MMMM')_ :  	Format of month in year.
* `format-year`  	_(Default: 'yyyy')_ :  	Format of year in year range.
* `format-day-header`  	_(Default: 'EEE')_ :  	Format of day in week header.
* `format-day-title`  	_(Default: 'MMMM yyyy')_ :  	Format of title when selecting day.
* `format-month-title`  	_(Default: 'yyyy')_ :  	Format of title when selecting month.
* `year-range`  	_(Default: 20)_ :  	Number of years displayed in year selection.
Options for datepicker can be passed as JSON using the `datepicker-options` attribute. Specific settings for the `datepicker-popup`, that can globally configured through the `datepickerPopupConfig`, are:
* `datepicker-popup`  	_(Default: 'yyyy-MM-dd')_ :  	The format for displayed dates.
* `show-button-bar`  	_(Default: true)_ :  	Whether to display a button bar underneath the datepicker.
* `current-text`  	_(Default: 'Today')_ :  	The text to display for the current day button.
* `clear-text`  	_(Default: 'Clear')_ :  	The text to display for the clear button.
* `close-text`  	_(Default: 'Done')_ :  	The text to display for the close button.
* `close-on-date-selection`  	_(Default: true)_ :  	Whether to close calendar when a date is chosen.
* `datepicker-append-to-body`   _(Default: false)_:   Append the datepicker popup element to `body`, rather than inserting after `datepicker-popup`. For global configuration, use `datepickerPopupConfig.appendToBody`.
Depending on datepicker's current mode, the date may reffer either to day, month or year. Accordingly, the term view reffers either to a month, year or year range.
* `Left`: Move focus to the previous date. Will move to the last date of the previous view, if the current date is the first date of a view.  * `Right`: Move focus to the next date. Will move to the first date of the following view, if the current date is the last date of a view.  * `Up`: Move focus to the same column of the previous row. Will wrap to the appropriate row in the previous view.  * `Down`: Move focus to the same column of the following row. Will wrap to the appropriate row in the following view.  * `PgUp`: Move focus to the same date of the previous view. If that date does not exist, focus is placed on the last date of the month.  * `PgDn`: Move focus to the same date of the following view. If that date does not exist, focus is placed on the last date of the month.  * `Home`: Move to the first date of the view.  * `End`: Move to the last date of the view.  * `Enter`/`Space`: Select date.  * `Ctrl`+`Up`: Move to an upper mode.  * `Ctrl`+`Down`: Move to a lower mode.  * `Esc`: Will close popup, and move focus to the input.
Dropdown is a simple directive which will toggle a dropdown menu on click or programmatically. You can either use `is-open` to toggle or add inside a `<a dropdown-toggle>` element to toggle it when is clicked. There is also the `on-toggle(open)` optional expression fired when dropdown changes state.
`$modal` is a service to quickly create AngularJS-powered modal windows. Creating custom modals is straightforward: create a partial view, its controller and reference them when using the service.
The `$modal` service has only one method: `open(options)` where available options are like follows:
* `templateUrl` - a path to a template representing modal's content * `template` - inline template representing the modal's content * `scope` - a scope instance to be used for the modal's content (actually the `$modal` service is going to create a child scope of a provided scope). Defaults to `$rootScope` * `controller` - a controller for a modal instance - it can initialize scope used by modal. Accepts the "controller-as" syntax, and can be injected with `$modalInstance` * `resolve` - members that will be resolved and passed to the controller as locals; it is equivalent of the `resolve` property for AngularJS routes * `backdrop` - controls presence of a backdrop. Allowed values: true (default), false (no backdrop), `'static'` - backdrop is present but modal window is not closed when clicking outside of the modal window. * `keyboard` - indicates whether the dialog should be closable by hitting the ESC key, defaults to true * `windowClass` - additional CSS class(es) to be added to a modal window template * `windowTemplateUrl` - a path to a template overriding modal's window template * `size` - optional size of modal window. Allowed values: `'sm'` (small) or  `'lg'` (large). Requires Bootstrap 3.1.0 or later
The `open` method returns a modal instance, an object with the following properties:
* `close(result)` - a method that can be used to close a modal, passing a result * `dismiss(reason)` - a method that can be used to dismiss a modal, passing a reason * `result` - a promise that is resolved when a modal is closed and rejected when a modal is dismissed * `opened` - a promise that is resolved when a modal gets opened after downloading content's template and resolving all variables
In addition the scope associated with modal's content is augmented with 2 methods:
* `$close(result)` * `$dismiss(reason)`
Those methods make it easy to close a modal window without a need to create a dedicated controller
A lightweight pagination directive that is focused on ... providing pagination & will take care of visualising a pagination bar and enable / disable buttons correctly!
Settings can be provided as attributes in the `<pagination>` or globally configured through the `paginationConfig`.
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>  	:  	Current page number. First page is 1.
* `total-items` <i class="glyphicon glyphicon-eye-open"></i>  	:  	Total number of items in all pages.
* `items-per-page` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: 10)_ :  	Maximum number of items per page. A value less than one indicates all items on one page.
* `max-size` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: null)_ :  	Limit number for pagination size.
* `num-pages` <small class="badge">readonly</small>  	_(Defaults: angular.noop)_ :  	An optional expression assigned the total number of pages to display.
* `rotate`  	_(Defaults: true)_ :  	Whether to keep current page in the middle of the visible ones.
* `direction-links`  	_(Default: true)_ :  	Whether to display Previous / Next buttons.
* `previous-text`  	_(Default: 'Previous')_ :  	Text for Previous button.
* `next-text`  	_(Default: 'Next')_ :  	Text for Next button.
* `boundary-links`  	_(Default: false)_ :  	Whether to display First / Last buttons.
* `first-text`  	_(Default: 'First')_ :  	Text for First button.
* `last-text`  	_(Default: 'Last')_ :  	Text for Last button.
Settings can be provided as attributes in the `<pager>` or globally configured through the `pagerConfig`.   For `ng-model`, `total-items`, `items-per-page` and `num-pages` see pagination settings. Other settings are:
* `align`  	_(Default: true)_ :  	Whether to align each link to the sides.
* `previous-text`  	_(Default: ' Previous')_ :  	Text for Previous button.
* `next-text`  	_(Default: 'Next ')_ :  	Text for Next button.
A lightweight, extensible directive for fancy popover creation. The popover directive supports multiple placements, optional transition animation, and more.
Like the Bootstrap jQuery plugin, the popover **requires** the tooltip module.
The popover directives provides several optional attributes to control how it will display:
- `popover-title`: A string to display as a fancy title. - `popover-placement`: Where to place it? Defaults to "top", but also accepts   "bottom", "left", "right". - `popover-animation`: Should it fade in and out? Defaults to "true". - `popover-popup-delay`: For how long should the user have to have the mouse   over the element before the popover shows (in milliseconds)? Defaults to 0. - `popover-trigger`: What should trigger the show of the popover? See the   `tooltip` directive for supported values. - `popover-append-to-body`: Should the tooltip be appended to `$body` instead of   the parent element?
The popover directives require the `$position` service.
The popover directive also supports various default configurations through the $tooltipProvider. See the [tooltip](#tooltip) section for more information.
A progress bar directive that is focused on providing feedback on the progress of a workflow or action.
It supports multiple (stacked) bars into the same `<progress>` element or a single `<progressbar>` elemtnt with optional `max` attribute and transition animations.
* `value` <i class="glyphicon glyphicon-eye-open"></i>  	:  	The current value of progress completed.
* `type`  	_(Default: null)_ :  	Style type. Possible values are 'success', 'warning' etc.
* `max`  	_(Default: 100)_ :  	A number that specifies the total value of bars that is required.
* `animate`  	_(Default: true)_ :  	Whether bars use transitions to achieve the width change.
Place multiple `<bars>` into the same `<progress>` element to stack them. `<progress>` supports `max` and `animate` &  `<bar>` supports  `value` and `type` attributes.
Rating directive that will take care of visualising a star rating bar.
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>  	:  	The current rate.
* `max`  	_(Defaults: 5)_ :  	Changes the number of icons.
* `readonly` <i class="icon-eye-open"></i>  	_(Defaults: false)_ :  	Prevent user's interaction.
* `on-hover(value)`  	:  	An optional expression called when user's mouse is over a particular icon.
* `on-leave()`  	:  	An optional expression called when user's mouse leaves the control altogether.
* `state-on`  	_(Defaults: null)_ :  	A variable used in template to specify the state (class, src, etc) for selected icons.
* `state-off`  	_(Defaults: null)_ :  	A variable used in template to specify the state for unselected icons.
* `rating-states`  	_(Defaults: null)_ :  	An array of objects defining properties for all icons. In default template, `stateOn` & `stateOff` property is used to specify the icon's class.
AngularJS version of the tabs directive.
* `vertical`  	_(Defaults: false)_ :  	Whether tabs appear vertically stacked.
* `justified`  	_(Defaults: false)_ :  	Whether tabs fill the container and have a consistent width.
* `type`  	_(Defaults: 'tabs')_ :  	Navigation type. Possible values are 'tabs' and 'pills'.
* `heading` or `<tab-heading>`  	:  	Heading text or HTML markup.
* `active` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: false)_ :  	Whether tab is currently selected.
* `disabled` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: false)_ :  	Whether tab is clickable and can be activated.
* `select()`  	_(Defaults: null)_ :  	An optional expression called when tab is activated.       * `deselect()`  	_(Defaults: null)_ :  	An optional expression called when tab is deactivated.
A lightweight & configurable timepicker directive.
All settings can be provided as attributes in the `<timepicker>` or globally configured through the `timepickerConfig`.
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>  	:  	The Date object that provides the time state.
* `hour-step` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: 1)_ :  	 Number of hours to increase or decrease when using a button.
* `minute-step` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: 1)_ :  	 Number of minutes to increase or decrease when using a button.
* `show-meridian` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: true)_ :  	Whether to display 12H or 24H mode.
* `meridians`  	_(Defaults: null)_ :  	 Meridian labels based on locale. To override you must supply an array like ['AM', 'PM'].
* `readonly-input`  	_(Defaults: false)_ :  	 Whether user can type inside the hours & minutes input.
* `mousewheel`  	_(Defaults: true)_ :  	 Whether user can scroll inside the hours & minutes input to increase or decrease it's values.
A lightweight, extensible directive for fancy tooltip creation. The tooltip directive supports multiple placements, optional transition animation, and more.
There are two versions of the tooltip: `tooltip` and `tooltip-html-unsafe`. The former takes text only and will escape any HTML provided. The latter takes whatever HTML is provided and displays it in a tooltip; it called "unsafe" because the HTML is not sanitized. *The user is responsible for ensuring the content is safe to put into the DOM!*
The tooltip directives provide several optional attributes to control how they will display:
- `tooltip-placement`: Where to place it? Defaults to "top", but also accepts   "bottom", "left", "right". - `tooltip-animation`: Should it fade in and out? Defaults to "true". - `tooltip-popup-delay`: For how long should the user have to have the mouse   over the element before the tooltip shows (in milliseconds)? Defaults to 0. - `tooltip-trigger`: What should trigger a show of the tooltip? - `tooltip-append-to-body`: Should the tooltip be appended to `$body` instead of   the parent element?
The tooltip directives require the `$position` service.
**Triggers**
The following show triggers are supported out of the box, along with their provided hide triggers:
- `mouseenter`: `mouseleave` - `click`: `click` - `focus`: `blur`
For any non-supported value, the trigger will be used to both show and hide the tooltip.
**$tooltipProvider**
Through the `$tooltipProvider`, you can change the way tooltips and popovers behave by default; the attributes above always take precedence. The following methods are available:
- `setTriggers( obj )`: Extends the default trigger mappings mentioned above   with mappings of your own. E.g. `{ 'openTrigger': 'closeTrigger' }`. - `options( obj )`: Provide a set of defaults for certain tooltip and popover   attributes. Currently supports 'placement', 'animation', 'popupDelay', and   `appendToBody`. Here are the defaults:
<pre>   placement: 'top',   animation: true,   popupDelay: 0,   appendToBody: false   </pre>
Typeahead is a AngularJS version of [Bootstrap v2's typeahead plugin](http://getbootstrap.com/2.3.2/javascript.html#typeahead). This directive can be used to quickly create elegant typeaheads with any form text input.
It is very well integrated into AngularJS as it uses a subset of the [select directive](http://docs.angularjs.org/api/ng.directive:select) syntax, which is very flexible. Supported expressions are:
* _label_ for _value_ in _sourceArray_ * _select_ as _label_ for _value_ in _sourceArray_
The `sourceArray` expression can use a special `$viewValue` variable that corresponds to the value entered inside the input.
This directive works with promises, meaning you can retrieve matches using the `$http` service with minimal effort.
The typeahead directives provide several attributes:
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>    :    Assignable angular expression to data-bind to
* `typeahead` <i class="glyphicon glyphicon-eye-open"></i>    :    Comprehension Angular expression (see [select directive](http://docs.angularjs.org/api/ng.directive:select))
* `typeahead-append-to-body` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: false)_ : Should the typeahead popup be appended to $body instead of the parent element?
* `typeahead-editable` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: true)_ :    Should it restrict model values to the ones selected from the popup only ?
* `typeahead-input-formatter` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: undefined)_ :    Format the ng-model result after selection
* `typeahead-loading` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: angular.noop)_ :    Binding to a variable that indicates if matches are being retrieved asynchronously
* `typeahead-min-length` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: 1)_ :    Minimal no of characters that needs to be entered before typeahead kicks-in
* `typeahead-on-select($item, $model, $label)`    _(Defaults: null)_ :    A callback executed when a match is selected
* `typeahead-template-url` <i class="glyphicon glyphicon-eye-open"></i>    :    Set custom item template
* `typeahead-wait-ms` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: 0)_ :    Minimal wait time after last character typed before typeahead kicks-in
<a name="v0.2.8"></a> ### v0.2.8 (2014-01-16)
* **$state:** allow null to be passed as 'params' param ([094dc30e](https://github.com/angular-ui/ui-router/commit/094dc30e883e1bd14e50a475553bafeaade3b178)) * **$state.go:** param inheritance shouldn't inherit from siblings ([aea872e0](https://github.com/angular-ui/ui-router/commit/aea872e0b983cb433436ce5875df10c838fccedb)) * **uiSrefActive:** annotate controller injection ([85921422](https://github.com/angular-ui/ui-router/commit/85921422ff7fb0effed358136426d616cce3d583), closes [#671](https://github.com/angular-ui/ui-router/issues/671)) * **uiView:**   * autoscroll tests pass on 1.2.4 & 1.1.5 ([86eacac0](https://github.com/angular-ui/ui-router/commit/86eacac09ca5e9000bd3b9c7ba6e2cc95d883a3a))   * don't animate initial load ([83b6634d](https://github.com/angular-ui/ui-router/commit/83b6634d27942ca74766b2b1244a7fc52c5643d9))   * test pass against 1.0.8 and 1.2.4 ([a402415a](https://github.com/angular-ui/ui-router/commit/a402415a2a28b360c43b9fe8f4f54c540f6c33de))   * it should autoscroll when expr is missing. ([8bb9e27a](https://github.com/angular-ui/ui-router/commit/8bb9e27a2986725f45daf44c4c9f846385095aff))
* **uiSref:** add target attribute behaviour ([c12bf9a5](https://github.com/angular-ui/ui-router/commit/c12bf9a520d30d70294e3d82de7661900f8e394e)) * **uiView:**   * merge autoscroll expression test. ([b89e0f87](https://github.com/angular-ui/ui-router/commit/b89e0f871d5cc35c10925ede986c10684d5c9252))   * cache and test autoscroll expression ([ee262282](https://github.com/angular-ui/ui-router/commit/ee2622828c2ce83807f006a459ac4e11406d9258))
---
AngularUI Router is a routing framework for [AngularJS](http://angularjs.org), which allows you to organize the parts of your interface into a [*state machine*](https://en.wikipedia.org/wiki/Finite-state_machine). Unlike the [`$route` service](http://docs.angularjs.org/api/ngRoute.$route) in Angular core, which is organized around URL routes, UI-Router is organized around [*states*](https://github.com/angular-ui/ui-router/blob/master/sample/states.js#L28-L269), which may optionally have routes, as well as other behavior, attached.
States are bound to *named*, *nested* and *parallel views*, allowing you to powerfully manage your application's interface.
- **Note:** *UI-Router is under active development. As such, while this library is well-tested, the API may change. Consider using it in production applications only if you're comfortable following a changelog and updating your usage accordingly.*
**(1)** Get UI-Router in one of 4 ways:  - clone & [build](#developing) this repository  - [download the release](http://angular-ui.github.io/ui-router/release/angular-ui-router.js) (or [minified](http://angular-ui.github.io/ui-router/release/angular-ui-router.min.js))  - via **[Bower](http://bower.io/)**: by running `$ bower install angular-ui-router` from your console  - or via **[Component](https://github.com/component/component)**: by running `$ component install angular-ui/ui-router` from your console
**(2)** Include `angular-ui-router.js` (or `angular-ui-router.min.js`) in your `index.html`, after including Angular itself (For Component users: ignore this step)
**(3)** Add `'ui.router'` to your main module's list of dependencies (For Component users: replace `'ui.router'` with `require('angular-ui-router')`)
When you're done, your setup should look similar to the following:
> ```html <!doctype html> <html ng-app="myApp"> <head>     <script src="//ajax.googleapis.com/ajax/libs/angularjs/1.1.5/angular.min.js"></script>     <script src="js/angular-ui-router.min.js"></script>     <script>         var myApp = angular.module('myApp', ['ui.router']);         // For Component users, it should look like this:         // var myApp = angular.module('myApp', [require('angular-ui-router')]);     </script>     ... </head> <body>     ... </body> </html> ```
The majority of UI-Router's power is in its ability to nest states & views.
**(1)** First, follow the [setup](#get-started) instructions detailed above.
**(2)** Then, add a [`ui-view` directive](https://github.com/angular-ui/ui-router/wiki/Quick-Reference#ui-view) to the `<body />` of your app.
> ```html <!-- index.html --> <body>     <div ui-view></div>     <!-- We'll also add some navigation: -->     <a ui-sref="state1">State 1</a>     <a ui-sref="state2">State 2</a> </body> ```
**(3)** You'll notice we also added some links with [`ui-sref` directives](https://github.com/angular-ui/ui-router/wiki/Quick-Reference#ui-sref). In addition to managing state transitions, this directive auto-generates the `href` attribute of the `<a />` element it's attached to, if the corresponding state has a URL. Next we'll add some templates. These will plug into the `ui-view` within `index.html`. Notice that they have their own `ui-view` as well! That is the key to nesting states and views.
> ```html <!-- partials/state1.html --> <h1>State 1</h1> <hr/> <a ui-sref="state1.list">Show List</a> <div ui-view></div> ``` ```html <!-- partials/state2.html --> <h1>State 2</h1> <hr/> <a ui-sref="state2.list">Show List</a> <div ui-view></div> ```
**(4)** Next, we'll add some child templates. *These* will get plugged into the `ui-view` of their parent state templates.
> ```html <!-- partials/state1.list.html --> <h3>List of State 1 Items</h3> <ul>   <li ng-repeat="item in items">{{ item }}</li> </ul> ```
> ```html <!-- partials/state2.list.html --> <h3>List of State 2 Things</h3> <ul>   <li ng-repeat="thing in things">{{ thing }}</li> </ul> ```
**(5)** Finally, we'll wire it all up with `$stateProvider`. Set up your states in the module config, as in the following:
> ```javascript myApp.config(function($stateProvider, $urlRouterProvider) {   //   // For any unmatched url, redirect to /state1   $urlRouterProvider.otherwise("/state1");   //   // Now set up the states   $stateProvider     .state('state1', {       url: "/state1",       templateUrl: "partials/state1.html"     })     .state('state1.list', {       url: "/list",       templateUrl: "partials/state1.list.html",       controller: function($scope) {         $scope.items = ["A", "List", "Of", "Items"];       }     })     .state('state2', {       url: "/state2",       templateUrl: "partials/state2.html"     })     .state('state2.list', {       url: "/list",         templateUrl: "partials/state2.list.html",         controller: function($scope) {           $scope.things = ["A", "Set", "Of", "Things"];         }       })     }); ```
**(6)** See this quick start example in action. >**[Go to Quick Start Plunker for Nested States & Views](http://plnkr.co/edit/u18KQc?p=preview)**
**(7)** This only scratches the surface >**[Dive Deeper!](https://github.com/angular-ui/ui-router/wiki)**
Another great feature is the ability to have multiple `ui-view`s view per template.
**Pro Tip:** *While multiple parallel views are a powerful feature, you'll often be able to manage your interfaces more effectively by nesting your views, and pairing those views with nested states.*
**(1)** Follow the [setup](#get-started) instructions detailed above.
**(2)** Add one or more `ui-view` to your app, give them names. > ```html <!-- index.html --> <body>     <div ui-view="viewA"></div>     <div ui-view="viewB"></div>     <!-- Also a way to navigate -->     <a ui-sref="route1">Route 1</a>     <a ui-sref="route2">Route 2</a> </body> ```
**(3)** Set up your states in the module config: > ```javascript myApp.config(function($stateProvider) {   $stateProvider     .state('index', {       url: "",       views: {         "viewA": { template: "index.viewA" },         "viewB": { template: "index.viewB" }       }     })     .state('route1', {       url: "/route1",       views: {         "viewA": { template: "route1.viewA" },         "viewB": { template: "route1.viewB" }       }     })     .state('route2', {       url: "/route2",       views: {         "viewA": { template: "route2.viewA" },         "viewB": { template: "route2.viewB" }       }     }) }); ```
**(4)** See this quick start example in action. >**[Go to Quick Start Plunker for Multiple & Named Views](http://plnkr.co/edit/SDOcGS?p=preview)**
* [In-Depth Guide](https://github.com/angular-ui/ui-router/wiki) * [API Reference](http://angular-ui.github.io/ui-router/site) * [Sample App](http://angular-ui.github.com/ui-router/sample/) ([Source](https://github.com/angular-ui/ui-router/tree/gh-pages/sample)) * [FAQ](https://github.com/angular-ui/ui-router/wiki/Frequently-Asked-Questions) * [Introduction Video](https://egghead.io/lessons/angularjs-introduction-ui-router) * [Slides comparing ngRoute to ui-router](http://slid.es/timkindberg/ui-router#/)
Help us make UI-Router better! If you think you might have found a bug, or some other weirdness, start by making sure it hasn't already been reported. You can [search through existing issues](https://github.com/angular-ui/ui-router/search?q=wat%3F&type=Issues) to see if someone's reported one similar to yours.
If not, then [create a plunkr](http://plnkr.co/edit/u18KQc?p=preview) that demonstrates the problem (try to use as little code as possible: the more minimalist, the faster we can debug it).
Next, [create a new issue](https://github.com/angular-ui/ui-router/issues/new) that briefly explains the problem, and provides a bit of background as to the circumstances that triggered it. Don't forget to include the link to that plunkr you created!
**Note**: If you're unsure how a feature is used, or are encountering some unexpected behavior that you aren't sure is a bug, it's best to talk it out in the [Google Group](https://groups.google.com/forum/#!categories/angular-ui/router) or on [StackOverflow](http://stackoverflow.com/questions/ask?tags=angularjs,angular-ui-router) before reporting it. This keeps development streamlined, and helps us focus on building great software.
Please keep in mind that the issue tracker is for *issues*. Please do *not* post an issue if you need help or support. Instead, see one of the above-mentioned forums or [IRC](irc://irc.freenode.net/#angularjs).
**(1)** See the **[Developing](#developing)** section below, to get the development version of UI-Router up and running on your local machine.
**(2)** Check out the [roadmap](https://github.com/angular-ui/ui-router/issues/milestones) to see where the project is headed, and if your feature idea fits with where we're headed.
**(3)** If you're not sure, [open an RFC](https://github.com/angular-ui/ui-router/issues/new?title=RFC:%20My%20idea) to get some feedback on your idea.
**(4)** Finally, commit some code and open a pull request. Code & commits should abide by the following rules:
- *Always* have test coverage for new features (or regression tests for bug fixes), and *never* break existing tests - Commits should represent one logical change each; if a feature goes through multiple iterations, squash your commits down to one - Make sure to follow the [Angular commit message format](https://github.com/angular/angular.js/blob/master/CONTRIBUTING.md#commit-message-format) so your change will appear in the changelog of the next release. - Changes should always respect the coding style of the project

UI-Router uses <code>grunt >= 0.4.x</code>. Make sure to upgrade your environment and read the [Migration Guide](http://gruntjs.com/upgrading-from-0.3-to-0.4).
Dependencies for building from source and running tests:
* [grunt-cli](https://github.com/gruntjs/grunt-cli) - run: `$ npm install -g grunt-cli` * Then, install the development dependencies by running `$ npm install` from the project directory
There are a number of targets in the gruntfile that are used to generating different builds:
* `grunt`: Perform a normal build, runs jshint and karma tests * `grunt build`: Perform a normal build * `grunt dist`: Perform a clean build and generate documentation * `grunt dev`: Run dev server (sample app) and watch for changes, builds and runs karma tests on changes.
<a name="v0.1.0"></a> ## v0.1.0 (2013-12-29)
* **mark:** TypeError: input is undefined ([5440d6fa](http://github.com/angular-ui/ui-utils/commit/5440d6fa8514ee86efc480b0abbf66cf244889ad)) * **publisher:**   * don't throw error when 'dist/sub' don't exist ([bd319236](http://github.com/angular-ui/ui-utils/commit/bd31923668c0ea80311b9dbe7d72bfbe55956325))   * rename sub componenet stuff ([5dcdc379](http://github.com/angular-ui/ui-utils/commit/5dcdc3794efe66112522415aafe9ebe965a274f6)) * **ui-scroll:**   * 'newitems' is not defined. ([796e310a](http://github.com/angular-ui/ui-utils/commit/796e310a26ac43a248c0c732877242890fdda2be))   * 'isArray' is not defined. ([3fd7fc47](http://github.com/angular-ui/ui-utils/commit/3fd7fc47de7d05460a55ca42e4afec60d8e8cc4d))   * 'setOffset' is not defined. ([32140e04](http://github.com/angular-ui/ui-utils/commit/32140e04be176c4b2a5954d2cf8e9ec3c48a6f5c))
* **alias:** Created a new ui-alias module for renaming/combining directives ([1582d54e](http://github.com/angular-ui/ui-utils/commit/1582d54ecaf81cb516a28368c0d409b5d5fe7da9)) * **grunt:**   * add 'changelog' task ([b7fed5a6](http://github.com/angular-ui/ui-utils/commit/b7fed5a6026121d0098f892aa0a221c0d9c14d56), closes [#145](http://github.com/angular-ui/ui-utils/issues/145))   * use Angular UI Publisher ([3c209713](http://github.com/angular-ui/ui-utils/commit/3c20971307e50741f88da21cb638077237e56da2), closes [#153](http://github.com/angular-ui/ui-utils/issues/153))   * new 'serve' task ([a18ed32c](http://github.com/angular-ui/ui-utils/commit/a18ed32ce134acabe7adc79b41e82ed6c52109ed))   * quality code more strict ([332ebff1](http://github.com/angular-ui/ui-utils/commit/332ebff1fdc7edf4d44d64f4796ec2f70e90947f))   * use ngmin in the 'dist' task ([93ba905f](http://github.com/angular-ui/ui-utils/commit/93ba905fadfd4d0970d384f7978e19a3561cea65))   * add ngmin build all subcomponents in dist/sub ([783140ab](http://github.com/angular-ui/ui-utils/commit/783140abe1b8d6c0f842eceb7fc24a0f16d73ca5)) * **publisher:**   * change travis scripts to work with the component-publisher system ([12d97d3b](http://github.com/angular-ui/ui-utils/commit/12d97d3bf88da86875141093fc164f1537d0dfe2))   * add and config component-publisher system ([4cea7ea5](http://github.com/angular-ui/ui-utils/commit/4cea7ea5bb4c47ad74c4f5123121a2896bf6f717)) * **travis:** add sub component auto publishing :) ([0d64db00](http://github.com/angular-ui/ui-utils/commit/0d64db00a5c50816cbf0b022aa5607fee29d5e2a))
This module exposes underscore's API into angular app's root scope, and provides some filters from underscore.
Whole Underscore's API for Collections, Arrays and Objects except decision API (e.g. functions return true|false), side effect guys, and _.range(not making sense as a filter).
For API details please check out http://underscorejs.org/
After load angular.js and underscore.js:
```html <script type="text/javascript" src="angular-underscore.js"></script> ```
```javascript angular.module('yourAwesomeApp', ['angular-underscore']); ```
```javascript angular.module('yourAwesomeApp', ['angular-underscore/utils']); ```
```javascript angular.module('yourAwesomeApp', ['angular-underscore/filters']); ```
```javascript // load `shuffle` only angular.module('yourAwesomeApp', ['angular-underscore/filters/shuffle']); ```
```html <script type="text/javascript">   angular.module('example', ['angular-underscore']); </script>
<body ng-app="example">   <!-- generate 10 unduplicated random number from 0 to 9 -->   <div ng-repeat="num in range(10)|shuffle">{{num}}</div> </body> ```
``` $ npm install uglify-js -g $ uglifyjs angular-underscore.js > angular-underscore.min.js ```
(The MIT License)
Copyright (c) 2014 <floydsoft@gmail.com>
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
* select2 * [checklist](https://github.com/vitalets/checklist-model) * [combodate](https://github.com/vitalets/combodate) * popup mode (waiting https://github.com/angular-ui/bootstrap/pull/1391) * internally move to [lazy-model](https://github.com/vitalets/lazy-model)
AngularJS-Toaster =================
**AngularJS Toaster** is a AngularJS port of the **toastr** non-blocking notification jQuery library. It requires AngularJS v1.2.6 or higher and angular-animate for the CSS3 transformations.  (I would suggest to use /1.2.8/angular-animate.js, there is a weird blinking in newer versions.)
1. Link scripts:
```html <link href="//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/2.3.2/css/bootstrap.min.css" rel="stylesheet" /> <link href="http://cdnjs.cloudflare.com/ajax/libs/angularjs-toaster/0.4.4/toaster.css" rel="stylesheet" /> <script src="https://ajax.googleapis.com/ajax/libs/angularjs/1.2.0/angular.min.js" ></script> <script src="http://code.angularjs.org/1.2.0/angular-animate.min.js" ></script> <script src="http://cdnjs.cloudflare.com/ajax/libs/angularjs-toaster/0.4.4/toaster.js"></script> ```
2. Add toaster container directive: `<toaster-container></toaster-container>`
3. Prepare the call of toaster method:
```js 	// Display an info toast with no title 	angular.module('main', ['toaster']) 	.controller('myController', function($scope, toaster) { 	    $scope.pop = function(){ 	        toaster.pop('success', "title", "text"); 	    }; 	}); ```
4. Call controller method on button click:
```html <div ng-controller="myController">     <button ng-click="pop()">Show a Toaster</button> </div> ```
```html // Change display position <toaster-container toaster-options="{'position-class': 'toast-top-full-width'}"></toaster-container> ```
#Animate.css *Just-add-water CSS animation*
`animate.css` is a bunch of cool, fun, and cross-browser animations for you to use in your projects. Great for emphasis, home pages, sliders, and general just-add-water-awesomeness.
##Usage To use animate.css in your website, simply drop the stylesheet into your document's `<head>`, and add the class `animated` to an element, along with any of the animation names. That's it! You've got a CSS animated element. Super!
```html <head>   <link rel="stylesheet" href="animate.min.css"> </head> ```
You can do a whole bunch of other stuff with animate.css when you combine it with jQuery or add your own CSS rules. Dynamically add animations using jQuery with ease:
```javascript $('#yourElement').addClass('animated bounceOutLeft'); ```
You can also detect when an animation ends:
<!-- Before you make changes to this file, you should know that $('#yourElement').one() is *NOT A TYPO*
http://api.jquery.com/one/ -->
```javascript $('#yourElement').one('webkitAnimationEnd mozAnimationEnd MSAnimationEnd oanimationend animationend', doSomething); ```
**Note:** `jQuery#one` is used when you want to execute the event handler at most *once*. More information [here](http://api.jquery.com/one/).
You can change the duration of your animations, add a delay or change the number of times that it plays:
```css #yourElement {   -vendor-animation-duration: 3s;   -vendor-animation-delay: 2s;   -vendor-animation-iteration-count: infinite; } ```
*Note: be sure to replace "vendor" in the CSS with the applicable vendor prefixes (webkit, moz, etc)*
```sh $ cd path/to/animate.css/ $ sudo npm install ```
Next, run `grunt watch` to watch for changes and compile your custom builds. For example, if you want only some of the the attention seekers, simply edit the `animate-config.json` file to select only the animations you want to use.
```javascript "attention_seekers": {   "bounce": true,   "flash": false,   "pulse": false,   "shake": true,   "swing": true,   "tada": true,   "wobble": true } ```
**Please follow these basic steps to simplify pull request reviews - if you don't you'll probably just be asked to anyway.**
* Please rebase your branch against the current master * Run ```npm install``` to make sure your development dependencies are up-to-date * [grunt-cli](https://github.com/gruntjs/grunt-cli) >= 0.4.0 is required to sanity check your contribution * Please ensure that the test suite passes **and** that bootbox.js is lint free before submitting a PR by running:  * ```grunt``` * If you've added new functionality, **please** include tests which validate its behaviour  * **this includes pull requests which _only_ add new locales!**
* Where at all possible, please try and provide a link to a jsfiddle.net example or similar * Please detail the affected browser(s) and operating system(s) * Please be sure to state which version of Bootbox, jQuery **and** Bootstrap you're using
Please see http://bootboxjs.com for full usage instructions, or head over to http://paynedigital.com/bootbox for the original writeup about the project.
The easiest thing is to [find me on twitter @makeusabrew](http://twitter.com/makeusabrew).
Please see the [CONTRIBUTING](https://github.com/makeusabrew/bootbox/blob/master/CONTRIBUTING.md) file for guidelines.
Tests are run using [Karma](http://karma-runner.github.io/0.8/index.html) using the Mocha test adapter. To run the tests yourself, simply run ```npm install``` within the project followed by ```npm test```. Please note that this will require [PhantomJS](http://phantomjs.org/) being installed and in your path - if it is not, you may run the tests and capture browsers manually by running ```karma start``` from the root of the project.
The project is also hosted on [Travis CI](https://travis-ci.org/makeusabrew/bootbox) - when submitting pull requests **please** ensure your tests pass as failing requests will be rejected. See the [CONTRIBUTING](https://github.com/makeusabrew/bootbox/blob/master/CONTRIBUTING.md) file for more information.
The repository no longer contains a minified bootbox.min.js file - this is now only generated [for releases](https://github.com/makeusabrew/bootbox/releases). To build your own minified copy for use in development simply run ```npm install``` if you haven't already, followed by ```grunt uglify```. This will generate a bootbox.min.js file in your working directory.
Bootbox **4.0.0** is the first release to support Bootstrap 3.0.0.
Bootbox **3.3.0** is the *last* release to support Bootstrap 2.2.x.
Much more dependency information can be found [on the Bootbox website](http://bootboxjs.com/#dependencies).
The latest major release of Bootbox - 4.0.0 - involved a total rewrite of the internal code and introduced an entirely new public API. It has not re-implemented some functionality from the 3.x series as of yet; this will be addressed in the coming weeks in the form of new minor releases; [a task list for 4.3.0 is available](https://github.com/makeusabrew/bootbox/issues/220) - please feel free to add feedback and requests.
There is no new major (e.g. 5.x) release on the roadmap at present.
* Add Swedish locale * Add Latvian locale * Add Turkish locale * Add Hebrew locale * Add password input type * Add textarea input type * Add date input type * Add time input type * Add number input type * Support DOM selectors for container argument * UMD support * Better support on mobile devices
For a full list of releases and changes please see [the changelog](https://github.com/makeusabrew/bootbox/blob/master/CHANGELOG.md).
(The MIT License)
Copyright (C) 2011-2014 by Nick Payne <nick@kurai.co.uk>
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE
Bootstrap is a sleek, intuitive, and powerful front-end framework for faster and easier web development, created by [Mark Otto](http://twitter.com/mdo) and [Jacob Thornton](http://twitter.com/fat), and maintained by the [core team](https://github.com/twbs?tab=members) with the massive support and involvement of the community.
To get started, check out <http://getbootstrap.com>!
- [Quick start](#quick-start)  - [Bugs and feature requests](#bugs-and-feature-requests)  - [Documentation](#documentation)  - [Compiling CSS and JavaScript](#compiling-css-and-javascript)  - [Contributing](#contributing)  - [Community](#community)  - [Versioning](#versioning)  - [Authors](#authors)  - [Copyright and license](#copyright-and-license)
Three quick start options are available:
- [Download the latest release](https://github.com/twbs/bootstrap/archive/v3.1.1.zip). - Clone the repo: `git clone https://github.com/twbs/bootstrap.git`. - Install with [Bower](http://bower.io): `bower install bootstrap`.
Read the [Getting Started page](http://getbootstrap.com/getting-started/) for information on the framework contents, templates and examples, and more.
Within the download you'll find the following directories and files, logically grouping common assets and providing both compiled and minified variations. You'll see something like this:
``` bootstrap/  css/     bootstrap.css     bootstrap.min.css     bootstrap-theme.css     bootstrap-theme.min.css  js/     bootstrap.js     bootstrap.min.js  fonts/      glyphicons-halflings-regular.eot      glyphicons-halflings-regular.svg      glyphicons-halflings-regular.ttf      glyphicons-halflings-regular.woff ```
We provide compiled CSS and JS (`bootstrap.*`), as well as compiled and minified CSS and JS (`bootstrap.min.*`). Fonts from Glyphicons are included, as is the optional Bootstrap theme.

Have a bug or a feature request? Please first read the [issue guidelines](https://github.com/twbs/bootstrap/blob/master/CONTRIBUTING.md#using-the-issue-tracker) and search for existing and closed issues. If your problem or idea is not addressed yet, [please open a new issue](https://github.com/twbs/bootstrap/issues/new).
Bootstrap's documentation, included in this repo in the root directory, is built with [Jekyll](http://jekyllrb.com) and publicly hosted on GitHub Pages at <http://getbootstrap.com>. The docs may also be run locally.
1. If necessary, [install Jekyll](http://jekyllrb.com/docs/installation) (requires v1.x).   - **Windows users:** Read [this unofficial guide](https://github.com/juthilo/run-jekyll-on-windows/) to get Jekyll up and running without problems. We use Pygments for syntax highlighting, so make sure to read the sections on installing Python and Pygments. 2. From the root `/bootstrap` directory, run `jekyll serve` in the command line.   - **Windows users:** While we use Jekyll's `encoding` setting, you might still need to change the command prompt's character encoding ([code page](http://en.wikipedia.org/wiki/Windows_code_page)) to UTF-8 so Jekyll runs without errors. For Ruby 2.0.0, run `chcp 65001` first. For Ruby 1.9.3, you can alternatively do `SET LANG=en_EN.UTF-8`. 3. Open <http://localhost:9001> in your browser, and voil.
Learn more about using Jekyll by reading its [documentation](http://jekyllrb.com/docs/home/).
Documentation for v2.3.2 has been made available for the time being at <http://getbootstrap.com/2.3.2/> while folks transition to Bootstrap 3.
[Previous releases](https://github.com/twbs/bootstrap/releases) and their documentation are also available for download.

Bootstrap uses [Grunt](http://gruntjs.com/) with convenient methods for working with the framework. It's how we compile our code, run tests, and more. To use it, install the required dependencies as directed and then run some Grunt commands.
From the command line:
1. Install `grunt-cli` globally with `npm install -g grunt-cli`. 2. Navigate to the root `/bootstrap` directory, then run `npm install`. npm will look at [package.json](https://github.com/twbs/bootstrap/blob/master/package.json) and automatically install the necessary local dependencies listed there.
When completed, you'll be able to run the various Grunt commands provided from the command line.
**Unfamiliar with `npm`? Don't have node installed?** That's a-okay. npm stands for [node packaged modules](http://npmjs.org/) and is a way to manage development dependencies through node.js. [Download and install node.js](http://nodejs.org/download/) before proceeding.
Should you encounter problems with installing dependencies or running Grunt commands, uninstall all previous dependency versions (global and local). Then, rerun `npm install`.

Please read through our [contributing guidelines](https://github.com/twbs/bootstrap/blob/master/CONTRIBUTING.md). Included are directions for opening issues, coding standards, and notes on development.
Moreover, if your pull request contains JavaScript patches or features, you must include relevant unit tests. All HTML and CSS should conform to the [Code Guide](http://github.com/mdo/code-guide), maintained by [Mark Otto](http://github.com/mdo).
Editor preferences are available in the [editor config](https://github.com/twbs/bootstrap/blob/master/.editorconfig) for easy use in common text editors. Read more and download plugins at <http://editorconfig.org>.

Keep track of development and community news.
- Follow [@twbootstrap on Twitter](http://twitter.com/twbootstrap). - Read and subscribe to [The Official Bootstrap Blog](http://blog.getbootstrap.com). - Chat with fellow Bootstrappers in IRC. On the `irc.freenode.net` server, in the `##twitter-bootstrap` channel. - Implementation help may be found at Stack Overflow (tagged [`twitter-bootstrap-3`](http://stackoverflow.com/questions/tagged/twitter-bootstrap-3)).

For transparency into our release cycle and in striving to maintain backward compatibility, Bootstrap is maintained under the Semantic Versioning guidelines. Sometimes we screw up, but we'll adhere to these rules whenever possible.
Releases will be numbered with the following format:
`<major>.<minor>.<patch>`
And constructed with the following guidelines:
- Breaking backward compatibility **bumps the major** while resetting minor and patch - New additions without breaking backward compatibility **bumps the minor** while resetting the patch - Bug fixes and misc changes **bumps only the patch**
For more information on SemVer, please visit <http://semver.org/>.

**Mark Otto**
- <http://twitter.com/mdo> - <http://github.com/mdo>
**Jacob Thornton**
- <http://twitter.com/fat> - <http://github.com/fat>

Code and documentation copyright 2011-2014 Twitter, Inc. Code released under [the MIT license](LICENSE). Docs released under [Creative Commons](docs/LICENSE).
The SHA-256 hash of the single file is used as the key for the cache. The directory is stored as a gzipped tarball.
All the tarballs are stored in S3's Reduced Redundancy Storage (RRS) storage class, since this is cheaper and the data is non-critical.
`s3_cache.py` itself never deletes cache entries; deletion should either be done manually or using automatic S3 lifecycle rules on the bucket.
Similar to git, `s3_cache.py` makes the assumption that [SHA-256 will effectively never have a collision](http://stackoverflow.com/questions/4014090/is-it-safe-to-ignore-the-possibility-of-sha-collisions-in-practice).
For npm, the `node_modules` directory is cached based on our `npm-shrinkwrap.canonical.json` file.
For RubyGems, the `gemdir` of the current RVM-selected Ruby is cached based on the `pseudo_Gemfile.lock` file generated by our Travis build script. `pseudo_Gemfile.lock` contains the versions of Ruby and Jekyll that we're using (read our `.travis.yml` for details).
Travis does offer built-in caching on their paid plans, but this do-it-ourselves S3 solution is significantly cheaper since we only need caching and not Travis' other paid features.
```bash     python -c "import uuid; print(uuid.uuid4())"     ```
9. Determine and note what your bucket's ARN is. The ARN for an S3 bucket is of the form: `arn:aws:s3:::the-bucket-name-goes-here` 10. In the bucket's Properties pane, in the "Permissions" section, click the "Edit bucket policy" button. 11. Input and submit an IAM Policy that grants the user at least read+write rights to the bucket. AWS has a policy generator and some examples to help with crafting the policy. Here's the policy that Bootstrap uses, with the sensitive bits censored:
```json     {         "Version": "2012-10-17",         "Id": "PolicyTravisReadWriteNoAdmin",         "Statement": [             {                 "Sid": "StmtXXXXXXXXXXXXXX",                 "Effect": "Allow",                 "Principal": {                     "AWS": "arn:aws:iam::XXXXXXXXXXXXXX:user/travis-ci"                 },                 "Action": [                     "s3:AbortMultipartUpload",                     "s3:GetObjectVersion",                     "s3:ListBucket",                     "s3:DeleteObject",                     "s3:DeleteObjectVersion",                     "s3:GetObject",                     "s3:PutObject"                 ],                 "Resource": [                     "arn:aws:s3:::XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX",                     "arn:aws:s3:::XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/*"                 ]             }         ]     }     ```
12. If you want deletion from the cache to be done automatically based on age (like Bootstrap does): In the bucket's Properties pane, in the "Lifecycle" section, add a rule to expire/delete files based on creation date. 13. Install the [`travis` RubyGem](https://github.com/travis-ci/travis): `gem install travis` 14. Encrypt the environment variables:
```bash     travis encrypt --repo twbs/bootstrap "AWS_ACCESS_KEY_ID=XXX"     travis encrypt --repo twbs/bootstrap "AWS_SECRET_ACCESS_KEY=XXX"     travis encrypt --repo twbs/bootstrap "TWBS_S3_BUCKET=XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"     ```
14. Add the resulting secure environment variables to `.travis.yml`.
I consider jStorage complete, so only bug fixes are accepted but no new features please. jStorage has an extremely permissive license, you can do whatever you like with the code with no kind of attribution required. If you want a version of jStorage that has additional features or has some existing features stripped, you can fork or clone the code of jStorage and treat it as you like. You can even republish it under another name and license if you like, no constraints about that.
If you do not need to support IE6 and IE7, you don't even need something like jStorage. You can accomplish all your storage needs with the folowing simple functions with no dependencies whatsoever
/**      * Stores a value to the persistent browser storage      *      * @param {String} key The key name of stored object      * @param {Mixed} value A value to be stored, can be anything that is JSON compatible      */     function store(key, value){         window.localStorage[key] = JSON.stringify(value);     }
/**      * Loads a value from the persistent browser storage by a key      *      * @param {String} key The key name of stored object      * @return {Mixed} Stored value, can be anything that is JSON compatible      */     function retrieve(key){         var value;         try{             value = JSON.parse(window.localStorage[key]);         }catch(E){}         return value;     }
The usage of JSON is required to support storing other values than strings which is the "native" storage type for using localStorage API.
Use 4 spaces instead of tabs. Commas last. Use double quotes instead of single quotes where possible.
**If you don't need to support older Internet Explorer Versions (IE7 and below), use [simpleStorage](https://github.com/andris9/simpleStorage) instead.**
----
**jStorage** is a cross-browser key-value store database to store data locally in the browser - jStorage supports all major browsers, both in **desktop** (yes - even Internet Explorer 6) and in **mobile**.
Additionally jStorage is library agnostic, it works well with any other JavaScript library on the same webpage, be it jQuery, Prototype, MooTools or something else. Though you still need to have either a third party library (Prototype, MooTools) or [JSON2](https://github.com/douglascrockford/JSON-js/blob/master/json2.js) on the page to support older IE versions.
jStorage supports storing Strings, Numbers, JavaScript objects, Arrays and even native XML nodes which kind of makes it a JSON storage. jStorage also supports setting TTL values for auto expiring stored keys and - best of all - notifying other tabs/windows when a key has been changed, which makes jStorage also a local PubSub platform for web applications.
jStorage is pretty small, about 7kB when minified, 3kB gzipped.
```javascript $.jStorage.set(key, value, options) ```
Saves a value to local storage. key needs to be string otherwise an exception is thrown. value can be any JSONeable value, including objects and arrays or a XML node. Currently XML nodes can't be nested inside other objects: `$.jStorage.set("xml", xml_node)` is OK but `$.jStorage.set("xml", {xml: xml_node})` is not.
Options is an optional options object. Currently only available option is options.TTL which can be used to set the TTL value to the key `$.jStorage.set(key, value, {TTL: 1000})`. NB - if no TTL option value has been set, any currently used TTL value for the key will be removed.
```javascript value = $.jStorage.get(key) value = $.jStorage.get(key, "default value") ```
get retrieves the value if key exists, or default if it doesn't. key needs to be string otherwise an exception is thrown. default can be any value.
```javascript $.jStorage.deleteKey(key) ```
Removes a key from the storage. key needs to be string otherwise an exception is thrown.
```javascript $.jStorage.set("mykey", "keyvalue"); $.jStorage.setTTL("mykey", 3000); // expires in 3 seconds ```
Sets a TTL (in milliseconds) for an existing key. Use 0 or negative value to clear TTL.
```javascript ttl = $.jStorage.getTTL("mykey"); // TTL in milliseconds or 0 Gets remaining TTL (in milliseconds) for a key or 0 if not TTL has been set. ```
```javascript $.jStorage.flush() ```
Clears the cache.
```javascript $.jStorage.index() ```
Returns all the keys currently in use as an array.
```javascript var index = $.jStorage.index(); console.log(index); // ["key1","key2","key3"] ```
```javascript $.jStorage.storageSize() ```
Returns the size of the stored data in bytes
```javascript $.jStorage.currentBackend() ```
Returns the storage engine currently in use or false if none
```javascript $.jStorage.reInit() ```
Reloads the data from browser storage
```javascript $.jStorage.storageAvailable() ```
Returns true if storage is available
```javascript $.jStorage.subscribe("ch1", function(channel, payload){     console.log(payload+ " from " + channel); }); ```
Subscribes to a Publish/Subscribe channel (see demo)
```javascript $.jStorage.publish("ch1", "data"); ```
Publishes payload to a Publish/Subscribe channel (see demo)
```javascript $.jStorage.listenKeyChange("mykey", function(key, action){     console.log(key + " has been " + action); }); ```
Listens for updates for selected key. NB! even updates made in other windows/tabs are reflected, so this feature can also be used for some kind of publish/subscribe service.
If you want to listen for any key change, use `"*"` as the key name
```javascript $.jStorage.listenKeyChange("*", function(key, action){     console.log(key + " has been " + action); }); ```
```javascript $.jStorage.stopListening("mykey"); // cancel all listeners for "mykey" change ```
Stops listening for key change. If callback is set, only the used callback will be cleared, otherwise all listeners will be dropped.
Support jStorage development
[![Donate to author](https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=DB26KWR2BQX5W)
jStorage supports the following features:
* store and retrieve data from browser storage using any JSON compatible data format (+ native XML nodes)   * set TTL values to stored keys for auto expiring   * publish and subscribe to cross-window/tab events   * listen for key changes (update, delete) from the current or any other browser window   * use any browser since IE6, both in desktop and in mobile
Current availability: jStorage supports all major browsers - Internet Explorer 6+, Firefox 2+, Safari 4+, Chrome 4+, Opera 10.50+
If the browser doesn't support data caching, then no exceptions are raised - jStorage can still be used by the script but nothing is actually stored.
See [tests/index.html](http://www.jstorage.info/static/tests/index.html) for unit tests
Project homepage and docs: [www.jstorage.info](http://www.jstorage.info)
[Unlicense](http://unlicense.org/) Since version 0.4.7
**MIT** (versions up to 0.4.6)
[![Bitdeli Badge](https://d2weczhvl823v0.cloudfront.net/andris9/jstorage/trend.png)](https://bitdeli.com/free "Bitdeli Badge")
Changelog =========
* bugfix [#1813](https://github.com/moment/moment/issues/1813): fix moment().lang([key]) incompatibility
* incompatible changes     * [#1761](https://github.com/moment/moment/issues/1761): moments created without a language are no longer following the global language, in case it changes. Only newly created moments take the global language by default. In case you're affected by this, wait, comment on [#1797](https://github.com/moment/moment/issues/1797) and wait for a proper reimplementation     * [#1642](https://github.com/moment/moment/issues/1642): 45 days is no longer "a month" according to humanize, cutoffs for month, and year have changed. Hopefully your code does not depend on a particular answer from humanize (which it shouldn't anyway)     * [#1784](https://github.com/moment/moment/issues/1784): if you use the human readable English datetime format in a weird way (like storing them in a database) that would break when the format changes you're at risk.
* deprecations (old behavior will be dropped in 3.0)     * [#1761](https://github.com/moment/moment/issues/1761) `lang` is renamed to `locale`, `langData` -> `localeData`. Also there is now `defineLocale` that should be used when creating new locales     * [#1763](https://github.com/moment/moment/issues/1763) `add(unit, value)` and `subtract(unit, value)` are now deprecated. Use `add(value, unit)` and `subtract(value, unit)` instead.     * [#1759](https://github.com/moment/moment/issues/1759) rename `duration.toIsoString` to `duration.toISOString`. The js standard library and moment's `toISOString` follow that convention.
* new locales     * [#1789](https://github.com/moment/moment/issues/1789) Tibetan (bo)     * [#1786](https://github.com/moment/moment/issues/1786) Africaans (af)     * [#1778](https://github.com/moment/moment/issues/1778) Burmese (my)     * [#1727](https://github.com/moment/moment/issues/1727) Belarusian (be)
* bugfixes, locale bugfixes, performance improvements, features
* new languages
* [#1678](https://github.com/moment/moment/issues/1678) Bengali (bn)   * [#1628](https://github.com/moment/moment/issues/1628) Azerbaijani (az)   * [#1633](https://github.com/moment/moment/issues/1633) Arabic, Saudi Arabia (ar-sa)   * [#1648](https://github.com/moment/moment/issues/1648) Austrian German (de-at)
* features
* [#1663](https://github.com/moment/moment/issues/1663) configurable relative time thresholds   * [#1554](https://github.com/moment/moment/issues/1554) support anchor time in moment.calendar   * [#1693](https://github.com/moment/moment/issues/1693) support moment.ISO_8601 as parsing format   * [#1637](https://github.com/moment/moment/issues/1637) add moment.min and moment.max and deprecate min/max instance methods   * [#1704](https://github.com/moment/moment/issues/1704) support string value in add/subtract   * [#1647](https://github.com/moment/moment/issues/1647) add spm support (package manager)
* bugfixes
* languages   * [#1529](https://github.com/moment/moment/issues/1529) Serbian-Cyrillic (sr-cyr)   * [#1544](https://github.com/moment/moment/issues/1544), [#1546](https://github.com/moment/moment/issues/1546) Khmer Cambodia (km)
* features     * [#1419](https://github.com/moment/moment/issues/1419), [#1468](https://github.com/moment/moment/issues/1468), [#1467](https://github.com/moment/moment/issues/1467), [#1546](https://github.com/moment/moment/issues/1546) better handling of timezone-d moments around DST     * [#1462](https://github.com/moment/moment/issues/1462) add weeksInYear and isoWeeksInYear     * [#1475](https://github.com/moment/moment/issues/1475) support ordinal parsing     * [#1499](https://github.com/moment/moment/issues/1499) composer support     * [#1577](https://github.com/moment/moment/issues/1577), [#1604](https://github.com/moment/moment/issues/1604) put Date parsing in moment.createFromInputFallback so it can be properly deprecated and controlled in the future     * [#1545](https://github.com/moment/moment/issues/1545) extract two-digit year parsing in moment.parseTwoDigitYear, so it can be overwritten     * [#1590](https://github.com/moment/moment/issues/1590) (see [#1574](https://github.com/moment/moment/issues/1574)) set AMD global before module definition to better support non AMD module dependencies used in AMD environment     * [#1589](https://github.com/moment/moment/issues/1589) remove global in Node.JS environment (was not working before, nobody complained, was scheduled for removal anyway)     * [#1586](https://github.com/moment/moment/issues/1586) support quarter setting and parsing
* 18 bugs fixed
* languages   * [#1392](https://github.com/moment/moment/issues/1392) Armenian (hy-am)
* bugfixes   * [#1429](https://github.com/moment/moment/issues/1429) fixes [#1423](https://github.com/moment/moment/issues/1423) weird chrome-32 bug with js object creation   * [#1421](https://github.com/moment/moment/issues/1421) remove html entities from Welsh   * [#1418](https://github.com/moment/moment/issues/1418) fixes [#1401](https://github.com/moment/moment/issues/1401) improved non-padded tokens in strict matching   * [#1417](https://github.com/moment/moment/issues/1417) fixes [#1404](https://github.com/moment/moment/issues/1404) handle buggy moment object created by property cloning   * [#1398](https://github.com/moment/moment/issues/1398) fixes [#1397](https://github.com/moment/moment/issues/1397) fix Arabic-like week number parsing   * [#1396](https://github.com/moment/moment/issues/1396) add leftZeroFill(4) to GGGG and gggg formats   * [#1373](https://github.com/moment/moment/issues/1373) use lowercase for months and days in Catalan
* testing   * [#1374](https://github.com/moment/moment/issues/1374) run tests on multiple browser/os combos via SauceLabs and Travis
* New languages   * Luxemburish (lb) [1247](https://github.com/moment/moment/issues/1247)   * Serbian (rs) [1319](https://github.com/moment/moment/issues/1319)   * Tamil (ta) [1324](https://github.com/moment/moment/issues/1324)   * Macedonian (mk) [1337](https://github.com/moment/moment/issues/1337)
* Features   * [1311](https://github.com/moment/moment/issues/1311) Add quarter getter and format token `Q`   * [1303](https://github.com/moment/moment/issues/1303) strict parsing now respects number of digits per token (fix [1196](https://github.com/moment/moment/issues/1196))   * 0d30bb7 add jspm support   * [1347](https://github.com/moment/moment/issues/1347) improve zone parsing   * [1362](https://github.com/moment/moment/issues/1362) support merideam parsing in Korean
* 22 bugfixes
* **Deprecate** globally exported moment, will be removed in next major * New languages   * Farose (fo) [#1206](https://github.com/moment/moment/issues/1206)   * Tagalog/Filipino (tl-ph) [#1197](https://github.com/moment/moment/issues/1197)   * Welsh (cy) [#1215](https://github.com/moment/moment/issues/1215) * Bugfixes   * properly handle Z at the end of iso RegExp [#1187](https://github.com/moment/moment/issues/1187)   * chinese meridian time improvements [#1076](https://github.com/moment/moment/issues/1076)   * fix language tests [#1177](https://github.com/moment/moment/issues/1177)   * remove some failing tests (that should have never existed :))     [#1185](https://github.com/moment/moment/issues/1185)     [#1183](https://github.com/moment/moment/issues/1183)   * handle russian noun cases in weird cases [#1195](https://github.com/moment/moment/issues/1195)
Removed a trailing comma [1169] and fixed a bug with `months`, `weekdays` getters [#1171](https://github.com/moment/moment/issues/1171).
Changed isValid, added strict parsing. Week tokens parsing.
Fixed bug in string prototype test. Updated authors and contributors.
Added bower support.
Language files now use UMD.
Creating moment defaults to current date/month/year.
Added a bundle of moment and all language files.
Added better week support.
Added ability to set offset with `moment#zone`.
Added ability to set month or weekday from a string.
Added `moment#min` and `moment#max`
Added short form localized tokens.
Added ability to define language a string should be parsed in.
Added support for reversed add/subtract arguments.
Added support for `endOf('week')` and `startOf('week')`.
Fixed the logic for `moment#diff(Moment, 'months')` and `moment#diff(Moment, 'years')`
`moment#diff` now floors instead of rounds.
Normalized `moment#toString`.
Added `isSame`, `isAfter`, and `isBefore` methods.
Added better week support.
Added `moment#toJSON`
Bugfix: Fixed parsing of first century dates
Bugfix: Parsing 10Sep2001 should work as expected
Bugfix: Fixed wierdness with `moment.utc()` parsing.
Changed language ordinal method to return the number + ordinal instead of just the ordinal.
Changed two digit year parsing cutoff to match strptime.
Removed `moment#sod` and `moment#eod` in favor of `moment#startOf` and `moment#endOf`.
Removed `moment.humanizeDuration()` in favor of `moment.duration().humanize()`.
Removed the lang data objects from the top level namespace.
Duplicate `Date` passed to `moment()` instead of referencing it.
Bugfixes
Bugfixes
Added `moment.fn.endOf()` and `moment.fn.startOf()`.
Added validation via `moment.fn.isValid()`.
Made formatting method 3x faster. http://jsperf.com/momentjs-cached-format-functions
Add support for month/weekday callbacks in `moment.fn.format()`
Added instance specific languages.
Added two letter weekday abbreviations with the formatting token `dd`.
Various language updates.
Various bugfixes.
Added Durations.
Revamped parser to support parsing non-separated strings (YYYYMMDD vs YYYY-MM-DD).
Added support for millisecond parsing and formatting tokens (S SS SSS)
Added a getter for `moment.lang()`
Various bugfixes.
There are a few things deprecated in the 1.6.0 release.
1. The format tokens `z` and `zz` (timezone abbreviations like EST CST MST etc) will no longer be supported. Due to inconsistent browser support, we are unable to consistently produce this value. See [this issue](https://github.com/timrwood/moment/issues/162) for more background.
2. The method `moment.fn.native` is deprecated in favor of `moment.fn.toDate`. There continue to be issues with Google Closure Compiler throwing errors when using `native`, even in valid instances.
3. The way to customize am/pm strings is being changed. This would only affect you if you created a custom language file. For more information, see [this issue](https://github.com/timrwood/moment/pull/222).
Added UTC mode.
Added automatic ISO8601 parsing.
Various bugfixes.
Added `moment.fn.toDate` as a replacement for `moment.fn.native`.
Added `moment.fn.sod` and `moment.fn.eod` to get the start and end of day.
Various bugfixes.
Added support for parsing month names in the current language.
Added escape blocks for parsing tokens.
Added `moment.fn.calendar` to format strings like 'Today 2:30 PM', 'Tomorrow 1:25 AM', and 'Last Sunday 4:30 AM'.
Added `moment.fn.day` as a setter.
Various bugfixes
Added timezones to parser and formatter.
Added `moment.fn.isDST`.
Added `moment.fn.zone` to get the timezone offset in minutes.
Various bugfixes
Added time specific diffs (months, days, hours, etc)
Added `moment.fn.format` localized masks. 'L LL LLL LLLL' [issue 29](https://github.com/timrwood/moment/pull/29)
Fixed [issue 31](https://github.com/timrwood/moment/pull/31).
Added `moment.version` to get the current version.
Removed `window !== undefined` when checking if module exists to support browserify. [issue 25](https://github.com/timrwood/moment/pull/25)
Added convenience methods for getting and setting date parts.
Added better support for `moment.add()`.
Added better lang support in NodeJS.
Renamed library from underscore.date to Moment.js
Added Portuguese, Italian, and French language support
Added _date.lang() support. Added support for passing multiple formats to try to parse a date. _date("07-10-1986", ["MM-DD-YYYY", "YYYY-MM-DD"]); Made parse from string and single format 25% faster.
Bugfix for [issue 8](https://github.com/timrwood/underscore.date/pull/8) and [issue 9](https://github.com/timrwood/underscore.date/pull/9).
Bugfix for [issue 5](https://github.com/timrwood/underscore.date/pull/5).
Dropped the redundant `_date.date()` in favor of `_date()`. Removed `_date.now()`, as it is a duplicate of `_date()` with no parameters. Removed `_date.isLeapYear(yearNumber)`. Use `_date([yearNumber]).isLeapYear()` instead. Exposed customization options through the `_date.relativeTime`, `_date.weekdays`, `_date.weekdaysShort`, `_date.months`, `_date.monthsShort`, and `_date.ordinal` variables instead of the `_date.customize()` function.
Added date input formats for input strings.
Added underscore.date to npm. Removed dependencies on underscore.
Added `'z'` and `'zz'` to `_.date().format()`. Cleaned up some redundant code to trim off some bytes.
Cleaned up the namespace. Moved all date manipulation and display functions to the _.date() object.
Switched to the Underscore methodology of not mucking with the native objects' prototypes. Made chaining possible.
Changed date names to be a more pseudo standardized 'dddd, MMMM Do YYYY, h:mm:ss a'. Added `Date.prototype` functions `add`, `subtract`, `isdst`, and `isleapyear`.
Changed function names to be more concise. Changed date format from php date format to custom format.
Initial release
[![NPM version][npm-version-image]][npm-url] [![NPM downloads][npm-downloads-image]][npm-url] [![MIT License][license-image]][license-url] [![Build Status][travis-image]][travis-url]
A lightweight javascript date library for parsing, validating, manipulating, and formatting dates.
There are a number of small backwards incompatible changes with version 2.0.0. [See the full descriptions here](https://gist.github.com/timrwood/e72f2eef320ed9e37c51#backwards-incompatible-changes)
* Changed language ordinal method to return the number + ordinal instead of just the ordinal.
* Changed two digit year parsing cutoff to match strptime.
* Removed `moment#sod` and `moment#eod` in favor of `moment#startOf` and `moment#endOf`.
* Removed `moment.humanizeDuration()` in favor of `moment.duration().humanize()`.
* Removed the lang data objects from the top level namespace.
* Duplicate `Date` passed to `moment()` instead of referencing it.
Moment.js is freely distributable under the terms of the [MIT license](LICENSE).
[license-image]: http://img.shields.io/badge/license-MIT-blue.svg?style=flat [license-url]: LICENSE
[npm-url]: https://npmjs.org/package/moment [npm-version-image]: http://img.shields.io/npm/v/moment.svg?style=flat [npm-downloads-image]: http://img.shields.io/npm/dm/moment.svg?style=flat
[travis-url]: http://travis-ci.org/moment/moment [travis-image]: http://img.shields.io/travis/moment/moment/develop.svg?style=flat
bower distribution of [angular-file-upload](https://github.com/danialfarid/angular-file-upload). All issues and pull request must be sumbitted to [angular-file-upload](https://github.com/danialfarid/angular-file-upload)
Install with `bower`:
```shell bower install ng-file-upload ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular/angular-file-upload-shim.js"></script> <!--only needed if you support upload progress/abort or non HTML5 FormData browsers.--> <!-- NOTE: angular.file-upload-shim.js MUST BE PLACED BEFORE angular.js--> <script src="/bower_components/angular/angular.js"></script> <script src="/bower_components/angular/angular-file-upload.js"></script> ```
Select2 =======
Select2 is a jQuery-based replacement for select boxes. It supports searching, remote data sets, and infinite scrolling of results.
To get started, checkout examples and documentation at http://ivaynberg.github.com/select2
Use cases ---------
* Enhancing native selects with search. * Enhancing native selects with a better multi-select interface. * Loading data from JavaScript: easily load items via ajax and have them searchable. * Nesting optgroups: native selects only support one level of nested. Select2 does not have this restriction. * Tagging: ability to add new items on the fly. * Working with large, remote datasets: ability to partially load a dataset based on the search term. * Paging of large datasets: easy support for loading more pages when the results are scrolled to the end. * Templating: support for custom rendering of results and selections.
Browser compatibility --------------------- * IE 8+ * Chrome 8+ * Firefox 10+ * Safari 3+ * Opera 10.6+   Usage ----- You can source Select2 directly from a [CDN like JSDliver](http://www.jsdelivr.com/#!select2), [download it from this GitHub repo](https://github.com/ivaynberg/select2/tags), or use one of the integrations below.
Integrations ------------
* [Wicket-Select2](https://github.com/ivaynberg/wicket-select2) (Java / [Apache Wicket](http://wicket.apache.org)) * [select2-rails](https://github.com/argerim/select2-rails) (Ruby on Rails) * [AngularUI](http://angular-ui.github.com/#directives-select2) ([AngularJS](angularjs.org)) * [Django](https://github.com/applegrew/django-select2) * [Symfony](https://github.com/19Gerhard85/sfSelect2WidgetsPlugin) * [Symfony2](https://github.com/avocode/FormExtensions) * [Bootstrap 2](https://github.com/t0m/select2-bootstrap-css) and [Bootstrap 3](https://github.com/t0m/select2-bootstrap-css/tree/bootstrap3) (CSS skins) * [Meteor](https://github.com/nate-strauser/meteor-select2) (modern reactive JavaScript framework; + [Bootstrap 3 skin](https://github.com/esperadomedia/meteor-select2-bootstrap3-css/)) * [Meteor](https://jquery-select2.meteor.com) * [Yii 2.x](http://demos.krajee.com/widgets#select2) * [Yii 1.x](https://github.com/tonybolzan/yii-select2) * [AtmosphereJS](https://atmospherejs.com/package/jquery-select2)
* [Knockout.js](https://github.com/ivaynberg/select2/wiki/Knockout.js-Integration) * [Socket.IO](https://github.com/ivaynberg/select2/wiki/Socket.IO-Integration) * [PHP](https://github.com/ivaynberg/select2/wiki/PHP-Example) * [.Net MVC] (https://github.com/ivaynberg/select2/wiki/.Net-MVC-Example)
Internationalization (i18n) ---------------------------
Select2 supports multiple languages by simply including the right language JS file (`select2_locale_it.js`, `select2_locale_nl.js`, etc.) after `select2.js`.
Missing a language? Just copy `select2_locale_en.js.template`, translate it, and make a pull request back to Select2 here on GitHub.
Bug tracker -----------
Have a bug? Please create an issue here on GitHub!
https://github.com/ivaynberg/select2/issues
Mailing list ------------
Have a question? Ask on our mailing list!
select2@googlegroups.com
https://groups.google.com/d/forum/select2
Copyright and license ---------------------
Copyright 2012 Igor Vaynberg
This software is licensed under the Apache License, Version 2.0 (the "Apache License") or the GNU General Public License version 2 (the "GPL License"). You may choose either license to govern your use of this software only upon the condition that you accept all of the terms of either the Apache License or the GPL License.
You may obtain a copy of the Apache License and the GPL License in the LICENSE file, or at:
http://www.apache.org/licenses/LICENSE-2.0 http://www.gnu.org/licenses/gpl-2.0.html
Unless required by applicable law or agreed to in writing, software distributed under the Apache License or the GPL License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the Apache License and the GPL License for the specific language governing permissions and limitations under the Apache License and the GPL License.
__                       /\ \                                                         __      __  __    ___    \_\ \     __   _ __   ____    ___    ___   _ __    __       /\_\    ____     /\ \/\ \ /' _ `\  /'_  \  /'__`\/\  __\/ ,__\  / ___\ / __`\/\  __\/'__`\     \/\ \  /',__\     \ \ \_\ \/\ \/\ \/\ \ \ \/\  __/\ \ \//\__, `\/\ \__//\ \ \ \ \ \//\  __/  __  \ \ \/\__, `\      \ \____/\ \_\ \_\ \___,_\ \____\\ \_\\/\____/\ \____\ \____/\ \_\\ \____\/\_\ _\ \ \/\____/       \/___/  \/_/\/_/\/__,_ /\/____/ \/_/ \/___/  \/____/\/___/  \/_/ \/____/\/_//\ \_\ \/___/                                                                                   \ \____/                                                                                    \/___/
Underscore.js is a utility-belt library for JavaScript that provides support for the usual functional suspects (each, map, reduce, filter...) without extending any core JavaScript objects.
For Docs, License, Tests, and pre-packed downloads, see: http://underscorejs.org
Underscore is an open-sourced component of DocumentCloud: https://github.com/documentcloud
Many thanks to our contributors: https://github.com/jashkenas/underscore/contributors
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular/angular.js"></script> ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngAnimate). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-animate ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular-animate/angular-animate.js"></script> ```
And add `ngAnimate` as a dependency for your app:
```javascript angular.module('myApp', ['ngAnimate']); ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/api/ngAnimate).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngCookies). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-cookies ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular-cookies/angular-cookies.js"></script> ```
And add `ngCookies` as a dependency for your app:
```javascript angular.module('myApp', ['ngCookies']); ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/api/ngCookies).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Angular Dialog Service ======================
>**Please use one of the release versions rather than the Master Branch**.  The Master Branch has untested merges and changes and is a work in progress.  I urge you to always use a release version rather than linking directly to the Master Branch, as the Master Branch may change and may not always be backward compatible.
**v4.x.x + is not backward compatible with versions 1,2,3,3.1  Please refer to the changes section to view what is different in v4.0**
A complete AngularJS service with controllers and templates for generating application modals and dialogs for use with Angular-UI-Bootstrap and Twitter Bootstrap.  Supports, i18n, language translations for dialog headers, messages and buttons via angular-translate.
Demos -----  - v1.0 : [Codepen: http://codepen.io/m-e-conroy/pen/ALsdF](http://codepen.io/m-e-conroy/pen/ALsdF)  - v2.0 : [Codepen: http://codepen.io/m-e-conroy/pen/AmBpL](http://codepen.io/m-e-conroy/pen/AmBpL)  - v4.2 : [Codepen: http://codepen.io/m-e-conroy/pen/rkIqv](http://codepen.io/m-e-conroy/pen/rkIqv)  - v4.2 : [Codepen: with UI-Bootstrap Date Picker directive](http://codepen.io/m-e-conroy/pen/DAxzs)
Release Versions ---------------- - v1.0 : supports AngularJS 1.1.5 and below. - v2.0 : supports AngularJS 1.2 + - v3.0 : supports AngularJS 1.2 +, Angular UI Bootstrap 0.10.0 - v4.0.0 - v4.1.0 : supports AngularJS 1.2 +, Angular UI Bootstrap 0.10.0, Bootstrap 3 + - v4.2.0 - v5.x.x+ : supports AngularJS 1.2 +, Angular UI Bootstrap 0.11.0, Bootstrap 3.1 +
v5.1.0 ------ 1. Fixed Wait dialog template, header should now display a passed parameter header to the wait service.  Prior to this it would always display the default header whether or not a passed header parameter was used or not. 2. Default translations have been removed from the dialogs.main module to their own module, in order to support applications that were already using Angular-Translate and had already defined translation lists for 'en-US.'  Previously including dialogs.main would have overwritten those translation lists supplied elsewhere in an application.  To use the default translations: 	- Include the dialogs-default-translations.min.js file in your HTML file and add 'dialogs.default-translations' to your application's dependency list along with 'dialogs.main' 	- OR If you already had a translation list setup elsewhere in your application just copy the $translationProvider translation list in the dialogs-default-translations module to where-ever it is that you have your list configured
v5.0.0 ------ Re-introduction of the [opts] parameter to dialogs methods.  I had many complaints about removing method level options in favor of wholly using the provider instead.
1. dialogs.error(header,msg[,opts]) 2. dialogs.wait(header,msg,progress[,opts]) 3. dialogs.notify(header,msg[,opts]) 4. dialogs.confirm(header,msg[,opts]) 5. dialogs.create(url,ctrlr,data[,opts])
v4.2.0 ------ Bootstrap 3.1.1 / Angular UI Bootstrap 0.11.0 introduced a size property for dialogs.  This can be controlled via the provider or by the optional *sz* parameter to the dialog methods.
1. dialogs.error(header,msg[,sz]) 2. dialogs.wait(header,msg,progress[,sz]) 3. dialogs.notify(header,msg[,sz]) 4. dialogs.confirm(header,msg[,sz]) 5. dialogs.create(url,ctrlr,data[,sz])
v4.0.0 - 4.1.0 -------------- Removed *opts* and *static* parameters from dialog methods in favor of provider settings.  The dialogs service is now longer **$dialogs**, the *\$* has be removed as this is reserved for Angular core services.
1. dialogs.error(header,msg) 2. dialogs.wait(header,msg,progress) 3. dialogs.notify(header,msg) 4. dialogs.confirm(header,msg) 5. dialogs.create(url,ctrlr,data)
v1.0 - v3.1.0 ------------- Predefined dialogs/modals.
1. $dialogs.error(header,msg,[static]) 2. $dialogs.wait(header,msg,progess,[static]) 3. $dialogs.notify(header,msg,[static]) 4. $dialogs.confirm(header,msg,[static]) 5. $dialogs.create(url,ctrlr,data,opts)
Dependencies ------------
v1.0 ----
1.  [Angular JS](http://www.angularjs.org) (version 1.1.5 and less)  2.  [Angular UI Bootstrap](http://angular-ui.github.io/bootstrap/#/modal) (version <= 0.6.0, Non-Bootstrap 3 Branch) with embedded templates. 3.  [Twitter Bootstrap CSS](http://getbootstrap.com) (version 2)
v2.0 Additional Dependencies ---------------------------- 1.  All version 1.0 dependencies. 2.  [Angular JS ngSanitize](http://code.angularjs.org/1.2.1/angular-sanitize.min.js) 	- [ngSanitize](http://docs.angularjs.org/api/ngSanitize) (needed for ng-bind-html)
v3.0 ----
1.  AngularJS 1.2 + 2.  Angular UI Bootstrap 0.10.0 3.  Twitter Bootstrap CSS 3.0.3 4.  AngularJS ngSanitize
v4.0.0 - v4.1.0 ---------------
1. AngularJS 1.2 + 2. [Angular UI Bootstrap Modal 0.10.0, with templates](http://angular-ui.github.io/bootstrap/#/modal) 3. Twitter Bootstrap CSS 3 + (includes 3.1.1) 4. Angular ngSanitize 5. [Angular Translate](https://github.com/angular-translate)
v4.2.0 & v5.x.x --------------- Same as v4.0.0 with the exception of the following:
1. [Angular UI Bootstrap Modal 0.11.0, with templates](http://angular-ui.github.io/bootstrap/#/modal) 2. [Twitter Bootstrap CSS 3.1.x](http://getbootstrap.com)
CSS --- Included a css file that has a .modal class fix for Bootstrap and also has some predefined styles for the various modals described in the service.
**v3.0 css file has the .modal class removed that had been a fix for a Bootstrap 3 display problem.  This has since been rectified by Angular UI and Bootstrap.**
Changes -------
- v3.0
1.  Added support for Angular UI Bootstrap 0.10.0. 2.  Added the ability to customize the header on the error and wait dialogs. 3.  Added example files.
- v4.0.0 - v4.1.0
1.  Removed *\$* from the *\$dialogs* service as this is reserved for core AngularJS naming.  The service is now just *dialogs.*  Include **dialogs.main** in your application module in order to use the the *dialogs* service 2.  Changed *dialogs* service from factory to provider, you can now use **dialogsProvider** to set various options of the modals that were previously passed as parameters to the dialogs' service methods. 	- **dialogsProvider.useBackdrop([true,false,'static'])** - True or false to use a backdrop for the modal, 'static' to use a backdrop and disallow closing on mouse click of the backdrop. 	- **dialogsProvider.useEscClose([true,false])** - Whether or not to allow the use of the 'ESC' key to close the modal 	- **dialogsProvider.useClass([string])** - Sets an additional CSS class to the modal window 	- **dialogsProvider.useCopy([true,false])** - Determines whether to use angular.copy or not when passing a data object to the custom dialog service.  Setting this to false will allow the modal to retain the two-way binding with the calling controller - thus changing data in the modal will automatically change it in the calling controller's scope.  The default is setting is true, so if you want the two-way binding you need to set this to false.  3.  Main module is no longer *dialogs* as this would conflict with the new naming of the service.  It is now *dialogs.main,* include that in your application's module definition to use the *dialogs* service. 4.  Added i18n support via [Angular-Translate](https://github.com/angular-translate), use the *$translateProvider* to set language specific defaults.  Default language is currently *en-US.*  An example is provided in the example folder that will show you how to change the defaults from English to Spanish.  Translations can be set on the following: 	- DIALOGS_ERROR (modal header) 	- DIALOGS_ERROR_MSG 	- DIALOGS_CLOSE (modal button) 	- DIALOGS_PLEASE_WAIT (modal header) 	- DIALOGS_PLEASE_WAIT_ELIPS (modal header) 	- DIALOGS_PLEASE_WAIT_MSG 	- DIALOGS_PERCENT_COMPLETE (modal message partial) 	- DIALOGS_NOTIFICATION (modal header) 	- DIALOGS_NOTIFICATION_MSG 	- DIALOGS_CONFIRMATION (modal header) 	- DIALOGS_CONFIRMATION_MSG 	- DIALOGS_OK (modal button) 	- DIALOGS_YES (modal button) 	- DIALOGS_NO (modal button)
- v4.2.0
1. Supports everything described above in v4.0.0 - v4.1.0 and added the following
2. dialogsProvider.setSize(['sm','lg']) - This will set modal size application wide, but can be overridden using the *sz* parameter added to each dialog method call.
- v5.0.0
1. Optionally pass in options object, possible overrides are as follows
```    opts = {         'keyboard': true or false         'backdrop': 'static' or true or false         'size': 'sm' or 'lg' //small or large modal size         'windowClass': 'dialogs-default' // additional CSS class(es) to be added to a modal window         'copy': true or false // used only with create custom dialog     }     ```
- v5.1.0
1. Separated out the default translations into their own module: **dialogs-default-translations.js**  Include this or the "min" version in your application if you are not already using $translationProvider elsewhere, otherwise just copy the translation list within the module to your translation list for 'en-US.'
Notes -----
- Angular Translate: v4.0 requires [Angular-Translate](https://github.com/angular-translate) be included. - Bootstrap 3: There's a problem with the actual modal being displayed even though it appears in the HTML code to be present.  I found that adding a "display: block" to Bootstrap 3's .modal class solved the problem. *(v3.0 of this service no longer requires this fix)* - It should not rely on including the Bootstrap JS. - For version 2.0 + of this service module do not forget to include the *ngSanitize* Angular module.
> Written with [StackEdit](https://stackedit.io/).
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngMock). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-mocks ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/guide/dev_guide.unit-testing).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngResource). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-resource ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular-resource/angular-resource.js"></script> ```
And add `ngResource` as a dependency for your app:
```javascript angular.module('myApp', ['ngResource']); ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/api/ngResource).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
This repo is for distribution on `bower`. The source for this module is in the [main AngularJS repo](https://github.com/angular/angular.js/tree/master/src/ngSanitize). Please file issues and pull requests against that repo.
Install with `bower`:
```shell bower install angular-sanitize ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular-sanitize/angular-sanitize.js"></script> ```
And add `ngSanitize` as a dependency for your app:
```javascript angular.module('myApp', ['ngSanitize']); ```
Documentation is available on the [AngularJS docs site](http://docs.angularjs.org/api/ngSanitize).
The MIT License
Copyright (c) 2010-2012 Google, Inc. http://angularjs.org
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- **accordion:**    - support `is-disabled` state ([9c43ae7c](http://github.com/angular-ui/bootstrap/commit/9c43ae7c))   - **alert:**    - add WAI-ARIA markup ([9a2638bf](http://github.com/angular-ui/bootstrap/commit/9a2638bf))   - **button:**    - allow uncheckable radio button ([82df4fb1](http://github.com/angular-ui/bootstrap/commit/82df4fb1))   - **carousel:**    - Support swipe for touchscreen devices ([85140f84](http://github.com/angular-ui/bootstrap/commit/85140f84))   - **dateParser:**    - add `dateParser` service ([bd2ae0ee](http://github.com/angular-ui/bootstrap/commit/bd2ae0ee))   - **datepicker:**    - add `datepicker-mode`, `init-date` & today hint ([7f4b40eb](http://github.com/angular-ui/bootstrap/commit/7f4b40eb))     - make widget accessible ([2423f6d4](http://github.com/angular-ui/bootstrap/commit/2423f6d4))     - full six-week calendar ([b0b14343](http://github.com/angular-ui/bootstrap/commit/b0b14343))   - **dropdown:**    - add WAI-ARIA attributes ([22ebd230](http://github.com/angular-ui/bootstrap/commit/22ebd230))     - focus toggle element when opening or closing with Esc` ([f715d052](http://github.com/angular-ui/bootstrap/commit/f715d052))   - **dropdownToggle:**    - support programmatic trigger & toggle callback ([ae31079c](http://github.com/angular-ui/bootstrap/commit/ae31079c))     - add support for `escape` key ([1417c548](http://github.com/angular-ui/bootstrap/commit/1417c548))   - **modal:**    - support custom template for modal window ([96def3d6](http://github.com/angular-ui/bootstrap/commit/96def3d6))     - support modal window sizes ([976f6083](http://github.com/angular-ui/bootstrap/commit/976f6083))     - improve accessibility - add role='dialog' ([60cee9dc](http://github.com/angular-ui/bootstrap/commit/60cee9dc))   - **pagination:**    - plug into `ngModel` controller ([d65901cf](http://github.com/angular-ui/bootstrap/commit/d65901cf))   - **progressbar:**    - make widget accessible ([9dfe3157](http://github.com/angular-ui/bootstrap/commit/9dfe3157))   - **rating:**    - plug into `ngModel` controller ([47e227f6](http://github.com/angular-ui/bootstrap/commit/47e227f6))     - make widget accessible ([4f56e60e](http://github.com/angular-ui/bootstrap/commit/4f56e60e))   - **tooltip:**    - support more positioning options ([3704db9a](http://github.com/angular-ui/bootstrap/commit/3704db9a))   - **typeahead:**    - add WAI-ARIA markup ([5ca23e97](http://github.com/angular-ui/bootstrap/commit/5ca23e97))     - add `aria-owns` & `aria-activedescendant` roles ([4c76a858](http://github.com/angular-ui/bootstrap/commit/4c76a858))
- **alert:**    - use interpolation for type attribute ([f0a129ad](http://github.com/angular-ui/bootstrap/commit/f0a129ad))     - add `alert-dismissable` class ([794954af](http://github.com/angular-ui/bootstrap/commit/794954af))   - **carousel:**    - correct glyphicon ([3b6ab25b](http://github.com/angular-ui/bootstrap/commit/3b6ab25b))   - **datepicker:**    - remove unneeded date creation ([68cb2e5a](http://github.com/angular-ui/bootstrap/commit/68cb2e5a))     - `Today` button should not set time ([e1993491](http://github.com/angular-ui/bootstrap/commit/e1993491))     - mark input field as invalid if the date is invalid ([467dd159](http://github.com/angular-ui/bootstrap/commit/467dd159))     - rename `dateFormat` to `datepickerPopup` in datepickerPopupConfig ([93da30d5](http://github.com/angular-ui/bootstrap/commit/93da30d5))     - parse input using dateParser ([e0eb1bce](http://github.com/angular-ui/bootstrap/commit/e0eb1bce))   - **dropdown:**   - use $animate for adding and removing classes ([e8d5fefc](http://github.com/angular-ui/bootstrap/commit/e8d5fefc))     - unbind toggle element event on scope destroy ([890e2d37](http://github.com/angular-ui/bootstrap/commit/890e2d37))     - do not call `on-toggle` initially ([004dd1de](http://github.com/angular-ui/bootstrap/commit/004dd1de))     - ensure `on-toggle` works when `is-open` is not used ([06ad3bd5](http://github.com/angular-ui/bootstrap/commit/06ad3bd5))   - **modal:**   - destroy modal scope after animation end ([dfc36fd9](http://github.com/angular-ui/bootstrap/commit/dfc36fd9))     - backdrop z-index when stacking modals ([94a7f593](http://github.com/angular-ui/bootstrap/commit/94a7f593))     - give a reason of rejection when escape key pressed ([cb31b875](http://github.com/angular-ui/bootstrap/commit/cb31b875))     - prevent default event when closing via escape key ([da951222](http://github.com/angular-ui/bootstrap/commit/da951222))   - toggle 'modal-open' class after animation ([4d641ca7](http://github.com/angular-ui/bootstrap/commit/4d641ca7)) - **pagination:**    - take maxSize defaults into account ([a294c87f](http://github.com/angular-ui/bootstrap/commit/a294c87f))   - **position:**    - remove deprecated body scrollTop and scrollLeft ([1ba07c1b](http://github.com/angular-ui/bootstrap/commit/1ba07c1b))   - **progressbar:**    - allow fractional values for bar width ([0daa7a74](http://github.com/angular-ui/bootstrap/commit/0daa7a74))     - number filter in bar template and only for percent ([378a9337](http://github.com/angular-ui/bootstrap/commit/378a9337))   - **tabs:**    - fire deselect before select callback ([7474c47b](http://github.com/angular-ui/bootstrap/commit/7474c47b))     - use interpolation for type attribute ([83ceb78a](http://github.com/angular-ui/bootstrap/commit/83ceb78a))     - remove `tabbable` class required for left/right tabs ([19468331](http://github.com/angular-ui/bootstrap/commit/19468331))   - **timepicker:**    - evaluate correctly the `readonly-input` attribute ([f9b6c496](http://github.com/angular-ui/bootstrap/commit/f9b6c496))   - **tooltip:**    - animation causes tooltip to hide on show ([2b429f5d](http://github.com/angular-ui/bootstrap/commit/2b429f5d))   - **typeahead:**    - correctly handle append to body attribute ([10785736](http://github.com/angular-ui/bootstrap/commit/10785736))     - correctly higlight numeric matches ([09678b12](http://github.com/angular-ui/bootstrap/commit/09678b12))     - loading callback updates after blur ([6a830116](http://github.com/angular-ui/bootstrap/commit/6a830116))     - incompatibility with ng-focus ([d0024931](http://github.com/angular-ui/bootstrap/commit/d0024931))
- **alert:**   Use interpolation for type attribute.
Before:
```html   <alert type="'info'" ...></alert >   ```   or   ```html   <alert type="alert.type" ...></alert >   ```
After:
```html   <alert type="info" ...></alert >   ```   or   ```html   <alert type="{{alert.type}}" ...></alert >   ```
- **datepicker:**
`show-weeks` is no longer a watched attribute `*-format` attributes have been renamed to `format-*` `min` attribute has been renamed to `min-date` `max` attribute has been renamed to `max-date`
- **pagination:**
Both `pagination` and `pager` are now integrated with `ngModelController`.  * `page` is replaced from `ng-model`.  * `on-select-page` is removed since `ng-change` can now be used.
Before:
<pagination page="current" on-select-page="changed(page)" ...></pagination>
After:
<pagination ng-model="current" ng-change="changed()" ...></pagination>
- **rating:**   `rating` is now integrated with `ngModelController`.  * `value` is replaced from `ng-model`.
Before:
<rating value="rate" ...></rating>
After:
<rating ng-model="rate" ...></rating>
- **tabs:**
Use interpolation for type attribute.
Before:
<tabset type="'pills'" ...></tabset >   or   <tabset type="navtype" ...></tabset>
After:
<tabset type="pills" ...></tabset>   or   <tabset type="{{navtype}}" ...></tabset>   # 0.10.0 (2014-01-13)
_This release adds AngularJS 1.2 support_
- **modal:**    - expose dismissAll on $modalStack ([bc8d21c1](http://github.com/angular-ui/bootstrap/commit/bc8d21c1))
- **datepicker:**    - evaluate `show-weeks` from `datepicker-options` ([92c1715f](http://github.com/angular-ui/bootstrap/commit/92c1715f))   - **modal:**    - leaking watchers due to scope re-use ([0754ad7b](http://github.com/angular-ui/bootstrap/commit/0754ad7b))     - support close animation ([1933488c](http://github.com/angular-ui/bootstrap/commit/1933488c))   - **timepicker:**    - add correct type for meridian button ([bcf39efe](http://github.com/angular-ui/bootstrap/commit/bcf39efe))   - **tooltip:**    - performance and scope fixes ([c0df3201](http://github.com/angular-ui/bootstrap/commit/c0df3201))
_This release adds Bootstrap3 support_
- **accordion:**    - convert to bootstrap3 panel styling ([458a9bd3](http://github.com/angular-ui/bootstrap/commit/458a9bd3))   - **carousel:**    - some changes for Bootstrap3 ([1f632b65](http://github.com/angular-ui/bootstrap/commit/1f632b65))   - **collapse:**    - make collapse work with bootstrap3 ([517dff6e](http://github.com/angular-ui/bootstrap/commit/517dff6e))   - **datepicker:**    - update to Bootstrap 3 ([37684330](http://github.com/angular-ui/bootstrap/commit/37684330))   - **modal:**    - added bootstrap3 support ([444c488d](http://github.com/angular-ui/bootstrap/commit/444c488d))   - **pagination:**    - support bootstrap3 ([3db699d7](http://github.com/angular-ui/bootstrap/commit/3db699d7))   - **progressbar:**    - update to bootstrap3 ([5bcff623](http://github.com/angular-ui/bootstrap/commit/5bcff623))   - **rating:**    - update rating to bootstrap3 ([7e60284e](http://github.com/angular-ui/bootstrap/commit/7e60284e))   - **tabs:**    - add nav-justified ([3199dd88](http://github.com/angular-ui/bootstrap/commit/3199dd88))   - **timepicker:**    - restyled for bootstrap 3 ([6724a721](http://github.com/angular-ui/bootstrap/commit/6724a721))   - **typeahead:**    - update to Bootstrap 3 ([eadf934a](http://github.com/angular-ui/bootstrap/commit/eadf934a))
- **alert:**    - update template to Bootstrap 3 ([dfc3b0bd](http://github.com/angular-ui/bootstrap/commit/dfc3b0bd))   - **collapse:**    - Prevent consecutive transitions & tidy up code ([b0032d68](http://github.com/angular-ui/bootstrap/commit/b0032d68))     - fixes after rebase ([dc02ad1d](http://github.com/angular-ui/bootstrap/commit/dc02ad1d))   - **rating:**    - user glyhicon classes ([d221d517](http://github.com/angular-ui/bootstrap/commit/d221d517))   - **timepicker:**    - fix look with bootstrap3 ([9613b61b](http://github.com/angular-ui/bootstrap/commit/9613b61b))   - **tooltip:**    - re-position tooltip after draw ([a99b3608](http://github.com/angular-ui/bootstrap/commit/a99b3608))
- **datepicker:**    - option whether to display button bar in popup ([4d158e0d](http://github.com/angular-ui/bootstrap/commit/4d158e0d))   - **modal:**    - add modal-open class to body on modal open ([e76512fa](http://github.com/angular-ui/bootstrap/commit/e76512fa))   - **progressbar:**    - add `max` attribute & support transclusion ([365573ab](http://github.com/angular-ui/bootstrap/commit/365573ab))   - **timepicker:**    - default meridian labels based on locale ([8b1ab79a](http://github.com/angular-ui/bootstrap/commit/8b1ab79a))   - **typeahead:**    - add typeahead-append-to-body option ([dd8eac22](http://github.com/angular-ui/bootstrap/commit/dd8eac22))
- **accordion:**    - correct `is-open` handling for dynamic groups ([9ec21286](http://github.com/angular-ui/bootstrap/commit/9ec21286))   - **carousel:**    - cancel timer on scope destruction ([5b9d929c](http://github.com/angular-ui/bootstrap/commit/5b9d929c))     - cancel goNext on scope destruction ([7515df45](http://github.com/angular-ui/bootstrap/commit/7515df45))   - **collapse:**    - dont animate height changes from 0 to 0 ([81e014a8](http://github.com/angular-ui/bootstrap/commit/81e014a8))   - **datepicker:**    - set default zero time after no date selected ([93cd0df8](http://github.com/angular-ui/bootstrap/commit/93cd0df8))     - fire `ngChange` on today/clear button press ([6b1c68fb](http://github.com/angular-ui/bootstrap/commit/6b1c68fb))     - remove datepicker's popup on scope destroy ([48955d69](http://github.com/angular-ui/bootstrap/commit/48955d69))     - remove edge case position updates ([1fbcb5d6](http://github.com/angular-ui/bootstrap/commit/1fbcb5d6))   - **modal:**    - put backdrop in before window ([d64f4a97](http://github.com/angular-ui/bootstrap/commit/d64f4a97))     - grab reference to body when it is needed in lieu of when the factory is created ([dd415a98](http://github.com/angular-ui/bootstrap/commit/dd415a98))   - focus freshly opened modal ([709e679c](http://github.com/angular-ui/bootstrap/commit/709e679c))     - properly animate backdrops on each modal opening ([672a557a](http://github.com/angular-ui/bootstrap/commit/672a557a))   - **tabs:**    - make nested tabs work ([c9acebbe](http://github.com/angular-ui/bootstrap/commit/c9acebbe))   - **tooltip:**    - update tooltip content when empty ([60515ae1](http://github.com/angular-ui/bootstrap/commit/60515ae1))     - support IE8 ([5dd98238](http://github.com/angular-ui/bootstrap/commit/5dd98238))     - unbind element events on scope destroy ([3fe7aa8c](http://github.com/angular-ui/bootstrap/commit/3fe7aa8c))     - respect animate attribute ([54e614a8](http://github.com/angular-ui/bootstrap/commit/54e614a8))
- **progressbar:**   The onFull/onEmpty handlers & auto/stacked types have been removed.
To migrate your code change your markup like below.
Before:
```html   <progress percent="var" class="progress-warning"></progress> ```
After:
```html   <progressbar value="var" type="warning"></progressbar> ```
and for stacked instead of passing array/objects you can do:
```html   <progress><bar ng-repeat="obj in objs" value="obj.var" type="{{obj.type}}"></bar></progress> ```
- **datepicker:**    - add i18n support for bar buttons in popup ([c6ba8d7f](http://github.com/angular-ui/bootstrap/commit/c6ba8d7f))     - dynamic date format for popup ([aa3eaa91](http://github.com/angular-ui/bootstrap/commit/aa3eaa91))     - datepicker-append-to-body attribute ([0cdc4609](http://github.com/angular-ui/bootstrap/commit/0cdc4609))   - **dropdownToggle:**    - disable dropdown when it has the disabled class ([104bdd1b](http://github.com/angular-ui/bootstrap/commit/104bdd1b))   - **tooltip:**    - add ability to enable / disable tooltip ([5d9bd058](http://github.com/angular-ui/bootstrap/commit/5d9bd058))
- **accordion:**    - assign `is-open` to correct scope ([157f614a](http://github.com/angular-ui/bootstrap/commit/157f614a))   - **collapse:**    - remove element height watching ([a72c635c](http://github.com/angular-ui/bootstrap/commit/a72c635c))     - add the "in" class for expanded panels ([9eca35a8](http://github.com/angular-ui/bootstrap/commit/9eca35a8))   - **datepicker:**   - some IE8 compatibility improvements ([4540476f](http://github.com/angular-ui/bootstrap/commit/4540476f))     - set popup initial position in append-to-body case ([78a1e9d7](http://github.com/angular-ui/bootstrap/commit/78a1e9d7))   - properly handle showWeeks config option ([570dba90](http://github.com/angular-ui/bootstrap/commit/570dba90))   - **modal:**    - correctly close modals with no backdrop ([e55c2de3](http://github.com/angular-ui/bootstrap/commit/e55c2de3))   - **pagination:**    - fix altering of current page caused by totals change ([81164dae](http://github.com/angular-ui/bootstrap/commit/81164dae))     - handle extreme values for `total-items` ([8ecf93ed](http://github.com/angular-ui/bootstrap/commit/8ecf93ed))   - **position:**    - correct positioning for SVG elements ([968e5407](http://github.com/angular-ui/bootstrap/commit/968e5407))   - **tabs:**    - initial tab selection ([a08173ec](http://github.com/angular-ui/bootstrap/commit/a08173ec))   - **timepicker:**    - use html5 for input elements ([53709f0f](http://github.com/angular-ui/bootstrap/commit/53709f0f))   - **tooltip:**    - restore html-unsafe compatibility with AngularJS 1.2 ([08d8b21d](http://github.com/angular-ui/bootstrap/commit/08d8b21d))     - hide tooltips when content becomes empty ([cf5c27ae](http://github.com/angular-ui/bootstrap/commit/cf5c27ae))     - tackle DOM node and event handlers leak ([0d810acd](http://github.com/angular-ui/bootstrap/commit/0d810acd))   - **typeahead:**    - do not set editable error when input is empty ([006986db](http://github.com/angular-ui/bootstrap/commit/006986db))     - remove popup flickering ([dde804b6](http://github.com/angular-ui/bootstrap/commit/dde804b6))     - don't show matches if an element is not focused ([d1f94530](http://github.com/angular-ui/bootstrap/commit/d1f94530))     - fix loading callback when deleting characters ([0149eff6](http://github.com/angular-ui/bootstrap/commit/0149eff6))     - prevent accidental form submission on ENTER ([253c49ff](http://github.com/angular-ui/bootstrap/commit/253c49ff))     - evaluate matches source against a correct scope ([fd21214d](http://github.com/angular-ui/bootstrap/commit/fd21214d))     - support IE8 ([0e9f9980](http://github.com/angular-ui/bootstrap/commit/0e9f9980))
- **modal:**    - rewrite $dialog as $modal ([d7a48523](http://github.com/angular-ui/bootstrap/commit/d7a48523))     - add support for custom window settings ([015625d1](http://github.com/angular-ui/bootstrap/commit/015625d1))     - expose $close and $dismiss options on modal's scope ([8d153acb](http://github.com/angular-ui/bootstrap/commit/8d153acb))   - **pagination:**    - `total-items` & optional `items-per-page` API ([e55d9063](http://github.com/angular-ui/bootstrap/commit/e55d9063))   - **rating:**    - add support for custom icons per instance ([20ab01ad](http://github.com/angular-ui/bootstrap/commit/20ab01ad))   - **timepicker:**    - plug into `ngModel` controller ([b08e993f](http://github.com/angular-ui/bootstrap/commit/b08e993f))
- **carousel:**    - correct reflow triggering on FFox and Safari ([d34f2de1](http://github.com/angular-ui/bootstrap/commit/d34f2de1))   - **datepicker:**    - correctly manage focus without jQuery present ([d474824b](http://github.com/angular-ui/bootstrap/commit/d474824b))     - compatibility with angular 1.1.5 and no jquery ([bf30898d](http://github.com/angular-ui/bootstrap/commit/bf30898d))     - use $setViewValue for inner changes ([dd99f35d](http://github.com/angular-ui/bootstrap/commit/dd99f35d)) - **modal:**   - insert backdrop before modal window ([d870f212](http://github.com/angular-ui/bootstrap/commit/d870f212))   - ie8 fix after $modal rewrite ([ff9d969e](http://github.com/angular-ui/bootstrap/commit/ff9d969e))   - opening a modal should not change default options ([82532d1b](http://github.com/angular-ui/bootstrap/commit/82532d1b))   - backdrop should cover previously opened modals ([7fce2fe8](http://github.com/angular-ui/bootstrap/commit/7fce2fe8))   - allow replacing object with default options ([8e7fbf06](http://github.com/angular-ui/bootstrap/commit/8e7fbf06)) - **position:**   - fallback for IE8's scrollTop/Left for offset ([9aecd4ed](http://github.com/angular-ui/bootstrap/commit/9aecd4ed))   - **tabs:**    - add DI array-style annotations ([aac4a0dd](http://github.com/angular-ui/bootstrap/commit/aac4a0dd))     - evaluate `vertical` on parent scope ([9af6f96e](http://github.com/angular-ui/bootstrap/commit/9af6f96e))   - **timepicker:**    - add type attribute for meridian button ([1f89fd4b](http://github.com/angular-ui/bootstrap/commit/1f89fd4b))   - **tooltip:**    - remove placement='mouse' option ([17163c22](http://github.com/angular-ui/bootstrap/commit/17163c22))   - **typeahead:**    - fix label rendering for equal model and items names ([5de71216](http://github.com/angular-ui/bootstrap/commit/5de71216))     - set validity flag for non-editable inputs ([366e0c8a](http://github.com/angular-ui/bootstrap/commit/366e0c8a))     - plug in front of existing parsers ([80cef614](http://github.com/angular-ui/bootstrap/commit/80cef614))     - highlight return match if no query ([45dd9be1](http://github.com/angular-ui/bootstrap/commit/45dd9be1))     - keep pop-up on clicking input ([5f9e270d](http://github.com/angular-ui/bootstrap/commit/5f9e270d))     - remove dependency on ng-bind-html-unsafe ([75893393](http://github.com/angular-ui/bootstrap/commit/75893393))
- **modal:**
* `$dialog` service was refactored into `$modal` * `modal` directive was removed - use the `$modal` service instead
Check the documentation for the `$modal` service to migrate from `$dialog`
- **pagination:**   API has undergone some changes in order to be easier to use.  * `current-page` is replaced from `page`.  * Number of pages is not defined by `num-pages`, but from `total-items` &   `items-per-page` instead. If `items-per-page` is missing, default is 10.  * `num-pages` still exists but is just readonly.
Before:
```html   <pagination num-pages="10" ...></pagination> ```
After:
```html   <pagination total-items="100" ...></pagination> ```
- **tooltip:**
The placment='mouse' is gone with no equivalent   # 0.5.0 (2013-08-04)
- **buttons:**    - support dynamic true / false values in btn-checkbox ([3e30cd94](http://github.com/angular-ui/bootstrap/commit/3e30cd94))   - **datepicker:**    - `ngModelController` plug & new `datepickerPopup` ([dab18336](http://github.com/angular-ui/bootstrap/commit/dab18336))   - **rating:**    - added onHover and onLeave. ([5b1115e3](http://github.com/angular-ui/bootstrap/commit/5b1115e3))   - **tabs:**    - added onDeselect callback, used similarly as onSelect ([fe47c9bb](http://github.com/angular-ui/bootstrap/commit/fe47c9bb))     - add the ability to set the direction of the tabs ([220e7b60](http://github.com/angular-ui/bootstrap/commit/220e7b60))   - **typeahead:**    - support custom templates for matched items ([e2238174](http://github.com/angular-ui/bootstrap/commit/e2238174))     - expose index to custom templates ([5ffae83d](http://github.com/angular-ui/bootstrap/commit/5ffae83d))
- **datepicker:**    - handle correctly `min`/`max` when cleared ([566bdd16](http://github.com/angular-ui/bootstrap/commit/566bdd16))     - add type attribute for buttons ([25caf5fb](http://github.com/angular-ui/bootstrap/commit/25caf5fb))   - **pagination:**    - handle `currentPage` number as string ([b1fa7bb8](http://github.com/angular-ui/bootstrap/commit/b1fa7bb8))     - use interpolation for text attributes ([f45815cb](http://github.com/angular-ui/bootstrap/commit/f45815cb))   - **popover:**    - don't unbind event handlers created by other directives ([56f624a2](http://github.com/angular-ui/bootstrap/commit/56f624a2))     - correctly position popovers appended to body ([93a82af0](http://github.com/angular-ui/bootstrap/commit/93a82af0))   - **rating:**    - evaluate `max` attribute on parent scope ([60619d51](http://github.com/angular-ui/bootstrap/commit/60619d51))   - **tabs:**    - make tab contents be correctly connected to parent (#524) ([be7ecff0](http://github.com/angular-ui/bootstrap/commit/be7ecff0))     - Make tabset template correctly use tabset attributes (#584) ([8868f236](http://github.com/angular-ui/bootstrap/commit/8868f236))     - fix tab content compiling wrong (Closes #599, #631, #574) ([224bc2f5](http://github.com/angular-ui/bootstrap/commit/224bc2f5))     - make tabs added with active=true be selected ([360cd5ca](http://github.com/angular-ui/bootstrap/commit/360cd5ca))     - if tab is active at start, always select it ([ba1f741d](http://github.com/angular-ui/bootstrap/commit/ba1f741d))   - **timepicker:**    - prevent date change ([ee741707](http://github.com/angular-ui/bootstrap/commit/ee741707))     - added wheel event to enable mousewheel on Firefox ([8dc92afa](http://github.com/angular-ui/bootstrap/commit/8dc92afa))   - **tooltip:**    - fix positioning inside scrolling element ([63ae7e12](http://github.com/angular-ui/bootstrap/commit/63ae7e12))     - triggers should be local to tooltip instances ([58e8ef4f](http://github.com/angular-ui/bootstrap/commit/58e8ef4f))     - correctly handle initial events unbinding ([4fd5bf43](http://github.com/angular-ui/bootstrap/commit/4fd5bf43))     - bind correct 'hide' event handler ([d50b0547](http://github.com/angular-ui/bootstrap/commit/d50b0547))   - **typeahead:**    - play nicelly with existing formatters ([d2df0b35](http://github.com/angular-ui/bootstrap/commit/d2df0b35))     - properly render initial input value ([c4e169cb](http://github.com/angular-ui/bootstrap/commit/c4e169cb))     - separate text field rendering and drop down rendering ([ea1e858a](http://github.com/angular-ui/bootstrap/commit/ea1e858a))     - fixed waitTime functionality ([90a8aa79](http://github.com/angular-ui/bootstrap/commit/90a8aa79))     - correctly close popup on match selection ([624fd5f5](http://github.com/angular-ui/bootstrap/commit/624fd5f5))
- **pagination:**   The 'first-text', 'previous-text', 'next-text' and 'last-text'   attributes are now interpolated.
To migrate your code, remove quotes for constant attributes and/or   interpolate scope variables.
Before:
```html   <pagination first-text="'<<'" ...></pagination> ```   and/or
```html   $scope.var1 = '<<';   <pagination first-text="var1" ...></pagination> ```   After:
```html   <pagination first-text="<<" ...></pagination> ```   and/or
```html   $scope.var1 = '<<';   <pagination first-text="{{var1}}" ...></pagination> ```
- **buttons:**    - support dynamic values in btn-radio ([e8c5b548](http://github.com/angular-ui/bootstrap/commit/e8c5b548))   - **carousel:**    - add option to prevent pause ([5f895c13](http://github.com/angular-ui/bootstrap/commit/5f895c13))   - **datepicker:**    - add datepicker directive ([30a00a07](http://github.com/angular-ui/bootstrap/commit/30a00a07))   - **pagination:**    - option for different mode when maxSize ([a023d082](http://github.com/angular-ui/bootstrap/commit/a023d082))     - add pager directive ([d9526475](http://github.com/angular-ui/bootstrap/commit/d9526475))   - **tabs:**    - Change directive name, add features ([c5326595](http://github.com/angular-ui/bootstrap/commit/c5326595))     - support disabled state ([2b78dd16](http://github.com/angular-ui/bootstrap/commit/2b78dd16))     - add support for vertical option ([88d17a75](http://github.com/angular-ui/bootstrap/commit/88d17a75))     - add support for other navigation types, like 'pills' ([53e0a39f](http://github.com/angular-ui/bootstrap/commit/53e0a39f))   - **timepicker:**    - add timepicker directive ([9bc5207b](http://github.com/angular-ui/bootstrap/commit/9bc5207b))   - **tooltip:**    - add mouse placement option ([ace7bc60](http://github.com/angular-ui/bootstrap/commit/ace7bc60))   - add *-append-to-body attribute ([d0896263](http://github.com/angular-ui/bootstrap/commit/d0896263))     - add custom trigger support ([dfa53155](http://github.com/angular-ui/bootstrap/commit/dfa53155))   - **typeahead:**    - support typeahead-on-select callback ([91ac17c9](http://github.com/angular-ui/bootstrap/commit/91ac17c9))     - support wait-ms option ([7f35a3f2](http://github.com/angular-ui/bootstrap/commit/7f35a3f2))
- **accordion:**    - allow accordion heading directives as attributes. ([25f6e55c](http://github.com/angular-ui/bootstrap/commit/25f6e55c)) - **carousel:**    - do not allow user to change slide if transitioning ([1d19663f](http://github.com/angular-ui/bootstrap/commit/1d19663f))     - make slide 'active' binding optional ([17d6c3b5](http://github.com/angular-ui/bootstrap/commit/17d6c3b5))     - fix error with deleting multiple slides at once ([3fcb70f0](http://github.com/angular-ui/bootstrap/commit/3fcb70f0))   - **dialog:**    - remove dialogOpenClass to get in line with v2.3 ([f009b23f](http://github.com/angular-ui/bootstrap/commit/f009b23f))   - **pagination:**    - bind *-text attributes ([e1bff6b7](http://github.com/angular-ui/bootstrap/commit/e1bff6b7))   - **progressbar:**    - user `percent` attribute instead of `value`. ([58efec80](http://github.com/angular-ui/bootstrap/commit/58efec80))   - **tooltip:**    - fix positioning error when appendToBody is set to true ([76fee1f9](http://github.com/angular-ui/bootstrap/commit/76fee1f9))     - close tooltips appended to body on location change ([041261b5](http://github.com/angular-ui/bootstrap/commit/041261b5))     - tooltips will hide on scope.$destroy ([3e5a58e5](http://github.com/angular-ui/bootstrap/commit/3e5a58e5))     - support of custom $interpolate.startSymbol ([88c94ee6](http://github.com/angular-ui/bootstrap/commit/88c94ee6))     - make sure tooltip scope is evicted from cache ([9246905a](http://github.com/angular-ui/bootstrap/commit/9246905a))   - **typeahead:**    - return focus to the input after selecting a suggestion ([04a21e33](http://github.com/angular-ui/bootstrap/commit/04a21e33))
- **pagination:**   The 'first-text', 'previous-text', 'next-text' and 'last-text'   attributes are now binded to parent scope.
To migrate your code, surround the text of these attributes with quotes.
Before:            ```html     <pagination first-text="<<"></pagination>     ```
After:          ```html     <pagination first-text="'<<'"></pagination>     ```
- **progressbar:**   The 'value' is replaced by 'percent'.
Before:          ```html     <progress value="..."></progress>     ```
After:          ```html     <progress percent="..."></progress>     ```
- **tabs:**   The 'tabs' directive has been renamed to 'tabset', and  the 'pane' directive has been renamed to 'tab'.
To migrate your code, follow the example below.
Before:
```html     <tabs>       <pane heading="one">         First Content       </pane>       <pane ng-repeat="apple in basket" heading="{{apple.heading}}">         {{apple.content}}       </pane>     </tabs>     ```
After:
```html     <tabset>       <tab heading="one">         First Content       </tab>       <tab ng-repeat="apple in basket" heading="{{apple.heading}}">         {{apple.content}}       </tab>     </tabset>     ```
- **progressbar:**   - add progressbar directive ([261f2072](https://github.com/angular-ui/bootstrap/commit/261f2072)) - **rating:**   - add rating directive ([6b5e6369](https://github.com/angular-ui/bootstrap/commit/6b5e6369)) - **typeahead:**   - support the editable property ([a40c3fbe](https://github.com/angular-ui/bootstrap/commit/a40c3fbe))   - support typeahead-loading bindable expression ([b58c9c88](https://github.com/angular-ui/bootstrap/commit/b58c9c88)) - **tooltip:**   - added popup-delay option ([a79a2ba8](https://github.com/angular-ui/bootstrap/commit/a79a2ba8))   - added appendToBody to $tooltip ([1ee467f8](https://github.com/angular-ui/bootstrap/commit/1ee467f8))   - added tooltip-html-unsafe directive ([45ed2805](https://github.com/angular-ui/bootstrap/commit/45ed2805))   - support for custom triggers ([b1ba821b](https://github.com/angular-ui/bootstrap/commit/b1ba821b))
- **alert:**   - don't show close button if no close callback specified ([c2645f4a](https://github.com/angular-ui/bootstrap/commit/c2645f4a)) - **carousel:**   - Hide navigation indicators if only one slide ([aedc0565](https://github.com/angular-ui/bootstrap/commit/aedc0565)) - **collapse:**   - remove reference to msTransition for IE10 ([55437b16](https://github.com/angular-ui/bootstrap/commit/55437b16)) - **dialog:**   - set _open to false on init ([dcc9ef31](https://github.com/angular-ui/bootstrap/commit/dcc9ef31))   - close dialog on location change ([474ce52e](https://github.com/angular-ui/bootstrap/commit/474ce52e))   - IE8 fix to not set data() against text nodes ([a6c540e5](https://github.com/angular-ui/bootstrap/commit/a6c540e5))   - fix $apply in progres on $location change ([77e6acb9](https://github.com/angular-ui/bootstrap/commit/77e6acb9)) - **tabs:**   - remove superfluous href from tabs template ([38c1badd](https://github.com/angular-ui/bootstrap/commit/38c1badd)) - **tooltip:**   - fix positioning issues in tooltips and popovers ([6458f487](https://github.com/angular-ui/bootstrap/commit/6458f487)) - **typeahead:**   - close matches popup on click outside typeahead ([acca7dcd](https://github.com/angular-ui/bootstrap/commit/acca7dcd))   - stop keydown event propagation when ESC pressed to discard matches ([22a00cd0](https://github.com/angular-ui/bootstrap/commit/22a00cd0))   - correctly render initial model value ([929a46fa](https://github.com/angular-ui/bootstrap/commit/929a46fa))   - correctly higlight matches if query contains regexp-special chars ([467afcd6](https://github.com/angular-ui/bootstrap/commit/467afcd6))   - fix matches pop-up positioning issues ([74beecdb](https://github.com/angular-ui/bootstrap/commit/74beecdb))
- **dialog:**   - Make $dialog 'resolve' property to work the same way of $routeProvider.when ([739f86f](https://github.com/angular-ui/bootstrap/commit/739f86f)) - **modal:**   - allow global override of modal options ([acaf72b](https://github.com/angular-ui/bootstrap/commit/acaf72b)) - **buttons:**   - add checkbox and radio buttons ([571ccf4](https://github.com/angular-ui/bootstrap/commit/571ccf4)) - **carousel:**   - add slide indicators ([3b677ee](https://github.com/angular-ui/bootstrap/commit/3b677ee)) - **typeahead:**   - add typeahead directive ([6a97da2](https://github.com/angular-ui/bootstrap/commit/6a97da2)) - **accordion:**   - enable HTML in accordion headings ([3afcaa4](https://github.com/angular-ui/bootstrap/commit/3afcaa4)) - **pagination:**   - add first/last link & constant congif options ([0ff0454](https://github.com/angular-ui/bootstrap/commit/0ff0454))
- **dialog:**   - update resolve section to new syntax ([1f87486](https://github.com/angular-ui/bootstrap/commit/1f87486))   - $compile entire modal ([7575b3c](https://github.com/angular-ui/bootstrap/commit/7575b3c)) - **tooltip:**   - don't show tooltips if there is no content to show ([030901e](https://github.com/angular-ui/bootstrap/commit/030901e))   - fix placement issues ([a2bbf4d](https://github.com/angular-ui/bootstrap/commit/a2bbf4d)) - **collapse:**   - Avoids fixed height on collapse ([ff5d119](https://github.com/angular-ui/bootstrap/commit/ff5d119)) - **accordion:**   - fix minification issues ([f4da4d6](https://github.com/angular-ui/bootstrap/commit/f4da4d6)) - **typeahead:**   -  update inputs value on mapping where label is not derived from the model ([a5f64de](https://github.com/angular-ui/bootstrap/commit/a5f64de))
_Very first, initial release_.
Version `0.1.0` was released with the following directives:
* accordion * alert * carousel * dialog * dropdownToggle * modal * pagination * popover * tabs * tooltip
We are always looking for the quality contributions and will be happy to accept your Pull Requests as long as those adhere to some basic rules:
* Please make sure that your contribution fits well in the project's context:   * we are aiming at rebuilding bootstrap directives in pure AngularJS, without any dependencies on any external JavaScript library;   * the only dependency should be bootstrap CSS and its markup structure;   * directives should be html-agnostic as much as possible which in practice means:         * templates should be referred to using the `templateUrl` property         * it should be easy to change a default template to a custom one         * directives shouldn't manipulate DOM structure directly (when possible) * Please assure that you are submitting quality code, specifically make sure that:   * your directive has accompanying tests and all the tests are passing; don't hesitate to contact us (angular-ui@googlegroups.com) if you need any help with unit testing   * your PR doesn't break the build; check the Travis-CI build status after opening a PR and push corrective commits if anything goes wrong
***
[![Build Status](https://secure.travis-ci.org/angular-ui/bootstrap.png)](http://travis-ci.org/angular-ui/bootstrap) [![devDependency Status](https://david-dm.org/angular-ui/bootstrap/dev-status.png?branch=master)](https://david-dm.org/angular-ui/bootstrap#info=devDependencies) [![Bitdeli Badge](https://d2weczhvl823v0.cloudfront.net/angular-ui/bootstrap/trend.png)](https://bitdeli.com/free "Bitdeli Badge")
Do you want to see directives in action? Visit http://angular-ui.github.io/bootstrap/!
Installation is easy as angular-ui-bootstrap has minimal dependencies - only the AngularJS and Bootstrap's CSS are required. After downloading dependencies (or better yet, referencing them from your favourite CDN) you need to download build version of this project. All the files and their purposes are described here:  https://github.com/angular-ui/bootstrap/tree/gh-pages#build-files Don't worry, if you are not sure which file to take, opt for `ui-bootstrap-tpls-[version].min.js`.
When you are done downloading all the dependencies and project files the only remaining part is to add dependencies on the `ui.bootstrap` AngularJS module:
```javascript angular.module('myModule', ['ui.bootstrap']); ```
Project files are also available through your favourite package manager: * **Bower**: `bower install angular-bootstrap` * **NuGet**: https://nuget.org/packages/Angular.UI.Bootstrap/
Directives from this repository are automatically tested with the following browsers: * Chrome (stable and canary channel) * Firefox * IE 9 and 10 * Opera * Safari
Modern mobile browsers should work without problems.
**IE 8 is not officially supported at the moment**. This project is run by volunteers and with the current number of commiters we are not in the position to guarantee IE8 support. If you need support for IE8 we would welcome a contributor who would like to take care about IE8. Alternatively you could sponsor this project to guarantee IE8 support.
We believe that most of the directives would work OK after: * including relevant shims (for ES5 we recommend https://github.com/kriskowal/es5-shim) * taking care of the steps described in http://docs.angularjs.org/guide/ie
We are simply not regularly testing against IE8.
We are aiming at providing a set of AngularJS directives based on Bootstrap's markup and CSS. The goal is to provide **native AngularJS directives** without any dependency on jQuery or Bootstrap's JavaScript. It is often better to rewrite an existing JavaScript code and create a new, pure AngularJS directive. Most of the time the resulting directive is smaller as compared to the original JavaScript code size and better integrated into the AngularJS ecosystem.
All the directives in this repository should have their markup externalized as templates (loaded via `templateUrl`). In practice it means that you can **customize directive's markup at will**. One could even imagine providing a non-Bootstrap version of the templates!
Each directive has its own AngularJS module without any dependencies on other modules or third-party JavaScript code. In practice it means that you can **just grab the code for the directives you need** and you are not obliged to drag the whole repository.
Directives should work. All the time and in all browsers. This is why all the directives have a comprehensive suite of unit tests. All the automated tests are executed on each checkin in several browsers: Chrome, ChromeCanary, Firefox, Opera, Safari, IE9. In fact we are fortunate enough to **benefit from the same testing infrastructure as AngularJS**!
If you are having problems making some directives work, there are several ways to get help:
* Live help in the IRC (`#angularjs` channel at the `freenode` network). Use this [webchat](https://webchat.freenode.net/) or your own IRC client. * Ask a question in [stackoverflow](http://stackoverflow.com/) under the [angular-ui-bootstrap](http://stackoverflow.com/questions/tagged/angular-ui-bootstrap) tag. * Write your question in our [mailing list](https://groups.google.com/forum/#!categories/angular-ui/bootstrap).
Project's issue on GitHub should be used discuss bugs and features.
We are always looking for the quality contributions! Please check the [CONTRIBUTING.md](CONTRIBUTING.md) for the contribution guidelines.
You can generate a custom build, containing only needed modules, from the project's homepage. Alternatively you can run local Grunt build from the command line and list needed modules as shown below:
``` grunt build:modal:tabs:alert:popover:dropdownToggle:buttons:progressbar ```
Check the Grunt build file for other tasks that are defined for this project.
As mentioned directives from this repository have all the markup externalized in templates. You might want to customize default templates to match your desired look & feel, add new functionality etc.
The easiest way to override an individual template is to use the `<script>` directive:
```javascript <script id="template/alert/alert.html" type="text/ng-template">     <div class='alert' ng-class='type && "alert-" + type'>         <button ng-show='closeable' type='button' class='close' ng-click='close()'>Close</button>         <div ng-transclude></div>     </div> </script> ```
If you want to override more templates it makes sense to store them as individual files and feed the `$templateCache` from those partials. For people using Grunt as the build tool it can be easily done using the `grunt-html2js` plugin. You can also configure your own template url. Let's have a look:
Your own template url is `views/partials/ui-bootstrap-tpls/alert/alert.html`.
Add "html2js" task to your Gruntfile ``` html2js: {   options: {     base: '.',     module: 'ui-templates',     rename: function (modulePath) {       var moduleName = modulePath.replace('app/views/partials/ui-bootstrap-tpls/', '').replace('.html', '');       return 'template' + '/' + moduleName + '.html';     }   },   main: {     src: ['app/views/partials/ui-bootstrap-tpls/**/*.html'],     dest: '.tmp/ui-templates.js'   } } ```
Make sure to load your template.js file `<script src="/ui-templates.js"></script>`
Inject the `ui-templates` module in your `app.js` ``` angular.module('myApp', [   'ui.bootstrap',   'ui-templates' ]); ```
Then it will work fine!
For more information visit: https://github.com/karlgoldstein/grunt-html2js
Well done! (If you don't like repeating yourself open a PR with a grunt task taking care of the above!)
Who will take the lead regarding any pull requests or decisions for a a directive?
<table width="100%"> <th>Component</th><th>Maintainer</th> <tr>   <td>accordion</td><td>@ajoslin</td> </tr> <tr>   <td>alert</td><td>@pkozlowski</td> </tr> <tr>   <td>bindHtml</td><td>frozen, use $sce?</td> </tr> <tr>   <td>buttons</td><td> @pkozlowski</td> </tr> <tr>   <td>carousel</td><td>@ajoslin</td> </tr> <tr>   <td>collapse</td><td>$animate (@chrisirhc)</td> </tr> <tr>   <td>datepicker</td><td>@bekos</td> </tr> <tr>   <td>dropdownToggle</td><td>@bekos</td> </tr> <tr>   <td>modal</td><td>@pkozlowski</td> </tr> <tr>   <td>pagination</td><td>@bekos</td> </tr> <tr>   <td>popover/tooltip</td><td>@chrisirhc</td> </tr> <tr>   <td>position</td><td>@ajoslin</td> </tr> <tr>   <td>progressbar</td><td>@bekos</td> </tr> <tr>   <td>rating</td><td>@bekos</td> </tr> <tr>   <td>tabs</td><td>@ajoslin</td> </tr> <tr>   <td>timepicker</td><td>@bekos</td> </tr> <tr>   <td>transition</td><td>@frozen, remove (@chrisirhc)</td> </tr> <tr>   <td>typeahead</td><td>@pkozlowski, @chrisirhc</td> </tr> </table>
Each directive should make its own two-letter prefix
`<tab tb-active=true tb-select=doThis()>`
* @chrisirhc is leading this
* @ajoslin is leading this * Building everything on travis commit * Push to bower, nuget, cdnjs, etc
* http://github.com/petebacondarwin/angular-doc-gen
- Boolean attributes - Stick AngularJS conventions rather than Bootstrap conventions
The **accordion directive** builds on top of the collapse directive to provide a list of items, with collapsible bodies that are collapsed or expanded by clicking on the item's header.
We can control whether expanding an item will cause the other items to close, using the `close-others` attribute on accordion.
The body of each accordion group is transcluded in to the body of the collapsible element.
Alert is an AngularJS-version of bootstrap's alert.
This directive can be used to generate alerts from the dynamic model data (using the ng-repeat directive);
The presence of the "close" attribute determines if a close button is displayed
There are two directives that can make a group of buttons behave like a set of checkboxes, radio buttons, or a hybrid where radio buttons can be unchecked.
Carousel creates a carousel similar to bootstrap's image carousel.
The carousel also offers support for touchscreen devices in the form of swiping. To enable swiping, load the `ngTouch` module as a dependency.
Use a `<carousel>` element with `<slide>` elements inside it.  It will automatically cycle through the slides at a given rate, and a current-index variable will be kept in sync with the currently visible slide.
AngularJS version of Bootstrap's collapse plugin. Provides a simple way to hide and show an element with a css transition
A clean, flexible, and fully customizable date picker.
User can navigate through months and years. The datepicker shows dates that come from other than the main month being displayed. These other dates are also selectable.
Everything is formatted using the [date filter](http://docs.angularjs.org/api/ng.filter:date) and thus is also localized.
All settings can be provided as attributes in the `datepicker` or globally configured through the `datepickerConfig`.
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>  	:  	The date object.
* `datepicker-mode` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: 'day')_ :    Current mode of the datepicker _(day|month|year)_. Can be used to initialize datepicker to specific mode.
* `min-date` <i class="glyphicon glyphicon-eye-open"></i>  	_(Default: null)_ :  	Defines the minimum available date.
* `max-date` <i class="glyphicon glyphicon-eye-open"></i>  	_(Default: null)_ :  	Defines the maximum available date.
* `date-disabled (date, mode)`  	_(Default: null)_ :  	An optional expression to disable visible options based on passing date and current mode _(day|month|year)_.
* `show-weeks`  	_(Defaults: true)_ :  	Whether to display week numbers.
* `starting-day`  	_(Defaults: 0)_ :  	Starting day of the week from 0-6 (0=Sunday, ..., 6=Saturday).
* `init-date`  	:  	The initial date view when no model value is not specified.
* `min-mode`    _(Defaults: 'day')_ :    Set a lower limit for mode.
* `max-mode`    _(Defaults: 'year')_ :    Set an upper limit for mode.
* `format-day`  	_(Default: 'dd')_ :  	Format of day in month.
* `format-month`  	_(Default: 'MMMM')_ :  	Format of month in year.
* `format-year`  	_(Default: 'yyyy')_ :  	Format of year in year range.
* `format-day-header`  	_(Default: 'EEE')_ :  	Format of day in week header.
* `format-day-title`  	_(Default: 'MMMM yyyy')_ :  	Format of title when selecting day.
* `format-month-title`  	_(Default: 'yyyy')_ :  	Format of title when selecting month.
* `year-range`  	_(Default: 20)_ :  	Number of years displayed in year selection.
Options for datepicker can be passed as JSON using the `datepicker-options` attribute. Specific settings for the `datepicker-popup`, that can globally configured through the `datepickerPopupConfig`, are:
* `datepicker-popup`  	_(Default: 'yyyy-MM-dd')_ :  	The format for displayed dates.
* `show-button-bar`  	_(Default: true)_ :  	Whether to display a button bar underneath the datepicker.
* `current-text`  	_(Default: 'Today')_ :  	The text to display for the current day button.
* `clear-text`  	_(Default: 'Clear')_ :  	The text to display for the clear button.
* `close-text`  	_(Default: 'Done')_ :  	The text to display for the close button.
* `close-on-date-selection`  	_(Default: true)_ :  	Whether to close calendar when a date is chosen.
* `datepicker-append-to-body`   _(Default: false)_:   Append the datepicker popup element to `body`, rather than inserting after `datepicker-popup`. For global configuration, use `datepickerPopupConfig.appendToBody`.
Depending on datepicker's current mode, the date may reffer either to day, month or year. Accordingly, the term view reffers either to a month, year or year range.
* `Left`: Move focus to the previous date. Will move to the last date of the previous view, if the current date is the first date of a view.  * `Right`: Move focus to the next date. Will move to the first date of the following view, if the current date is the last date of a view.  * `Up`: Move focus to the same column of the previous row. Will wrap to the appropriate row in the previous view.  * `Down`: Move focus to the same column of the following row. Will wrap to the appropriate row in the following view.  * `PgUp`: Move focus to the same date of the previous view. If that date does not exist, focus is placed on the last date of the month.  * `PgDn`: Move focus to the same date of the following view. If that date does not exist, focus is placed on the last date of the month.  * `Home`: Move to the first date of the view.  * `End`: Move to the last date of the view.  * `Enter`/`Space`: Select date.  * `Ctrl`+`Up`: Move to an upper mode.  * `Ctrl`+`Down`: Move to a lower mode.  * `Esc`: Will close popup, and move focus to the input.
Dropdown is a simple directive which will toggle a dropdown menu on click or programmatically. You can either use `is-open` to toggle or add inside a `<a dropdown-toggle>` element to toggle it when is clicked. There is also the `on-toggle(open)` optional expression fired when dropdown changes state.
`$modal` is a service to quickly create AngularJS-powered modal windows. Creating custom modals is straightforward: create a partial view, its controller and reference them when using the service.
The `$modal` service has only one method: `open(options)` where available options are like follows:
* `templateUrl` - a path to a template representing modal's content * `template` - inline template representing the modal's content * `scope` - a scope instance to be used for the modal's content (actually the `$modal` service is going to create a child scope of a provided scope). Defaults to `$rootScope` * `controller` - a controller for a modal instance - it can initialize scope used by modal. Accepts the "controller-as" syntax, and can be injected with `$modalInstance` * `resolve` - members that will be resolved and passed to the controller as locals; it is equivalent of the `resolve` property for AngularJS routes * `backdrop` - controls presence of a backdrop. Allowed values: true (default), false (no backdrop), `'static'` - backdrop is present but modal window is not closed when clicking outside of the modal window. * `keyboard` - indicates whether the dialog should be closable by hitting the ESC key, defaults to true * `windowClass` - additional CSS class(es) to be added to a modal window template * `windowTemplateUrl` - a path to a template overriding modal's window template * `size` - optional size of modal window. Allowed values: `'sm'` (small) or  `'lg'` (large). Requires Bootstrap 3.1.0 or later
The `open` method returns a modal instance, an object with the following properties:
* `close(result)` - a method that can be used to close a modal, passing a result * `dismiss(reason)` - a method that can be used to dismiss a modal, passing a reason * `result` - a promise that is resolved when a modal is closed and rejected when a modal is dismissed * `opened` - a promise that is resolved when a modal gets opened after downloading content's template and resolving all variables
In addition the scope associated with modal's content is augmented with 2 methods:
* `$close(result)` * `$dismiss(reason)`
Those methods make it easy to close a modal window without a need to create a dedicated controller
A lightweight pagination directive that is focused on ... providing pagination & will take care of visualising a pagination bar and enable / disable buttons correctly!
Settings can be provided as attributes in the `<pagination>` or globally configured through the `paginationConfig`.
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>  	:  	Current page number. First page is 1.
* `total-items` <i class="glyphicon glyphicon-eye-open"></i>  	:  	Total number of items in all pages.
* `items-per-page` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: 10)_ :  	Maximum number of items per page. A value less than one indicates all items on one page.
* `max-size` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: null)_ :  	Limit number for pagination size.
* `num-pages` <small class="badge">readonly</small>  	_(Defaults: angular.noop)_ :  	An optional expression assigned the total number of pages to display.
* `rotate`  	_(Defaults: true)_ :  	Whether to keep current page in the middle of the visible ones.
* `direction-links`  	_(Default: true)_ :  	Whether to display Previous / Next buttons.
* `previous-text`  	_(Default: 'Previous')_ :  	Text for Previous button.
* `next-text`  	_(Default: 'Next')_ :  	Text for Next button.
* `boundary-links`  	_(Default: false)_ :  	Whether to display First / Last buttons.
* `first-text`  	_(Default: 'First')_ :  	Text for First button.
* `last-text`  	_(Default: 'Last')_ :  	Text for Last button.
Settings can be provided as attributes in the `<pager>` or globally configured through the `pagerConfig`.   For `ng-model`, `total-items`, `items-per-page` and `num-pages` see pagination settings. Other settings are:
* `align`  	_(Default: true)_ :  	Whether to align each link to the sides.
* `previous-text`  	_(Default: ' Previous')_ :  	Text for Previous button.
* `next-text`  	_(Default: 'Next ')_ :  	Text for Next button.
A lightweight, extensible directive for fancy popover creation. The popover directive supports multiple placements, optional transition animation, and more.
Like the Bootstrap jQuery plugin, the popover **requires** the tooltip module.
The popover directives provides several optional attributes to control how it will display:
- `popover-title`: A string to display as a fancy title. - `popover-placement`: Where to place it? Defaults to "top", but also accepts   "bottom", "left", "right". - `popover-animation`: Should it fade in and out? Defaults to "true". - `popover-popup-delay`: For how long should the user have to have the mouse   over the element before the popover shows (in milliseconds)? Defaults to 0. - `popover-trigger`: What should trigger the show of the popover? See the   `tooltip` directive for supported values. - `popover-append-to-body`: Should the tooltip be appended to `$body` instead of   the parent element?
The popover directives require the `$position` service.
The popover directive also supports various default configurations through the $tooltipProvider. See the [tooltip](#tooltip) section for more information.
A progress bar directive that is focused on providing feedback on the progress of a workflow or action.
It supports multiple (stacked) bars into the same `<progress>` element or a single `<progressbar>` elemtnt with optional `max` attribute and transition animations.
* `value` <i class="glyphicon glyphicon-eye-open"></i>  	:  	The current value of progress completed.
* `type`  	_(Default: null)_ :  	Style type. Possible values are 'success', 'warning' etc.
* `max`  	_(Default: 100)_ :  	A number that specifies the total value of bars that is required.
* `animate`  	_(Default: true)_ :  	Whether bars use transitions to achieve the width change.
Place multiple `<bars>` into the same `<progress>` element to stack them. `<progress>` supports `max` and `animate` &  `<bar>` supports  `value` and `type` attributes.
Rating directive that will take care of visualising a star rating bar.
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>  	:  	The current rate.
* `max`  	_(Defaults: 5)_ :  	Changes the number of icons.
* `readonly` <i class="icon-eye-open"></i>  	_(Defaults: false)_ :  	Prevent user's interaction.
* `on-hover(value)`  	:  	An optional expression called when user's mouse is over a particular icon.
* `on-leave()`  	:  	An optional expression called when user's mouse leaves the control altogether.
* `state-on`  	_(Defaults: null)_ :  	A variable used in template to specify the state (class, src, etc) for selected icons.
* `state-off`  	_(Defaults: null)_ :  	A variable used in template to specify the state for unselected icons.
* `rating-states`  	_(Defaults: null)_ :  	An array of objects defining properties for all icons. In default template, `stateOn` & `stateOff` property is used to specify the icon's class.
AngularJS version of the tabs directive.
* `vertical`  	_(Defaults: false)_ :  	Whether tabs appear vertically stacked.
* `justified`  	_(Defaults: false)_ :  	Whether tabs fill the container and have a consistent width.
* `type`  	_(Defaults: 'tabs')_ :  	Navigation type. Possible values are 'tabs' and 'pills'.
* `heading` or `<tab-heading>`  	:  	Heading text or HTML markup.
* `active` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: false)_ :  	Whether tab is currently selected.
* `disabled` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: false)_ :  	Whether tab is clickable and can be activated.
* `select()`  	_(Defaults: null)_ :  	An optional expression called when tab is activated.       * `deselect()`  	_(Defaults: null)_ :  	An optional expression called when tab is deactivated.
A lightweight & configurable timepicker directive.
All settings can be provided as attributes in the `<timepicker>` or globally configured through the `timepickerConfig`.
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>  	:  	The Date object that provides the time state.
* `hour-step` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: 1)_ :  	 Number of hours to increase or decrease when using a button.
* `minute-step` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: 1)_ :  	 Number of minutes to increase or decrease when using a button.
* `show-meridian` <i class="glyphicon glyphicon-eye-open"></i>  	_(Defaults: true)_ :  	Whether to display 12H or 24H mode.
* `meridians`  	_(Defaults: null)_ :  	 Meridian labels based on locale. To override you must supply an array like ['AM', 'PM'].
* `readonly-input`  	_(Defaults: false)_ :  	 Whether user can type inside the hours & minutes input.
* `mousewheel`  	_(Defaults: true)_ :  	 Whether user can scroll inside the hours & minutes input to increase or decrease it's values.
A lightweight, extensible directive for fancy tooltip creation. The tooltip directive supports multiple placements, optional transition animation, and more.
There are two versions of the tooltip: `tooltip` and `tooltip-html-unsafe`. The former takes text only and will escape any HTML provided. The latter takes whatever HTML is provided and displays it in a tooltip; it called "unsafe" because the HTML is not sanitized. *The user is responsible for ensuring the content is safe to put into the DOM!*
The tooltip directives provide several optional attributes to control how they will display:
- `tooltip-placement`: Where to place it? Defaults to "top", but also accepts   "bottom", "left", "right". - `tooltip-animation`: Should it fade in and out? Defaults to "true". - `tooltip-popup-delay`: For how long should the user have to have the mouse   over the element before the tooltip shows (in milliseconds)? Defaults to 0. - `tooltip-trigger`: What should trigger a show of the tooltip? - `tooltip-append-to-body`: Should the tooltip be appended to `$body` instead of   the parent element?
The tooltip directives require the `$position` service.
**Triggers**
The following show triggers are supported out of the box, along with their provided hide triggers:
- `mouseenter`: `mouseleave` - `click`: `click` - `focus`: `blur`
For any non-supported value, the trigger will be used to both show and hide the tooltip.
**$tooltipProvider**
Through the `$tooltipProvider`, you can change the way tooltips and popovers behave by default; the attributes above always take precedence. The following methods are available:
- `setTriggers( obj )`: Extends the default trigger mappings mentioned above   with mappings of your own. E.g. `{ 'openTrigger': 'closeTrigger' }`. - `options( obj )`: Provide a set of defaults for certain tooltip and popover   attributes. Currently supports 'placement', 'animation', 'popupDelay', and   `appendToBody`. Here are the defaults:
<pre>   placement: 'top',   animation: true,   popupDelay: 0,   appendToBody: false   </pre>
Typeahead is a AngularJS version of [Bootstrap v2's typeahead plugin](http://getbootstrap.com/2.3.2/javascript.html#typeahead). This directive can be used to quickly create elegant typeaheads with any form text input.
It is very well integrated into AngularJS as it uses a subset of the [select directive](http://docs.angularjs.org/api/ng.directive:select) syntax, which is very flexible. Supported expressions are:
* _label_ for _value_ in _sourceArray_ * _select_ as _label_ for _value_ in _sourceArray_
The `sourceArray` expression can use a special `$viewValue` variable that corresponds to the value entered inside the input.
This directive works with promises, meaning you can retrieve matches using the `$http` service with minimal effort.
The typeahead directives provide several attributes:
* `ng-model` <i class="glyphicon glyphicon-eye-open"></i>    :    Assignable angular expression to data-bind to
* `typeahead` <i class="glyphicon glyphicon-eye-open"></i>    :    Comprehension Angular expression (see [select directive](http://docs.angularjs.org/api/ng.directive:select))
* `typeahead-append-to-body` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: false)_ : Should the typeahead popup be appended to $body instead of the parent element?
* `typeahead-editable` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: true)_ :    Should it restrict model values to the ones selected from the popup only ?
* `typeahead-input-formatter` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: undefined)_ :    Format the ng-model result after selection
* `typeahead-loading` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: angular.noop)_ :    Binding to a variable that indicates if matches are being retrieved asynchronously
* `typeahead-min-length` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: 1)_ :    Minimal no of characters that needs to be entered before typeahead kicks-in
* `typeahead-on-select($item, $model, $label)`    _(Defaults: null)_ :    A callback executed when a match is selected
* `typeahead-template-url` <i class="glyphicon glyphicon-eye-open"></i>    :    Set custom item template
* `typeahead-wait-ms` <i class="glyphicon glyphicon-eye-open"></i>    _(Defaults: 0)_ :    Minimal wait time after last character typed before typeahead kicks-in
<a name="v0.2.8"></a> ### v0.2.8 (2014-01-16)
* **$state:** allow null to be passed as 'params' param ([094dc30e](https://github.com/angular-ui/ui-router/commit/094dc30e883e1bd14e50a475553bafeaade3b178)) * **$state.go:** param inheritance shouldn't inherit from siblings ([aea872e0](https://github.com/angular-ui/ui-router/commit/aea872e0b983cb433436ce5875df10c838fccedb)) * **uiSrefActive:** annotate controller injection ([85921422](https://github.com/angular-ui/ui-router/commit/85921422ff7fb0effed358136426d616cce3d583), closes [#671](https://github.com/angular-ui/ui-router/issues/671)) * **uiView:**   * autoscroll tests pass on 1.2.4 & 1.1.5 ([86eacac0](https://github.com/angular-ui/ui-router/commit/86eacac09ca5e9000bd3b9c7ba6e2cc95d883a3a))   * don't animate initial load ([83b6634d](https://github.com/angular-ui/ui-router/commit/83b6634d27942ca74766b2b1244a7fc52c5643d9))   * test pass against 1.0.8 and 1.2.4 ([a402415a](https://github.com/angular-ui/ui-router/commit/a402415a2a28b360c43b9fe8f4f54c540f6c33de))   * it should autoscroll when expr is missing. ([8bb9e27a](https://github.com/angular-ui/ui-router/commit/8bb9e27a2986725f45daf44c4c9f846385095aff))
* **uiSref:** add target attribute behaviour ([c12bf9a5](https://github.com/angular-ui/ui-router/commit/c12bf9a520d30d70294e3d82de7661900f8e394e)) * **uiView:**   * merge autoscroll expression test. ([b89e0f87](https://github.com/angular-ui/ui-router/commit/b89e0f871d5cc35c10925ede986c10684d5c9252))   * cache and test autoscroll expression ([ee262282](https://github.com/angular-ui/ui-router/commit/ee2622828c2ce83807f006a459ac4e11406d9258))
---
AngularUI Router is a routing framework for [AngularJS](http://angularjs.org), which allows you to organize the parts of your interface into a [*state machine*](https://en.wikipedia.org/wiki/Finite-state_machine). Unlike the [`$route` service](http://docs.angularjs.org/api/ngRoute.$route) in Angular core, which is organized around URL routes, UI-Router is organized around [*states*](https://github.com/angular-ui/ui-router/blob/master/sample/states.js#L28-L269), which may optionally have routes, as well as other behavior, attached.
States are bound to *named*, *nested* and *parallel views*, allowing you to powerfully manage your application's interface.
- **Note:** *UI-Router is under active development. As such, while this library is well-tested, the API may change. Consider using it in production applications only if you're comfortable following a changelog and updating your usage accordingly.*
**(1)** Get UI-Router in one of 4 ways:  - clone & [build](#developing) this repository  - [download the release](http://angular-ui.github.io/ui-router/release/angular-ui-router.js) (or [minified](http://angular-ui.github.io/ui-router/release/angular-ui-router.min.js))  - via **[Bower](http://bower.io/)**: by running `$ bower install angular-ui-router` from your console  - or via **[Component](https://github.com/component/component)**: by running `$ component install angular-ui/ui-router` from your console
**(2)** Include `angular-ui-router.js` (or `angular-ui-router.min.js`) in your `index.html`, after including Angular itself (For Component users: ignore this step)
**(3)** Add `'ui.router'` to your main module's list of dependencies (For Component users: replace `'ui.router'` with `require('angular-ui-router')`)
When you're done, your setup should look similar to the following:
> ```html <!doctype html> <html ng-app="myApp"> <head>     <script src="//ajax.googleapis.com/ajax/libs/angularjs/1.1.5/angular.min.js"></script>     <script src="js/angular-ui-router.min.js"></script>     <script>         var myApp = angular.module('myApp', ['ui.router']);         // For Component users, it should look like this:         // var myApp = angular.module('myApp', [require('angular-ui-router')]);     </script>     ... </head> <body>     ... </body> </html> ```
The majority of UI-Router's power is in its ability to nest states & views.
**(1)** First, follow the [setup](#get-started) instructions detailed above.
**(2)** Then, add a [`ui-view` directive](https://github.com/angular-ui/ui-router/wiki/Quick-Reference#ui-view) to the `<body />` of your app.
> ```html <!-- index.html --> <body>     <div ui-view></div>     <!-- We'll also add some navigation: -->     <a ui-sref="state1">State 1</a>     <a ui-sref="state2">State 2</a> </body> ```
**(3)** You'll notice we also added some links with [`ui-sref` directives](https://github.com/angular-ui/ui-router/wiki/Quick-Reference#ui-sref). In addition to managing state transitions, this directive auto-generates the `href` attribute of the `<a />` element it's attached to, if the corresponding state has a URL. Next we'll add some templates. These will plug into the `ui-view` within `index.html`. Notice that they have their own `ui-view` as well! That is the key to nesting states and views.
> ```html <!-- partials/state1.html --> <h1>State 1</h1> <hr/> <a ui-sref="state1.list">Show List</a> <div ui-view></div> ``` ```html <!-- partials/state2.html --> <h1>State 2</h1> <hr/> <a ui-sref="state2.list">Show List</a> <div ui-view></div> ```
**(4)** Next, we'll add some child templates. *These* will get plugged into the `ui-view` of their parent state templates.
> ```html <!-- partials/state1.list.html --> <h3>List of State 1 Items</h3> <ul>   <li ng-repeat="item in items">{{ item }}</li> </ul> ```
> ```html <!-- partials/state2.list.html --> <h3>List of State 2 Things</h3> <ul>   <li ng-repeat="thing in things">{{ thing }}</li> </ul> ```
**(5)** Finally, we'll wire it all up with `$stateProvider`. Set up your states in the module config, as in the following:
> ```javascript myApp.config(function($stateProvider, $urlRouterProvider) {   //   // For any unmatched url, redirect to /state1   $urlRouterProvider.otherwise("/state1");   //   // Now set up the states   $stateProvider     .state('state1', {       url: "/state1",       templateUrl: "partials/state1.html"     })     .state('state1.list', {       url: "/list",       templateUrl: "partials/state1.list.html",       controller: function($scope) {         $scope.items = ["A", "List", "Of", "Items"];       }     })     .state('state2', {       url: "/state2",       templateUrl: "partials/state2.html"     })     .state('state2.list', {       url: "/list",         templateUrl: "partials/state2.list.html",         controller: function($scope) {           $scope.things = ["A", "Set", "Of", "Things"];         }       })     }); ```
**(6)** See this quick start example in action. >**[Go to Quick Start Plunker for Nested States & Views](http://plnkr.co/edit/u18KQc?p=preview)**
**(7)** This only scratches the surface >**[Dive Deeper!](https://github.com/angular-ui/ui-router/wiki)**
Another great feature is the ability to have multiple `ui-view`s view per template.
**Pro Tip:** *While multiple parallel views are a powerful feature, you'll often be able to manage your interfaces more effectively by nesting your views, and pairing those views with nested states.*
**(1)** Follow the [setup](#get-started) instructions detailed above.
**(2)** Add one or more `ui-view` to your app, give them names. > ```html <!-- index.html --> <body>     <div ui-view="viewA"></div>     <div ui-view="viewB"></div>     <!-- Also a way to navigate -->     <a ui-sref="route1">Route 1</a>     <a ui-sref="route2">Route 2</a> </body> ```
**(3)** Set up your states in the module config: > ```javascript myApp.config(function($stateProvider) {   $stateProvider     .state('index', {       url: "",       views: {         "viewA": { template: "index.viewA" },         "viewB": { template: "index.viewB" }       }     })     .state('route1', {       url: "/route1",       views: {         "viewA": { template: "route1.viewA" },         "viewB": { template: "route1.viewB" }       }     })     .state('route2', {       url: "/route2",       views: {         "viewA": { template: "route2.viewA" },         "viewB": { template: "route2.viewB" }       }     }) }); ```
**(4)** See this quick start example in action. >**[Go to Quick Start Plunker for Multiple & Named Views](http://plnkr.co/edit/SDOcGS?p=preview)**
* [In-Depth Guide](https://github.com/angular-ui/ui-router/wiki) * [API Reference](http://angular-ui.github.io/ui-router/site) * [Sample App](http://angular-ui.github.com/ui-router/sample/) ([Source](https://github.com/angular-ui/ui-router/tree/gh-pages/sample)) * [FAQ](https://github.com/angular-ui/ui-router/wiki/Frequently-Asked-Questions) * [Introduction Video](https://egghead.io/lessons/angularjs-introduction-ui-router) * [Slides comparing ngRoute to ui-router](http://slid.es/timkindberg/ui-router#/)
Help us make UI-Router better! If you think you might have found a bug, or some other weirdness, start by making sure it hasn't already been reported. You can [search through existing issues](https://github.com/angular-ui/ui-router/search?q=wat%3F&type=Issues) to see if someone's reported one similar to yours.
If not, then [create a plunkr](http://plnkr.co/edit/u18KQc?p=preview) that demonstrates the problem (try to use as little code as possible: the more minimalist, the faster we can debug it).
Next, [create a new issue](https://github.com/angular-ui/ui-router/issues/new) that briefly explains the problem, and provides a bit of background as to the circumstances that triggered it. Don't forget to include the link to that plunkr you created!
**Note**: If you're unsure how a feature is used, or are encountering some unexpected behavior that you aren't sure is a bug, it's best to talk it out in the [Google Group](https://groups.google.com/forum/#!categories/angular-ui/router) or on [StackOverflow](http://stackoverflow.com/questions/ask?tags=angularjs,angular-ui-router) before reporting it. This keeps development streamlined, and helps us focus on building great software.
Please keep in mind that the issue tracker is for *issues*. Please do *not* post an issue if you need help or support. Instead, see one of the above-mentioned forums or [IRC](irc://irc.freenode.net/#angularjs).
**(1)** See the **[Developing](#developing)** section below, to get the development version of UI-Router up and running on your local machine.
**(2)** Check out the [roadmap](https://github.com/angular-ui/ui-router/issues/milestones) to see where the project is headed, and if your feature idea fits with where we're headed.
**(3)** If you're not sure, [open an RFC](https://github.com/angular-ui/ui-router/issues/new?title=RFC:%20My%20idea) to get some feedback on your idea.
**(4)** Finally, commit some code and open a pull request. Code & commits should abide by the following rules:
- *Always* have test coverage for new features (or regression tests for bug fixes), and *never* break existing tests - Commits should represent one logical change each; if a feature goes through multiple iterations, squash your commits down to one - Make sure to follow the [Angular commit message format](https://github.com/angular/angular.js/blob/master/CONTRIBUTING.md#commit-message-format) so your change will appear in the changelog of the next release. - Changes should always respect the coding style of the project

UI-Router uses <code>grunt >= 0.4.x</code>. Make sure to upgrade your environment and read the [Migration Guide](http://gruntjs.com/upgrading-from-0.3-to-0.4).
Dependencies for building from source and running tests:
* [grunt-cli](https://github.com/gruntjs/grunt-cli) - run: `$ npm install -g grunt-cli` * Then, install the development dependencies by running `$ npm install` from the project directory
There are a number of targets in the gruntfile that are used to generating different builds:
* `grunt`: Perform a normal build, runs jshint and karma tests * `grunt build`: Perform a normal build * `grunt dist`: Perform a clean build and generate documentation * `grunt dev`: Run dev server (sample app) and watch for changes, builds and runs karma tests on changes.
<a name="v0.1.0"></a> ## v0.1.0 (2013-12-29)
* **mark:** TypeError: input is undefined ([5440d6fa](http://github.com/angular-ui/ui-utils/commit/5440d6fa8514ee86efc480b0abbf66cf244889ad)) * **publisher:**   * don't throw error when 'dist/sub' don't exist ([bd319236](http://github.com/angular-ui/ui-utils/commit/bd31923668c0ea80311b9dbe7d72bfbe55956325))   * rename sub componenet stuff ([5dcdc379](http://github.com/angular-ui/ui-utils/commit/5dcdc3794efe66112522415aafe9ebe965a274f6)) * **ui-scroll:**   * 'newitems' is not defined. ([796e310a](http://github.com/angular-ui/ui-utils/commit/796e310a26ac43a248c0c732877242890fdda2be))   * 'isArray' is not defined. ([3fd7fc47](http://github.com/angular-ui/ui-utils/commit/3fd7fc47de7d05460a55ca42e4afec60d8e8cc4d))   * 'setOffset' is not defined. ([32140e04](http://github.com/angular-ui/ui-utils/commit/32140e04be176c4b2a5954d2cf8e9ec3c48a6f5c))
* **alias:** Created a new ui-alias module for renaming/combining directives ([1582d54e](http://github.com/angular-ui/ui-utils/commit/1582d54ecaf81cb516a28368c0d409b5d5fe7da9)) * **grunt:**   * add 'changelog' task ([b7fed5a6](http://github.com/angular-ui/ui-utils/commit/b7fed5a6026121d0098f892aa0a221c0d9c14d56), closes [#145](http://github.com/angular-ui/ui-utils/issues/145))   * use Angular UI Publisher ([3c209713](http://github.com/angular-ui/ui-utils/commit/3c20971307e50741f88da21cb638077237e56da2), closes [#153](http://github.com/angular-ui/ui-utils/issues/153))   * new 'serve' task ([a18ed32c](http://github.com/angular-ui/ui-utils/commit/a18ed32ce134acabe7adc79b41e82ed6c52109ed))   * quality code more strict ([332ebff1](http://github.com/angular-ui/ui-utils/commit/332ebff1fdc7edf4d44d64f4796ec2f70e90947f))   * use ngmin in the 'dist' task ([93ba905f](http://github.com/angular-ui/ui-utils/commit/93ba905fadfd4d0970d384f7978e19a3561cea65))   * add ngmin build all subcomponents in dist/sub ([783140ab](http://github.com/angular-ui/ui-utils/commit/783140abe1b8d6c0f842eceb7fc24a0f16d73ca5)) * **publisher:**   * change travis scripts to work with the component-publisher system ([12d97d3b](http://github.com/angular-ui/ui-utils/commit/12d97d3bf88da86875141093fc164f1537d0dfe2))   * add and config component-publisher system ([4cea7ea5](http://github.com/angular-ui/ui-utils/commit/4cea7ea5bb4c47ad74c4f5123121a2896bf6f717)) * **travis:** add sub component auto publishing :) ([0d64db00](http://github.com/angular-ui/ui-utils/commit/0d64db00a5c50816cbf0b022aa5607fee29d5e2a))
This module exposes underscore's API into angular app's root scope, and provides some filters from underscore.
Whole Underscore's API for Collections, Arrays and Objects except decision API (e.g. functions return true|false), side effect guys, and _.range(not making sense as a filter).
For API details please check out http://underscorejs.org/
After load angular.js and underscore.js:
```html <script type="text/javascript" src="angular-underscore.js"></script> ```
```javascript angular.module('yourAwesomeApp', ['angular-underscore']); ```
```javascript angular.module('yourAwesomeApp', ['angular-underscore/utils']); ```
```javascript angular.module('yourAwesomeApp', ['angular-underscore/filters']); ```
```javascript // load `shuffle` only angular.module('yourAwesomeApp', ['angular-underscore/filters/shuffle']); ```
```html <script type="text/javascript">   angular.module('example', ['angular-underscore']); </script>
<body ng-app="example">   <!-- generate 10 unduplicated random number from 0 to 9 -->   <div ng-repeat="num in range(10)|shuffle">{{num}}</div> </body> ```
``` $ npm install uglify-js -g $ uglifyjs angular-underscore.js > angular-underscore.min.js ```
(The MIT License)
Copyright (c) 2014 <floydsoft@gmail.com>
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
* select2 * [checklist](https://github.com/vitalets/checklist-model) * [combodate](https://github.com/vitalets/combodate) * popup mode (waiting https://github.com/angular-ui/bootstrap/pull/1391) * internally move to [lazy-model](https://github.com/vitalets/lazy-model)
AngularJS-Toaster =================
**AngularJS Toaster** is a AngularJS port of the **toastr** non-blocking notification jQuery library. It requires AngularJS v1.2.6 or higher and angular-animate for the CSS3 transformations.  (I would suggest to use /1.2.8/angular-animate.js, there is a weird blinking in newer versions.)
1. Link scripts:
```html <link href="//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/2.3.2/css/bootstrap.min.css" rel="stylesheet" /> <link href="http://cdnjs.cloudflare.com/ajax/libs/angularjs-toaster/0.4.4/toaster.css" rel="stylesheet" /> <script src="https://ajax.googleapis.com/ajax/libs/angularjs/1.2.0/angular.min.js" ></script> <script src="http://code.angularjs.org/1.2.0/angular-animate.min.js" ></script> <script src="http://cdnjs.cloudflare.com/ajax/libs/angularjs-toaster/0.4.4/toaster.js"></script> ```
2. Add toaster container directive: `<toaster-container></toaster-container>`
3. Prepare the call of toaster method:
```js 	// Display an info toast with no title 	angular.module('main', ['toaster']) 	.controller('myController', function($scope, toaster) { 	    $scope.pop = function(){ 	        toaster.pop('success', "title", "text"); 	    }; 	}); ```
4. Call controller method on button click:
```html <div ng-controller="myController">     <button ng-click="pop()">Show a Toaster</button> </div> ```
```html // Change display position <toaster-container toaster-options="{'position-class': 'toast-top-full-width'}"></toaster-container> ```
#Animate.css *Just-add-water CSS animation*
`animate.css` is a bunch of cool, fun, and cross-browser animations for you to use in your projects. Great for emphasis, home pages, sliders, and general just-add-water-awesomeness.
##Usage To use animate.css in your website, simply drop the stylesheet into your document's `<head>`, and add the class `animated` to an element, along with any of the animation names. That's it! You've got a CSS animated element. Super!
```html <head>   <link rel="stylesheet" href="animate.min.css"> </head> ```
You can do a whole bunch of other stuff with animate.css when you combine it with jQuery or add your own CSS rules. Dynamically add animations using jQuery with ease:
```javascript $('#yourElement').addClass('animated bounceOutLeft'); ```
You can also detect when an animation ends:
<!-- Before you make changes to this file, you should know that $('#yourElement').one() is *NOT A TYPO*
http://api.jquery.com/one/ -->
```javascript $('#yourElement').one('webkitAnimationEnd mozAnimationEnd MSAnimationEnd oanimationend animationend', doSomething); ```
**Note:** `jQuery#one` is used when you want to execute the event handler at most *once*. More information [here](http://api.jquery.com/one/).
You can change the duration of your animations, add a delay or change the number of times that it plays:
```css #yourElement {   -vendor-animation-duration: 3s;   -vendor-animation-delay: 2s;   -vendor-animation-iteration-count: infinite; } ```
*Note: be sure to replace "vendor" in the CSS with the applicable vendor prefixes (webkit, moz, etc)*
```sh $ cd path/to/animate.css/ $ sudo npm install ```
Next, run `grunt watch` to watch for changes and compile your custom builds. For example, if you want only some of the the attention seekers, simply edit the `animate-config.json` file to select only the animations you want to use.
```javascript "attention_seekers": {   "bounce": true,   "flash": false,   "pulse": false,   "shake": true,   "swing": true,   "tada": true,   "wobble": true } ```
**Please follow these basic steps to simplify pull request reviews - if you don't you'll probably just be asked to anyway.**
* Please rebase your branch against the current master * Run ```npm install``` to make sure your development dependencies are up-to-date * [grunt-cli](https://github.com/gruntjs/grunt-cli) >= 0.4.0 is required to sanity check your contribution * Please ensure that the test suite passes **and** that bootbox.js is lint free before submitting a PR by running:  * ```grunt``` * If you've added new functionality, **please** include tests which validate its behaviour  * **this includes pull requests which _only_ add new locales!**
* Where at all possible, please try and provide a link to a jsfiddle.net example or similar * Please detail the affected browser(s) and operating system(s) * Please be sure to state which version of Bootbox, jQuery **and** Bootstrap you're using
Please see http://bootboxjs.com for full usage instructions, or head over to http://paynedigital.com/bootbox for the original writeup about the project.
The easiest thing is to [find me on twitter @makeusabrew](http://twitter.com/makeusabrew).
Please see the [CONTRIBUTING](https://github.com/makeusabrew/bootbox/blob/master/CONTRIBUTING.md) file for guidelines.
Tests are run using [Karma](http://karma-runner.github.io/0.8/index.html) using the Mocha test adapter. To run the tests yourself, simply run ```npm install``` within the project followed by ```npm test```. Please note that this will require [PhantomJS](http://phantomjs.org/) being installed and in your path - if it is not, you may run the tests and capture browsers manually by running ```karma start``` from the root of the project.
The project is also hosted on [Travis CI](https://travis-ci.org/makeusabrew/bootbox) - when submitting pull requests **please** ensure your tests pass as failing requests will be rejected. See the [CONTRIBUTING](https://github.com/makeusabrew/bootbox/blob/master/CONTRIBUTING.md) file for more information.
The repository no longer contains a minified bootbox.min.js file - this is now only generated [for releases](https://github.com/makeusabrew/bootbox/releases). To build your own minified copy for use in development simply run ```npm install``` if you haven't already, followed by ```grunt uglify```. This will generate a bootbox.min.js file in your working directory.
Bootbox **4.0.0** is the first release to support Bootstrap 3.0.0.
Bootbox **3.3.0** is the *last* release to support Bootstrap 2.2.x.
Much more dependency information can be found [on the Bootbox website](http://bootboxjs.com/#dependencies).
The latest major release of Bootbox - 4.0.0 - involved a total rewrite of the internal code and introduced an entirely new public API. It has not re-implemented some functionality from the 3.x series as of yet; this will be addressed in the coming weeks in the form of new minor releases; [a task list for 4.3.0 is available](https://github.com/makeusabrew/bootbox/issues/220) - please feel free to add feedback and requests.
There is no new major (e.g. 5.x) release on the roadmap at present.
* Add Swedish locale * Add Latvian locale * Add Turkish locale * Add Hebrew locale * Add password input type * Add textarea input type * Add date input type * Add time input type * Add number input type * Support DOM selectors for container argument * UMD support * Better support on mobile devices
For a full list of releases and changes please see [the changelog](https://github.com/makeusabrew/bootbox/blob/master/CHANGELOG.md).
(The MIT License)
Copyright (C) 2011-2014 by Nick Payne <nick@kurai.co.uk>
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE
Bootstrap is a sleek, intuitive, and powerful front-end framework for faster and easier web development, created by [Mark Otto](http://twitter.com/mdo) and [Jacob Thornton](http://twitter.com/fat), and maintained by the [core team](https://github.com/twbs?tab=members) with the massive support and involvement of the community.
To get started, check out <http://getbootstrap.com>!
- [Quick start](#quick-start)  - [Bugs and feature requests](#bugs-and-feature-requests)  - [Documentation](#documentation)  - [Compiling CSS and JavaScript](#compiling-css-and-javascript)  - [Contributing](#contributing)  - [Community](#community)  - [Versioning](#versioning)  - [Authors](#authors)  - [Copyright and license](#copyright-and-license)
Three quick start options are available:
- [Download the latest release](https://github.com/twbs/bootstrap/archive/v3.1.1.zip). - Clone the repo: `git clone https://github.com/twbs/bootstrap.git`. - Install with [Bower](http://bower.io): `bower install bootstrap`.
Read the [Getting Started page](http://getbootstrap.com/getting-started/) for information on the framework contents, templates and examples, and more.
Within the download you'll find the following directories and files, logically grouping common assets and providing both compiled and minified variations. You'll see something like this:
``` bootstrap/  css/     bootstrap.css     bootstrap.min.css     bootstrap-theme.css     bootstrap-theme.min.css  js/     bootstrap.js     bootstrap.min.js  fonts/      glyphicons-halflings-regular.eot      glyphicons-halflings-regular.svg      glyphicons-halflings-regular.ttf      glyphicons-halflings-regular.woff ```
We provide compiled CSS and JS (`bootstrap.*`), as well as compiled and minified CSS and JS (`bootstrap.min.*`). Fonts from Glyphicons are included, as is the optional Bootstrap theme.

Have a bug or a feature request? Please first read the [issue guidelines](https://github.com/twbs/bootstrap/blob/master/CONTRIBUTING.md#using-the-issue-tracker) and search for existing and closed issues. If your problem or idea is not addressed yet, [please open a new issue](https://github.com/twbs/bootstrap/issues/new).
Bootstrap's documentation, included in this repo in the root directory, is built with [Jekyll](http://jekyllrb.com) and publicly hosted on GitHub Pages at <http://getbootstrap.com>. The docs may also be run locally.
1. If necessary, [install Jekyll](http://jekyllrb.com/docs/installation) (requires v1.x).   - **Windows users:** Read [this unofficial guide](https://github.com/juthilo/run-jekyll-on-windows/) to get Jekyll up and running without problems. We use Pygments for syntax highlighting, so make sure to read the sections on installing Python and Pygments. 2. From the root `/bootstrap` directory, run `jekyll serve` in the command line.   - **Windows users:** While we use Jekyll's `encoding` setting, you might still need to change the command prompt's character encoding ([code page](http://en.wikipedia.org/wiki/Windows_code_page)) to UTF-8 so Jekyll runs without errors. For Ruby 2.0.0, run `chcp 65001` first. For Ruby 1.9.3, you can alternatively do `SET LANG=en_EN.UTF-8`. 3. Open <http://localhost:9001> in your browser, and voil.
Learn more about using Jekyll by reading its [documentation](http://jekyllrb.com/docs/home/).
Documentation for v2.3.2 has been made available for the time being at <http://getbootstrap.com/2.3.2/> while folks transition to Bootstrap 3.
[Previous releases](https://github.com/twbs/bootstrap/releases) and their documentation are also available for download.

Bootstrap uses [Grunt](http://gruntjs.com/) with convenient methods for working with the framework. It's how we compile our code, run tests, and more. To use it, install the required dependencies as directed and then run some Grunt commands.
From the command line:
1. Install `grunt-cli` globally with `npm install -g grunt-cli`. 2. Navigate to the root `/bootstrap` directory, then run `npm install`. npm will look at [package.json](https://github.com/twbs/bootstrap/blob/master/package.json) and automatically install the necessary local dependencies listed there.
When completed, you'll be able to run the various Grunt commands provided from the command line.
**Unfamiliar with `npm`? Don't have node installed?** That's a-okay. npm stands for [node packaged modules](http://npmjs.org/) and is a way to manage development dependencies through node.js. [Download and install node.js](http://nodejs.org/download/) before proceeding.
Should you encounter problems with installing dependencies or running Grunt commands, uninstall all previous dependency versions (global and local). Then, rerun `npm install`.

Please read through our [contributing guidelines](https://github.com/twbs/bootstrap/blob/master/CONTRIBUTING.md). Included are directions for opening issues, coding standards, and notes on development.
Moreover, if your pull request contains JavaScript patches or features, you must include relevant unit tests. All HTML and CSS should conform to the [Code Guide](http://github.com/mdo/code-guide), maintained by [Mark Otto](http://github.com/mdo).
Editor preferences are available in the [editor config](https://github.com/twbs/bootstrap/blob/master/.editorconfig) for easy use in common text editors. Read more and download plugins at <http://editorconfig.org>.

Keep track of development and community news.
- Follow [@twbootstrap on Twitter](http://twitter.com/twbootstrap). - Read and subscribe to [The Official Bootstrap Blog](http://blog.getbootstrap.com). - Chat with fellow Bootstrappers in IRC. On the `irc.freenode.net` server, in the `##twitter-bootstrap` channel. - Implementation help may be found at Stack Overflow (tagged [`twitter-bootstrap-3`](http://stackoverflow.com/questions/tagged/twitter-bootstrap-3)).

For transparency into our release cycle and in striving to maintain backward compatibility, Bootstrap is maintained under the Semantic Versioning guidelines. Sometimes we screw up, but we'll adhere to these rules whenever possible.
Releases will be numbered with the following format:
`<major>.<minor>.<patch>`
And constructed with the following guidelines:
- Breaking backward compatibility **bumps the major** while resetting minor and patch - New additions without breaking backward compatibility **bumps the minor** while resetting the patch - Bug fixes and misc changes **bumps only the patch**
For more information on SemVer, please visit <http://semver.org/>.

**Mark Otto**
- <http://twitter.com/mdo> - <http://github.com/mdo>
**Jacob Thornton**
- <http://twitter.com/fat> - <http://github.com/fat>

Code and documentation copyright 2011-2014 Twitter, Inc. Code released under [the MIT license](LICENSE). Docs released under [Creative Commons](docs/LICENSE).
The SHA-256 hash of the single file is used as the key for the cache. The directory is stored as a gzipped tarball.
All the tarballs are stored in S3's Reduced Redundancy Storage (RRS) storage class, since this is cheaper and the data is non-critical.
`s3_cache.py` itself never deletes cache entries; deletion should either be done manually or using automatic S3 lifecycle rules on the bucket.
Similar to git, `s3_cache.py` makes the assumption that [SHA-256 will effectively never have a collision](http://stackoverflow.com/questions/4014090/is-it-safe-to-ignore-the-possibility-of-sha-collisions-in-practice).
For npm, the `node_modules` directory is cached based on our `npm-shrinkwrap.canonical.json` file.
For RubyGems, the `gemdir` of the current RVM-selected Ruby is cached based on the `pseudo_Gemfile.lock` file generated by our Travis build script. `pseudo_Gemfile.lock` contains the versions of Ruby and Jekyll that we're using (read our `.travis.yml` for details).
Travis does offer built-in caching on their paid plans, but this do-it-ourselves S3 solution is significantly cheaper since we only need caching and not Travis' other paid features.
```bash     python -c "import uuid; print(uuid.uuid4())"     ```
9. Determine and note what your bucket's ARN is. The ARN for an S3 bucket is of the form: `arn:aws:s3:::the-bucket-name-goes-here` 10. In the bucket's Properties pane, in the "Permissions" section, click the "Edit bucket policy" button. 11. Input and submit an IAM Policy that grants the user at least read+write rights to the bucket. AWS has a policy generator and some examples to help with crafting the policy. Here's the policy that Bootstrap uses, with the sensitive bits censored:
```json     {         "Version": "2012-10-17",         "Id": "PolicyTravisReadWriteNoAdmin",         "Statement": [             {                 "Sid": "StmtXXXXXXXXXXXXXX",                 "Effect": "Allow",                 "Principal": {                     "AWS": "arn:aws:iam::XXXXXXXXXXXXXX:user/travis-ci"                 },                 "Action": [                     "s3:AbortMultipartUpload",                     "s3:GetObjectVersion",                     "s3:ListBucket",                     "s3:DeleteObject",                     "s3:DeleteObjectVersion",                     "s3:GetObject",                     "s3:PutObject"                 ],                 "Resource": [                     "arn:aws:s3:::XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX",                     "arn:aws:s3:::XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/*"                 ]             }         ]     }     ```
12. If you want deletion from the cache to be done automatically based on age (like Bootstrap does): In the bucket's Properties pane, in the "Lifecycle" section, add a rule to expire/delete files based on creation date. 13. Install the [`travis` RubyGem](https://github.com/travis-ci/travis): `gem install travis` 14. Encrypt the environment variables:
```bash     travis encrypt --repo twbs/bootstrap "AWS_ACCESS_KEY_ID=XXX"     travis encrypt --repo twbs/bootstrap "AWS_SECRET_ACCESS_KEY=XXX"     travis encrypt --repo twbs/bootstrap "TWBS_S3_BUCKET=XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"     ```
14. Add the resulting secure environment variables to `.travis.yml`.
I consider jStorage complete, so only bug fixes are accepted but no new features please. jStorage has an extremely permissive license, you can do whatever you like with the code with no kind of attribution required. If you want a version of jStorage that has additional features or has some existing features stripped, you can fork or clone the code of jStorage and treat it as you like. You can even republish it under another name and license if you like, no constraints about that.
If you do not need to support IE6 and IE7, you don't even need something like jStorage. You can accomplish all your storage needs with the folowing simple functions with no dependencies whatsoever
/**      * Stores a value to the persistent browser storage      *      * @param {String} key The key name of stored object      * @param {Mixed} value A value to be stored, can be anything that is JSON compatible      */     function store(key, value){         window.localStorage[key] = JSON.stringify(value);     }
/**      * Loads a value from the persistent browser storage by a key      *      * @param {String} key The key name of stored object      * @return {Mixed} Stored value, can be anything that is JSON compatible      */     function retrieve(key){         var value;         try{             value = JSON.parse(window.localStorage[key]);         }catch(E){}         return value;     }
The usage of JSON is required to support storing other values than strings which is the "native" storage type for using localStorage API.
Use 4 spaces instead of tabs. Commas last. Use double quotes instead of single quotes where possible.
**If you don't need to support older Internet Explorer Versions (IE7 and below), use [simpleStorage](https://github.com/andris9/simpleStorage) instead.**
----
**jStorage** is a cross-browser key-value store database to store data locally in the browser - jStorage supports all major browsers, both in **desktop** (yes - even Internet Explorer 6) and in **mobile**.
Additionally jStorage is library agnostic, it works well with any other JavaScript library on the same webpage, be it jQuery, Prototype, MooTools or something else. Though you still need to have either a third party library (Prototype, MooTools) or [JSON2](https://github.com/douglascrockford/JSON-js/blob/master/json2.js) on the page to support older IE versions.
jStorage supports storing Strings, Numbers, JavaScript objects, Arrays and even native XML nodes which kind of makes it a JSON storage. jStorage also supports setting TTL values for auto expiring stored keys and - best of all - notifying other tabs/windows when a key has been changed, which makes jStorage also a local PubSub platform for web applications.
jStorage is pretty small, about 7kB when minified, 3kB gzipped.
```javascript $.jStorage.set(key, value, options) ```
Saves a value to local storage. key needs to be string otherwise an exception is thrown. value can be any JSONeable value, including objects and arrays or a XML node. Currently XML nodes can't be nested inside other objects: `$.jStorage.set("xml", xml_node)` is OK but `$.jStorage.set("xml", {xml: xml_node})` is not.
Options is an optional options object. Currently only available option is options.TTL which can be used to set the TTL value to the key `$.jStorage.set(key, value, {TTL: 1000})`. NB - if no TTL option value has been set, any currently used TTL value for the key will be removed.
```javascript value = $.jStorage.get(key) value = $.jStorage.get(key, "default value") ```
get retrieves the value if key exists, or default if it doesn't. key needs to be string otherwise an exception is thrown. default can be any value.
```javascript $.jStorage.deleteKey(key) ```
Removes a key from the storage. key needs to be string otherwise an exception is thrown.
```javascript $.jStorage.set("mykey", "keyvalue"); $.jStorage.setTTL("mykey", 3000); // expires in 3 seconds ```
Sets a TTL (in milliseconds) for an existing key. Use 0 or negative value to clear TTL.
```javascript ttl = $.jStorage.getTTL("mykey"); // TTL in milliseconds or 0 Gets remaining TTL (in milliseconds) for a key or 0 if not TTL has been set. ```
```javascript $.jStorage.flush() ```
Clears the cache.
```javascript $.jStorage.index() ```
Returns all the keys currently in use as an array.
```javascript var index = $.jStorage.index(); console.log(index); // ["key1","key2","key3"] ```
```javascript $.jStorage.storageSize() ```
Returns the size of the stored data in bytes
```javascript $.jStorage.currentBackend() ```
Returns the storage engine currently in use or false if none
```javascript $.jStorage.reInit() ```
Reloads the data from browser storage
```javascript $.jStorage.storageAvailable() ```
Returns true if storage is available
```javascript $.jStorage.subscribe("ch1", function(channel, payload){     console.log(payload+ " from " + channel); }); ```
Subscribes to a Publish/Subscribe channel (see demo)
```javascript $.jStorage.publish("ch1", "data"); ```
Publishes payload to a Publish/Subscribe channel (see demo)
```javascript $.jStorage.listenKeyChange("mykey", function(key, action){     console.log(key + " has been " + action); }); ```
Listens for updates for selected key. NB! even updates made in other windows/tabs are reflected, so this feature can also be used for some kind of publish/subscribe service.
If you want to listen for any key change, use `"*"` as the key name
```javascript $.jStorage.listenKeyChange("*", function(key, action){     console.log(key + " has been " + action); }); ```
```javascript $.jStorage.stopListening("mykey"); // cancel all listeners for "mykey" change ```
Stops listening for key change. If callback is set, only the used callback will be cleared, otherwise all listeners will be dropped.
Support jStorage development
[![Donate to author](https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=DB26KWR2BQX5W)
jStorage supports the following features:
* store and retrieve data from browser storage using any JSON compatible data format (+ native XML nodes)   * set TTL values to stored keys for auto expiring   * publish and subscribe to cross-window/tab events   * listen for key changes (update, delete) from the current or any other browser window   * use any browser since IE6, both in desktop and in mobile
Current availability: jStorage supports all major browsers - Internet Explorer 6+, Firefox 2+, Safari 4+, Chrome 4+, Opera 10.50+
If the browser doesn't support data caching, then no exceptions are raised - jStorage can still be used by the script but nothing is actually stored.
See [tests/index.html](http://www.jstorage.info/static/tests/index.html) for unit tests
Project homepage and docs: [www.jstorage.info](http://www.jstorage.info)
[Unlicense](http://unlicense.org/) Since version 0.4.7
**MIT** (versions up to 0.4.6)
[![Bitdeli Badge](https://d2weczhvl823v0.cloudfront.net/andris9/jstorage/trend.png)](https://bitdeli.com/free "Bitdeli Badge")
Changelog =========
* bugfix [#1813](https://github.com/moment/moment/issues/1813): fix moment().lang([key]) incompatibility
* incompatible changes     * [#1761](https://github.com/moment/moment/issues/1761): moments created without a language are no longer following the global language, in case it changes. Only newly created moments take the global language by default. In case you're affected by this, wait, comment on [#1797](https://github.com/moment/moment/issues/1797) and wait for a proper reimplementation     * [#1642](https://github.com/moment/moment/issues/1642): 45 days is no longer "a month" according to humanize, cutoffs for month, and year have changed. Hopefully your code does not depend on a particular answer from humanize (which it shouldn't anyway)     * [#1784](https://github.com/moment/moment/issues/1784): if you use the human readable English datetime format in a weird way (like storing them in a database) that would break when the format changes you're at risk.
* deprecations (old behavior will be dropped in 3.0)     * [#1761](https://github.com/moment/moment/issues/1761) `lang` is renamed to `locale`, `langData` -> `localeData`. Also there is now `defineLocale` that should be used when creating new locales     * [#1763](https://github.com/moment/moment/issues/1763) `add(unit, value)` and `subtract(unit, value)` are now deprecated. Use `add(value, unit)` and `subtract(value, unit)` instead.     * [#1759](https://github.com/moment/moment/issues/1759) rename `duration.toIsoString` to `duration.toISOString`. The js standard library and moment's `toISOString` follow that convention.
* new locales     * [#1789](https://github.com/moment/moment/issues/1789) Tibetan (bo)     * [#1786](https://github.com/moment/moment/issues/1786) Africaans (af)     * [#1778](https://github.com/moment/moment/issues/1778) Burmese (my)     * [#1727](https://github.com/moment/moment/issues/1727) Belarusian (be)
* bugfixes, locale bugfixes, performance improvements, features
* new languages
* [#1678](https://github.com/moment/moment/issues/1678) Bengali (bn)   * [#1628](https://github.com/moment/moment/issues/1628) Azerbaijani (az)   * [#1633](https://github.com/moment/moment/issues/1633) Arabic, Saudi Arabia (ar-sa)   * [#1648](https://github.com/moment/moment/issues/1648) Austrian German (de-at)
* features
* [#1663](https://github.com/moment/moment/issues/1663) configurable relative time thresholds   * [#1554](https://github.com/moment/moment/issues/1554) support anchor time in moment.calendar   * [#1693](https://github.com/moment/moment/issues/1693) support moment.ISO_8601 as parsing format   * [#1637](https://github.com/moment/moment/issues/1637) add moment.min and moment.max and deprecate min/max instance methods   * [#1704](https://github.com/moment/moment/issues/1704) support string value in add/subtract   * [#1647](https://github.com/moment/moment/issues/1647) add spm support (package manager)
* bugfixes
* languages   * [#1529](https://github.com/moment/moment/issues/1529) Serbian-Cyrillic (sr-cyr)   * [#1544](https://github.com/moment/moment/issues/1544), [#1546](https://github.com/moment/moment/issues/1546) Khmer Cambodia (km)
* features     * [#1419](https://github.com/moment/moment/issues/1419), [#1468](https://github.com/moment/moment/issues/1468), [#1467](https://github.com/moment/moment/issues/1467), [#1546](https://github.com/moment/moment/issues/1546) better handling of timezone-d moments around DST     * [#1462](https://github.com/moment/moment/issues/1462) add weeksInYear and isoWeeksInYear     * [#1475](https://github.com/moment/moment/issues/1475) support ordinal parsing     * [#1499](https://github.com/moment/moment/issues/1499) composer support     * [#1577](https://github.com/moment/moment/issues/1577), [#1604](https://github.com/moment/moment/issues/1604) put Date parsing in moment.createFromInputFallback so it can be properly deprecated and controlled in the future     * [#1545](https://github.com/moment/moment/issues/1545) extract two-digit year parsing in moment.parseTwoDigitYear, so it can be overwritten     * [#1590](https://github.com/moment/moment/issues/1590) (see [#1574](https://github.com/moment/moment/issues/1574)) set AMD global before module definition to better support non AMD module dependencies used in AMD environment     * [#1589](https://github.com/moment/moment/issues/1589) remove global in Node.JS environment (was not working before, nobody complained, was scheduled for removal anyway)     * [#1586](https://github.com/moment/moment/issues/1586) support quarter setting and parsing
* 18 bugs fixed
* languages   * [#1392](https://github.com/moment/moment/issues/1392) Armenian (hy-am)
* bugfixes   * [#1429](https://github.com/moment/moment/issues/1429) fixes [#1423](https://github.com/moment/moment/issues/1423) weird chrome-32 bug with js object creation   * [#1421](https://github.com/moment/moment/issues/1421) remove html entities from Welsh   * [#1418](https://github.com/moment/moment/issues/1418) fixes [#1401](https://github.com/moment/moment/issues/1401) improved non-padded tokens in strict matching   * [#1417](https://github.com/moment/moment/issues/1417) fixes [#1404](https://github.com/moment/moment/issues/1404) handle buggy moment object created by property cloning   * [#1398](https://github.com/moment/moment/issues/1398) fixes [#1397](https://github.com/moment/moment/issues/1397) fix Arabic-like week number parsing   * [#1396](https://github.com/moment/moment/issues/1396) add leftZeroFill(4) to GGGG and gggg formats   * [#1373](https://github.com/moment/moment/issues/1373) use lowercase for months and days in Catalan
* testing   * [#1374](https://github.com/moment/moment/issues/1374) run tests on multiple browser/os combos via SauceLabs and Travis
* New languages   * Luxemburish (lb) [1247](https://github.com/moment/moment/issues/1247)   * Serbian (rs) [1319](https://github.com/moment/moment/issues/1319)   * Tamil (ta) [1324](https://github.com/moment/moment/issues/1324)   * Macedonian (mk) [1337](https://github.com/moment/moment/issues/1337)
* Features   * [1311](https://github.com/moment/moment/issues/1311) Add quarter getter and format token `Q`   * [1303](https://github.com/moment/moment/issues/1303) strict parsing now respects number of digits per token (fix [1196](https://github.com/moment/moment/issues/1196))   * 0d30bb7 add jspm support   * [1347](https://github.com/moment/moment/issues/1347) improve zone parsing   * [1362](https://github.com/moment/moment/issues/1362) support merideam parsing in Korean
* 22 bugfixes
* **Deprecate** globally exported moment, will be removed in next major * New languages   * Farose (fo) [#1206](https://github.com/moment/moment/issues/1206)   * Tagalog/Filipino (tl-ph) [#1197](https://github.com/moment/moment/issues/1197)   * Welsh (cy) [#1215](https://github.com/moment/moment/issues/1215) * Bugfixes   * properly handle Z at the end of iso RegExp [#1187](https://github.com/moment/moment/issues/1187)   * chinese meridian time improvements [#1076](https://github.com/moment/moment/issues/1076)   * fix language tests [#1177](https://github.com/moment/moment/issues/1177)   * remove some failing tests (that should have never existed :))     [#1185](https://github.com/moment/moment/issues/1185)     [#1183](https://github.com/moment/moment/issues/1183)   * handle russian noun cases in weird cases [#1195](https://github.com/moment/moment/issues/1195)
Removed a trailing comma [1169] and fixed a bug with `months`, `weekdays` getters [#1171](https://github.com/moment/moment/issues/1171).
Changed isValid, added strict parsing. Week tokens parsing.
Fixed bug in string prototype test. Updated authors and contributors.
Added bower support.
Language files now use UMD.
Creating moment defaults to current date/month/year.
Added a bundle of moment and all language files.
Added better week support.
Added ability to set offset with `moment#zone`.
Added ability to set month or weekday from a string.
Added `moment#min` and `moment#max`
Added short form localized tokens.
Added ability to define language a string should be parsed in.
Added support for reversed add/subtract arguments.
Added support for `endOf('week')` and `startOf('week')`.
Fixed the logic for `moment#diff(Moment, 'months')` and `moment#diff(Moment, 'years')`
`moment#diff` now floors instead of rounds.
Normalized `moment#toString`.
Added `isSame`, `isAfter`, and `isBefore` methods.
Added better week support.
Added `moment#toJSON`
Bugfix: Fixed parsing of first century dates
Bugfix: Parsing 10Sep2001 should work as expected
Bugfix: Fixed wierdness with `moment.utc()` parsing.
Changed language ordinal method to return the number + ordinal instead of just the ordinal.
Changed two digit year parsing cutoff to match strptime.
Removed `moment#sod` and `moment#eod` in favor of `moment#startOf` and `moment#endOf`.
Removed `moment.humanizeDuration()` in favor of `moment.duration().humanize()`.
Removed the lang data objects from the top level namespace.
Duplicate `Date` passed to `moment()` instead of referencing it.
Bugfixes
Bugfixes
Added `moment.fn.endOf()` and `moment.fn.startOf()`.
Added validation via `moment.fn.isValid()`.
Made formatting method 3x faster. http://jsperf.com/momentjs-cached-format-functions
Add support for month/weekday callbacks in `moment.fn.format()`
Added instance specific languages.
Added two letter weekday abbreviations with the formatting token `dd`.
Various language updates.
Various bugfixes.
Added Durations.
Revamped parser to support parsing non-separated strings (YYYYMMDD vs YYYY-MM-DD).
Added support for millisecond parsing and formatting tokens (S SS SSS)
Added a getter for `moment.lang()`
Various bugfixes.
There are a few things deprecated in the 1.6.0 release.
1. The format tokens `z` and `zz` (timezone abbreviations like EST CST MST etc) will no longer be supported. Due to inconsistent browser support, we are unable to consistently produce this value. See [this issue](https://github.com/timrwood/moment/issues/162) for more background.
2. The method `moment.fn.native` is deprecated in favor of `moment.fn.toDate`. There continue to be issues with Google Closure Compiler throwing errors when using `native`, even in valid instances.
3. The way to customize am/pm strings is being changed. This would only affect you if you created a custom language file. For more information, see [this issue](https://github.com/timrwood/moment/pull/222).
Added UTC mode.
Added automatic ISO8601 parsing.
Various bugfixes.
Added `moment.fn.toDate` as a replacement for `moment.fn.native`.
Added `moment.fn.sod` and `moment.fn.eod` to get the start and end of day.
Various bugfixes.
Added support for parsing month names in the current language.
Added escape blocks for parsing tokens.
Added `moment.fn.calendar` to format strings like 'Today 2:30 PM', 'Tomorrow 1:25 AM', and 'Last Sunday 4:30 AM'.
Added `moment.fn.day` as a setter.
Various bugfixes
Added timezones to parser and formatter.
Added `moment.fn.isDST`.
Added `moment.fn.zone` to get the timezone offset in minutes.
Various bugfixes
Added time specific diffs (months, days, hours, etc)
Added `moment.fn.format` localized masks. 'L LL LLL LLLL' [issue 29](https://github.com/timrwood/moment/pull/29)
Fixed [issue 31](https://github.com/timrwood/moment/pull/31).
Added `moment.version` to get the current version.
Removed `window !== undefined` when checking if module exists to support browserify. [issue 25](https://github.com/timrwood/moment/pull/25)
Added convenience methods for getting and setting date parts.
Added better support for `moment.add()`.
Added better lang support in NodeJS.
Renamed library from underscore.date to Moment.js
Added Portuguese, Italian, and French language support
Added _date.lang() support. Added support for passing multiple formats to try to parse a date. _date("07-10-1986", ["MM-DD-YYYY", "YYYY-MM-DD"]); Made parse from string and single format 25% faster.
Bugfix for [issue 8](https://github.com/timrwood/underscore.date/pull/8) and [issue 9](https://github.com/timrwood/underscore.date/pull/9).
Bugfix for [issue 5](https://github.com/timrwood/underscore.date/pull/5).
Dropped the redundant `_date.date()` in favor of `_date()`. Removed `_date.now()`, as it is a duplicate of `_date()` with no parameters. Removed `_date.isLeapYear(yearNumber)`. Use `_date([yearNumber]).isLeapYear()` instead. Exposed customization options through the `_date.relativeTime`, `_date.weekdays`, `_date.weekdaysShort`, `_date.months`, `_date.monthsShort`, and `_date.ordinal` variables instead of the `_date.customize()` function.
Added date input formats for input strings.
Added underscore.date to npm. Removed dependencies on underscore.
Added `'z'` and `'zz'` to `_.date().format()`. Cleaned up some redundant code to trim off some bytes.
Cleaned up the namespace. Moved all date manipulation and display functions to the _.date() object.
Switched to the Underscore methodology of not mucking with the native objects' prototypes. Made chaining possible.
Changed date names to be a more pseudo standardized 'dddd, MMMM Do YYYY, h:mm:ss a'. Added `Date.prototype` functions `add`, `subtract`, `isdst`, and `isleapyear`.
Changed function names to be more concise. Changed date format from php date format to custom format.
Initial release
[![NPM version][npm-version-image]][npm-url] [![NPM downloads][npm-downloads-image]][npm-url] [![MIT License][license-image]][license-url] [![Build Status][travis-image]][travis-url]
A lightweight javascript date library for parsing, validating, manipulating, and formatting dates.
There are a number of small backwards incompatible changes with version 2.0.0. [See the full descriptions here](https://gist.github.com/timrwood/e72f2eef320ed9e37c51#backwards-incompatible-changes)
* Changed language ordinal method to return the number + ordinal instead of just the ordinal.
* Changed two digit year parsing cutoff to match strptime.
* Removed `moment#sod` and `moment#eod` in favor of `moment#startOf` and `moment#endOf`.
* Removed `moment.humanizeDuration()` in favor of `moment.duration().humanize()`.
* Removed the lang data objects from the top level namespace.
* Duplicate `Date` passed to `moment()` instead of referencing it.
Moment.js is freely distributable under the terms of the [MIT license](LICENSE).
[license-image]: http://img.shields.io/badge/license-MIT-blue.svg?style=flat [license-url]: LICENSE
[npm-url]: https://npmjs.org/package/moment [npm-version-image]: http://img.shields.io/npm/v/moment.svg?style=flat [npm-downloads-image]: http://img.shields.io/npm/dm/moment.svg?style=flat
[travis-url]: http://travis-ci.org/moment/moment [travis-image]: http://img.shields.io/travis/moment/moment/develop.svg?style=flat
bower distribution of [angular-file-upload](https://github.com/danialfarid/angular-file-upload). All issues and pull request must be sumbitted to [angular-file-upload](https://github.com/danialfarid/angular-file-upload)
Install with `bower`:
```shell bower install ng-file-upload ```
Add a `<script>` to your `index.html`:
```html <script src="/bower_components/angular/angular-file-upload-shim.js"></script> <!--only needed if you support upload progress/abort or non HTML5 FormData browsers.--> <!-- NOTE: angular.file-upload-shim.js MUST BE PLACED BEFORE angular.js--> <script src="/bower_components/angular/angular.js"></script> <script src="/bower_components/angular/angular-file-upload.js"></script> ```
Select2 =======
Select2 is a jQuery-based replacement for select boxes. It supports searching, remote data sets, and infinite scrolling of results.
To get started, checkout examples and documentation at http://ivaynberg.github.com/select2
Use cases ---------
* Enhancing native selects with search. * Enhancing native selects with a better multi-select interface. * Loading data from JavaScript: easily load items via ajax and have them searchable. * Nesting optgroups: native selects only support one level of nested. Select2 does not have this restriction. * Tagging: ability to add new items on the fly. * Working with large, remote datasets: ability to partially load a dataset based on the search term. * Paging of large datasets: easy support for loading more pages when the results are scrolled to the end. * Templating: support for custom rendering of results and selections.
Browser compatibility --------------------- * IE 8+ * Chrome 8+ * Firefox 10+ * Safari 3+ * Opera 10.6+   Usage ----- You can source Select2 directly from a [CDN like JSDliver](http://www.jsdelivr.com/#!select2), [download it from this GitHub repo](https://github.com/ivaynberg/select2/tags), or use one of the integrations below.
Integrations ------------
* [Wicket-Select2](https://github.com/ivaynberg/wicket-select2) (Java / [Apache Wicket](http://wicket.apache.org)) * [select2-rails](https://github.com/argerim/select2-rails) (Ruby on Rails) * [AngularUI](http://angular-ui.github.com/#directives-select2) ([AngularJS](angularjs.org)) * [Django](https://github.com/applegrew/django-select2) * [Symfony](https://github.com/19Gerhard85/sfSelect2WidgetsPlugin) * [Symfony2](https://github.com/avocode/FormExtensions) * [Bootstrap 2](https://github.com/t0m/select2-bootstrap-css) and [Bootstrap 3](https://github.com/t0m/select2-bootstrap-css/tree/bootstrap3) (CSS skins) * [Meteor](https://github.com/nate-strauser/meteor-select2) (modern reactive JavaScript framework; + [Bootstrap 3 skin](https://github.com/esperadomedia/meteor-select2-bootstrap3-css/)) * [Meteor](https://jquery-select2.meteor.com) * [Yii 2.x](http://demos.krajee.com/widgets#select2) * [Yii 1.x](https://github.com/tonybolzan/yii-select2) * [AtmosphereJS](https://atmospherejs.com/package/jquery-select2)
* [Knockout.js](https://github.com/ivaynberg/select2/wiki/Knockout.js-Integration) * [Socket.IO](https://github.com/ivaynberg/select2/wiki/Socket.IO-Integration) * [PHP](https://github.com/ivaynberg/select2/wiki/PHP-Example) * [.Net MVC] (https://github.com/ivaynberg/select2/wiki/.Net-MVC-Example)
Internationalization (i18n) ---------------------------
Select2 supports multiple languages by simply including the right language JS file (`select2_locale_it.js`, `select2_locale_nl.js`, etc.) after `select2.js`.
Missing a language? Just copy `select2_locale_en.js.template`, translate it, and make a pull request back to Select2 here on GitHub.
Bug tracker -----------
Have a bug? Please create an issue here on GitHub!
https://github.com/ivaynberg/select2/issues
Mailing list ------------
Have a question? Ask on our mailing list!
select2@googlegroups.com
https://groups.google.com/d/forum/select2
Copyright and license ---------------------
Copyright 2012 Igor Vaynberg
This software is licensed under the Apache License, Version 2.0 (the "Apache License") or the GNU General Public License version 2 (the "GPL License"). You may choose either license to govern your use of this software only upon the condition that you accept all of the terms of either the Apache License or the GPL License.
You may obtain a copy of the Apache License and the GPL License in the LICENSE file, or at:
http://www.apache.org/licenses/LICENSE-2.0 http://www.gnu.org/licenses/gpl-2.0.html
Unless required by applicable law or agreed to in writing, software distributed under the Apache License or the GPL License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the Apache License and the GPL License for the specific language governing permissions and limitations under the Apache License and the GPL License.
__                       /\ \                                                         __      __  __    ___    \_\ \     __   _ __   ____    ___    ___   _ __    __       /\_\    ____     /\ \/\ \ /' _ `\  /'_  \  /'__`\/\  __\/ ,__\  / ___\ / __`\/\  __\/'__`\     \/\ \  /',__\     \ \ \_\ \/\ \/\ \/\ \ \ \/\  __/\ \ \//\__, `\/\ \__//\ \ \ \ \ \//\  __/  __  \ \ \/\__, `\      \ \____/\ \_\ \_\ \___,_\ \____\\ \_\\/\____/\ \____\ \____/\ \_\\ \____\/\_\ _\ \ \/\____/       \/___/  \/_/\/_/\/__,_ /\/____/ \/_/ \/___/  \/____/\/___/  \/_/ \/____/\/_//\ \_\ \/___/                                                                                   \ \____/                                                                                    \/___/
Underscore.js is a utility-belt library for JavaScript that provides support for the usual functional suspects (each, map, reduce, filter...) without extending any core JavaScript objects.
For Docs, License, Tests, and pre-packed downloads, see: http://underscorejs.org
Underscore is an open-sourced component of DocumentCloud: https://github.com/documentcloud
Many thanks to our contributors: https://github.com/jashkenas/underscore/contributors
Cryptix General License
Copyright (c) 1995-2005 The Cryptix Foundation Limited. All rights reserved.
Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
1. Redistributions of source code must retain the copyright notice,      this list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright      notice, this list of conditions and the following disclaimer in      the documentation and/or other materials provided with the      distribution.
THIS SOFTWARE IS PROVIDED BY THE CRYPTIX FOUNDATION LIMITED AND CONTRIBUTORS ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE CRYPTIX FOUNDATION LIMITED OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre>
Copyright (c) 2000-2011 France Tlcom All rights reserved.
Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
1. Redistributions of source code must retain the above copyright    notice, this list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright    notice, this list of conditions and the following disclaimer in the    documentation and/or other materials provided with the distribution.
3. Neither the name of the copyright holders nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.
THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre>
Copyright  1991-2016 Unicode, Inc. All rights reserved.
Distributed under the Terms of Use in http://www.unicode.org/copyright.html.
Permission is hereby granted, free of charge, to any person obtaining a copy of the Unicode data files and any associated documentation (the "Data Files") or Unicode software and any associated documentation (the "Software") to deal in the Data Files or Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, and/or sell copies of the Data Files or Software, and to permit persons to whom the Data Files or Software are furnished to do so, provided that (a) this copyright and permission notice appear with all copies of the Data Files or Software, (b) this copyright and permission notice appear in associated documentation, and (c) there is clear notice in each modified Data File or in the Software as well as in the documentation associated with the Data File(s) or Software that the data or software has been modified.
THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF THIRD PARTY RIGHTS. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THE DATA FILES OR SOFTWARE.
Except as contained in this notice, the name of a copyright holder shall not be used in advertising or otherwise to promote the sale, use or other dealings in these Data Files or Software without prior written authorization of the copyright holder.
</pre>
UNICODE, INC. LICENSE AGREEMENT - DATA FILES AND SOFTWARE Unicode Data Files include all data files under the directories http://www.unicode.org/Public/, http://www.unicode.org/reports/, http://www.unicode.org/cldr/data/, http://source.icu-project.org/repos/icu/, and http://www.unicode.org/utility/trac/browser/.
Unicode Data Files do not include PDF online code charts under the directory http://www.unicode.org/Public/.
Software includes any source code published in the Unicode Standard or under the directories http://www.unicode.org/Public/, http://www.unicode.org/reports/, http://www.unicode.org/cldr/data/, http://source.icu-project.org/repos/icu/, and http://www.unicode.org/utility/trac/browser/.
NOTICE TO USER: Carefully read the following legal agreement. BY DOWNLOADING, INSTALLING, COPYING OR OTHERWISE USING UNICODE INC.'S DATA FILES ("DATA FILES"), AND/OR SOFTWARE ("SOFTWARE"), YOU UNEQUIVOCALLY ACCEPT, AND AGREE TO BE BOUND BY, ALL OF THE TERMS AND CONDITIONS OF THIS AGREEMENT. IF YOU DO NOT AGREE, DO NOT DOWNLOAD, INSTALL, COPY, DISTRIBUTE OR USE THE DATA FILES OR SOFTWARE.
COPYRIGHT AND PERMISSION NOTICE
Copyright  1991-2016 Unicode, Inc. All rights reserved. Distributed under the Terms of Use in http://www.unicode.org/copyright.html.
Permission is hereby granted, free of charge, to any person obtaining a copy of the Unicode data files and any associated documentation (the "Data Files") or Unicode software and any associated documentation (the "Software") to deal in the Data Files or Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, and/or sell copies of the Data Files or Software, and to permit persons to whom the Data Files or Software are furnished to do so, provided that either (a) this copyright and permission notice appear with all copies of the Data Files or Software, or (b) this copyright and permission notice appear in associated Documentation.
THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF THIRD PARTY RIGHTS. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THE DATA FILES OR SOFTWARE.
Except as contained in this notice, the name of a copyright holder shall not be used in advertising or otherwise to promote the sale, use or other dealings in these Data Files or Software without prior written authorization of the copyright holder.
</pre>
The Source Code of this file is available under the Mozilla Public License, v. 2.0 and is located at https://github.com/publicsuffix/list/blob/03089bfe4aa5b7a2e291f33e07a28d20f875cb83/public_suffix_list.dat If a copy of the MPL was not distributed with this file, you can obtain one at http://mozilla.org/MPL/2.0/.
Software distributed under the License is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License for the specific language governing rights and limitations under the License.  </pre>
1. Definitions --------------
1.1. "Contributor"     means each individual or legal entity that creates, contributes to     the creation of, or owns Covered Software.
1.2. "Contributor Version"     means the combination of the Contributions of others (if any) used     by a Contributor and that particular Contributor's Contribution.
1.3. "Contribution"     means Covered Software of a particular Contributor.
1.4. "Covered Software"     means Source Code Form to which the initial Contributor has attached     the notice in Exhibit A, the Executable Form of such Source Code     Form, and Modifications of such Source Code Form, in each case     including portions thereof.
1.5. "Incompatible With Secondary Licenses"     means
(a) that the initial Contributor has attached the notice described         in Exhibit B to the Covered Software; or
(b) that the Covered Software was made available under the terms of         version 1.1 or earlier of the License, but not also under the         terms of a Secondary License.
1.6. "Executable Form"     means any form of the work other than Source Code Form.
1.7. "Larger Work"     means a work that combines Covered Software with other material, in      a separate file or files, that is not Covered Software.
1.8. "License"     means this document.
1.9. "Licensable"     means having the right to grant, to the maximum extent possible,     whether at the time of the initial grant or subsequently, any and     all of the rights conveyed by this License.
1.10. "Modifications"     means any of the following:
(a) any file in Source Code Form that results from an addition to,         deletion from, or modification of the contents of Covered         Software; or
(b) any new file in Source Code Form that contains any Covered         Software.
1.11. "Patent Claims" of a Contributor     means any patent claim(s), including without limitation, method,     process, and apparatus claims, in any patent Licensable by such     Contributor that would be infringed, but for the grant of the     License, by the making, using, selling, offering for sale, having     made, import, or transfer of either its Contributions or its     Contributor Version.
1.12. "Secondary License"     means either the GNU General Public License, Version 2.0, the GNU     Lesser General Public License, Version 2.1, the GNU Affero General     Public License, Version 3.0, or any later versions of those     licenses.
1.13. "Source Code Form"     means the form of the work preferred for making modifications.
1.14. "You" (or "Your")     means an individual or a legal entity exercising rights under this     License. For legal entities, "You" includes any entity that     controls, is controlled by, or is under common control with You. For     purposes of this definition, "control" means (a) the power, direct     or indirect, to cause the direction or management of such entity,     whether by contract or otherwise, or (b) ownership of more than     fifty percent (50%) of the outstanding shares or beneficial     ownership of such entity.
2. License Grants and Conditions --------------------------------
2.1. Grants
Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license:
(a) under intellectual property rights (other than patent or trademark)     Licensable by such Contributor to use, reproduce, make available,     modify, display, perform, distribute, and otherwise exploit its     Contributions, either on an unmodified basis, with Modifications, or     as part of a Larger Work; and
(b) under Patent Claims of such Contributor to make, use, sell, offer     for sale, have made, import, and otherwise transfer either its     Contributions or its Contributor Version.
2.2. Effective Date
The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution.
2.3. Limitations on Grant Scope
The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor:
(a) for any code that a Contributor has removed from Covered Software;     or
(b) for infringements caused by: (i) Your and any other third party's     modifications of Covered Software, or (ii) the combination of its     Contributions with other software (except as part of its Contributor     Version); or
(c) under Patent Claims infringed by Covered Software in the absence of     its Contributions.
This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4).
2.4. Subsequent Licenses
No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3).
2.5. Representation
Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License.
2.6. Fair Use
This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents.
2.7. Conditions
Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1.
3. Responsibilities -------------------
3.1. Distribution of Source Form
All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients' rights in the Source Code Form.
3.2. Distribution of Executable Form
If You distribute Covered Software in Executable Form then:
(a) such Covered Software must also be made available in Source Code     Form, as described in Section 3.1, and You must inform recipients of     the Executable Form how they can obtain a copy of such Source Code     Form by reasonable means in a timely manner, at a charge no more     than the cost of distribution to the recipient; and
(b) You may distribute such Executable Form under the terms of this     License, or sublicense it under different terms, provided that the     license for the Executable Form does not attempt to limit or alter     the recipients' rights in the Source Code Form under this License.
3.3. Distribution of a Larger Work
You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s).
3.4. Notices
You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies.
3.5. Application of Additional Terms
You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction.
4. Inability to Comply Due to Statute or Regulation ---------------------------------------------------
If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it.
5. Termination --------------
5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice.
5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate.
5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination.
************************************************************************ *                                                                      * *  6. Disclaimer of Warranty                                           * *  -------------------------                                           * *                                                                      * *  Covered Software is provided under this License on an "as is"       * *  basis, without warranty of any kind, either expressed, implied, or  * *  statutory, including, without limitation, warranties that the       * *  Covered Software is free of defects, merchantable, fit for a        * *  particular purpose or non-infringing. The entire risk as to the     * *  quality and performance of the Covered Software is with You.        * *  Should any Covered Software prove defective in any respect, You     * *  (not any Contributor) assume the cost of any necessary servicing,   * *  repair, or correction. This disclaimer of warranty constitutes an   * *  essential part of this License. No use of any Covered Software is   * *  authorized under this License except under this disclaimer.         * *                                                                      * ************************************************************************
************************************************************************ *                                                                      * *  7. Limitation of Liability                                          * *  --------------------------                                          * *                                                                      * *  Under no circumstances and under no legal theory, whether tort      * *  (including negligence), contract, or otherwise, shall any           * *  Contributor, or anyone who distributes Covered Software as          * *  permitted above, be liable to You for any direct, indirect,         * *  special, incidental, or consequential damages of any character      * *  including, without limitation, damages for lost profits, loss of    * *  goodwill, work stoppage, computer failure or malfunction, or any    * *  and all other commercial damages or losses, even if such party      * *  shall have been informed of the possibility of such damages. This   * *  limitation of liability shall not apply to liability for death or   * *  personal injury resulting from such party's negligence to the       * *  extent applicable law prohibits such limitation. Some               * *  jurisdictions do not allow the exclusion or limitation of           * *  incidental or consequential damages, so this exclusion and          * *  limitation may not apply to You.                                    * *                                                                      * ************************************************************************
8. Litigation -------------
Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party's ability to bring cross-claims or counter-claims.
9. Miscellaneous ----------------
This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor.
10. Versions of the License ---------------------------
10.1. New Versions
Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number.
10.2. Effect of New Versions
You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward.
10.3. Modified Versions
If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License).
10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses
If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached.
Exhibit A - Source Code Form License Notice -------------------------------------------
This Source Code Form is subject to the terms of the Mozilla Public   License, v. 2.0. If a copy of the MPL was not distributed with this   file, You can obtain one at http://mozilla.org/MPL/2.0/.
If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice.
You may add additional accurate notices of copyright ownership.
Exhibit B - "Incompatible With Secondary Licenses" Notice ---------------------------------------------------------
This Source Code Form is "Incompatible With Secondary Licenses", as   defined by the Mozilla Public License, v. 2.0.
</pre>
Copyright (C) 1995-2017 Jean-loup Gailly and Mark Adler
This software is provided 'as-is', without any express or implied warranty.  In no event will the authors be held liable for any damages arising from the use of this software.
Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions:
1. The origin of this software must not be misrepresented; you must not    claim that you wrote the original software. If you use this software    in a product, an acknowledgment in the product documentation would be    appreciated but is not required. 2. Altered source versions must be plainly marked as such, and must not be    misrepresented as being the original software. 3. This notice may not be removed or altered from any source distribution.
Jean-loup Gailly        Mark Adler jloup@gzip.org          madler@alumni.caltech.edu
</pre>
Copyright 2001,2003 Keith Packard
Permission to use, copy, modify, distribute, and sell this software and its documentation for any purpose is hereby granted without fee, provided that the above copyright notice appear in all copies and that both that copyright notice and this permission notice appear in supporting documentation, and that the name of Keith Packard not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission. Keith Packard makes no representations about the suitability of this software for any purpose.  It is provided "as is" without express or implied warranty.
KEITH PACKARD DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN NO EVENT SHALL KEITH PACKARD BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
</pre>
The GIFLIB distribution is Copyright (c) 1997 Eric S. Raymond
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
http://cgit.freedesktop.org/harfbuzz/tree/COPYING
<pre>
HarfBuzz is licensed under the so-called "Old MIT" license.  Details follow. For parts of HarfBuzz that are licensed under different licenses see individual files names COPYING in subdirectories where applicable.
Copyright  2010,2011,2012, 2013  Google, Inc. Copyright  2012, 2013  Mozilla Foundation Copyright  2011  Codethink Limited Copyright  2008,2010  Nokia Corporation and/or its subsidiary(-ies) Copyright  2009  Keith Stribley Copyright (C) 2012 Grigori Goronzy <greg@kinoho.net> Copyright  2009, 2011  Martin Hosken and SIL International Copyright  2007  Chris Wilson Copyright  2006  Behdad Esfahbod Copyright  2005  David Turner Copyright  2004,2007,2008,2009,2010, 2013  Red Hat, Inc. Copyright  1998-2004  David Turner and Werner Lemberg
For full copyright notices consult the individual files in the package.
Permission is hereby granted, without written agreement and without license or royalty fees, to use, copy, modify, and distribute this software and its documentation for any purpose, provided that the above copyright notice and the following two paragraphs appear in all copies of this software.
IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE TO ANY PARTY FOR DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN IF THE COPYRIGHT HOLDER HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
THE COPYRIGHT HOLDER SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE SOFTWARE PROVIDED HEREUNDER IS ON AN "AS IS" BASIS, AND THE COPYRIGHT HOLDER HAS NO OBLIGATION TO PROVIDE MAINTENANCE, SUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS.
All source code, except for one section, is licensed as above.   The one exception is licensed with a slightly different MIT variant: The contents of this directory are licensed under the following terms:
Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.
THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
</pre>
Must reproduce following license in documentation and/or other materials provided with distribution:
The authors make NO WARRANTY or representation, either express or implied, with respect to this software, its quality, accuracy, merchantability, or fitness for a particular purpose.  This software is provided "AS IS", and you, its user, assume the entire risk as to its quality and accuracy.
This software is copyright (C) 1991-1998, Thomas G. Lane. All Rights Reserved except as specified below.
Permission is hereby granted to use, copy, modify, and distribute this software (or portions thereof) for any purpose, without fee, subject to these conditions:
(1) If any part of the source code for this software is distributed, then this README file must be included, with this copyright and no-warranty notice unaltered; and any additions, deletions, or changes to the original files must be clearly indicated in accompanying documentation.
(2) If only executable code is distributed, then the accompanying documentation must state that "this software is based in part on the work of the Independent JPEG Group".
(3) Permission for use of this software is granted only if the user accepts full responsibility for any undesirable consequences; the authors accept NO LIABILITY for damages of any kind.
These conditions apply to any software derived from or based on the IJG code, not just to the unmodified library.  If you use our work, you ought to acknowledge us.
Permission is NOT granted for the use of any IJG author's name or company name in advertising or publicity relating to this software or products derived from it.  This software may be referred to only as "the Independent JPEG Group's software".
We specifically permit and encourage the use of this software as the basis of commercial products, provided that all warranty or liability claims are assumed by the product vendor.
ansi2knr.c is included in this distribution by permission of L. Peter Deutsch, sole proprietor of its copyright holder, Aladdin Enterprises of Menlo Park, CA. ansi2knr.c is NOT covered by the above copyright and conditions, but instead by the usual distribution terms of the Free Software Foundation; principally, that you must include source code if you redistribute it. (See the file ansi2knr.c for full details.)  However, since ansi2knr.c is not needed as part of any program generated from the IJG code, this does not limit you more than the foregoing paragraphs do.
The Unix configuration script "configure" was produced with GNU Autoconf. It is copyright by the Free Software Foundation but is freely distributable. The same holds for its supporting scripts (config.guess, config.sub, ltconfig, ltmain.sh).  Another support script, install-sh, is copyright by M.I.T. but is also freely distributable.
It appears that the arithmetic coding option of the JPEG spec is covered by patents owned by IBM, AT&T, and Mitsubishi.  Hence arithmetic coding cannot legally be used without obtaining one or more licenses.  For this reason, support for arithmetic coding has been removed from the free JPEG software. (Since arithmetic coding provides only a marginal gain over the unpatented Huffman mode, it is unlikely that very many implementations will support it.) So far as we are aware, there are no patent restrictions on the remaining code.
The IJG distribution formerly included code to read and write GIF files. To avoid entanglement with the Unisys LZW patent, GIF reading support has been removed altogether, and the GIF writer has been simplified to produce "uncompressed GIFs".  This technique does not use the LZW algorithm; the resulting GIF files are larger than usual, but are readable by all standard GIF decoders.
We are required to state that "The Graphics Interchange Format(c) is the Copyright property of CompuServe Incorporated.  GIF(sm) is a Service Mark property of CompuServe Incorporated."
</pre>
Little Color Management System Copyright (c) 1998-2016 Marti Maria Saguer
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
This copy of the libpng notices is provided for your convenience.  In case of any discrepancy between this copy and the notices in the file png.h that is included in the libpng distribution, the latter shall prevail.
COPYRIGHT NOTICE, DISCLAIMER, and LICENSE:
If you modify libpng you may insert additional notices immediately following this sentence.
This code is released under the libpng license.
libpng versions 1.0.7, July 1, 2000 through 1.6.23, June 9, 2016 are Copyright (c) 2000-2002, 2004, 2006-2016 Glenn Randers-Pehrson, are derived from libpng-1.0.6, and are distributed according to the same disclaimer and license as libpng-1.0.6 with the following individuals added to the list of Contributing Authors:
Simon-Pierre Cadieux    Eric S. Raymond    Mans Rullgard    Cosmin Truta    Gilles Vollant    James Yu
and with the following additions to the disclaimer:
There is no warranty against interference with your enjoyment of the    library or against infringement.  There is no warranty that our    efforts or the library will fulfill any of your particular purposes    or needs.  This library is provided with all faults, and the entire    risk of satisfactory quality, performance, accuracy, and effort is with    the user.
Some files in the "contrib" directory and some configure-generated files that are distributed with libpng have other copyright owners and are released under other open source licenses.
libpng versions 0.97, January 1998, through 1.0.6, March 20, 2000, are Copyright (c) 1998-2000 Glenn Randers-Pehrson, are derived from libpng-0.96, and are distributed according to the same disclaimer and license as libpng-0.96, with the following individuals added to the list of Contributing Authors:
Tom Lane    Glenn Randers-Pehrson    Willem van Schaik
libpng versions 0.89, June 1996, through 0.96, May 1997, are Copyright (c) 1996-1997 Andreas Dilger, are derived from libpng-0.88, and are distributed according to the same disclaimer and license as libpng-0.88, with the following individuals added to the list of Contributing Authors:
John Bowler    Kevin Bracey    Sam Bushell    Magnus Holmgren    Greg Roelofs    Tom Tanner
Some files in the "scripts" directory have other copyright owners but are released under this license.
libpng versions 0.5, May 1995, through 0.88, January 1996, are Copyright (c) 1995-1996 Guy Eric Schalnat, Group 42, Inc.
For the purposes of this copyright and license, "Contributing Authors" is defined as the following set of individuals:
Andreas Dilger    Dave Martindale    Guy Eric Schalnat    Paul Schmidt    Tim Wegner
The PNG Reference Library is supplied "AS IS".  The Contributing Authors and Group 42, Inc. disclaim all warranties, expressed or implied, including, without limitation, the warranties of merchantability and of fitness for any purpose.  The Contributing Authors and Group 42, Inc. assume no liability for direct, indirect, incidental, special, exemplary, or consequential damages, which may result from the use of the PNG Reference Library, even if advised of the possibility of such damage.
Permission is hereby granted to use, copy, modify, and distribute this source code, or portions hereof, for any purpose, without fee, subject to the following restrictions:
1. The origin of this source code must not be misrepresented.
2. Altered versions must be plainly marked as such and must not      be misrepresented as being the original source.
3. This Copyright notice may not be removed or altered from any      source or altered source distribution.
The Contributing Authors and Group 42, Inc. specifically permit, without fee, and encourage the use of this source code as a component to supporting the PNG file format in commercial products.  If you use this source code in a product, acknowledgment is not required but would be appreciated.
END OF COPYRIGHT NOTICE, DISCLAIMER, and LICENSE.
</pre>
Mesa 3-D graphics library Version:  4.1
Copyright (C) 1999-2002  Brian Paul   All Rights Reserved.
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL BRIAN PAUL BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
Copyright (c) 2007 The Khronos Group Inc.
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and/or associated documentation files (the "Materials"), to deal in the Materials without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Materials, and to permit persons to whom the Materials are furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Materials.
THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE MATERIALS OR THE USE OR OTHER DEALINGS IN THE MATERIALS.
</pre>
This is the copyright for the files in src/java.desktop/unix/native/libawt_xawt: list.h, multiVis.h, wsutils.h, list.c, multiVis.c
Copyright (c) 1994 Hewlett-Packard Co. Copyright (c) 1996 X Consortium
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE X CONSORTIUM BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Except as contained in this notice, the name of the X Consortium shall not be used in advertising or otherwise to promote the sale, use or other dealings in this Software without prior written authorization from the X Consortium.
___________________________
The files in motif/lib/Xm/util included this copyright: mkdirhier.man,xmkmf.man, chownxterm.c, makeg.man, mergelib.cpp,  lndir.man, makestrs.man, checktree.c, lndir.c, makestrs.c
Copyright (c) 1993, 1994 X Consortium
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE X CONSORTIUM BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Except as contained in this notice, the name of the X Consortium shall not be used in advertising or otherwise to promote the sale, use or other dealing in this Software without prior written authorization from the X Consortium.
_____________________________
Xmos_r.h: /* Copyright (c) 1996 X Consortium
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE X CONSORTIUM BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Except as contained in this notice, the name of the X Consortium shall not be used in advertising or otherwise to promote the sale, use or other dealings in this Software without prior written authorization from the X Consortium. */
_____________________________
Copyright notice for extutil.h: Copyright 1989, 1998 The Open Group
All Rights Reserved.
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE OPEN GROUP BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Except as contained in this notice, the name of The Open Group shall not be used in advertising or otherwise to promote the sale, use or other dealings in this Software without prior written authorization from The Open Group. * * Author: Jim Fulton, MIT The Open Group * * Xlib Extension-Writing Utilities * * This package contains utilities for writing the client API for various * protocol extensions. THESE INTERFACES ARE NOT PART OF THE X STANDARD AND * ARE SUBJECT TO CHANGE! */
_____________________________
Copyright notice for HPkeysym.h: /*
Copyright 1987, 1998 The Open Group
All Rights Reserved.
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE OPEN GROUP BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Except as contained in this notice, the name of The Open Group shall not be used in advertising or otherwise to promote the sale, use or other dealings in this Software without prior written authorization from The Open Group.
Copyright 1987 by Digital Equipment Corporation, Maynard, Massachusetts,
All Rights Reserved
Permission to use, copy, modify, and distribute this software and its documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appear in all copies and that both that copyright notice and this permission notice appear in supporting documentation, and that the names of Hewlett Packard or Digital not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission.
DIGITAL DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN NO EVENT SHALL DIGITAL BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
HEWLETT-PACKARD MAKES NO WARRANTY OF ANY KIND WITH REGARD TO THIS SOFWARE, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. Hewlett-Packard shall not be liable for errors contained herein or direct, indirect, special, incidental or consequential damages in connection with the furnishing, performance, or use of this material.
*/ _____________________________________
Copyright notice in keysym2ucs.h:
Copyright 1987, 1994, 1998 The Open Group
Permission to use, copy, modify, distribute, and sell this software and its documentation for any purpose is hereby granted without fee, provided that the above copyright notice appear in all copies and that both that copyright notice and this permission notice appear in supporting documentation.
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE OPEN GROUP BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Except as contained in this notice, the name of The Open Group shall not be used in advertising or otherwise to promote the sale, use or other dealings in this Software without prior written authorization from The Open Group.
Copyright 1987 by Digital Equipment Corporation, Maynard, Massachusetts
All Rights Reserved
Permission to use, copy, modify, and distribute this software and its documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appear in all copies and that both that copyright notice and this permission notice appear in supporting documentation, and that the name of Digital not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission.
DIGITAL DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN NO EVENT SHALL DIGITAL BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
******************************************************************/
</pre>
Copyright (c) 1999-2004 David Corcoran <corcoran@linuxnet.com> Copyright (c) 1999-2004 Ludovic Rousseau <ludovic.rousseau (at) free.fr> All rights reserved.
Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
1. Redistributions of source code must retain the above copyright    notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright    notice, this list of conditions and the following disclaimer in the    documentation and/or other materials provided with the distribution. 3. All advertising materials mentioning features or use of this software    must display the following acknowledgement:      This product includes software developed by:       David Corcoran <corcoran@linuxnet.com>       http://www.linuxnet.com (MUSCLE) 4. The name of the author may not be used to endorse or promote products    derived from this software without specific prior written permission.
Changes to this license can be made only by the copyright author with explicit written consent.
THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre>
=========================================================================     ==  NOTICE file corresponding to the section 4 d of                    ==     ==  the Apache License, Version 2.0,                                   ==     ==  in this case for the Apache Jakarta-BCEL distribution.             ==     =========================================================================
This product includes software developed by    The Apache Software Foundation (http://www.apache.org/).
</pre>
Apache License                         Version 2.0, January 2004                      http://www.apache.org/licenses/
TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
1. Definitions.
"License" shall mean the terms and conditions for use, reproduction,    and distribution as defined by Sections 1 through 9 of this document.
"Licensor" shall mean the copyright owner or entity authorized by    the copyright owner that is granting the License.
"Legal Entity" shall mean the union of the acting entity and all    other entities that control, are controlled by, or are under common    control with that entity. For the purposes of this definition,    "control" means (i) the power, direct or indirect, to cause the    direction or management of such entity, whether by contract or    otherwise, or (ii) ownership of fifty percent (50%) or more of the    outstanding shares, or (iii) beneficial ownership of such entity.
"You" (or "Your") shall mean an individual or Legal Entity    exercising permissions granted by this License.
"Source" form shall mean the preferred form for making modifications,    including but not limited to software source code, documentation    source, and configuration files.
"Object" form shall mean any form resulting from mechanical    transformation or translation of a Source form, including but    not limited to compiled object code, generated documentation,    and conversions to other media types.
"Work" shall mean the work of authorship, whether in Source or    Object form, made available under the License, as indicated by a    copyright notice that is included in or attached to the work    (an example is provided in the Appendix below).
"Derivative Works" shall mean any work, whether in Source or Object    form, that is based on (or derived from) the Work and for which the    editorial revisions, annotations, elaborations, or other modifications    represent, as a whole, an original work of authorship. For the purposes    of this License, Derivative Works shall not include works that remain    separable from, or merely link (or bind by name) to the interfaces of,    the Work and Derivative Works thereof.
"Contribution" shall mean any work of authorship, including    the original version of the Work and any modifications or additions    to that Work or Derivative Works thereof, that is intentionally    submitted to Licensor for inclusion in the Work by the copyright owner    or by an individual or Legal Entity authorized to submit on behalf of    the copyright owner. For the purposes of this definition, "submitted"    means any form of electronic, verbal, or written communication sent    to the Licensor or its representatives, including but not limited to    communication on electronic mailing lists, source code control systems,    and issue tracking systems that are managed by, or on behalf of, the    Licensor for the purpose of discussing and improving the Work, but    excluding communication that is conspicuously marked or otherwise    designated in writing by the copyright owner as "Not a Contribution."
"Contributor" shall mean Licensor and any individual or Legal Entity    on behalf of whom a Contribution has been received by Licensor and    subsequently incorporated within the Work.
2. Grant of Copyright License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    copyright license to reproduce, prepare Derivative Works of,    publicly display, publicly perform, sublicense, and distribute the    Work and such Derivative Works in Source or Object form.
3. Grant of Patent License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    (except as stated in this section) patent license to make, have made,    use, offer to sell, sell, import, and otherwise transfer the Work,    where such license applies only to those patent claims licensable    by such Contributor that are necessarily infringed by their    Contribution(s) alone or by combination of their Contribution(s)    with the Work to which such Contribution(s) was submitted. If You    institute patent litigation against any entity (including a    cross-claim or counterclaim in a lawsuit) alleging that the Work    or a Contribution incorporated within the Work constitutes direct    or contributory patent infringement, then any patent licenses    granted to You under this License for that Work shall terminate    as of the date such litigation is filed.
4. Redistribution. You may reproduce and distribute copies of the    Work or Derivative Works thereof in any medium, with or without    modifications, and in Source or Object form, provided that You    meet the following conditions:
(a) You must give any other recipients of the Work or        Derivative Works a copy of this License; and
(b) You must cause any modified files to carry prominent notices        stating that You changed the files; and
(c) You must retain, in the Source form of any Derivative Works        that You distribute, all copyright, patent, trademark, and        attribution notices from the Source form of the Work,        excluding those notices that do not pertain to any part of        the Derivative Works; and
(d) If the Work includes a "NOTICE" text file as part of its        distribution, then any Derivative Works that You distribute must        include a readable copy of the attribution notices contained        within such NOTICE file, excluding those notices that do not        pertain to any part of the Derivative Works, in at least one        of the following places: within a NOTICE text file distributed        as part of the Derivative Works; within the Source form or        documentation, if provided along with the Derivative Works; or,        within a display generated by the Derivative Works, if and        wherever such third-party notices normally appear. The contents        of the NOTICE file are for informational purposes only and        do not modify the License. You may add Your own attribution        notices within Derivative Works that You distribute, alongside        or as an addendum to the NOTICE text from the Work, provided        that such additional attribution notices cannot be construed        as modifying the License.
You may add Your own copyright statement to Your modifications and    may provide additional or different license terms and conditions    for use, reproduction, or distribution of Your modifications, or    for any such Derivative Works as a whole, provided Your use,    reproduction, and distribution of the Work otherwise complies with    the conditions stated in this License.
5. Submission of Contributions. Unless You explicitly state otherwise,    any Contribution intentionally submitted for inclusion in the Work    by You to the Licensor shall be under the terms and conditions of    this License, without any additional terms or conditions.    Notwithstanding the above, nothing herein shall supersede or modify    the terms of any separate license agreement you may have executed    with Licensor regarding such Contributions.
6. Trademarks. This License does not grant permission to use the trade    names, trademarks, service marks, or product names of the Licensor,    except as required for reasonable and customary use in describing the    origin of the Work and reproducing the content of the NOTICE file.
7. Disclaimer of Warranty. Unless required by applicable law or    agreed to in writing, Licensor provides the Work (and each    Contributor provides its Contributions) on an "AS IS" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or    implied, including, without limitation, any warranties or conditions    of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A    PARTICULAR PURPOSE. You are solely responsible for determining the    appropriateness of using or redistributing the Work and assume any    risks associated with Your exercise of permissions under this License.
8. Limitation of Liability. In no event and under no legal theory,    whether in tort (including negligence), contract, or otherwise,    unless required by applicable law (such as deliberate and grossly    negligent acts) or agreed to in writing, shall any Contributor be    liable to You for damages, including any direct, indirect, special,    incidental, or consequential damages of any character arising as a    result of this License or out of the use or inability to use the    Work (including but not limited to damages for loss of goodwill,    work stoppage, computer failure or malfunction, or any and all    other commercial damages or losses), even if such Contributor    has been advised of the possibility of such damages.
9. Accepting Warranty or Additional Liability. While redistributing    the Work or Derivative Works thereof, You may choose to offer,    and charge a fee for, acceptance of support, warranty, indemnity,    or other liability obligations and/or rights consistent with this    License. However, in accepting such obligations, You may act only    on Your own behalf and on Your sole responsibility, not on behalf    of any other Contributor, and only if You agree to indemnify,    defend, and hold each Contributor harmless for any liability    incurred by, or claims asserted against, such Contributor by reason    of your accepting any such warranty or additional liability.
END OF TERMS AND CONDITIONS
APPENDIX: How to apply the Apache License to your work.
To apply the Apache License to your work, attach the following    boilerplate notice, with the fields enclosed by brackets "[]"    replaced with your own identifying information. (Don't include    the brackets!)  The text should be enclosed in the appropriate    comment syntax for the file format. We also recommend that a    file or class name and description of purpose be included on the    same "printed page" as the copyright notice for easier    identification within third-party archives.
Copyright [yyyy] [name of copyright owner]
Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
</pre>
W3C SOFTWARE NOTICE AND LICENSE
http://www.w3.org/Consortium/Legal/2002/copyright-software-20021231
This work (and included software, documentation such as READMEs, or other related items) is being provided by the copyright holders under the following license. By obtaining, using and/or copying this work, you (the licensee) agree that you have read, understood, and will comply with the following terms and conditions.
Permission to copy, modify, and distribute this software and its documentation, with or without modification, for any purpose and without fee or royalty is hereby granted, provided that you include the following on ALL copies of the software and documentation or portions thereof, including modifications:
1.The full text of this NOTICE in a location viewable to users of the    redistributed or derivative work.
2.Any pre-existing intellectual property disclaimers, notices, or terms and    conditions. If none exist, the W3C Software Short Notice should be included    (hypertext is preferred, text is permitted) within the body of any    redistributed or derivative code.
3.Notice of any changes or modifications to the files, including the date    changes were made. (We recommend you provide URIs to the location from    which the code is derived.)
THIS SOFTWARE AND DOCUMENTATION IS PROVIDED "AS IS," AND COPYRIGHT HOLDERS MAKE NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO, WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE OR DOCUMENTATION WILL NOT INFRINGE ANY THIRD PARTY PATENTS,COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS.
COPYRIGHT HOLDERS WILL NOT BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF ANY USE OF THE SOFTWARE OR DOCUMENTATION.  The name and trademarks of copyright holders may NOT be used in advertising or publicity pertaining to the software without specific, written prior permission. Title to copyright in this software and any associated documentation will at all times remain with copyright holders.
____________________________________
This formulation of W3C's notice and license became active on December 31 2002. This version removes the copyright ownership notice such that this license can be used with materials other than those owned by the W3C, reflects that ERCIM is now a host of the W3C, includes references to this specific dated version of the license, and removes the ambiguous grant of "use". Otherwise, this version is the same as the previous version and is written so as to preserve the Free Software Foundation's assessment of GPL compatibility and OSI's certification under the Open Source Definition. Please see our Copyright FAQ for common questions about using materials from our site, including specific terms and conditions for packages like libwww, Amaya, and Jigsaw. Other questions about this notice can be directed to site-policy@w3.org.
</pre>
Copyright 1996-1999 by Scott Hudson, Frank Flannery, C. Scott Ananian
Permission to use, copy, modify, and distribute this software and its documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appear in all copies and that both the copyright notice and this permission notice and warranty disclaimer appear in supporting documentation, and that the names of the authors or their employers not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission.
The authors and their employers disclaim all warranties with regard to this software, including all implied warranties of merchantability and fitness. In no event shall the authors or their employers be liable for any special, indirect or consequential damages or any damages whatsoever resulting from loss of use, data or profits, whether in an action of contract, negligence or other tortious action, arising out of or in connection with the use or performance of this software.
</pre>
======================================================================================     ==  NOTICE file corresponding to the section 4d of the Apache License, Version 2.0, ==     ==  in this case for the Apache Xalan distribution.                                 ==     ======================================================================================
This product includes software developed by    The Apache Software Foundation (http://www.apache.org/).
Portions of this software was originally based on the following:
- software copyright (c) 1999-2002, Lotus Development Corporation., http://www.lotus.com.      - software copyright (c) 2001-2002, Sun Microsystems., http://www.sun.com.      - software copyright (c) 2003, IBM Corporation., http://www.ibm.com.      - voluntary contributions made by Ovidiu Predescu (ovidiu@cup.hp.com) on behalf of the        Apache Software Foundation and was originally developed at Hewlett Packard Company.
</pre>
Apache License                         Version 2.0, January 2004                      http://www.apache.org/licenses/
TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
1. Definitions.
"License" shall mean the terms and conditions for use, reproduction,    and distribution as defined by Sections 1 through 9 of this document.
"Licensor" shall mean the copyright owner or entity authorized by    the copyright owner that is granting the License.
"Legal Entity" shall mean the union of the acting entity and all    other entities that control, are controlled by, or are under common    control with that entity. For the purposes of this definition,    "control" means (i) the power, direct or indirect, to cause the    direction or management of such entity, whether by contract or    otherwise, or (ii) ownership of fifty percent (50%) or more of the    outstanding shares, or (iii) beneficial ownership of such entity.
"You" (or "Your") shall mean an individual or Legal Entity    exercising permissions granted by this License.
"Source" form shall mean the preferred form for making modifications,    including but not limited to software source code, documentation    source, and configuration files.
"Object" form shall mean any form resulting from mechanical    transformation or translation of a Source form, including but    not limited to compiled object code, generated documentation,    and conversions to other media types.
"Work" shall mean the work of authorship, whether in Source or    Object form, made available under the License, as indicated by a    copyright notice that is included in or attached to the work    (an example is provided in the Appendix below).
"Derivative Works" shall mean any work, whether in Source or Object    form, that is based on (or derived from) the Work and for which the    editorial revisions, annotations, elaborations, or other modifications    represent, as a whole, an original work of authorship. For the purposes    of this License, Derivative Works shall not include works that remain    separable from, or merely link (or bind by name) to the interfaces of,    the Work and Derivative Works thereof.
"Contribution" shall mean any work of authorship, including    the original version of the Work and any modifications or additions    to that Work or Derivative Works thereof, that is intentionally    submitted to Licensor for inclusion in the Work by the copyright owner    or by an individual or Legal Entity authorized to submit on behalf of    the copyright owner. For the purposes of this definition, "submitted"    means any form of electronic, verbal, or written communication sent    to the Licensor or its representatives, including but not limited to    communication on electronic mailing lists, source code control systems,    and issue tracking systems that are managed by, or on behalf of, the    Licensor for the purpose of discussing and improving the Work, but    excluding communication that is conspicuously marked or otherwise    designated in writing by the copyright owner as "Not a Contribution."
"Contributor" shall mean Licensor and any individual or Legal Entity    on behalf of whom a Contribution has been received by Licensor and    subsequently incorporated within the Work.
2. Grant of Copyright License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    copyright license to reproduce, prepare Derivative Works of,    publicly display, publicly perform, sublicense, and distribute the    Work and such Derivative Works in Source or Object form.
3. Grant of Patent License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    (except as stated in this section) patent license to make, have made,    use, offer to sell, sell, import, and otherwise transfer the Work,    where such license applies only to those patent claims licensable    by such Contributor that are necessarily infringed by their    Contribution(s) alone or by combination of their Contribution(s)    with the Work to which such Contribution(s) was submitted. If You    institute patent litigation against any entity (including a    cross-claim or counterclaim in a lawsuit) alleging that the Work    or a Contribution incorporated within the Work constitutes direct    or contributory patent infringement, then any patent licenses    granted to You under this License for that Work shall terminate    as of the date such litigation is filed.
4. Redistribution. You may reproduce and distribute copies of the    Work or Derivative Works thereof in any medium, with or without    modifications, and in Source or Object form, provided that You    meet the following conditions:
(a) You must give any other recipients of the Work or        Derivative Works a copy of this License; and
(b) You must cause any modified files to carry prominent notices        stating that You changed the files; and
(c) You must retain, in the Source form of any Derivative Works        that You distribute, all copyright, patent, trademark, and        attribution notices from the Source form of the Work,        excluding those notices that do not pertain to any part of        the Derivative Works; and
(d) If the Work includes a "NOTICE" text file as part of its        distribution, then any Derivative Works that You distribute must        include a readable copy of the attribution notices contained        within such NOTICE file, excluding those notices that do not        pertain to any part of the Derivative Works, in at least one        of the following places: within a NOTICE text file distributed        as part of the Derivative Works; within the Source form or        documentation, if provided along with the Derivative Works; or,        within a display generated by the Derivative Works, if and        wherever such third-party notices normally appear. The contents        of the NOTICE file are for informational purposes only and        do not modify the License. You may add Your own attribution        notices within Derivative Works that You distribute, alongside        or as an addendum to the NOTICE text from the Work, provided        that such additional attribution notices cannot be construed        as modifying the License.
You may add Your own copyright statement to Your modifications and    may provide additional or different license terms and conditions    for use, reproduction, or distribution of Your modifications, or    for any such Derivative Works as a whole, provided Your use,    reproduction, and distribution of the Work otherwise complies with    the conditions stated in this License.
5. Submission of Contributions. Unless You explicitly state otherwise,    any Contribution intentionally submitted for inclusion in the Work    by You to the Licensor shall be under the terms and conditions of    this License, without any additional terms or conditions.    Notwithstanding the above, nothing herein shall supersede or modify    the terms of any separate license agreement you may have executed    with Licensor regarding such Contributions.
6. Trademarks. This License does not grant permission to use the trade    names, trademarks, service marks, or product names of the Licensor,    except as required for reasonable and customary use in describing the    origin of the Work and reproducing the content of the NOTICE file.
7. Disclaimer of Warranty. Unless required by applicable law or    agreed to in writing, Licensor provides the Work (and each    Contributor provides its Contributions) on an "AS IS" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or    implied, including, without limitation, any warranties or conditions    of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A    PARTICULAR PURPOSE. You are solely responsible for determining the    appropriateness of using or redistributing the Work and assume any    risks associated with Your exercise of permissions under this License.
8. Limitation of Liability. In no event and under no legal theory,    whether in tort (including negligence), contract, or otherwise,    unless required by applicable law (such as deliberate and grossly    negligent acts) or agreed to in writing, shall any Contributor be    liable to You for damages, including any direct, indirect, special,    incidental, or consequential damages of any character arising as a    result of this License or out of the use or inability to use the    Work (including but not limited to damages for loss of goodwill,    work stoppage, computer failure or malfunction, or any and all    other commercial damages or losses), even if such Contributor    has been advised of the possibility of such damages.
9. Accepting Warranty or Additional Liability. While redistributing    the Work or Derivative Works thereof, You may choose to offer,    and charge a fee for, acceptance of support, warranty, indemnity,    or other liability obligations and/or rights consistent with this    License. However, in accepting such obligations, You may act only    on Your own behalf and on Your sole responsibility, not on behalf    of any other Contributor, and only if You agree to indemnify,    defend, and hold each Contributor harmless for any liability    incurred by, or claims asserted against, such Contributor by reason    of your accepting any such warranty or additional liability.
END OF TERMS AND CONDITIONS
APPENDIX: How to apply the Apache License to your work.
To apply the Apache License to your work, attach the following    boilerplate notice, with the fields enclosed by brackets "[]"    replaced with your own identifying information. (Don't include    the brackets!)  The text should be enclosed in the appropriate    comment syntax for the file format. We also recommend that a    file or class name and description of purpose be included on the    same "printed page" as the copyright notice for easier    identification within third-party archives.
Copyright [yyyy] [name of copyright owner]
Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
</pre>
Apache License                         Version 2.0, January 2004                      http://www.apache.org/licenses/
TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
1. Definitions.
"License" shall mean the terms and conditions for use, reproduction,    and distribution as defined by Sections 1 through 9 of this document.
"Licensor" shall mean the copyright owner or entity authorized by    the copyright owner that is granting the License.
"Legal Entity" shall mean the union of the acting entity and all    other entities that control, are controlled by, or are under common    control with that entity. For the purposes of this definition,    "control" means (i) the power, direct or indirect, to cause the    direction or management of such entity, whether by contract or    otherwise, or (ii) ownership of fifty percent (50%) or more of the    outstanding shares, or (iii) beneficial ownership of such entity.
"You" (or "Your") shall mean an individual or Legal Entity    exercising permissions granted by this License.
"Source" form shall mean the preferred form for making modifications,    including but not limited to software source code, documentation    source, and configuration files.
"Object" form shall mean any form resulting from mechanical    transformation or translation of a Source form, including but    not limited to compiled object code, generated documentation,    and conversions to other media types.
"Work" shall mean the work of authorship, whether in Source or    Object form, made available under the License, as indicated by a    copyright notice that is included in or attached to the work    (an example is provided in the Appendix below).
"Derivative Works" shall mean any work, whether in Source or Object    form, that is based on (or derived from) the Work and for which the    editorial revisions, annotations, elaborations, or other modifications    represent, as a whole, an original work of authorship. For the purposes    of this License, Derivative Works shall not include works that remain    separable from, or merely link (or bind by name) to the interfaces of,    the Work and Derivative Works thereof.
"Contribution" shall mean any work of authorship, including    the original version of the Work and any modifications or additions    to that Work or Derivative Works thereof, that is intentionally    submitted to Licensor for inclusion in the Work by the copyright owner    or by an individual or Legal Entity authorized to submit on behalf of    the copyright owner. For the purposes of this definition, "submitted"    means any form of electronic, verbal, or written communication sent    to the Licensor or its representatives, including but not limited to    communication on electronic mailing lists, source code control systems,    and issue tracking systems that are managed by, or on behalf of, the    Licensor for the purpose of discussing and improving the Work, but    excluding communication that is conspicuously marked or otherwise    designated in writing by the copyright owner as "Not a Contribution."
"Contributor" shall mean Licensor and any individual or Legal Entity    on behalf of whom a Contribution has been received by Licensor and    subsequently incorporated within the Work.
2. Grant of Copyright License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    copyright license to reproduce, prepare Derivative Works of,    publicly display, publicly perform, sublicense, and distribute the    Work and such Derivative Works in Source or Object form.
3. Grant of Patent License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    (except as stated in this section) patent license to make, have made,    use, offer to sell, sell, import, and otherwise transfer the Work,    where such license applies only to those patent claims licensable    by such Contributor that are necessarily infringed by their    Contribution(s) alone or by combination of their Contribution(s)    with the Work to which such Contribution(s) was submitted. If You    institute patent litigation against any entity (including a    cross-claim or counterclaim in a lawsuit) alleging that the Work    or a Contribution incorporated within the Work constitutes direct    or contributory patent infringement, then any patent licenses    granted to You under this License for that Work shall terminate    as of the date such litigation is filed.
4. Redistribution. You may reproduce and distribute copies of the    Work or Derivative Works thereof in any medium, with or without    modifications, and in Source or Object form, provided that You    meet the following conditions:
(a) You must give any other recipients of the Work or        Derivative Works a copy of this License; and
(b) You must cause any modified files to carry prominent notices        stating that You changed the files; and
(c) You must retain, in the Source form of any Derivative Works        that You distribute, all copyright, patent, trademark, and        attribution notices from the Source form of the Work,        excluding those notices that do not pertain to any part of        the Derivative Works; and
(d) If the Work includes a "NOTICE" text file as part of its        distribution, then any Derivative Works that You distribute must        include a readable copy of the attribution notices contained        within such NOTICE file, excluding those notices that do not        pertain to any part of the Derivative Works, in at least one        of the following places: within a NOTICE text file distributed        as part of the Derivative Works; within the Source form or        documentation, if provided along with the Derivative Works; or,        within a display generated by the Derivative Works, if and        wherever such third-party notices normally appear. The contents        of the NOTICE file are for informational purposes only and        do not modify the License. You may add Your own attribution        notices within Derivative Works that You distribute, alongside        or as an addendum to the NOTICE text from the Work, provided        that such additional attribution notices cannot be construed        as modifying the License.
You may add Your own copyright statement to Your modifications and    may provide additional or different license terms and conditions    for use, reproduction, or distribution of Your modifications, or    for any such Derivative Works as a whole, provided Your use,    reproduction, and distribution of the Work otherwise complies with    the conditions stated in this License.
5. Submission of Contributions. Unless You explicitly state otherwise,    any Contribution intentionally submitted for inclusion in the Work    by You to the Licensor shall be under the terms and conditions of    this License, without any additional terms or conditions.    Notwithstanding the above, nothing herein shall supersede or modify    the terms of any separate license agreement you may have executed    with Licensor regarding such Contributions.
6. Trademarks. This License does not grant permission to use the trade    names, trademarks, service marks, or product names of the Licensor,    except as required for reasonable and customary use in describing the    origin of the Work and reproducing the content of the NOTICE file.
7. Disclaimer of Warranty. Unless required by applicable law or    agreed to in writing, Licensor provides the Work (and each    Contributor provides its Contributions) on an "AS IS" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or    implied, including, without limitation, any warranties or conditions    of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A    PARTICULAR PURPOSE. You are solely responsible for determining the    appropriateness of using or redistributing the Work and assume any    risks associated with Your exercise of permissions under this License.
8. Limitation of Liability. In no event and under no legal theory,    whether in tort (including negligence), contract, or otherwise,    unless required by applicable law (such as deliberate and grossly    negligent acts) or agreed to in writing, shall any Contributor be    liable to You for damages, including any direct, indirect, special,    incidental, or consequential damages of any character arising as a    result of this License or out of the use or inability to use the    Work (including but not limited to damages for loss of goodwill,    work stoppage, computer failure or malfunction, or any and all    other commercial damages or losses), even if such Contributor    has been advised of the possibility of such damages.
9. Accepting Warranty or Additional Liability. While redistributing    the Work or Derivative Works thereof, You may choose to offer,    and charge a fee for, acceptance of support, warranty, indemnity,    or other liability obligations and/or rights consistent with this    License. However, in accepting such obligations, You may act only    on Your own behalf and on Your sole responsibility, not on behalf    of any other Contributor, and only if You agree to indemnify,    defend, and hold each Contributor harmless for any liability    incurred by, or claims asserted against, such Contributor by reason    of your accepting any such warranty or additional liability.
END OF TERMS AND CONDITIONS
APPENDIX: How to apply the Apache License to your work.
To apply the Apache License to your work, attach the following    boilerplate notice, with the fields enclosed by brackets "[]"    replaced with your own identifying information. (Don't include    the brackets!)  The text should be enclosed in the appropriate    comment syntax for the file format. We also recommend that a    file or class name and description of purpose be included on the    same "printed page" as the copyright notice for easier    identification within third-party archives.
Copyright [yyyy] [name of copyright owner]
Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
</pre>
Apache XML Commons Resolver Copyright 2006 The Apache Software Foundation.
This product includes software developed at The Apache Software Foundation http://www.apache.org/
Portions of this code are derived from classes placed in the public domain by Arbortext on 10 Apr 2000. See: http://www.arbortext.com/customer_support/updates_and_technical_notes/catalogs/docs/README.htm
</pre>
Apache License                         Version 2.0, January 2004                      http://www.apache.org/licenses/
TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
1. Definitions.
"License" shall mean the terms and conditions for use, reproduction,    and distribution as defined by Sections 1 through 9 of this document.
"Licensor" shall mean the copyright owner or entity authorized by    the copyright owner that is granting the License.
"Legal Entity" shall mean the union of the acting entity and all    other entities that control, are controlled by, or are under common    control with that entity. For the purposes of this definition,    "control" means (i) the power, direct or indirect, to cause the    direction or management of such entity, whether by contract or    otherwise, or (ii) ownership of fifty percent (50%) or more of the    outstanding shares, or (iii) beneficial ownership of such entity.
"You" (or "Your") shall mean an individual or Legal Entity    exercising permissions granted by this License.
"Source" form shall mean the preferred form for making modifications,    including but not limited to software source code, documentation    source, and configuration files.
"Object" form shall mean any form resulting from mechanical    transformation or translation of a Source form, including but    not limited to compiled object code, generated documentation,    and conversions to other media types.
"Work" shall mean the work of authorship, whether in Source or    Object form, made available under the License, as indicated by a    copyright notice that is included in or attached to the work    (an example is provided in the Appendix below).
"Derivative Works" shall mean any work, whether in Source or Object    form, that is based on (or derived from) the Work and for which the    editorial revisions, annotations, elaborations, or other modifications    represent, as a whole, an original work of authorship. For the purposes    of this License, Derivative Works shall not include works that remain    separable from, or merely link (or bind by name) to the interfaces of,    the Work and Derivative Works thereof.
"Contribution" shall mean any work of authorship, including    the original version of the Work and any modifications or additions    to that Work or Derivative Works thereof, that is intentionally    submitted to Licensor for inclusion in the Work by the copyright owner    or by an individual or Legal Entity authorized to submit on behalf of    the copyright owner. For the purposes of this definition, "submitted"    means any form of electronic, verbal, or written communication sent    to the Licensor or its representatives, including but not limited to    communication on electronic mailing lists, source code control systems,    and issue tracking systems that are managed by, or on behalf of, the    Licensor for the purpose of discussing and improving the Work, but    excluding communication that is conspicuously marked or otherwise    designated in writing by the copyright owner as "Not a Contribution."
"Contributor" shall mean Licensor and any individual or Legal Entity    on behalf of whom a Contribution has been received by Licensor and    subsequently incorporated within the Work.
2. Grant of Copyright License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    copyright license to reproduce, prepare Derivative Works of,    publicly display, publicly perform, sublicense, and distribute the    Work and such Derivative Works in Source or Object form.
3. Grant of Patent License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    (except as stated in this section) patent license to make, have made,    use, offer to sell, sell, import, and otherwise transfer the Work,    where such license applies only to those patent claims licensable    by such Contributor that are necessarily infringed by their    Contribution(s) alone or by combination of their Contribution(s)    with the Work to which such Contribution(s) was submitted. If You    institute patent litigation against any entity (including a    cross-claim or counterclaim in a lawsuit) alleging that the Work    or a Contribution incorporated within the Work constitutes direct    or contributory patent infringement, then any patent licenses    granted to You under this License for that Work shall terminate    as of the date such litigation is filed.
4. Redistribution. You may reproduce and distribute copies of the    Work or Derivative Works thereof in any medium, with or without    modifications, and in Source or Object form, provided that You    meet the following conditions:
(a) You must give any other recipients of the Work or        Derivative Works a copy of this License; and
(b) You must cause any modified files to carry prominent notices        stating that You changed the files; and
(c) You must retain, in the Source form of any Derivative Works        that You distribute, all copyright, patent, trademark, and        attribution notices from the Source form of the Work,        excluding those notices that do not pertain to any part of        the Derivative Works; and
(d) If the Work includes a "NOTICE" text file as part of its        distribution, then any Derivative Works that You distribute must        include a readable copy of the attribution notices contained        within such NOTICE file, excluding those notices that do not        pertain to any part of the Derivative Works, in at least one        of the following places: within a NOTICE text file distributed        as part of the Derivative Works; within the Source form or        documentation, if provided along with the Derivative Works; or,        within a display generated by the Derivative Works, if and        wherever such third-party notices normally appear. The contents        of the NOTICE file are for informational purposes only and        do not modify the License. You may add Your own attribution        notices within Derivative Works that You distribute, alongside        or as an addendum to the NOTICE text from the Work, provided        that such additional attribution notices cannot be construed        as modifying the License.
You may add Your own copyright statement to Your modifications and    may provide additional or different license terms and conditions    for use, reproduction, or distribution of Your modifications, or    for any such Derivative Works as a whole, provided Your use,    reproduction, and distribution of the Work otherwise complies with    the conditions stated in this License.
5. Submission of Contributions. Unless You explicitly state otherwise,    any Contribution intentionally submitted for inclusion in the Work    by You to the Licensor shall be under the terms and conditions of    this License, without any additional terms or conditions.    Notwithstanding the above, nothing herein shall supersede or modify    the terms of any separate license agreement you may have executed    with Licensor regarding such Contributions.
6. Trademarks. This License does not grant permission to use the trade    names, trademarks, service marks, or product names of the Licensor,    except as required for reasonable and customary use in describing the    origin of the Work and reproducing the content of the NOTICE file.
7. Disclaimer of Warranty. Unless required by applicable law or    agreed to in writing, Licensor provides the Work (and each    Contributor provides its Contributions) on an "AS IS" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or    implied, including, without limitation, any warranties or conditions    of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A    PARTICULAR PURPOSE. You are solely responsible for determining the    appropriateness of using or redistributing the Work and assume any    risks associated with Your exercise of permissions under this License.
8. Limitation of Liability. In no event and under no legal theory,    whether in tort (including negligence), contract, or otherwise,    unless required by applicable law (such as deliberate and grossly    negligent acts) or agreed to in writing, shall any Contributor be    liable to You for damages, including any direct, indirect, special,    incidental, or consequential damages of any character arising as a    result of this License or out of the use or inability to use the    Work (including but not limited to damages for loss of goodwill,    work stoppage, computer failure or malfunction, or any and all    other commercial damages or losses), even if such Contributor    has been advised of the possibility of such damages.
9. Accepting Warranty or Additional Liability. While redistributing    the Work or Derivative Works thereof, You may choose to offer,    and charge a fee for, acceptance of support, warranty, indemnity,    or other liability obligations and/or rights consistent with this    License. However, in accepting such obligations, You may act only    on Your own behalf and on Your sole responsibility, not on behalf    of any other Contributor, and only if You agree to indemnify,    defend, and hold each Contributor harmless for any liability    incurred by, or claims asserted against, such Contributor by reason    of your accepting any such warranty or additional liability.
END OF TERMS AND CONDITIONS
APPENDIX: How to apply the Apache License to your work.
To apply the Apache License to your work, attach the following    boilerplate notice, with the fields enclosed by brackets "[]"    replaced with your own identifying information. (Don't include    the brackets!)  The text should be enclosed in the appropriate    comment syntax for the file format. We also recommend that a    file or class name and description of purpose be included on the    same "printed page" as the copyright notice for easier    identification within third-party archives.
Copyright [yyyy] [name of copyright owner]
Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
</pre>
Apache Santuario - XML Security for Java   Copyright 1999-2015 The Apache Software Foundation
This product includes software developed at   The Apache Software Foundation (http://www.apache.org/).
It was originally based on software copyright (c) 2001, Institute for   Data Communications Systems, <http://www.nue.et-inf.uni-siegen.de/>.
The development of this software was partly funded by the European   Commission in the <WebSig> project in the ISIS Programme.
</pre>
Apache License                         Version 2.0, January 2004                      http://www.apache.org/licenses/
TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
1. Definitions.
"License" shall mean the terms and conditions for use, reproduction,    and distribution as defined by Sections 1 through 9 of this document.
"Licensor" shall mean the copyright owner or entity authorized by    the copyright owner that is granting the License.
"Legal Entity" shall mean the union of the acting entity and all    other entities that control, are controlled by, or are under common    control with that entity. For the purposes of this definition,    "control" means (i) the power, direct or indirect, to cause the    direction or management of such entity, whether by contract or    otherwise, or (ii) ownership of fifty percent (50%) or more of the    outstanding shares, or (iii) beneficial ownership of such entity.
"You" (or "Your") shall mean an individual or Legal Entity    exercising permissions granted by this License.
"Source" form shall mean the preferred form for making modifications,    including but not limited to software source code, documentation    source, and configuration files.
"Object" form shall mean any form resulting from mechanical    transformation or translation of a Source form, including but    not limited to compiled object code, generated documentation,    and conversions to other media types.
"Work" shall mean the work of authorship, whether in Source or    Object form, made available under the License, as indicated by a    copyright notice that is included in or attached to the work    (an example is provided in the Appendix below).
"Derivative Works" shall mean any work, whether in Source or Object    form, that is based on (or derived from) the Work and for which the    editorial revisions, annotations, elaborations, or other modifications    represent, as a whole, an original work of authorship. For the purposes    of this License, Derivative Works shall not include works that remain    separable from, or merely link (or bind by name) to the interfaces of,    the Work and Derivative Works thereof.
"Contribution" shall mean any work of authorship, including    the original version of the Work and any modifications or additions    to that Work or Derivative Works thereof, that is intentionally    submitted to Licensor for inclusion in the Work by the copyright owner    or by an individual or Legal Entity authorized to submit on behalf of    the copyright owner. For the purposes of this definition, "submitted"    means any form of electronic, verbal, or written communication sent    to the Licensor or its representatives, including but not limited to    communication on electronic mailing lists, source code control systems,    and issue tracking systems that are managed by, or on behalf of, the    Licensor for the purpose of discussing and improving the Work, but    excluding communication that is conspicuously marked or otherwise    designated in writing by the copyright owner as "Not a Contribution."
"Contributor" shall mean Licensor and any individual or Legal Entity    on behalf of whom a Contribution has been received by Licensor and    subsequently incorporated within the Work.
2. Grant of Copyright License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    copyright license to reproduce, prepare Derivative Works of,    publicly display, publicly perform, sublicense, and distribute the    Work and such Derivative Works in Source or Object form.
3. Grant of Patent License. Subject to the terms and conditions of    this License, each Contributor hereby grants to You a perpetual,    worldwide, non-exclusive, no-charge, royalty-free, irrevocable    (except as stated in this section) patent license to make, have made,    use, offer to sell, sell, import, and otherwise transfer the Work,    where such license applies only to those patent claims licensable    by such Contributor that are necessarily infringed by their    Contribution(s) alone or by combination of their Contribution(s)    with the Work to which such Contribution(s) was submitted. If You    institute patent litigation against any entity (including a    cross-claim or counterclaim in a lawsuit) alleging that the Work    or a Contribution incorporated within the Work constitutes direct    or contributory patent infringement, then any patent licenses    granted to You under this License for that Work shall terminate    as of the date such litigation is filed.
4. Redistribution. You may reproduce and distribute copies of the    Work or Derivative Works thereof in any medium, with or without    modifications, and in Source or Object form, provided that You    meet the following conditions:
(a) You must give any other recipients of the Work or        Derivative Works a copy of this License; and
(b) You must cause any modified files to carry prominent notices        stating that You changed the files; and
(c) You must retain, in the Source form of any Derivative Works        that You distribute, all copyright, patent, trademark, and        attribution notices from the Source form of the Work,        excluding those notices that do not pertain to any part of        the Derivative Works; and
(d) If the Work includes a "NOTICE" text file as part of its        distribution, then any Derivative Works that You distribute must        include a readable copy of the attribution notices contained        within such NOTICE file, excluding those notices that do not        pertain to any part of the Derivative Works, in at least one        of the following places: within a NOTICE text file distributed        as part of the Derivative Works; within the Source form or        documentation, if provided along with the Derivative Works; or,        within a display generated by the Derivative Works, if and        wherever such third-party notices normally appear. The contents        of the NOTICE file are for informational purposes only and        do not modify the License. You may add Your own attribution        notices within Derivative Works that You distribute, alongside        or as an addendum to the NOTICE text from the Work, provided        that such additional attribution notices cannot be construed        as modifying the License.
You may add Your own copyright statement to Your modifications and    may provide additional or different license terms and conditions    for use, reproduction, or distribution of Your modifications, or    for any such Derivative Works as a whole, provided Your use,    reproduction, and distribution of the Work otherwise complies with    the conditions stated in this License.
5. Submission of Contributions. Unless You explicitly state otherwise,    any Contribution intentionally submitted for inclusion in the Work    by You to the Licensor shall be under the terms and conditions of    this License, without any additional terms or conditions.    Notwithstanding the above, nothing herein shall supersede or modify    the terms of any separate license agreement you may have executed    with Licensor regarding such Contributions.
6. Trademarks. This License does not grant permission to use the trade    names, trademarks, service marks, or product names of the Licensor,    except as required for reasonable and customary use in describing the    origin of the Work and reproducing the content of the NOTICE file.
7. Disclaimer of Warranty. Unless required by applicable law or    agreed to in writing, Licensor provides the Work (and each    Contributor provides its Contributions) on an "AS IS" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or    implied, including, without limitation, any warranties or conditions    of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A    PARTICULAR PURPOSE. You are solely responsible for determining the    appropriateness of using or redistributing the Work and assume any    risks associated with Your exercise of permissions under this License.
8. Limitation of Liability. In no event and under no legal theory,    whether in tort (including negligence), contract, or otherwise,    unless required by applicable law (such as deliberate and grossly    negligent acts) or agreed to in writing, shall any Contributor be    liable to You for damages, including any direct, indirect, special,    incidental, or consequential damages of any character arising as a    result of this License or out of the use or inability to use the    Work (including but not limited to damages for loss of goodwill,    work stoppage, computer failure or malfunction, or any and all    other commercial damages or losses), even if such Contributor    has been advised of the possibility of such damages.
9. Accepting Warranty or Additional Liability. While redistributing    the Work or Derivative Works thereof, You may choose to offer,    and charge a fee for, acceptance of support, warranty, indemnity,    or other liability obligations and/or rights consistent with this    License. However, in accepting such obligations, You may act only    on Your own behalf and on Your sole responsibility, not on behalf    of any other Contributor, and only if You agree to indemnify,    defend, and hold each Contributor harmless for any liability    incurred by, or claims asserted against, such Contributor by reason    of your accepting any such warranty or additional liability.
END OF TERMS AND CONDITIONS
APPENDIX: How to apply the Apache License to your work.
To apply the Apache License to your work, attach the following    boilerplate notice, with the fields enclosed by brackets "[]"    replaced with your own identifying information. (Don't include    the brackets!)  The text should be enclosed in the appropriate    comment syntax for the file format. We also recommend that a    file or class name and description of purpose be included on the    same "printed page" as the copyright notice for easier    identification within third-party archives.
Copyright [yyyy] [name of copyright owner]
Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
</pre>
COPYRIGHT AND PERMISSION NOTICE
Copyright (c) 1995-2013 International Business Machines Corporation and others
All rights reserved.
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, provided that the above copyright notice(s) and this permission notice appear in all copies of the Software and that both the above copyright notice(s) and this permission notice appear in supporting documentation.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF THIRD PARTY RIGHTS. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
Except as contained in this notice, the name of a copyright holder shall not be used in advertising or otherwise to promote the sale, use or other dealings in this Software without prior written authorization of the copyright holder.
All trademarks and registered trademarks mentioned herein are the property of  their respective owners.
Third-Party Software Licenses This section contains third-party software notices and/or additional terms for licensed third-party software components included within ICU libraries. 1. Unicode Data Files and Software
EXHIBIT 1  UNICODE, INC. LICENSE AGREEMENT - DATA FILES AND SOFTWARE
Unicode Data Files include all data files under the directories http://www.unicode.org/Public/, http://www.unicode.org/reports/, and http://www.unicode.org/cldr/data/. Unicode Data Files do not include PDF online code charts under the directory http://www.unicode.org/Public/. Software includes any source code published in the Unicode Standard or under the directories http://www.unicode.org/Public/, http://www.unicode.org/reports/, and http://www.unicode.org/cldr/data/.
NOTICE TO USER: Carefully read the following legal agreement. BY DOWNLOADING, INSTALLING, COPYING OR OTHERWISE USING UNICODE INC.'S DATA FILES ("DATA FILES"), AND/OR SOFTWARE ("SOFTWARE"), YOU UNEQUIVOCALLY ACCEPT, AND AGREE TO BE BOUND BY, ALL OF THE TERMS AND CONDITIONS OF THIS AGREEMENT. IF YOU DO NOT AGREE, DO NOT DOWNLOAD, INSTALL, COPY, DISTRIBUTE OR USE THE DATA FILES OR SOFTWARE.
COPYRIGHT AND PERMISSION NOTICE
Copyright  1991-2013 Unicode, Inc. All rights reserved. Distributed under the Terms of Use in http://www.unicode.org/copyright.html.
Permission is hereby granted, free of charge, to any person obtaining a copy of the Unicode data files and any associated documentation (the "Data Files") or Unicode software and any associated documentation (the "Software") to deal in the Data Files or Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, and/or sell copies of the Data Files or Software, and to permit persons to whom the Data Files or Software are furnished to do so, provided that (a) the above copyright notice(s) and this permission notice appear with all copies of the Data Files or Software, (b) both the above copyright notice(s) and this permission notice appear in associated documentation, and (c) there is clear notice in each modified Data File or in the Software as well as in the documentation associated with the Data File(s) or Software that the data or software has been modified.
THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF THIRD PARTY RIGHTS. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THE DATA FILES OR SOFTWARE.
Except as contained in this notice, the name of a copyright holder shall not be used in advertising or otherwise to promote the sale, use or other dealings in these Data Files or Software without prior written authorization of the copyright holder.
Unicode and the Unicode logo are trademarks of Unicode, Inc. in the United States and other countries. All third party trademarks referenced herein are the property of their respective owners.
2. Chinese/Japanese Word Break Dictionary Data (cjdict.txt)  # The Google Chrome software developed by Google is licensed under the BSD  # license. Other software included in this distribution is provided under other  # licenses, as set forth below.  #  # The BSD License  # http://opensource.org/licenses/bsd-license.php  # Copyright (C) 2006-2008, Google Inc.  #  # All rights reserved.  #  # Redistribution and use in source and binary forms, with or without  # modification, are permitted provided that the following conditions are met:  #  # Redistributions of source code must retain the above copyright notice, this  # list of conditions and the following disclaimer.  # Redistributions in binary form must reproduce the above copyright notice,  # this list of conditions and the following disclaimer in the documentation  # and/or other materials provided with the distribution.  # Neither the name of Google Inc. nor the names of its contributors may be used  # to endorse or promote products derived from this software without specific  # prior written permission.  #  #  # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"  # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE  # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE  # ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE  # LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR  # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF  # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS  # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN  # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE  # POSSIBILITY OF SUCH DAMAGE.  #  #  # The word list in cjdict.txt are generated by combining three word lists  # listed below with further processing for compound word breaking. The  # frequency is generated  # with an iterative training against Google web corpora.  #  # * Libtabe (Chinese)  # - https://sourceforge.net/project/?group_id=1519  # - Its license terms and conditions are shown below.  #  # * IPADIC (Japanese)  # - http://chasen.aist-nara.ac.jp/chasen/distribution.html  # - Its license terms and conditions are shown below.  #  # ---------COPYING.libtabe ---- BEGIN--------------------  #  # /*  # * Copyrighy (c) 1999 TaBE Project.  # * Copyright (c) 1999 Pai-Hsiang Hsiao.  # * All rights reserved.  # *  # * Redistribution and use in source and binary forms, with or without  # * modification, are permitted provided that the following conditions  # * are met:  # *  # * . Redistributions of source code must retain the above copyright  # * notice, this list of conditions and the following disclaimer.  # * . Redistributions in binary form must reproduce the above copyright  # * notice, this list of conditions and the following disclaimer in  # * the documentation and/or other materials provided with the  # * distribution.  # * . Neither the name of the TaBE Project nor the names of its  # * contributors may be used to endorse or promote products derived  # * from this software without specific prior written permission.  # *  # * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS  # * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT  # * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS  # * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE  # * REGENTS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,  # * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES  # * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR  # * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  # * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,  # * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  # * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED  # * OF THE POSSIBILITY OF SUCH DAMAGE.  # */  #  # /*  # * Copyright (c) 1999 Computer Systems and Communication Lab,  # * Institute of Information Science, Academia Sinica.  # * All rights reserved.  # *  # * Redistribution and use in source and binary forms, with or without  # * modification, are permitted provided that the following conditions  # * are met:  # *  # * . Redistributions of source code must retain the above copyright  # * notice, this list of conditions and the following disclaimer.  # * . Redistributions in binary form must reproduce the above copyright  # * notice, this list of conditions and the following disclaimer in  # * the documentation and/or other materials provided with the  # * distribution.  # * . Neither the name of the Computer Systems and Communication Lab  # * nor the names of its contributors may be used to endorse or  # * promote products derived from this software without specific  # * prior written permission.  # *  # * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS  # * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT  # * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS  # * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE  # * REGENTS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,  # * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES  # * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR  # * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  # * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,  # * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  # * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED  # * OF THE POSSIBILITY OF SUCH DAMAGE.  # */  #  # Copyright 1996 Chih-Hao Tsai @ Beckman Institute, University of Illinois  # c-tsai4@uiuc.edu http://casper.beckman.uiuc.edu/~c-tsai4  #  # ---------------COPYING.libtabe-----END------------------------------------  #  #  # ---------------COPYING.ipadic-----BEGIN------------------------------------  #  # Copyright 2000, 2001, 2002, 2003 Nara Institute of Science  # and Technology. All Rights Reserved.  #  # Use, reproduction, and distribution of this software is permitted.  # Any copy of this software, whether in its original form or modified,  # must include both the above copyright notice and the following  # paragraphs.  #  # Nara Institute of Science and Technology (NAIST),  # the copyright holders, disclaims all warranties with regard to this  # software, including all implied warranties of merchantability and  # fitness, in no event shall NAIST be liable for  # any special, indirect or consequential damages or any damages  # whatsoever resulting from loss of use, data or profits, whether in an  # action of contract, negligence or other tortuous action, arising out  # of or in connection with the use or performance of this software.  #  # A large portion of the dictionary entries  # originate from ICOT Free Software. The following conditions for ICOT  # Free Software applies to the current dictionary as well.  #  # Each User may also freely distribute the Program, whether in its  # original form or modified, to any third party or parties, PROVIDED  # that the provisions of Section 3 ("NO WARRANTY") will ALWAYS appear  # on, or be attached to, the Program, which is distributed substantially  # in the same form as set out herein and that such intended  # distribution, if actually made, will neither violate or otherwise  # contravene any of the laws and regulations of the countries having  # jurisdiction over the User or the intended distribution itself.  #  # NO WARRANTY  #  # The program was produced on an experimental basis in the course of the  # research and development conducted during the project and is provided  # to users as so produced on an experimental basis. Accordingly, the  # program is provided without any warranty whatsoever, whether express,  # implied, statutory or otherwise. The term "warranty" used herein  # includes, but is not limited to, any warranty of the quality,  # performance, merchantability and fitness for a particular purpose of  # the program and the nonexistence of any infringement or violation of  # any right of any third party.  #  # Each user of the program will agree and understand, and be deemed to  # have agreed and understood, that there is no warranty whatsoever for  # the program and, accordingly, the entire risk arising from or  # otherwise connected with the program is assumed by the user.  #  # Therefore, neither ICOT, the copyright holder, or any other  # organization that participated in or was otherwise related to the  # development of the program and their respective officials, directors,  # officers and other employees shall be held liable for any and all  # damages, including, without limitation, general, special, incidental  # and consequential damages, arising out of or otherwise in connection  # with the use or inability to use the program or any product, material  # or result produced or otherwise obtained by using the program,  # regardless of whether they have been advised of, or otherwise had  # knowledge of, the possibility of such damages at any time during the  # project or thereafter. Each user will be deemed to have agreed to the  # foregoing by his or her commencement of use of the program. The term  # "use" as used herein includes, but is not limited to, the use,  # modification, copying and distribution of the program and the  # production of secondary products from the program.  #  # In the case where the program, whether in its original form or  # modified, was distributed or delivered to or received by a user from  # any person, organization or entity other than ICOT, unless it makes or  # grants independently of ICOT any specific warranty to the user in  # writing, such person, organization or entity, will also be exempted  # from and not be held liable to the user for any such damages as noted  # above as far as the program is concerned.  #  # ---------------COPYING.ipadic-----END------------------------------------
3. Time Zone Database
ICU uses the public domain data and code derived from Time Zone Database for its time zone support. The ownership of the TZ database is explained in BCP 175: Procedure for Maintaining the Time Zone Database section 7.
7. Database Ownership
The TZ database itself is not an IETF Contribution or an IETF    document. Rather it is a pre-existing and regularly updated work    that is in the public domain, and is intended to remain in the public    domain. Therefore, BCPs 78 [RFC5378] and 79 [RFC3979] do not apply    to the TZ Database or contributions that individuals make to it.    Should any claims be made and substantiated against the TZ Database,    the organization that is providing the IANA Considerations defined in    this RFC, under the memorandum of understanding with the IETF,    currently ICANN, may act in accordance with all competent court    orders. No ownership claims will be made by ICANN or the IETF Trust    on the database or the code. Any person making a contribution to the    database or code waives all rights to future claims in that    contribution or in the TZ Database.
</pre>
This software is copyright (C) 1991-2009, Thomas G. Lane, Guido Vollbeding. All Rights Reserved except as specified below.
Permission is hereby granted to use, copy, modify, and distribute this software (or portions thereof) for any purpose, without fee, subject to these conditions: (1) If any part of the source code for this software is distributed, then this README file must be included, with this copyright and no-warranty notice unaltered; and any additions, deletions, or changes to the original files must be clearly indicated in accompanying documentation. (2) If only executable code is distributed, then the accompanying documentation must state that "this software is based in part on the work of the Independent JPEG Group". (3) Permission for use of this software is granted only if the user accepts full responsibility for any undesirable consequences; the authors accept NO LIABILITY for damages of any kind.
These conditions apply to any software derived from or based on the IJG code, not just to the unmodified library. If you use our work, you ought to acknowledge us.
Permission is NOT granted for the use of any IJG author's name or company name in advertising or publicity relating to this software or products derived from it. This software may be referred to only as "the Independent JPEG Group's software".
We specifically permit and encourage the use of this software as the basis of commercial products, provided that all warranty or liability claims are assumed by the product vendor.
</pre>
File: Abstract: Part of CoreAudio Utility Classes Version: 1.1
Disclaimer: IMPORTANT: This Apple software is supplied to you by Apple Inc. ("Apple") in consideration of your agreement to the following terms, and your use, installation, modification or redistribution of this Apple software constitutes acceptance of these terms. If you do not agree with these terms, please do not use, install, modify or redistribute this Apple software.
In consideration of your agreement to abide by the following terms, and subject to these terms, Apple grants you a personal, non-exclusive license, under Apple's copyrights in this original Apple software (the "Apple Software"), to use, reproduce, modify and redistribute the Apple Software, with or without modifications, in source and/or binary forms; provided that if you redistribute the Apple Software in its entirety and without modifications, you must retain this notice and the following text and disclaimers in all such redistributions of the Apple Software. Neither the name, trademarks, service marks or logos of Apple Inc. may be used to endorse or promote products derived from the Apple Software without specific prior written permission from Apple. Except as expressly stated in this notice, no other rights or licenses, express or implied, are granted by Apple herein, including but not limited to any patent rights that may be infringed by your derivative works or by other works in which the Apple Software may be incorporated.
The Apple Software is provided by Apple on an "AS IS" basis. APPLE MAKES NO WARRANTIES, EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION THE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, REGARDING THE APPLE SOFTWARE OR ITS USE AND OPERATION ALONE OR IN COMBINATION WITH YOUR PRODUCTS.
IN NO EVENT SHALL APPLE BE LIABLE FOR ANY SPECIAL, INDIRECT, INCIDENTAL OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) ARISING IN ANY WAY OUT OF THE USE, REPRODUCTION, MODIFICATION AND/OR DISTRIBUTION OF THE APPLE SOFTWARE, HOWEVER CAUSED AND WHETHER UNDER THEORY OF CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY OR OTHERWISE, EVEN IF APPLE HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
Copyright (C) 2014 Apple Inc. All Rights Reserved.
</pre>
- On Linux systems: N/A (library is not present)    - On Mac OS X systems: delete $(JAVA_HOME)/lib/libglib-lite.dylib    - On Windows systems: delete $(JAVA_HOME)\bin\glib-lite.dll
A copy of the Oracle modified GNU Glib library source code is located in the following OpenJDK Mercurial repository:
http://hg.openjdk.java.net/openjfx/9/rt
You can use Mercurial to clone the repository or you can browse the source using a web browser. The root directory of the GNU Glib source code is here:
rt/modules/javafx.media/src/main/native/gstreamer/3rd_party/glib/ </pre>
Copyright (C) 1991, 1999 Free Software Foundation, Inc.  51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA  Everyone is permitted to copy and distribute verbatim copies  of this license document, but changing it is not allowed.
[This is the first released version of the Lesser GPL.  It also counts  as the successor of the GNU Library Public License, version 2, hence  the version number 2.1.]
Preamble
The licenses for most software are designed to take away your freedom to share and change it.  By contrast, the GNU General Public Licenses are intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users.
This license, the Lesser General Public License, applies to some specially designated software packages--typically libraries--of the Free Software Foundation and other authors who decide to use it.  You can use it too, but we suggest you first think carefully about whether this license or the ordinary General Public License is the better strategy to use in any particular case, based on the explanations below.
When we speak of free software, we are referring to freedom of use, not price.  Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish); that you receive source code or can get it if you want it; that you can change the software and use pieces of it in new free programs; and that you are informed that you can do these things.
To protect your rights, we need to make restrictions that forbid distributors to deny you these rights or to ask you to surrender these rights.  These restrictions translate to certain responsibilities for you if you distribute copies of the library or if you modify it.
For example, if you distribute copies of the library, whether gratis or for a fee, you must give the recipients all the rights that we gave you.  You must make sure that they, too, receive or can get the source code.  If you link other code with the library, you must provide complete object files to the recipients, so that they can relink them with the library after making changes to the library and recompiling it.  And you must show them these terms so they know their rights.
We protect your rights with a two-step method: (1) we copyright the library, and (2) we offer you this license, which gives you legal permission to copy, distribute and/or modify the library.
To protect each distributor, we want to make it very clear that there is no warranty for the free library.  Also, if the library is modified by someone else and passed on, the recipients should know that what they have is not the original version, so that the original author's reputation will not be affected by problems that might be introduced by others.    Finally, software patents pose a constant threat to the existence of any free program.  We wish to make sure that a company cannot effectively restrict the users of a free program by obtaining a restrictive license from a patent holder.  Therefore, we insist that any patent license obtained for a version of the library must be consistent with the full freedom of use specified in this license.
Most GNU software, including some libraries, is covered by the ordinary GNU General Public License.  This license, the GNU Lesser General Public License, applies to certain designated libraries, and is quite different from the ordinary General Public License.  We use this license for certain libraries in order to permit linking those libraries into non-free programs.
When a program is linked with a library, whether statically or using a shared library, the combination of the two is legally speaking a combined work, a derivative of the original library.  The ordinary General Public License therefore permits such linking only if the entire combination fits its criteria of freedom.  The Lesser General Public License permits more lax criteria for linking other code with the library.
We call this license the "Lesser" General Public License because it does Less to protect the user's freedom than the ordinary General Public License.  It also provides other free software developers Less of an advantage over competing non-free programs.  These disadvantages are the reason we use the ordinary General Public License for many libraries.  However, the Lesser license provides advantages in certain special circumstances.
For example, on rare occasions, there may be a special need to encourage the widest possible use of a certain library, so that it becomes a de-facto standard.  To achieve this, non-free programs must be allowed to use the library.  A more frequent case is that a free library does the same job as widely used non-free libraries.  In this case, there is little to gain by limiting the free library to free software only, so we use the Lesser General Public License.
In other cases, permission to use a particular library in non-free programs enables a greater number of people to use a large body of free software.  For example, permission to use the GNU C Library in non-free programs enables many more people to use the whole GNU operating system, as well as its variant, the GNU/Linux operating system.
Although the Lesser General Public License is Less protective of the users' freedom, it does ensure that the user of a program that is linked with the Library has the freedom and the wherewithal to run that program using a modified version of the Library.
The precise terms and conditions for copying, distribution and modification follow.  Pay close attention to the difference between a "work based on the library" and a "work that uses the library".  The former contains code derived from the library, whereas the latter must be combined with the library in order to run.                    GNU LESSER GENERAL PUBLIC LICENSE    TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
0. This License Agreement applies to any software library or other program which contains a notice placed by the copyright holder or other authorized party saying it may be distributed under the terms of this Lesser General Public License (also called "this License"). Each licensee is addressed as "you".
A "library" means a collection of software functions and/or data prepared so as to be conveniently linked with application programs (which use some of those functions and data) to form executables.
The "Library", below, refers to any such software library or work which has been distributed under these terms.  A "work based on the Library" means either the Library or any derivative work under copyright law: that is to say, a work containing the Library or a portion of it, either verbatim or with modifications and/or translated straightforwardly into another language.  (Hereinafter, translation is included without limitation in the term "modification".)
"Source code" for a work means the preferred form of the work for making modifications to it.  For a library, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the library.
Activities other than copying, distribution and modification are not covered by this License; they are outside its scope.  The act of running a program using the Library is not restricted, and output from such a program is covered only if its contents constitute a work based on the Library (independent of the use of the Library in a tool for writing it).  Whether that is true depends on what the Library does and what the program that uses the Library does.
1. You may copy and distribute verbatim copies of the Library's complete source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and distribute a copy of this License along with the Library.
You may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.    2. You may modify your copy or copies of the Library or any portion of it, thus forming a work based on the Library, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:
a) The modified work must itself be a software library.
b) You must cause the files modified to carry prominent notices     stating that you changed the files and the date of any change.
c) You must cause the whole of the work to be licensed at no     charge to all third parties under the terms of this License.
d) If a facility in the modified Library refers to a function or a     table of data to be supplied by an application program that uses     the facility, other than as an argument passed when the facility     is invoked, then you must make a good faith effort to ensure that,     in the event an application does not supply such function or     table, the facility still operates, and performs whatever part of     its purpose remains meaningful.
(For example, a function in a library to compute square roots has     a purpose that is entirely well-defined independent of the     application.  Therefore, Subsection 2d requires that any     application-supplied function or table used by this function must     be optional: if the application does not supply it, the square     root function must still compute square roots.)
These requirements apply to the modified work as a whole.  If identifiable sections of that work are not derived from the Library, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works.  But when you distribute the same sections as part of a whole which is a work based on the Library, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.
Thus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Library.
In addition, mere aggregation of another work not based on the Library with the Library (or with a work based on the Library) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.
3. You may opt to apply the terms of the ordinary GNU General Public License instead of this License to a given copy of the Library.  To do this, you must alter all the notices that refer to this License, so that they refer to the ordinary GNU General Public License, version 2, instead of to this License.  (If a newer version than version 2 of the ordinary GNU General Public License has appeared, then you can specify that version instead if you wish.)  Do not make any other change in these notices.    Once this change is made in a given copy, it is irreversible for that copy, so the ordinary GNU General Public License applies to all subsequent copies and derivative works made from that copy.
This option is useful when you wish to copy part of the code of the Library into a program that is not a library.
4. You may copy and distribute the Library (or a portion or derivative of it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange.
If distribution of object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place satisfies the requirement to distribute the source code, even though third parties are not compelled to copy the source along with the object code.
5. A program that contains no derivative of any portion of the Library, but is designed to work with the Library by being compiled or linked with it, is called a "work that uses the Library".  Such a work, in isolation, is not a derivative work of the Library, and therefore falls outside the scope of this License.
However, linking a "work that uses the Library" with the Library creates an executable that is a derivative of the Library (because it contains portions of the Library), rather than a "work that uses the library".  The executable is therefore covered by this License. Section 6 states terms for distribution of such executables.
When a "work that uses the Library" uses material from a header file that is part of the Library, the object code for the work may be a derivative work of the Library even though the source code is not. Whether this is true is especially significant if the work can be linked without the Library, or if the work is itself a library.  The threshold for this to be true is not precisely defined by law.
If such an object file uses only numerical parameters, data structure layouts and accessors, and small macros and small inline functions (ten lines or less in length), then the use of the object file is unrestricted, regardless of whether it is legally a derivative work.  (Executables containing this object code plus portions of the Library will still fall under Section 6.)
Otherwise, if the work is a derivative of the Library, you may distribute the object code for the work under the terms of Section 6. Any executables containing that work also fall under Section 6, whether or not they are linked directly with the Library itself.    6. As an exception to the Sections above, you may also combine or link a "work that uses the Library" with the Library to produce a work containing portions of the Library, and distribute that work under terms of your choice, provided that the terms permit modification of the work for the customer's own use and reverse engineering for debugging such modifications.
You must give prominent notice with each copy of the work that the Library is used in it and that the Library and its use are covered by this License.  You must supply a copy of this License.  If the work during execution displays copyright notices, you must include the copyright notice for the Library among them, as well as a reference directing the user to the copy of this License.  Also, you must do one of these things:
a) Accompany the work with the complete corresponding     machine-readable source code for the Library including whatever     changes were used in the work (which must be distributed under     Sections 1 and 2 above); and, if the work is an executable linked     with the Library, with the complete machine-readable "work that     uses the Library", as object code and/or source code, so that the     user can modify the Library and then relink to produce a modified     executable containing the modified Library.  (It is understood     that the user who changes the contents of definitions files in the     Library will not necessarily be able to recompile the application     to use the modified definitions.)
b) Use a suitable shared library mechanism for linking with the     Library.  A suitable mechanism is one that (1) uses at run time a     copy of the library already present on the user's computer system,     rather than copying library functions into the executable, and (2)     will operate properly with a modified version of the library, if     the user installs one, as long as the modified version is     interface-compatible with the version that the work was made with.
c) Accompany the work with a written offer, valid for at     least three years, to give the same user the materials     specified in Subsection 6a, above, for a charge no more     than the cost of performing this distribution.
d) If distribution of the work is made by offering access to copy     from a designated place, offer equivalent access to copy the above     specified materials from the same place.
e) Verify that the user has already received a copy of these     materials or that you have already sent this user a copy.
For an executable, the required form of the "work that uses the Library" must include any data and utility programs needed for reproducing the executable from it.  However, as a special exception, the materials to be distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.
It may happen that this requirement contradicts the license restrictions of other proprietary libraries that do not normally accompany the operating system.  Such a contradiction means you cannot use both them and the Library together in an executable that you distribute.    7. You may place library facilities that are a work based on the Library side-by-side in a single library together with other library facilities not covered by this License, and distribute such a combined library, provided that the separate distribution of the work based on the Library and of the other library facilities is otherwise permitted, and provided that you do these two things:
a) Accompany the combined library with a copy of the same work     based on the Library, uncombined with any other library     facilities.  This must be distributed under the terms of the     Sections above.
b) Give prominent notice with the combined library of the fact     that part of it is a work based on the Library, and explaining     where to find the accompanying uncombined form of the same work.
8. You may not copy, modify, sublicense, link with, or distribute the Library except as expressly provided under this License.  Any attempt otherwise to copy, modify, sublicense, link with, or distribute the Library is void, and will automatically terminate your rights under this License.  However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.
9. You are not required to accept this License, since you have not signed it.  However, nothing else grants you permission to modify or distribute the Library or its derivative works.  These actions are prohibited by law if you do not accept this License.  Therefore, by modifying or distributing the Library (or any work based on the Library), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Library or works based on it.
10. Each time you redistribute the Library (or any work based on the Library), the recipient automatically receives a license from the original licensor to copy, distribute, link with or modify the Library subject to these terms and conditions.  You may not impose any further restrictions on the recipients' exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties with this License.    11. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License.  If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Library at all.  For example, if a patent license would not permit royalty-free redistribution of the Library by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Library.
If any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply, and the section as a whole is intended to apply in other circumstances.
It is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system which is implemented by public license practices.  Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice.
This section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.
12. If the distribution and/or use of the Library is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Library under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded.  In such case, this License incorporates the limitation as if written in the body of this License.
13. The Free Software Foundation may publish revised and/or new versions of the Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.
Each version is given a distinguishing version number.  If the Library specifies a version number of this License which applies to it and "any later version", you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation.  If the Library does not specify a license version number, you may choose any version ever published by the Free Software Foundation.    14. If you wish to incorporate parts of the Library into other free programs whose distribution conditions are incompatible with these, write to the author to ask for permission.  For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this.  Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.
NO WARRANTY
15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE LIBRARY "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE LIBRARY IS WITH YOU.  SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.
END OF TERMS AND CONDITIONS             How to Apply These Terms to Your New Libraries
If you develop a new library, and you want it to be of the greatest possible use to the public, we recommend making it free software that everyone can redistribute and change.  You can do so by permitting redistribution under these terms (or, alternatively, under the terms of the ordinary General Public License).
To apply these terms, attach the following notices to the library.  It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the "copyright" line and a pointer to where the full notice is found.
<one line to give the library's name and a brief idea of what it does.>     Copyright (C) <year>  <name of author>
This library is free software; you can redistribute it and/or     modify it under the terms of the GNU Lesser General Public     License as published by the Free Software Foundation; either     version 2.1 of the License, or (at your option) any later version.
This library is distributed in the hope that it will be useful,     but WITHOUT ANY WARRANTY; without even the implied warranty of     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU     Lesser General Public License for more details.
You should have received a copy of the GNU Lesser General Public     License along with this library; if not, write to the Free Software     Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
Also add information on how to contact you by electronic and paper mail.
You should also get your employer (if you work as a programmer) or your school, if any, to sign a "copyright disclaimer" for the library, if necessary.  Here is a sample; alter the names:
Yoyodyne, Inc., hereby disclaims all copyright interest in the   library `Frob' (a library for tweaking knobs) written by James Random Hacker.
<signature of Ty Coon>, 1 April 1990   Ty Coon, President of Vice
That's all there is to it!
</pre>

- On Linux systems: delete $(JAVA_HOME)/lib/libgstreamer-lite.so    - On Mac OS X systems: delete $(JAVA_HOME)/lib/libgstreamer-lite.dylib    - On Windows systems: delete $(JAVA_HOME)\bin\gstreamer-lite.dll
A copy of the Oracle modified GStreamer library source code is located in the following OpenJDK Mercurial repository:
http://hg.openjdk.java.net/openjfx/9/rt
You can use Mercurial to clone the repository or you can browse the source using a web browser. The root directory of the GStreamer source code is here:
rt/modules/javafx.media/src/main/native/gstreamer/gstreamer-lite/ </pre>
Copyright (C) 1991, 1999 Free Software Foundation, Inc.  51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA  Everyone is permitted to copy and distribute verbatim copies  of this license document, but changing it is not allowed.
[This is the first released version of the Lesser GPL.  It also counts  as the successor of the GNU Library Public License, version 2, hence  the version number 2.1.]
Preamble
The licenses for most software are designed to take away your freedom to share and change it.  By contrast, the GNU General Public Licenses are intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users.
This license, the Lesser General Public License, applies to some specially designated software packages--typically libraries--of the Free Software Foundation and other authors who decide to use it.  You can use it too, but we suggest you first think carefully about whether this license or the ordinary General Public License is the better strategy to use in any particular case, based on the explanations below.
When we speak of free software, we are referring to freedom of use, not price.  Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish); that you receive source code or can get it if you want it; that you can change the software and use pieces of it in new free programs; and that you are informed that you can do these things.
To protect your rights, we need to make restrictions that forbid distributors to deny you these rights or to ask you to surrender these rights.  These restrictions translate to certain responsibilities for you if you distribute copies of the library or if you modify it.
For example, if you distribute copies of the library, whether gratis or for a fee, you must give the recipients all the rights that we gave you.  You must make sure that they, too, receive or can get the source code.  If you link other code with the library, you must provide complete object files to the recipients, so that they can relink them with the library after making changes to the library and recompiling it.  And you must show them these terms so they know their rights.
We protect your rights with a two-step method: (1) we copyright the library, and (2) we offer you this license, which gives you legal permission to copy, distribute and/or modify the library.
To protect each distributor, we want to make it very clear that there is no warranty for the free library.  Also, if the library is modified by someone else and passed on, the recipients should know that what they have is not the original version, so that the original author's reputation will not be affected by problems that might be introduced by others.    Finally, software patents pose a constant threat to the existence of any free program.  We wish to make sure that a company cannot effectively restrict the users of a free program by obtaining a restrictive license from a patent holder.  Therefore, we insist that any patent license obtained for a version of the library must be consistent with the full freedom of use specified in this license.
Most GNU software, including some libraries, is covered by the ordinary GNU General Public License.  This license, the GNU Lesser General Public License, applies to certain designated libraries, and is quite different from the ordinary General Public License.  We use this license for certain libraries in order to permit linking those libraries into non-free programs.
When a program is linked with a library, whether statically or using a shared library, the combination of the two is legally speaking a combined work, a derivative of the original library.  The ordinary General Public License therefore permits such linking only if the entire combination fits its criteria of freedom.  The Lesser General Public License permits more lax criteria for linking other code with the library.
We call this license the "Lesser" General Public License because it does Less to protect the user's freedom than the ordinary General Public License.  It also provides other free software developers Less of an advantage over competing non-free programs.  These disadvantages are the reason we use the ordinary General Public License for many libraries.  However, the Lesser license provides advantages in certain special circumstances.
For example, on rare occasions, there may be a special need to encourage the widest possible use of a certain library, so that it becomes a de-facto standard.  To achieve this, non-free programs must be allowed to use the library.  A more frequent case is that a free library does the same job as widely used non-free libraries.  In this case, there is little to gain by limiting the free library to free software only, so we use the Lesser General Public License.
In other cases, permission to use a particular library in non-free programs enables a greater number of people to use a large body of free software.  For example, permission to use the GNU C Library in non-free programs enables many more people to use the whole GNU operating system, as well as its variant, the GNU/Linux operating system.
Although the Lesser General Public License is Less protective of the users' freedom, it does ensure that the user of a program that is linked with the Library has the freedom and the wherewithal to run that program using a modified version of the Library.
The precise terms and conditions for copying, distribution and modification follow.  Pay close attention to the difference between a "work based on the library" and a "work that uses the library".  The former contains code derived from the library, whereas the latter must be combined with the library in order to run.                    GNU LESSER GENERAL PUBLIC LICENSE    TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
0. This License Agreement applies to any software library or other program which contains a notice placed by the copyright holder or other authorized party saying it may be distributed under the terms of this Lesser General Public License (also called "this License"). Each licensee is addressed as "you".
A "library" means a collection of software functions and/or data prepared so as to be conveniently linked with application programs (which use some of those functions and data) to form executables.
The "Library", below, refers to any such software library or work which has been distributed under these terms.  A "work based on the Library" means either the Library or any derivative work under copyright law: that is to say, a work containing the Library or a portion of it, either verbatim or with modifications and/or translated straightforwardly into another language.  (Hereinafter, translation is included without limitation in the term "modification".)
"Source code" for a work means the preferred form of the work for making modifications to it.  For a library, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the library.
Activities other than copying, distribution and modification are not covered by this License; they are outside its scope.  The act of running a program using the Library is not restricted, and output from such a program is covered only if its contents constitute a work based on the Library (independent of the use of the Library in a tool for writing it).  Whether that is true depends on what the Library does and what the program that uses the Library does.
1. You may copy and distribute verbatim copies of the Library's complete source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and distribute a copy of this License along with the Library.
You may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.    2. You may modify your copy or copies of the Library or any portion of it, thus forming a work based on the Library, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:
a) The modified work must itself be a software library.
b) You must cause the files modified to carry prominent notices     stating that you changed the files and the date of any change.
c) You must cause the whole of the work to be licensed at no     charge to all third parties under the terms of this License.
d) If a facility in the modified Library refers to a function or a     table of data to be supplied by an application program that uses     the facility, other than as an argument passed when the facility     is invoked, then you must make a good faith effort to ensure that,     in the event an application does not supply such function or     table, the facility still operates, and performs whatever part of     its purpose remains meaningful.
(For example, a function in a library to compute square roots has     a purpose that is entirely well-defined independent of the     application.  Therefore, Subsection 2d requires that any     application-supplied function or table used by this function must     be optional: if the application does not supply it, the square     root function must still compute square roots.)
These requirements apply to the modified work as a whole.  If identifiable sections of that work are not derived from the Library, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works.  But when you distribute the same sections as part of a whole which is a work based on the Library, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.
Thus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Library.
In addition, mere aggregation of another work not based on the Library with the Library (or with a work based on the Library) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.
3. You may opt to apply the terms of the ordinary GNU General Public License instead of this License to a given copy of the Library.  To do this, you must alter all the notices that refer to this License, so that they refer to the ordinary GNU General Public License, version 2, instead of to this License.  (If a newer version than version 2 of the ordinary GNU General Public License has appeared, then you can specify that version instead if you wish.)  Do not make any other change in these notices.    Once this change is made in a given copy, it is irreversible for that copy, so the ordinary GNU General Public License applies to all subsequent copies and derivative works made from that copy.
This option is useful when you wish to copy part of the code of the Library into a program that is not a library.
4. You may copy and distribute the Library (or a portion or derivative of it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange.
If distribution of object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place satisfies the requirement to distribute the source code, even though third parties are not compelled to copy the source along with the object code.
5. A program that contains no derivative of any portion of the Library, but is designed to work with the Library by being compiled or linked with it, is called a "work that uses the Library".  Such a work, in isolation, is not a derivative work of the Library, and therefore falls outside the scope of this License.
However, linking a "work that uses the Library" with the Library creates an executable that is a derivative of the Library (because it contains portions of the Library), rather than a "work that uses the library".  The executable is therefore covered by this License. Section 6 states terms for distribution of such executables.
When a "work that uses the Library" uses material from a header file that is part of the Library, the object code for the work may be a derivative work of the Library even though the source code is not. Whether this is true is especially significant if the work can be linked without the Library, or if the work is itself a library.  The threshold for this to be true is not precisely defined by law.
If such an object file uses only numerical parameters, data structure layouts and accessors, and small macros and small inline functions (ten lines or less in length), then the use of the object file is unrestricted, regardless of whether it is legally a derivative work.  (Executables containing this object code plus portions of the Library will still fall under Section 6.)
Otherwise, if the work is a derivative of the Library, you may distribute the object code for the work under the terms of Section 6. Any executables containing that work also fall under Section 6, whether or not they are linked directly with the Library itself.    6. As an exception to the Sections above, you may also combine or link a "work that uses the Library" with the Library to produce a work containing portions of the Library, and distribute that work under terms of your choice, provided that the terms permit modification of the work for the customer's own use and reverse engineering for debugging such modifications.
You must give prominent notice with each copy of the work that the Library is used in it and that the Library and its use are covered by this License.  You must supply a copy of this License.  If the work during execution displays copyright notices, you must include the copyright notice for the Library among them, as well as a reference directing the user to the copy of this License.  Also, you must do one of these things:
a) Accompany the work with the complete corresponding     machine-readable source code for the Library including whatever     changes were used in the work (which must be distributed under     Sections 1 and 2 above); and, if the work is an executable linked     with the Library, with the complete machine-readable "work that     uses the Library", as object code and/or source code, so that the     user can modify the Library and then relink to produce a modified     executable containing the modified Library.  (It is understood     that the user who changes the contents of definitions files in the     Library will not necessarily be able to recompile the application     to use the modified definitions.)
b) Use a suitable shared library mechanism for linking with the     Library.  A suitable mechanism is one that (1) uses at run time a     copy of the library already present on the user's computer system,     rather than copying library functions into the executable, and (2)     will operate properly with a modified version of the library, if     the user installs one, as long as the modified version is     interface-compatible with the version that the work was made with.
c) Accompany the work with a written offer, valid for at     least three years, to give the same user the materials     specified in Subsection 6a, above, for a charge no more     than the cost of performing this distribution.
d) If distribution of the work is made by offering access to copy     from a designated place, offer equivalent access to copy the above     specified materials from the same place.
e) Verify that the user has already received a copy of these     materials or that you have already sent this user a copy.
For an executable, the required form of the "work that uses the Library" must include any data and utility programs needed for reproducing the executable from it.  However, as a special exception, the materials to be distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.
It may happen that this requirement contradicts the license restrictions of other proprietary libraries that do not normally accompany the operating system.  Such a contradiction means you cannot use both them and the Library together in an executable that you distribute.    7. You may place library facilities that are a work based on the Library side-by-side in a single library together with other library facilities not covered by this License, and distribute such a combined library, provided that the separate distribution of the work based on the Library and of the other library facilities is otherwise permitted, and provided that you do these two things:
a) Accompany the combined library with a copy of the same work     based on the Library, uncombined with any other library     facilities.  This must be distributed under the terms of the     Sections above.
b) Give prominent notice with the combined library of the fact     that part of it is a work based on the Library, and explaining     where to find the accompanying uncombined form of the same work.
8. You may not copy, modify, sublicense, link with, or distribute the Library except as expressly provided under this License.  Any attempt otherwise to copy, modify, sublicense, link with, or distribute the Library is void, and will automatically terminate your rights under this License.  However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.
9. You are not required to accept this License, since you have not signed it.  However, nothing else grants you permission to modify or distribute the Library or its derivative works.  These actions are prohibited by law if you do not accept this License.  Therefore, by modifying or distributing the Library (or any work based on the Library), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Library or works based on it.
10. Each time you redistribute the Library (or any work based on the Library), the recipient automatically receives a license from the original licensor to copy, distribute, link with or modify the Library subject to these terms and conditions.  You may not impose any further restrictions on the recipients' exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties with this License.    11. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License.  If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Library at all.  For example, if a patent license would not permit royalty-free redistribution of the Library by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Library.
If any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply, and the section as a whole is intended to apply in other circumstances.
It is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system which is implemented by public license practices.  Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice.
This section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.
12. If the distribution and/or use of the Library is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Library under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded.  In such case, this License incorporates the limitation as if written in the body of this License.
13. The Free Software Foundation may publish revised and/or new versions of the Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.
Each version is given a distinguishing version number.  If the Library specifies a version number of this License which applies to it and "any later version", you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation.  If the Library does not specify a license version number, you may choose any version ever published by the Free Software Foundation.    14. If you wish to incorporate parts of the Library into other free programs whose distribution conditions are incompatible with these, write to the author to ask for permission.  For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this.  Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.
NO WARRANTY
15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE LIBRARY "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE LIBRARY IS WITH YOU.  SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.
END OF TERMS AND CONDITIONS             How to Apply These Terms to Your New Libraries
If you develop a new library, and you want it to be of the greatest possible use to the public, we recommend making it free software that everyone can redistribute and change.  You can do so by permitting redistribution under these terms (or, alternatively, under the terms of the ordinary General Public License).
To apply these terms, attach the following notices to the library.  It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the "copyright" line and a pointer to where the full notice is found.
<one line to give the library's name and a brief idea of what it does.>     Copyright (C) <year>  <name of author>
This library is free software; you can redistribute it and/or     modify it under the terms of the GNU Lesser General Public     License as published by the Free Software Foundation; either     version 2.1 of the License, or (at your option) any later version.
This library is distributed in the hope that it will be useful,     but WITHOUT ANY WARRANTY; without even the implied warranty of     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU     Lesser General Public License for more details.
You should have received a copy of the GNU Lesser General Public     License along with this library; if not, write to the Free Software     Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
Also add information on how to contact you by electronic and paper mail.
You should also get your employer (if you work as a programmer) or your school, if any, to sign a "copyright disclaimer" for the library, if necessary.  Here is a sample; alter the names:
Yoyodyne, Inc., hereby disclaims all copyright interest in the   library `Frob' (a library for tweaking knobs) written by James Random Hacker.
<signature of Ty Coon>, 1 April 1990   Ty Coon, President of Vice
That's all there is to it!
</pre>
libffi - Copyright (c) 1996-2014  Anthony Green, Red Hat, Inc and others. See source files for details.
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ``Software''), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED ``AS IS'', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL BLFS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
- On Linux systems: delete $(JAVA_HOME)/lib/libjfxwebkit.so    - On Mac OS X systems: delete $(JAVA_HOME)/lib/libjfxwebkit.dylib    - On Windows systems: delete $(JAVA_HOME)\bin\jfxwebkit.dll
A copy of the Oracle modified WebKit library source code is located in the following OpenJDK Mercurial repository:
http://hg.openjdk.java.net/openjfx/9/rt
You can use Mercurial to clone the repository or you can browse the source using a web browser. The root directory of the WebKit source code is here:
rt/modules/javafx.web/src/main/native/ </pre>
Copyright (C) 1991, 1999 Free Software Foundation, Inc.  51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA  Everyone is permitted to copy and distribute verbatim copies  of this license document, but changing it is not allowed.
[This is the first released version of the Lesser GPL.  It also counts  as the successor of the GNU Library Public License, version 2, hence  the version number 2.1.]
Preamble
The licenses for most software are designed to take away your freedom to share and change it.  By contrast, the GNU General Public Licenses are intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users.
This license, the Lesser General Public License, applies to some specially designated software packages--typically libraries--of the Free Software Foundation and other authors who decide to use it.  You can use it too, but we suggest you first think carefully about whether this license or the ordinary General Public License is the better strategy to use in any particular case, based on the explanations below.
When we speak of free software, we are referring to freedom of use, not price.  Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish); that you receive source code or can get it if you want it; that you can change the software and use pieces of it in new free programs; and that you are informed that you can do these things.
To protect your rights, we need to make restrictions that forbid distributors to deny you these rights or to ask you to surrender these rights.  These restrictions translate to certain responsibilities for you if you distribute copies of the library or if you modify it.
For example, if you distribute copies of the library, whether gratis or for a fee, you must give the recipients all the rights that we gave you.  You must make sure that they, too, receive or can get the source code.  If you link other code with the library, you must provide complete object files to the recipients, so that they can relink them with the library after making changes to the library and recompiling it.  And you must show them these terms so they know their rights.
We protect your rights with a two-step method: (1) we copyright the library, and (2) we offer you this license, which gives you legal permission to copy, distribute and/or modify the library.
To protect each distributor, we want to make it very clear that there is no warranty for the free library.  Also, if the library is modified by someone else and passed on, the recipients should know that what they have is not the original version, so that the original author's reputation will not be affected by problems that might be introduced by others.    Finally, software patents pose a constant threat to the existence of any free program.  We wish to make sure that a company cannot effectively restrict the users of a free program by obtaining a restrictive license from a patent holder.  Therefore, we insist that any patent license obtained for a version of the library must be consistent with the full freedom of use specified in this license.
Most GNU software, including some libraries, is covered by the ordinary GNU General Public License.  This license, the GNU Lesser General Public License, applies to certain designated libraries, and is quite different from the ordinary General Public License.  We use this license for certain libraries in order to permit linking those libraries into non-free programs.
When a program is linked with a library, whether statically or using a shared library, the combination of the two is legally speaking a combined work, a derivative of the original library.  The ordinary General Public License therefore permits such linking only if the entire combination fits its criteria of freedom.  The Lesser General Public License permits more lax criteria for linking other code with the library.
We call this license the "Lesser" General Public License because it does Less to protect the user's freedom than the ordinary General Public License.  It also provides other free software developers Less of an advantage over competing non-free programs.  These disadvantages are the reason we use the ordinary General Public License for many libraries.  However, the Lesser license provides advantages in certain special circumstances.
For example, on rare occasions, there may be a special need to encourage the widest possible use of a certain library, so that it becomes a de-facto standard.  To achieve this, non-free programs must be allowed to use the library.  A more frequent case is that a free library does the same job as widely used non-free libraries.  In this case, there is little to gain by limiting the free library to free software only, so we use the Lesser General Public License.
In other cases, permission to use a particular library in non-free programs enables a greater number of people to use a large body of free software.  For example, permission to use the GNU C Library in non-free programs enables many more people to use the whole GNU operating system, as well as its variant, the GNU/Linux operating system.
Although the Lesser General Public License is Less protective of the users' freedom, it does ensure that the user of a program that is linked with the Library has the freedom and the wherewithal to run that program using a modified version of the Library.
The precise terms and conditions for copying, distribution and modification follow.  Pay close attention to the difference between a "work based on the library" and a "work that uses the library".  The former contains code derived from the library, whereas the latter must be combined with the library in order to run.                    GNU LESSER GENERAL PUBLIC LICENSE    TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
0. This License Agreement applies to any software library or other program which contains a notice placed by the copyright holder or other authorized party saying it may be distributed under the terms of this Lesser General Public License (also called "this License"). Each licensee is addressed as "you".
A "library" means a collection of software functions and/or data prepared so as to be conveniently linked with application programs (which use some of those functions and data) to form executables.
The "Library", below, refers to any such software library or work which has been distributed under these terms.  A "work based on the Library" means either the Library or any derivative work under copyright law: that is to say, a work containing the Library or a portion of it, either verbatim or with modifications and/or translated straightforwardly into another language.  (Hereinafter, translation is included without limitation in the term "modification".)
"Source code" for a work means the preferred form of the work for making modifications to it.  For a library, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the library.
Activities other than copying, distribution and modification are not covered by this License; they are outside its scope.  The act of running a program using the Library is not restricted, and output from such a program is covered only if its contents constitute a work based on the Library (independent of the use of the Library in a tool for writing it).  Whether that is true depends on what the Library does and what the program that uses the Library does.
1. You may copy and distribute verbatim copies of the Library's complete source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and distribute a copy of this License along with the Library.
You may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.    2. You may modify your copy or copies of the Library or any portion of it, thus forming a work based on the Library, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:
a) The modified work must itself be a software library.
b) You must cause the files modified to carry prominent notices     stating that you changed the files and the date of any change.
c) You must cause the whole of the work to be licensed at no     charge to all third parties under the terms of this License.
d) If a facility in the modified Library refers to a function or a     table of data to be supplied by an application program that uses     the facility, other than as an argument passed when the facility     is invoked, then you must make a good faith effort to ensure that,     in the event an application does not supply such function or     table, the facility still operates, and performs whatever part of     its purpose remains meaningful.
(For example, a function in a library to compute square roots has     a purpose that is entirely well-defined independent of the     application.  Therefore, Subsection 2d requires that any     application-supplied function or table used by this function must     be optional: if the application does not supply it, the square     root function must still compute square roots.)
These requirements apply to the modified work as a whole.  If identifiable sections of that work are not derived from the Library, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works.  But when you distribute the same sections as part of a whole which is a work based on the Library, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.
Thus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Library.
In addition, mere aggregation of another work not based on the Library with the Library (or with a work based on the Library) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.
3. You may opt to apply the terms of the ordinary GNU General Public License instead of this License to a given copy of the Library.  To do this, you must alter all the notices that refer to this License, so that they refer to the ordinary GNU General Public License, version 2, instead of to this License.  (If a newer version than version 2 of the ordinary GNU General Public License has appeared, then you can specify that version instead if you wish.)  Do not make any other change in these notices.    Once this change is made in a given copy, it is irreversible for that copy, so the ordinary GNU General Public License applies to all subsequent copies and derivative works made from that copy.
This option is useful when you wish to copy part of the code of the Library into a program that is not a library.
4. You may copy and distribute the Library (or a portion or derivative of it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange.
If distribution of object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place satisfies the requirement to distribute the source code, even though third parties are not compelled to copy the source along with the object code.
5. A program that contains no derivative of any portion of the Library, but is designed to work with the Library by being compiled or linked with it, is called a "work that uses the Library".  Such a work, in isolation, is not a derivative work of the Library, and therefore falls outside the scope of this License.
However, linking a "work that uses the Library" with the Library creates an executable that is a derivative of the Library (because it contains portions of the Library), rather than a "work that uses the library".  The executable is therefore covered by this License. Section 6 states terms for distribution of such executables.
When a "work that uses the Library" uses material from a header file that is part of the Library, the object code for the work may be a derivative work of the Library even though the source code is not. Whether this is true is especially significant if the work can be linked without the Library, or if the work is itself a library.  The threshold for this to be true is not precisely defined by law.
If such an object file uses only numerical parameters, data structure layouts and accessors, and small macros and small inline functions (ten lines or less in length), then the use of the object file is unrestricted, regardless of whether it is legally a derivative work.  (Executables containing this object code plus portions of the Library will still fall under Section 6.)
Otherwise, if the work is a derivative of the Library, you may distribute the object code for the work under the terms of Section 6. Any executables containing that work also fall under Section 6, whether or not they are linked directly with the Library itself.    6. As an exception to the Sections above, you may also combine or link a "work that uses the Library" with the Library to produce a work containing portions of the Library, and distribute that work under terms of your choice, provided that the terms permit modification of the work for the customer's own use and reverse engineering for debugging such modifications.
You must give prominent notice with each copy of the work that the Library is used in it and that the Library and its use are covered by this License.  You must supply a copy of this License.  If the work during execution displays copyright notices, you must include the copyright notice for the Library among them, as well as a reference directing the user to the copy of this License.  Also, you must do one of these things:
a) Accompany the work with the complete corresponding     machine-readable source code for the Library including whatever     changes were used in the work (which must be distributed under     Sections 1 and 2 above); and, if the work is an executable linked     with the Library, with the complete machine-readable "work that     uses the Library", as object code and/or source code, so that the     user can modify the Library and then relink to produce a modified     executable containing the modified Library.  (It is understood     that the user who changes the contents of definitions files in the     Library will not necessarily be able to recompile the application     to use the modified definitions.)
b) Use a suitable shared library mechanism for linking with the     Library.  A suitable mechanism is one that (1) uses at run time a     copy of the library already present on the user's computer system,     rather than copying library functions into the executable, and (2)     will operate properly with a modified version of the library, if     the user installs one, as long as the modified version is     interface-compatible with the version that the work was made with.
c) Accompany the work with a written offer, valid for at     least three years, to give the same user the materials     specified in Subsection 6a, above, for a charge no more     than the cost of performing this distribution.
d) If distribution of the work is made by offering access to copy     from a designated place, offer equivalent access to copy the above     specified materials from the same place.
e) Verify that the user has already received a copy of these     materials or that you have already sent this user a copy.
For an executable, the required form of the "work that uses the Library" must include any data and utility programs needed for reproducing the executable from it.  However, as a special exception, the materials to be distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.
It may happen that this requirement contradicts the license restrictions of other proprietary libraries that do not normally accompany the operating system.  Such a contradiction means you cannot use both them and the Library together in an executable that you distribute.    7. You may place library facilities that are a work based on the Library side-by-side in a single library together with other library facilities not covered by this License, and distribute such a combined library, provided that the separate distribution of the work based on the Library and of the other library facilities is otherwise permitted, and provided that you do these two things:
a) Accompany the combined library with a copy of the same work     based on the Library, uncombined with any other library     facilities.  This must be distributed under the terms of the     Sections above.
b) Give prominent notice with the combined library of the fact     that part of it is a work based on the Library, and explaining     where to find the accompanying uncombined form of the same work.
8. You may not copy, modify, sublicense, link with, or distribute the Library except as expressly provided under this License.  Any attempt otherwise to copy, modify, sublicense, link with, or distribute the Library is void, and will automatically terminate your rights under this License.  However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.
9. You are not required to accept this License, since you have not signed it.  However, nothing else grants you permission to modify or distribute the Library or its derivative works.  These actions are prohibited by law if you do not accept this License.  Therefore, by modifying or distributing the Library (or any work based on the Library), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Library or works based on it.
10. Each time you redistribute the Library (or any work based on the Library), the recipient automatically receives a license from the original licensor to copy, distribute, link with or modify the Library subject to these terms and conditions.  You may not impose any further restrictions on the recipients' exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties with this License.    11. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License.  If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Library at all.  For example, if a patent license would not permit royalty-free redistribution of the Library by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Library.
If any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply, and the section as a whole is intended to apply in other circumstances.
It is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system which is implemented by public license practices.  Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice.
This section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.
12. If the distribution and/or use of the Library is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Library under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded.  In such case, this License incorporates the limitation as if written in the body of this License.
13. The Free Software Foundation may publish revised and/or new versions of the Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.
Each version is given a distinguishing version number.  If the Library specifies a version number of this License which applies to it and "any later version", you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation.  If the Library does not specify a license version number, you may choose any version ever published by the Free Software Foundation.    14. If you wish to incorporate parts of the Library into other free programs whose distribution conditions are incompatible with these, write to the author to ask for permission.  For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this.  Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.
NO WARRANTY
15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE LIBRARY "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE LIBRARY IS WITH YOU.  SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.
END OF TERMS AND CONDITIONS             How to Apply These Terms to Your New Libraries
If you develop a new library, and you want it to be of the greatest possible use to the public, we recommend making it free software that everyone can redistribute and change.  You can do so by permitting redistribution under these terms (or, alternatively, under the terms of the ordinary General Public License).
To apply these terms, attach the following notices to the library.  It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the "copyright" line and a pointer to where the full notice is found.
<one line to give the library's name and a brief idea of what it does.>     Copyright (C) <year>  <name of author>
This library is free software; you can redistribute it and/or     modify it under the terms of the GNU Lesser General Public     License as published by the Free Software Foundation; either     version 2.1 of the License, or (at your option) any later version.
This library is distributed in the hope that it will be useful,     but WITHOUT ANY WARRANTY; without even the implied warranty of     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU     Lesser General Public License for more details.
You should have received a copy of the GNU Lesser General Public     License along with this library; if not, write to the Free Software     Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
Also add information on how to contact you by electronic and paper mail.
You should also get your employer (if you work as a programmer) or your school, if any, to sign a "copyright disclaimer" for the library, if necessary.  Here is a sample; alter the names:
Yoyodyne, Inc., hereby disclaims all copyright interest in the   library `Frob' (a library for tweaking knobs) written by James Random Hacker.
<signature of Ty Coon>, 1 April 1990   Ty Coon, President of Vice
That's all there is to it!
</pre>
License to copy and use this software is granted provided that it is identified as "RSA Security Inc. PKCS #11 Cryptographic Token Interface (Cryptoki)" in all material mentioning or referencing this software.
License is also granted to make and use derivative works provided that such works are identified as "derived from the RSA Security Inc. PKCS #11 Cryptographic Token Interface (Cryptoki)" in all material mentioning or referencing the derived work.
RSA Security Inc. makes no representations concerning either the merchantability of this software or the suitability of this software for any particular purpose. It is provided "as is" without express or implied warranty of any kind.
</pre>
Copyright (c) 2002 Graz University of Technology. All rights reserved.
Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
1. Redistributions of source code must retain the above copyright notice, this    list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright notice,    this list of conditions and the following disclaimer in the documentation    and/or other materials provided with the distribution.
3. The end-user documentation included with the redistribution, if any, must    include the following acknowledgment:
"This product includes software developed by IAIK of Graz University of     Technology."
Alternately, this acknowledgment may appear in the software itself, if and    wherever such third-party acknowledgments normally appear.
4. The names "Graz University of Technology" and "IAIK of Graz University of    Technology" must not be used to endorse or promote products derived from this    software without prior written permission.
5. Products derived from this software may not be called "IAIK PKCS Wrapper",    nor may "IAIK" appear in their name, without prior written permission of    Graz University of Technology.
THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE LICENSOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre>
This notice is provided with respect to Elliptic Curve Cryptography, which is included with JRE, JDK, and OpenJDK.
You are receiving a [copy](http://hg.openjdk.java.net/jdk9/jdk9/jdk/file/tip/src/jdk.crypto.ec/share/native/libsunec/impl) of the Elliptic Curve Cryptography library in source form with the JDK and OpenJDK source distributions, and as object code in the JRE & JDK runtimes. <pre> In the case of the JRE & JDK runtimes, the terms of the Oracle license do NOT apply to the Elliptic Curve Cryptography library; it is licensed under the following license, separately from Oracle's JDK & JRE.  If you do not wish to install the Elliptic Curve Cryptography library, you may delete the Elliptic Curve Cryptography library:    - On Solaris and Linux systems: delete $(JAVA_HOME)/lib/libsunec.so    - On Mac OSX systems: delete $(JAVA_HOME)/lib/libsunec.dylib    - On Windows systems: delete $(JAVA_HOME)\bin\sunec.dll
</pre>
For third party technology that you receive from Oracle in binary form  which is licensed under an open source license that gives you the right to receive the source code for that binary, you can obtain a copy of  the applicable source code from this page:     http://hg.openjdk.java.net/jdk9/jdk9/jdk/file/tip/src/jdk.crypto.ec/share/native/libsunec/impl
If the source code for the technology was not provided to you with the  binary, you can also receive a copy of the source code on physical  media by submitting a written request to:
Oracle America, Inc.    Attn: Associate General Counsel,    Development and Engineering Legal    500 Oracle Parkway, 10th Floor    Redwood Shores, CA 94065
Or, you may send an email to Oracle using the form at:
http://www.oracle.com/goto/opensourcecode/request
Your request should include:
- The name of the component or binary file(s) for which you are requesting the source code
- The name and version number of the Oracle product containing the binary
- The date you received the Oracle product
- Your name
- Your company name (if applicable)
- Your return mailing address and email and
- A telephone number in the event we need to reach you.
We may charge you a fee to cover the cost of physical media and processing.  Your request must be sent (i) within three (3) years of the date you  received the Oracle product that included the component or binary  file(s) that are the subject of your request, or (ii) in the case of  code licensed under the GPL v3, for as long as Oracle offers spare  parts or customer support for that product model.
</pre>
GNU LESSER GENERAL PUBLIC LICENSE                        Version 2.1, February 1999
Copyright (C) 1991, 1999 Free Software Foundation, Inc.  51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA  Everyone is permitted to copy and distribute verbatim copies  of this license document, but changing it is not allowed.
[This is the first released version of the Lesser GPL.  It also counts  as the successor of the GNU Library Public License, version 2, hence  the version number 2.1.]
Preamble
The licenses for most software are designed to take away your freedom to share and change it.  By contrast, the GNU General Public Licenses are intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users.
This license, the Lesser General Public License, applies to some specially designated software packages--typically libraries--of the Free Software Foundation and other authors who decide to use it.  You can use it too, but we suggest you first think carefully about whether this license or the ordinary General Public License is the better strategy to use in any particular case, based on the explanations below.
When we speak of free software, we are referring to freedom of use, not price.  Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish); that you receive source code or can get it if you want it; that you can change the software and use pieces of it in new free programs; and that you are informed that you can do these things.
To protect your rights, we need to make restrictions that forbid distributors to deny you these rights or to ask you to surrender these rights.  These restrictions translate to certain responsibilities for you if you distribute copies of the library or if you modify it.
For example, if you distribute copies of the library, whether gratis or for a fee, you must give the recipients all the rights that we gave you.  You must make sure that they, too, receive or can get the source code.  If you link other code with the library, you must provide complete object files to the recipients, so that they can relink them with the library after making changes to the library and recompiling it.  And you must show them these terms so they know their rights.
We protect your rights with a two-step method: (1) we copyright the library, and (2) we offer you this license, which gives you legal permission to copy, distribute and/or modify the library.
To protect each distributor, we want to make it very clear that there is no warranty for the free library.  Also, if the library is modified by someone else and passed on, the recipients should know that what they have is not the original version, so that the original author's reputation will not be affected by problems that might be introduced by others.
Finally, software patents pose a constant threat to the existence of any free program.  We wish to make sure that a company cannot effectively restrict the users of a free program by obtaining a restrictive license from a patent holder.  Therefore, we insist that any patent license obtained for a version of the library must be consistent with the full freedom of use specified in this license.
Most GNU software, including some libraries, is covered by the ordinary GNU General Public License.  This license, the GNU Lesser General Public License, applies to certain designated libraries, and is quite different from the ordinary General Public License.  We use this license for certain libraries in order to permit linking those libraries into non-free programs.
When a program is linked with a library, whether statically or using a shared library, the combination of the two is legally speaking a combined work, a derivative of the original library.  The ordinary General Public License therefore permits such linking only if the entire combination fits its criteria of freedom.  The Lesser General Public License permits more lax criteria for linking other code with the library.
We call this license the "Lesser" General Public License because it does Less to protect the user's freedom than the ordinary General Public License.  It also provides other free software developers Less of an advantage over competing non-free programs.  These disadvantages are the reason we use the ordinary General Public License for many libraries.  However, the Lesser license provides advantages in certain special circumstances.
For example, on rare occasions, there may be a special need to encourage the widest possible use of a certain library, so that it becomes a de-facto standard.  To achieve this, non-free programs must be allowed to use the library.  A more frequent case is that a free library does the same job as widely used non-free libraries.  In this case, there is little to gain by limiting the free library to free software only, so we use the Lesser General Public License.
In other cases, permission to use a particular library in non-free programs enables a greater number of people to use a large body of free software.  For example, permission to use the GNU C Library in non-free programs enables many more people to use the whole GNU operating system, as well as its variant, the GNU/Linux operating system.
Although the Lesser General Public License is Less protective of the users' freedom, it does ensure that the user of a program that is linked with the Library has the freedom and the wherewithal to run that program using a modified version of the Library.
The precise terms and conditions for copying, distribution and modification follow.  Pay close attention to the difference between a "work based on the library" and a "work that uses the library".  The former contains code derived from the library, whereas the latter must be combined with the library in order to run.
GNU LESSER GENERAL PUBLIC LICENSE    TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
0. This License Agreement applies to any software library or other program which contains a notice placed by the copyright holder or other authorized party saying it may be distributed under the terms of this Lesser General Public License (also called "this License"). Each licensee is addressed as "you".
A "library" means a collection of software functions and/or data prepared so as to be conveniently linked with application programs (which use some of those functions and data) to form executables.
The "Library", below, refers to any such software library or work which has been distributed under these terms.  A "work based on the Library" means either the Library or any derivative work under copyright law: that is to say, a work containing the Library or a portion of it, either verbatim or with modifications and/or translated straightforwardly into another language.  (Hereinafter, translation is included without limitation in the term "modification".)
"Source code" for a work means the preferred form of the work for making modifications to it.  For a library, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the library.
Activities other than copying, distribution and modification are not covered by this License; they are outside its scope.  The act of running a program using the Library is not restricted, and output from such a program is covered only if its contents constitute a work based on the Library (independent of the use of the Library in a tool for writing it).  Whether that is true depends on what the Library does and what the program that uses the Library does.
1. You may copy and distribute verbatim copies of the Library's complete source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and distribute a copy of this License along with the Library.
You may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.
2. You may modify your copy or copies of the Library or any portion of it, thus forming a work based on the Library, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:
a) The modified work must itself be a software library.
b) You must cause the files modified to carry prominent notices     stating that you changed the files and the date of any change.
c) You must cause the whole of the work to be licensed at no     charge to all third parties under the terms of this License.
d) If a facility in the modified Library refers to a function or a     table of data to be supplied by an application program that uses     the facility, other than as an argument passed when the facility     is invoked, then you must make a good faith effort to ensure that,     in the event an application does not supply such function or     table, the facility still operates, and performs whatever part of     its purpose remains meaningful.
(For example, a function in a library to compute square roots has     a purpose that is entirely well-defined independent of the     application.  Therefore, Subsection 2d requires that any     application-supplied function or table used by this function must     be optional: if the application does not supply it, the square     root function must still compute square roots.)
These requirements apply to the modified work as a whole.  If identifiable sections of that work are not derived from the Library, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works.  But when you distribute the same sections as part of a whole which is a work based on the Library, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.
Thus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Library.
In addition, mere aggregation of another work not based on the Library with the Library (or with a work based on the Library) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.
3. You may opt to apply the terms of the ordinary GNU General Public License instead of this License to a given copy of the Library.  To do this, you must alter all the notices that refer to this License, so that they refer to the ordinary GNU General Public License, version 2, instead of to this License.  (If a newer version than version 2 of the ordinary GNU General Public License has appeared, then you can specify that version instead if you wish.)  Do not make any other change in these notices.
Once this change is made in a given copy, it is irreversible for that copy, so the ordinary GNU General Public License applies to all subsequent copies and derivative works made from that copy.
This option is useful when you wish to copy part of the code of the Library into a program that is not a library.
4. You may copy and distribute the Library (or a portion or derivative of it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange.
If distribution of object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place satisfies the requirement to distribute the source code, even though third parties are not compelled to copy the source along with the object code.
5. A program that contains no derivative of any portion of the Library, but is designed to work with the Library by being compiled or linked with it, is called a "work that uses the Library".  Such a work, in isolation, is not a derivative work of the Library, and therefore falls outside the scope of this License.
However, linking a "work that uses the Library" with the Library creates an executable that is a derivative of the Library (because it contains portions of the Library), rather than a "work that uses the library".  The executable is therefore covered by this License. Section 6 states terms for distribution of such executables.
When a "work that uses the Library" uses material from a header file that is part of the Library, the object code for the work may be a derivative work of the Library even though the source code is not. Whether this is true is especially significant if the work can be linked without the Library, or if the work is itself a library.  The threshold for this to be true is not precisely defined by law.
If such an object file uses only numerical parameters, data structure layouts and accessors, and small macros and small inline functions (ten lines or less in length), then the use of the object file is unrestricted, regardless of whether it is legally a derivative work.  (Executables containing this object code plus portions of the Library will still fall under Section 6.)
Otherwise, if the work is a derivative of the Library, you may distribute the object code for the work under the terms of Section 6. Any executables containing that work also fall under Section 6, whether or not they are linked directly with the Library itself.
6. As an exception to the Sections above, you may also combine or link a "work that uses the Library" with the Library to produce a work containing portions of the Library, and distribute that work under terms of your choice, provided that the terms permit modification of the work for the customer's own use and reverse engineering for debugging such modifications.
You must give prominent notice with each copy of the work that the Library is used in it and that the Library and its use are covered by this License.  You must supply a copy of this License.  If the work during execution displays copyright notices, you must include the copyright notice for the Library among them, as well as a reference directing the user to the copy of this License.  Also, you must do one of these things:
a) Accompany the work with the complete corresponding     machine-readable source code for the Library including whatever     changes were used in the work (which must be distributed under     Sections 1 and 2 above); and, if the work is an executable linked     with the Library, with the complete machine-readable "work that     uses the Library", as object code and/or source code, so that the     user can modify the Library and then relink to produce a modified     executable containing the modified Library.  (It is understood     that the user who changes the contents of definitions files in the     Library will not necessarily be able to recompile the application     to use the modified definitions.)
b) Use a suitable shared library mechanism for linking with the     Library.  A suitable mechanism is one that (1) uses at run time a     copy of the library already present on the user's computer system,     rather than copying library functions into the executable, and (2)     will operate properly with a modified version of the library, if     the user installs one, as long as the modified version is     interface-compatible with the version that the work was made with.
c) Accompany the work with a written offer, valid for at     least three years, to give the same user the materials     specified in Subsection 6a, above, for a charge no more     than the cost of performing this distribution.
d) If distribution of the work is made by offering access to copy     from a designated place, offer equivalent access to copy the above     specified materials from the same place.
e) Verify that the user has already received a copy of these     materials or that you have already sent this user a copy.
For an executable, the required form of the "work that uses the Library" must include any data and utility programs needed for reproducing the executable from it.  However, as a special exception, the materials to be distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.
It may happen that this requirement contradicts the license restrictions of other proprietary libraries that do not normally accompany the operating system.  Such a contradiction means you cannot use both them and the Library together in an executable that you distribute.
7. You may place library facilities that are a work based on the Library side-by-side in a single library together with other library facilities not covered by this License, and distribute such a combined library, provided that the separate distribution of the work based on the Library and of the other library facilities is otherwise permitted, and provided that you do these two things:
a) Accompany the combined library with a copy of the same work     based on the Library, uncombined with any other library     facilities.  This must be distributed under the terms of the     Sections above.
b) Give prominent notice with the combined library of the fact     that part of it is a work based on the Library, and explaining     where to find the accompanying uncombined form of the same work.
8. You may not copy, modify, sublicense, link with, or distribute the Library except as expressly provided under this License.  Any attempt otherwise to copy, modify, sublicense, link with, or distribute the Library is void, and will automatically terminate your rights under this License.  However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.
9. You are not required to accept this License, since you have not signed it.  However, nothing else grants you permission to modify or distribute the Library or its derivative works.  These actions are prohibited by law if you do not accept this License.  Therefore, by modifying or distributing the Library (or any work based on the Library), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Library or works based on it.
10. Each time you redistribute the Library (or any work based on the Library), the recipient automatically receives a license from the original licensor to copy, distribute, link with or modify the Library subject to these terms and conditions.  You may not impose any further restrictions on the recipients' exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties with this License.
11. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License.  If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Library at all.  For example, if a patent license would not permit royalty-free redistribution of the Library by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Library.
If any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply, and the section as a whole is intended to apply in other circumstances.
It is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system which is implemented by public license practices.  Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice.
This section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.
12. If the distribution and/or use of the Library is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Library under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded.  In such case, this License incorporates the limitation as if written in the body of this License.
13. The Free Software Foundation may publish revised and/or new versions of the Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.
Each version is given a distinguishing version number.  If the Library specifies a version number of this License which applies to it and "any later version", you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation.  If the Library does not specify a license version number, you may choose any version ever published by the Free Software Foundation.
14. If you wish to incorporate parts of the Library into other free programs whose distribution conditions are incompatible with these, write to the author to ask for permission.  For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this.  Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.
NO WARRANTY
15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE LIBRARY "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE LIBRARY IS WITH YOU.  SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.
END OF TERMS AND CONDITIONS
How to Apply These Terms to Your New Libraries
If you develop a new library, and you want it to be of the greatest possible use to the public, we recommend making it free software that everyone can redistribute and change.  You can do so by permitting redistribution under these terms (or, alternatively, under the terms of the ordinary General Public License).
To apply these terms, attach the following notices to the library.  It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the "copyright" line and a pointer to where the full notice is found.
<one line to give the library's name and a brief idea of what it does.>     Copyright (C) <year>  <name of author>
This library is free software; you can redistribute it and/or     modify it under the terms of the GNU Lesser General Public     License as published by the Free Software Foundation; either     version 2.1 of the License, or (at your option) any later version.
This library is distributed in the hope that it will be useful,     but WITHOUT ANY WARRANTY; without even the implied warranty of     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU     Lesser General Public License for more details.
You should have received a copy of the GNU Lesser General Public     License along with this library; if not, write to the Free Software     Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
Also add information on how to contact you by electronic and paper mail.
You should also get your employer (if you work as a programmer) or your school, if any, to sign a "copyright disclaimer" for the library, if necessary.  Here is a sample; alter the names:
Yoyodyne, Inc., hereby disclaims all copyright interest in the   library `Frob' (a library for tweaking knobs) written by James Random Hacker.
<signature of Ty Coon>, 1 April 1990   Ty Coon, President of Vice
That's all there is to it!
</pre>
Copyright (c) 2009-2013, Attila Szegedi
All rights reserved.Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Attila Szegedi nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THEPOSSIBILITY OF SUCH DAMAGE.
</pre>
Copyright (c) 2002-2006, Marc Prud'hommeaux <mwp1@cornell.edu> All rights reserved.
Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
Neither the name of JLine nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre>
Copyright (c) 2004-2015 Paul R. Holser, Jr.
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
******************************************
The jQuery JavaScript Library v1.10.2 also includes Sizzle.js
Sizzle.js includes the following license:
Copyright JS Foundation and other contributors, https://js.foundation/
This software consists of voluntary contributions made by many individuals. For exact contribution history, see the revision history available at https://github.com/jquery/sizzle
The following license applies to all parts of this software except as documented below:
====
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
====
All files located in the node_modules and external directories are externally maintained libraries used by this software which have their own licenses; we recommend you read them, as their terms may differ from the terms above.
*********************
</pre>
Copyright (c) 2009-2014 Stuart Knightley, David Duponchel, Franz Buchinger, Antnio Afonso
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. (C) 1995-2013 Jean-loup Gailly and Mark Adler (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software.
Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions:
1. The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required. 2. Altered source versions must be plainly marked as such, and must not be  misrepresented as being the original software. 3. This notice may not be removed or altered from any source distribution.
</pre>

Copyright (C) 1982 The Royal Institute, Thai Royal Government.
Copyright (C) 1998 National Electronics and Computer Technology Center, National Science and Technology Development Agency, Ministry of Science Technology and Environment, Thai Royal Government.
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
https://raw.githubusercontent.com/google/double-conversion/master/LICENSE
<pre>
Copyright 2006-2011, the V8 project authors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
* Redistributions of source code must retain the above copyright   notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above   copyright notice, this list of conditions and the following   disclaimer in the documentation and/or other materials provided   with the distribution. * Neither the name of Google Inc. nor the names of its   contributors may be used to endorse or promote products derived   from this software without specific prior written permission.
THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre>
Jruby 2012
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
The names "The freebXML Registry Project" and "freebxml Software Foundation" must not be  used to endorse or promote products derived from this software or be used in a product  name without prior written permission. For written permission,  please contact ebxmlrr-team@lists.sourceforge.net.
This software consists of voluntary contributions made by many individuals on behalf of  the the freebxml Software Foundation. For more information on the freebxml Software  Foundation, please see <http://www.freebxml.org/>.
This product includes software developed by the Apache Software Foundation  (http://www.apache.org/).
The freebxml License, Version 1.1 5 Copyright (c) 2001 freebxml.org. All rights reserved.
Redistribution and use in source and binary forms, with or without modification, are  permitted provided that the following conditions are met:
1. Redistributions of source code must retain the above copyright notice, this list of  conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright notice, this list  of conditions and the following disclaimer in the documentation and/or other materials  provided with the distribution.
3. The end-user documentation included with the redistribution, if any, must include the  following acknowlegement:
"This product includes software developed by freebxml.org (http://www.freebxml.org/)."
Alternately, this acknowlegement may appear in the software itself, if and wherever  such third-party acknowlegements normally appear.
4. The names "The freebXML Registry Project", "freebxml Software Foundation" must not be  used to endorse or promote products derived from this software without prior written  permission. For written permission, please contact ebxmlrr-team@lists.sourceforge.net.
5. Products derived from this software may not be called "freebxml", "freebXML Registry"  nor may freebxml" appear in their names without prior written permission of the  freebxml Group.
THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING,  BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A  PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE freebxml SOFTWARE FOUNDATION OR  ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON  ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF  ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre>
Copyright (c) 2005, 2010 Thai Open Source Software Center Ltd All rights reserved.
Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
Redistributions of source code must retain the above copyright     notice, this list of conditions and the following disclaimer.
Redistributions in binary form must reproduce the above copyright     notice, this list of conditions and the following disclaimer in     the documentation and/or other materials provided with the     distribution.
Neither the names of the copyright holders nor the names of its     contributors may be used to endorse or promote products derived     from this software without specific prior written permission.
THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
</pre>
Copyright (c) 2004-2012 RELAXNG
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</pre>
1. Fork the repo and create your branch from `master`. 2. If you've added code that should be tested, add tests. 3. If you've changed APIs, update the documentation. 4. Ensure the test suite passes. 5. Make sure your code lints. 6. If you haven't already, complete the Contributor License Agreement ("CLA").
Complete your CLA here: <https://code.facebook.com/cla>
Facebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe disclosure of security bugs. In those cases, please go through the process outlined on that page and do not file a public issue.
[![Build Status](https://travis-ci.org/facebookincubator/gloo.svg?branch=master)](https://travis-ci.org/facebookincubator/gloo)
Gloo is a collective communications library. It comes with a number of collective algorithms useful for machine learning applications. These include a barrier, broadcast, and allreduce.
Transport of data between participating machines is abstracted so that IP can be used at all times, or InifiniBand (or RoCE) when available. In the latter case, if the InfiniBand transport is used, [GPUDirect][gpudirect] can be used to accelerate cross machine GPU-to-GPU memory transfers.
[gpudirect]: https://developer.nvidia.com/gpudirect
Where applicable, algorithms have an implementation that works with system memory buffers, and one that works with NVIDIA GPU memory buffers. In the latter case, it is not necessary to copy memory between host and device; this is taken care of by the algorithm implementations.
Gloo is built to run on Linux and has no hard dependencies other than libstdc++. That said, it will generally only be useful when used in combination with a few optional dependencies below.
Optional dependencies are: * [CUDA][cuda] and [NCCL][nccl] -- for CUDA aware algorithms, tests, and benchmark * [Google Test][gtest] -- to build and run tests * [Eigen][eigen] -- for fast floating point routines * [Hiredis][hiredis] -- for coordinating machine rendezvous through Redis * [MPI][mpi] -- for coordinating machine rendezvous through MPI
[cuda]: http://www.nvidia.com/object/cuda_home_new.html [nccl]: https://github.com/nvidia/nccl [gtest]: https://github.com/google/googletest [eigen]: http://eigen.tuxfamily.org [hiredis]: https://github.com/redis/hiredis [mpi]: https://www.open-mpi.org/
Please refer to [docs/](docs/) for detailed documentation.
You can build Gloo using CMake.
Since it is a library, it is most convenient to vendor it in your own project and include the project root in your own CMake configuration.
For standalone builds (e.g. to run tests or benchmarks), first check out the submodules in `third-party` by running:
```shell git submodule update --init ```
Also install the dependencies required by the benchmark tool. On Ubuntu, you can do so by running:
``` shell sudo apt-get install -y libhiredis-dev libeigen3-dev ```
Then, to build:
``` shell mkdir build cd build cmake ../ -DBUILD_TEST=1 -DBUILD_BENCHMARK=1 ls -l gloo/{test,benchmark}/{test,benchmark} ```
The benchmark tool depends on 1) Eigen for floating point math and 2) Redis/Hiredis for rendezvous. The benchmark tool for CUDA algorithms obviously also depends on both CUDA and NCCL.
To run a benchmark:
1. Copy the benchmark tool to all participating machines
2. Start a Redis server on any host (either a client machine or one of    the machines participating in the test). Note that Redis Cluster is **not** supported.
3. Determine some unique ID for the benchmark run (e.g. the `uuid`    tool or some number).
4. On each machine, run (or pass `--help` for more options):
```     ./benchmark \       --size <number of machines> \       --rank <index of this machine, starting at 0> \       --redis-host <Redis host> \       --redis-port <Redis port> \       --prefix <unique identifier for this run> \       --transport tcp \       --elements <number of elements; -1 for a sweep> \       --iteration-time 1s \       allreduce_ring_chunked     ```
Example output (running on 4 machines with a 40GbE network):
``` text    elements   min (us)   p50 (us)   p99 (us)   max (us)    samples           1        195        263        342        437       3921           2        195        261        346        462       4039           5        197        261        339        402       3963          10        197        263        338        398       3749          20        199        268        343        395       4146          50        200        265        344        401       3889         100        205        265        351        414       3645         200        197        264        328        387       3960         500        201        264        329        394       4274        1000        200        267        330        380       3344        2000        205        263        323        395       3682        5000        240        335        424        460       3277       10000        271        346        402        457       2721       20000        283        358        392        428       2719       50000        342        438        495        649       1654      100000        413        487        669        799       1687      200000       1113       1450       1837       2801        669      500000       1099       1294       1665       1959        560     1000000       1858       2286       2779       6100        320     2000000       3546       3993       4364       4886        252     5000000      10030      10608      11106      11628         92 ```
Gloo is BSD-licensed. We also provide an additional patent grant.
Index of algorithms provided by Gloo and their semantics.
Variables used: * **P**: Number of processes/machines * **N**: Number of buffers per process * **S**: Size of buffer
Terms used: * **Communication steps**: number of communication steps. Every   communication step has some latency, depending on the transport.   Therefore, the fewer steps an algorithm uses, the better it is   suited towards higher latency transports. Lower latency transports   better tolerate more communication steps. * **Bytes on the wire**: total number of bytes transmitted per   participating process. The higher this number, the sooner an   algorithm will be bound by the network bandwidth.
Compute sum of N arrays per process across P processes. This computation happens in place; all input arrays contain the resulting sum after the algorithm completes.
There are 3 phases to each implementation of this algorithm: 1. Local reduction of N buffers 2. Allreduce between processes 3. Broadcast result back to N buffers
* Communication steps: P-1 * Bytes on the wire: P\*S
Phase 2 is implemented as follows: 1. Transmit local result to right side neighbor 2. Receive buffer from left side neighbor and reduce into local result 3. Transmit incoming buffer to right side neighbor 4. Repeat 2-3 until process has seen all data
* Communication steps: 4\*P * Bytes on the wire: 2\*S
Phase 2 is implemented in 2 sub-phases: 1. First, the algorithm iterates over the local reduction,    transmitting chunks of the buffer and reducing at every step. The    number of chunks is equal to 2\*P, allowing double buffering to be    used. This means there is always one chunk in flight while    reduction is done on another chunk concurrently. At the end of this    phase, every process P holds 1/P of the reduced result. 2. Second, the algorithm iterates over the local reduction again, now    broadcasting the local results.
With 2\*P chunks and two sub-phases, we arrive at 4\*P communication steps.
These sub-phases are implemented as followed (roughly):
First: 1. Compute offset into local reduction buffer based on process rank 2. Transmit chunk at offset to right side neighbor 3. Receive chunk at offset-1 from left side neighbor and reduce into    local result 4. Subtract 1 from offset, wrapping when needed 5. Repeat 2-4 until process has walked entire buffer
Second: 1. Transmit chunk at offset+1 (containing the global reduction) to    right side neighbor 2. Receive chunk at offset from left side neighbor and copy into local    result 3. Subtract 1 from offset, wrapping when needed 4. Repeat 1-3 until process has walked entire buffer
* Communication steps: 2\*lg(P) * Bytes on the wire: 2\*S
Phase 2 is implemented in two sub-phases:
1. First, a reduce-scatter is performed in lg(P) steps using a recursive vector-halving, distance-doubling approach. In the first step of this algorithm processes communicate in pairs (rank 0 with 1, 2 with 3, etc.), sending and receiving for different halves of their input buffer. For example, process 0 sends the second half of its buffer to process 1 and receives and reduces data for the first half of the buffer from process 1. A reduction over the received data is performed before proceeding to the next communication step, where the distance to the destination rank is doubled while the data sent and received is halved. After the reduce-scatter phase is finished, each process has a portion of the final reduced array.
2. The second sub-phase of Phase 2 performs an allgather. This is again done using a recursive algorithm, retracing the communication steps from the reduce-scatter in reverse, but this time simply concatenating the received data at each step. At each process and step, the portion of the buffer that was being sent in the reduce-scatter is received in the allgather, and the portion that was being received in the reduce-scatter is now sent.
Across the steps of the reduce-scatter, data is received into different buffers and there is no potential for race conditions. However, mirrored steps of the reduce-scatter and allgather (e.g. last step of the reduce-scatter and first step of the allgather) write into the same buffers. To prevent race conditions, a notification is sent after data is processed in the reduce-scatter subphase. This notification is processed in the allgather subphase prior to performing the send. In the majority of cases these notification messages will arrive long before the step of the allgather where they are processed, so their effect on performance should be minimal.
When running on non-power-of-two number of processes, the algorithm works by breaking up execution into blocks that are powers of two and communicating interblock after the intrablock reduce-scatter. Non-power-of-two cases will have some degree of load imbalance compared to power-of-two, but cases with few large blocks (e.g. 8 + 4 or 16 + 8) should still perform relatively well.
The halving-doubling / binary-blocks algorithm is described and analyzed in (Thakur et al., Optimization of Collective Communication Operations in MPICH, IJHPCA, 2005).
Additional variables used: * **B**: Base (maximum number of peers per step)
* Communication steps: 2\*log_B(P) * Bytes on the wire: 2\*Sum(S/B^s) {s: 0 to log_B(P) - 1}
This is another allreduce implementation. Bcube is a scheme where nodes are divided in groups. In reduce-scatter stage, in each group, a node peers with `base - 1` other nodes. In the first step data is reduced between nodes within the group. In the next step each node of a group peers with `base - 1` nodes from other exclusively different groups. Since each node would start with reduced data communicating with it would be like communicating with `base` number of nodes/groups from the previous step. This process continues until all the groups are covered and to be able to do that the algorithm would have log_base(n) number of steps. Each step the node reduces totalNumElems / (base^step) amount of elements. At the end of reduce-scatter stage each node would have reduced a chunk of elements. Now, in all-gather we follow a reverse process of reduce-scatter to communicate the reduced data with other nodes.
CUDA-aware implementation of `allreduce_ring`. GPU side buffers are copied to system memory in parallel, prior to running local reduction on CPU. After phase 2 completes, CPU side result is copied back to GPU side buffers in parallel.
CUDA-aware implementation of `allreduce_ring_chunked`. GPU side buffers are reduced into GPU buffer 0 (using NCCL). The result is copied to system memory asynchronously. After phase 2 completes, the CPU side result is copied back to GPU buffer 0, and then broadcast to other GPU buffers in parallel (using NCCL).
Both local reduction in phase 1 and broadcast in phase 3 is pipelined with the communication steps where this data is needed or becomes available.
CUDA-aware implementation of `allreduce_halving_doubling` with no pipelining between reduction/broadcast steps and the communication.
CUDA-aware implementation of `allreduce_halving_doubling` with pipelining between local reduction/broadcast steps and communication. Local reduction step is split into two steps (since the first communication step sends half the buffer size). Final broadcast is pipelined across lgP steps, with each step corresponding to a receive during the allgather phase.
Synchronization point between processes.
* Communication steps: 1 * Bytes on the wire: P
Every process sends a notification to every other process. Then, it waits for a notification from every other process.
* Communication steps: 2 * Bytes on the wire: 1 for non-root, P for root
_Non-root processes_: send notification to root, wait for notification from root.
_Root process_: wait for notification from P-1 processes, send notification to P-1 processes.
Broadcast contents of buffer on one process to other P-1 processes.
* Communication steps: 1 * Bytes on the wire: P\*S
_Non-root processes_: receive buffer from root.
_Root process_: send buffer to P-1 processes.
* Communication steps: variable * Bytes on the wire: S
A communication pattern similar to the halving-doubling reduce-scatter, simplified for benchmarking purposes. The number of communication steps, C (which must be between 1 and lg(P)) is specified as input to the algorithm. In each step, the set of nodes is partitioned into pairs as in the corresponding step of halving-doubling reduce-scatter. Unlike the reduce-scatter, however, the buffer size sent in each step is the same (equal to S/C).
GPU-aware algorithms require CUDA 7 or newer for various CUDA and NCCL features.
If no `cudaStream_t`(s) are passed to the gloo collective function, GPU buffer outputs are valid when the gloo collective function returns. Otherwise, the calling code must synchronize with the streams before using the GPU buffer outputs, i.e., explicitly with `cudaStreamSynchronize()` or inserting dependent operations in the stream.
See CUDA documentation for additional information about using streams.
```cpp void broadcastZeros(     std::shared_ptr<::gloo::Context>& context,     int rank,     float* devicePtr,     size_t count) {   // Allocate a stream to serialize GPU device operations   cudaStream_t stream;   cudaStreamCreate(&stream);
// Zero local GPU device buffer asynchronously   cudaMemsetAsync(devicePtr, 0, count, stream);
// Broadcast the buffer to participating machines   gloo::CudaBroadcastOneToAll<float> broadcast(     context, devicePtr, count, rank, stream);   broadcast.run();
// Wait until the broadcast is complete   cudaStreamSynchronize(stream);
cudaStreamDestroy(stream); } ```
```cpp // Define a mutex to synchronize calls to cudaMalloc/cudaFree std::mutex m;
// Share the mutex with gloo gloo::CudaShared::setMutex(&m);
// Always call cudaMalloc/cudaFree while holding the mutex void* allocateCudaMemory(size_t bytes) {   std::lock_guard<std::mutex> lock(m);   void* ptr;   cudaMalloc(&ptr, bytes);   return ptr; } ```
For `::gloo::IoException` specifically, the caller should assume the transport layer is in an unknown state and recreate the transport [pairs](../gloo/transport/pair.h) or containing collective algorithm instance.
Exceptions are defined in [`error.h`](../gloo/common/error.h) and should extend `::gloo::Exception`.
These tips apply to Linux.
The process calling into Gloo algorithms should ideally be pinned to a single NUMA node. If it isn't, the scheduler can decide to move back and forth between nodes, which typically hurts performance.
With different NUMA nodes representing different PCIe root complexes, make sure that the NUMA node you run on is the same one that the NIC you use is connected to. Requiring transfers from and to the NIC to traverse root complexes means introducing additional latency and unnecessary inter-processor communication.
It is not enough to only pin the process to a particular NUMA node (e.g. using `numactl(8)`). The NIC being used needs to have ALL its interrupts pinned to this NUMA node as well. You can verify this by looking at `/proc/interrupts` and configure this through `/proc/irq/${IRQ}/smp_affinity`. See the [documentation on SMP IRQ affinity][100] for more information.
[100]: https://www.kernel.org/doc/Documentation/IRQ-affinity.txt
In no particular order:
Make sure it is enabled if your NIC supports it. For high bandwidth NICs, this is absolutely necessary to achieve line rate on a single connection (some anecdotal evidence: 10Gb/s without TSO at 100% CPU usage versus 40Gb/s (line rate) with TSO at 30% CPU usage).
``` # ethtool -k eth0 | grep segmentation tcp-segmentation-offload: on         tx-tcp-segmentation: on         tx-tcp6-segmentation: on ```
Uses valuable kernel cycles and not needed in network environments where Gloo is typically used (low latency, packet drop extremely rare). ER and TLP are configured using the same sysctl and both can be disabled.
``` echo 0 > /proc/sys/net/ipv4/tcp_early_retrans ```
For more information, see [`ip-sysctl.txt`][200] (see `tcp_early_retrans`).
[200]: https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt
Documentation is split by domain. This file contains a general overview of these domains and how they interact.
* [Overview](readme.md) -- this file
* [Rendezvous](rendezvous.md) -- creating a `gloo::Context`    * [Algorithms](algorithms.md) -- index of collective algorithms   and their semantics and complexity
* [Transport details](transport.md) -- the transport API and its   implementations
* [CUDA integration](cuda.md) -- integration of CUDA aware Gloo   algorithms with existing CUDA code
* [Latency optimization](latency.md) -- number of tips and tricks to   improve performance
Gloo algorithms are collective algorithms, meaning they can run in parallel across two or more processes/machines. To be able to execute across multiple machines, they first need to find each other. We call this _rendezvous_ and it is the first thing to address when integrating Gloo into your code base. See [`rendezvous.md`](./rendezvous.md) for more information.
Once rendezvous completes, participating machines have setup connections to one another, either in a full mesh (every machine has a bidirectional communication channel to every other machine), or some subset. The required connectivity between machines depends on the type of algorithm that is used. For example, a ring algorithm only needs communication channels to a machine's neighbors.
Every participating process knows about the number of participating processes, and its _rank_ (or 0-based index) within the list of participating processes. This state, as well as the state needed to store the persistent communication channels, is stored in a `gloo::Context` class. Gloo does not maintain global state or thread-local state. This means that you can setup as many contexts as needed, and introduce as much parallelism as needed by your application.
If you find particular documentation is missing, please consider [contributing](../CONTRIBUTING.md).
The rendezvous process needs to happen exactly once per Gloo context. It makes participating Gloo processes exchange details for setting up their communication channels. For example, when the TCP transport is used, processes exchange IP address and port number details of listening sockets.
For example:
```c++ // Initialize context auto myRank = 0;  // Rank of this process within list of participating processes auto contextSize = 2;  // Number of participating processes gloo::rendezvous::Context context(myRank, contextSize);
// Perform rendezvous for TCP pairs auto dev = gloo::transport::tcp::CreateDevice(); gloo::rendezvous::RedisStore redis("redishost"); context.connectFullMesh(redis, dev); ```
Rendezvous can be executed by accessing a key/value store that is accessible by all participating processes. Every process is responsible for setting a number of keys and will wait until their peers have set their keys. The values stored against these keys hold the information that is passed to the transport layer.
This interface is defined in [`store.h`](../gloo/rendezvous/store.h).
The [HashStore](../gloo/rendezvous/hash_store.cc) is an in-process implementation of this interface. This is realistically not useful in any application but integration tests.
The [FileStore](../gloo/rendezvous/file_store.cc) is a simple file system based implementation of this interface. The primary use case is multi-process testing, but it may be useful in other scenarios with a shared file system.
The [RedisStore](../gloo/rendezvous/redis_store.cc) implementation uses the Hiredis library to set/get values against a Redis server. This server needs to be accessible to all participating machines.
Since the keys used by the Redis implementation are accessible to any process using that server -- which would prevent usage for concurrent rendezvous execution -- the [PrefixStore](../gloo/rendezvous/prefix_store.cc) can be used to scope rendezvous to a particular namespace.
There are many more key/value stores that can be used for rendezvous (e.g. [etcd](https://coreos.com/etcd) or [ZooKeeper](https://zookeeper.apache.org/)). As long as a C or C++ interface for your store of choice is available, is relatively easy to hook it up to the Gloo rendezvous process. See the `gloo::rendezvous::Store` abstract base class for the interface to implement.
If you are already using MPI to run jobs across machines, getting started with Gloo should be straightforward. Instead of using a separate key/value store for rendezvous, the existing MPI communicator is used to create contexts. Make sure to compile Gloo with `USE_MPI=ON`.
Note that Gloo does **NOT** use MPI for anything after a context has been created.
[![Build Status](https://travis-ci.org/google/googletest.svg?branch=master)](https://travis-ci.org/google/googletest) [![Build status](https://ci.appveyor.com/api/projects/status/4o38plt0xbo1ubc8/branch/master?svg=true)](https://ci.appveyor.com/project/BillyDonahue/googletest/branch/master)
Welcome to **Google Test**, Google's C++ test framework!
This repository is a merger of the formerly separate GoogleTest and GoogleMock projects. These were so closely related that it makes sense to maintain and release them together.
Please see the project page above for more information as well as the mailing list for questions, discussions, and development.  There is also an IRC channel on OFTC (irc.oftc.net) #gtest available.  Please join us!
Getting started information for **Google Test** is available in the  [Google Test Primer](googletest/docs/Primer.md) documentation.
**Google Mock** is an extension to Google Test for writing and using C++ mock classes.  See the separate [Google Mock documentation](googlemock/README.md).
More detailed documentation for googletest (including build instructions) are in its interior [googletest/README.md](googletest/README.md) file.
* An [XUnit](https://en.wikipedia.org/wiki/XUnit) test framework.   * Test discovery.   * A rich set of assertions.   * User-defined assertions.   * Death tests.   * Fatal and non-fatal failures.   * Value-parameterized tests.   * Type-parameterized tests.   * Various options for running the tests.   * XML test report generation.
Google test has been used on a variety of platforms:
* Linux   * Mac OS X   * Windows   * Cygwin   * MinGW   * Windows Mobile   * Symbian
In addition to many internal projects at Google, Google Test is also used by the following notable projects:
* The [Chromium projects](http://www.chromium.org/) (behind the Chrome     browser and Chrome OS).   * The [LLVM](http://llvm.org/) compiler.   * [Protocol Buffers](https://github.com/google/protobuf), Google's data     interchange format.   * The [OpenCV](http://opencv.org/) computer vision library.
[Google Test UI](https://github.com/ospector/gtest-gbar) is test runner that runs your test binary, allows you to track its progress via a progress bar, and displays a list of test failures. Clicking on one shows failure text. Google Test UI is written in C#.
[GTest TAP Listener](https://github.com/kinow/gtest-tap-listener) is an event listener for Google Test that implements the [TAP protocol](https://en.wikipedia.org/wiki/Test_Anything_Protocol) for test result output. If your test runner understands TAP, you may find it useful.
Google Test is designed to have fairly minimal requirements to build and use with your projects, but there are some.  Currently, we support Linux, Windows, Mac OS X, and Cygwin.  We will also make our best effort to support other platforms (e.g. Solaris, AIX, and z/OS). However, since core members of the Google Test project have no access to these platforms, Google Test may have outstanding issues there.  If you notice any problems on your platform, please notify <googletestframework@googlegroups.com>. Patches for fixing them are even more welcome!
These are the base requirements to build and use Google Test from a source package (as described below):
* GNU-compatible Make or gmake   * POSIX-standard shell   * POSIX(-2) Regular Expressions (regex.h)   * A C++98-standard-compliant compiler
* Microsoft Visual C++ v7.1 or newer
* Cygwin v1.5.25-14 or newer
* Mac OS X v10.4 Tiger or newer   * Xcode Developer Tools
We welcome patches.  If you plan to contribute a patch, you need to build Google Test and its own tests from a git checkout (described below), which has further requirements:
* [Python](https://www.python.org/) v2.3 or newer (for running some of     the tests and re-generating certain source files from templates)   * [CMake](https://cmake.org/) v2.6.4 or newer
Some of Google Test's source files are generated from templates (not in the C++ sense) using a script. For example, the file include/gtest/internal/gtest-type-util.h.pump is used to generate gtest-type-util.h in the same directory.
You don't need to worry about regenerating the source files unless you need to modify them.  You would then modify the corresponding `.pump` files and run the '[pump.py](googletest/scripts/pump.py)' generator script.  See the [Pump Manual](googletest/docs/PumpManual.md).
We welcome patches.  Please read the [Developer's Guide](googletest/docs/DevGuide.md) for how you can contribute. In particular, make sure you have signed the Contributor License Agreement, or we won't be able to accept the patch.
Happy testing!
The Google C++ mocking framework.
Google's framework for writing and using C++ mock classes. It can help you derive better designs of your system and write better tests.
It is inspired by:
* [jMock](http://www.jmock.org/),   * [EasyMock](http://www.easymock.org/), and   * [Hamcrest](http://code.google.com/p/hamcrest/),
and designed with C++'s specifics in mind.
Google mock:
* lets you create mock classes trivially using simple macros.   * supports a rich set of matchers and actions.   * handles unordered, partially ordered, or completely ordered expectations.   * is extensible by users.
We hope you find it useful!
* Provides a declarative syntax for defining mocks.   * Can easily define partial (hybrid) mocks, which are a cross of real     and mock objects.   * Handles functions of arbitrary types and overloaded functions.   * Comes with a rich set of matchers for validating function arguments.   * Uses an intuitive syntax for controlling the behavior of a mock.   * Does automatic verification of expectations (no record-and-replay needed).   * Allows arbitrary (partial) ordering constraints on     function calls to be expressed,.   * Lets a user extend it by defining new matchers and actions.   * Does not use exceptions.   * Is easy to learn and use.
Please see the project page above for more information as well as the mailing list for questions, discussions, and development.  There is also an IRC channel on OFTC (irc.oftc.net) #gtest available.  Please join us!
Please note that code under [scripts/generator](scripts/generator/) is from [cppclean](http://code.google.com/p/cppclean/) and released under the Apache License, which is different from Google Mock's license.
If you are new to the project, we suggest that you read the user documentation in the following order:
* Learn the [basics](../googletest/docs/Primer.md) of     Google Test, if you choose to use Google Mock with it (recommended).   * Read [Google Mock for Dummies](docs/ForDummies.md).   * Read the instructions below on how to build Google Mock.
You can also watch Zhanyong's [talk](http://www.youtube.com/watch?v=sYpCyLI47rM) on Google Mock's usage and implementation.
Once you understand the basics, check out the rest of the docs:
* [CheatSheet](docs/CheatSheet.md) - all the commonly used stuff     at a glance.   * [CookBook](docs/CookBook.md) - recipes for getting things done,     including advanced techniques.
If you need help, please check the [KnownIssues](docs/KnownIssues.md) and [FrequentlyAskedQuestions](docs/FrequentlyAskedQuestions.md) before posting a question on the [discussion group](http://groups.google.com/group/googlemock).
Google Mock is not a testing framework itself.  Instead, it needs a testing framework for writing tests.  Google Mock works seamlessly with [Google Test](http://code.google.com/p/googletest/), but you can also use it with [any C++ testing framework](googlemock/ForDummies.md#Using_Google_Mock_with_Any_Testing_Framework).
Google Mock is implemented on top of [Google Test]( http://github.com/google/googletest/), and depends on it. You must use the bundled version of Google Test when using Google Mock.
You can also easily configure Google Mock to work with another testing framework, although it will still need Google Test.  Please read ["Using_Google_Mock_with_Any_Testing_Framework"](     docs/ForDummies.md#Using_Google_Mock_with_Any_Testing_Framework) for instructions.
Google Mock depends on advanced C++ features and thus requires a more modern compiler. The following are needed to use Google Mock:
* GNU-compatible Make or "gmake"   * POSIX-standard shell   * POSIX(-2) Regular Expressions (regex.h)   * C++98-standard-compliant compiler (e.g. GCC 3.4 or newer)
* Microsoft Visual C++ 8.0 SP1 or newer
* Mac OS X 10.4 Tiger or newer   * Developer Tools Installed
We welcome patches. If you plan to contribute a patch, you need to build Google Mock and its tests, which has further requirements:
* Automake version 1.9 or newer   * Autoconf version 2.59 or newer   * Libtool / Libtoolize   * Python version 2.3 or newer (for running some of the tests and     re-generating certain source files from templates)
If you are using a Unix system and plan to use the GNU Autotools build system to build Google Mock (described below), you'll need to configure it now.
To prepare the Autotools build system:
cd googlemock     autoreconf -fvi
To build Google Mock and your tests that use it, you need to tell your build system where to find its headers and source files.  The exact way to do it depends on which build system you use, and is usually straightforward.
This section shows how you can integrate Google Mock into your existing build system.
Suppose you put Google Mock in directory `${GMOCK_DIR}` and Google Test in `${GTEST_DIR}` (the latter is `${GMOCK_DIR}/gtest` by default).  To build Google Mock, create a library build target (or a project as called by Visual Studio and Xcode) to compile
${GTEST_DIR}/src/gtest-all.cc and ${GMOCK_DIR}/src/gmock-all.cc
with
${GTEST_DIR}/include and ${GMOCK_DIR}/include
in the system header search path, and
${GTEST_DIR} and ${GMOCK_DIR}
in the normal header search path.  Assuming a Linux-like system and gcc, something like the following will do:
g++ -isystem ${GTEST_DIR}/include -I${GTEST_DIR} \         -isystem ${GMOCK_DIR}/include -I${GMOCK_DIR} \         -pthread -c ${GTEST_DIR}/src/gtest-all.cc     g++ -isystem ${GTEST_DIR}/include -I${GTEST_DIR} \         -isystem ${GMOCK_DIR}/include -I${GMOCK_DIR} \         -pthread -c ${GMOCK_DIR}/src/gmock-all.cc     ar -rv libgmock.a gtest-all.o gmock-all.o
(We need -pthread as Google Test and Google Mock use threads.)
Next, you should compile your test source file with ${GTEST\_DIR}/include and ${GMOCK\_DIR}/include in the header search path, and link it with gmock and any other necessary libraries:
g++ -isystem ${GTEST_DIR}/include -isystem ${GMOCK_DIR}/include \         -pthread path/to/your_test.cc libgmock.a -o your_test
As an example, the make/ directory contains a Makefile that you can use to build Google Mock on systems where GNU make is available (e.g. Linux, Mac OS X, and Cygwin).  It doesn't try to build Google Mock's own tests.  Instead, it just builds the Google Mock library and a sample test.  You can use it as a starting point for your own build script.
If the default settings are correct for your environment, the following commands should succeed:
cd ${GMOCK_DIR}/make     make     ./gmock_test
If you see errors, try to tweak the contents of [make/Makefile](make/Makefile) to make them go away.
The msvc/2005 directory contains VC++ 2005 projects and the msvc/2010 directory contains VC++ 2010 projects for building Google Mock and selected tests.
Change to the appropriate directory and run "msbuild gmock.sln" to build the library and tests (or open the gmock.sln in the MSVC IDE). If you want to create your own project to use with Google Mock, you'll have to configure it to use the `gmock_config` propety sheet.  For that:
* Open the Property Manager window (View | Other Windows | Property Manager)  * Right-click on your project and select "Add Existing Property Sheet..."  * Navigate to `gmock_config.vsprops` or `gmock_config.props` and select it.  * In Project Properties | Configuration Properties | General | Additional    Include Directories, type <path to Google Mock>/include.
Google Mock can be used in diverse environments.  The default configuration may not work (or may not work well) out of the box in some environments.  However, you can easily tweak Google Mock by defining control macros on the compiler command line.  Generally, these macros are named like `GTEST_XYZ` and you define them to either 1 or 0 to enable or disable a certain feature.
We list the most frequently used macros below.  For a complete list, see file [${GTEST\_DIR}/include/gtest/internal/gtest-port.h]( ../googletest/include/gtest/internal/gtest-port.h).
Google Mock uses the C++ Technical Report 1 (TR1) tuple library heavily.  Unfortunately TR1 tuple is not yet widely available with all compilers.  The good news is that Google Test 1.4.0+ implements a subset of TR1 tuple that's enough for Google Mock's need.  Google Mock will automatically use that implementation when the compiler doesn't provide TR1 tuple.
Usually you don't need to care about which tuple library Google Test and Google Mock use.  However, if your project already uses TR1 tuple, you need to tell Google Test and Google Mock to use the same TR1 tuple library the rest of your project uses, or the two tuple implementations will clash.  To do that, add
-DGTEST_USE_OWN_TR1_TUPLE=0
to the compiler flags while compiling Google Test, Google Mock, and your tests.  If you want to force Google Test and Google Mock to use their own tuple library, just add
-DGTEST_USE_OWN_TR1_TUPLE=1
to the compiler flags instead.
If you want to use Boost's TR1 tuple library with Google Mock, please refer to the Boost website (http://www.boost.org/) for how to obtain it and set it up.
Google Mock is compact, so most users can build and link it as a static library for the simplicity.  Google Mock can be used as a DLL, but the same DLL must contain Google Test as well.  See [Google Test's README][gtest_readme] for instructions on how to set up necessary compiler settings.
Most of Google Test's control macros apply to Google Mock as well. Please see [Google Test's README][gtest_readme] for how to tweak them.
We strive to keep Google Mock releases backward compatible. Sometimes, though, we have to make some breaking changes for the users' long-term benefits.  This section describes what you'll need to do if you are upgrading from an earlier version of Google Mock.
You may need to explicitly enable or disable Google Test's own TR1 tuple library.  See the instructions in section "[Choosing a TR1 Tuple Library](../googletest/#choosing-a-tr1-tuple-library)".
On platforms where the pthread library is available, Google Test and Google Mock use it in order to be thread-safe.  For this to work, you may need to tweak your compiler and/or linker flags.  Please see the "[Multi-threaded Tests](../googletest#multi-threaded-tests )" section in file Google Test's README for what you may need to do.
If you have custom matchers defined using `MatcherInterface` or `MakePolymorphicMatcher()`, you'll need to update their definitions to use the new matcher API ( [monomorphic](http://code.google.com/p/googlemock/wiki/CookBook#Writing_New_Monomorphic_Matchers), [polymorphic](http://code.google.com/p/googlemock/wiki/CookBook#Writing_New_Polymorphic_Matchers)). Matchers defined using `MATCHER()` or `MATCHER_P*()` aren't affected.
This section discusses how to make your own changes to Google Mock.
To make sure your changes work as intended and don't break existing functionality, you'll want to compile and run Google Test's own tests. For that you'll need Autotools.  First, make sure you have followed the instructions above to configure Google Mock. Then, create a build output directory and enter it.  Next,
${GMOCK_DIR}/configure  # try --help for more info
Once you have successfully configured Google Mock, the build steps are standard for GNU-style OSS packages.
make        # Standard makefile following GNU conventions     make check  # Builds and runs all tests - all should pass.
Note that when building your project against Google Mock, you are building against Google Test as well.  There is no need to configure Google Test separately.
We welcome patches. Please read the [Developer's Guide](docs/DevGuide.md) for how you can contribute. In particular, make sure you have signed the Contributor License Agreement, or we won't be able to accept the patch.
Happy testing!
[gtest_readme]: ../googletest/README.md "googletest"

Given ``` class Foo {   ...   virtual ~Foo();   virtual int GetSize() const = 0;   virtual string Describe(const char* name) = 0;   virtual string Describe(int type) = 0;   virtual bool Process(Bar elem, int count) = 0; }; ``` (note that `~Foo()` **must** be virtual) we can define its mock as ``` #include "gmock/gmock.h"
class MockFoo : public Foo {   MOCK_CONST_METHOD0(GetSize, int());   MOCK_METHOD1(Describe, string(const char* name));   MOCK_METHOD1(Describe, string(int type));   MOCK_METHOD2(Process, bool(Bar elem, int count)); }; ```
To create a "nice" mock object which ignores all uninteresting calls, or a "strict" mock object, which treats them as failures: ``` NiceMock<MockFoo> nice_foo;     // The type is a subclass of MockFoo. StrictMock<MockFoo> strict_foo; // The type is a subclass of MockFoo. ```
To mock ``` template <typename Elem> class StackInterface {  public:   ...   virtual ~StackInterface();   virtual int GetSize() const = 0;   virtual void Push(const Elem& x) = 0; }; ``` (note that `~StackInterface()` **must** be virtual) just append `_T` to the `MOCK_*` macros: ``` template <typename Elem> class MockStack : public StackInterface<Elem> {  public:   ...   MOCK_CONST_METHOD0_T(GetSize, int());   MOCK_METHOD1_T(Push, void(const Elem& x)); }; ```
If your mock function doesn't use the default calling convention, you can specify it by appending `_WITH_CALLTYPE` to any of the macros described in the previous two sections and supplying the calling convention as the first argument to the macro. For example, ```   MOCK_METHOD_1_WITH_CALLTYPE(STDMETHODCALLTYPE, Foo, bool(int n));   MOCK_CONST_METHOD2_WITH_CALLTYPE(STDMETHODCALLTYPE, Bar, int(double x, double y)); ``` where `STDMETHODCALLTYPE` is defined by `<objbase.h>` on Windows.
The typical flow is:   1. Import the Google Mock names you need to use. All Google Mock names are in the `testing` namespace unless they are macros or otherwise noted.   1. Create the mock objects.   1. Optionally, set the default actions of the mock objects.   1. Set your expectations on the mock objects (How will they be called? What wil they do?).   1. Exercise code that uses the mock objects; if necessary, check the result using [Google Test](../../googletest/) assertions.   1. When a mock objects is destructed, Google Mock automatically verifies that all expectations on it have been satisfied.
Here is an example: ``` using ::testing::Return;                            // #1
TEST(BarTest, DoesThis) {   MockFoo foo;                                    // #2
ON_CALL(foo, GetSize())                         // #3       .WillByDefault(Return(1));   // ... other default actions ...
EXPECT_CALL(foo, Describe(5))                   // #4       .Times(3)       .WillRepeatedly(Return("Category 5"));   // ... other expectations ...
EXPECT_EQ("good", MyProductionFunction(&foo));  // #5 }                                                 // #6 ```
Google Mock has a **built-in default action** for any function that returns `void`, `bool`, a numeric value, or a pointer.
To customize the default action for functions with return type `T` globally: ``` using ::testing::DefaultValue;
// Sets the default value to be returned. T must be CopyConstructible. DefaultValue<T>::Set(value); // Sets a factory. Will be invoked on demand. T must be MoveConstructible. //   T MakeT(); DefaultValue<T>::SetFactory(&MakeT); // ... use the mocks ... // Resets the default value. DefaultValue<T>::Clear(); ```
To customize the default action for a particular method, use `ON_CALL()`: ``` ON_CALL(mock_object, method(matchers))     .With(multi_argument_matcher)  ?     .WillByDefault(action); ```
`EXPECT_CALL()` sets **expectations** on a mock method (How will it be called? What will it do?): ``` EXPECT_CALL(mock_object, method(matchers))     .With(multi_argument_matcher)  ?     .Times(cardinality)            ?     .InSequence(sequences)         *     .After(expectations)           *     .WillOnce(action)              *     .WillRepeatedly(action)        ?     .RetiresOnSaturation();        ? ```
If `Times()` is omitted, the cardinality is assumed to be:
* `Times(1)` when there is neither `WillOnce()` nor `WillRepeatedly()`;   * `Times(n)` when there are `n WillOnce()`s but no `WillRepeatedly()`, where `n` >= 1; or   * `Times(AtLeast(n))` when there are `n WillOnce()`s and a `WillRepeatedly()`, where `n` >= 0.
A method with no `EXPECT_CALL()` is free to be invoked _any number of times_, and the default action will be taken each time.
A **matcher** matches a _single_ argument.  You can use it inside `ON_CALL()` or `EXPECT_CALL()`, or use it to validate a value directly:
| `EXPECT_THAT(value, matcher)` | Asserts that `value` matches `matcher`. | |:------------------------------|:----------------------------------------| | `ASSERT_THAT(value, matcher)` | The same as `EXPECT_THAT(value, matcher)`, except that it generates a **fatal** failure. |
Built-in matchers (where `argument` is the function argument) are divided into several categories:
|`Eq(value)` or `value`|`argument == value`| |:---------------------|:------------------| |`Ge(value)`           |`argument >= value`| |`Gt(value)`           |`argument > value` | |`Le(value)`           |`argument <= value`| |`Lt(value)`           |`argument < value` | |`Ne(value)`           |`argument != value`| |`IsNull()`            |`argument` is a `NULL` pointer (raw or smart).| |`NotNull()`           |`argument` is a non-null pointer (raw or smart).| |`Ref(variable)`       |`argument` is a reference to `variable`.| |`TypedEq<type>(value)`|`argument` has type `type` and is equal to `value`. You may need to use this instead of `Eq(value)` when the mock function is overloaded.|
Except `Ref()`, these matchers make a _copy_ of `value` in case it's modified or destructed later. If the compiler complains that `value` doesn't have a public copy constructor, try wrap it in `ByRef()`, e.g. `Eq(ByRef(non_copyable_value))`. If you do that, make sure `non_copyable_value` is not changed afterwards, or the meaning of your matcher will be changed.
|`DoubleEq(a_double)`|`argument` is a `double` value approximately equal to `a_double`, treating two NaNs as unequal.| |:-------------------|:----------------------------------------------------------------------------------------------| |`FloatEq(a_float)`  |`argument` is a `float` value approximately equal to `a_float`, treating two NaNs as unequal.  | |`NanSensitiveDoubleEq(a_double)`|`argument` is a `double` value approximately equal to `a_double`, treating two NaNs as equal.  | |`NanSensitiveFloatEq(a_float)`|`argument` is a `float` value approximately equal to `a_float`, treating two NaNs as equal.    |
The above matchers use ULP-based comparison (the same as used in [Google Test](../../googletest/)). They automatically pick a reasonable error bound based on the absolute value of the expected value.  `DoubleEq()` and `FloatEq()` conform to the IEEE standard, which requires comparing two NaNs for equality to return false. The `NanSensitive*` version instead treats two NaNs as equal, which is often what a user wants.
|`DoubleNear(a_double, max_abs_error)`|`argument` is a `double` value close to `a_double` (absolute error <= `max_abs_error`), treating two NaNs as unequal.| |:------------------------------------|:--------------------------------------------------------------------------------------------------------------------| |`FloatNear(a_float, max_abs_error)`  |`argument` is a `float` value close to `a_float` (absolute error <= `max_abs_error`), treating two NaNs as unequal.  | |`NanSensitiveDoubleNear(a_double, max_abs_error)`|`argument` is a `double` value close to `a_double` (absolute error <= `max_abs_error`), treating two NaNs as equal.  | |`NanSensitiveFloatNear(a_float, max_abs_error)`|`argument` is a `float` value close to `a_float` (absolute error <= `max_abs_error`), treating two NaNs as equal.    |
The `argument` can be either a C string or a C++ string object:
|`ContainsRegex(string)`|`argument` matches the given regular expression.| |:----------------------|:-----------------------------------------------| |`EndsWith(suffix)`     |`argument` ends with string `suffix`.           | |`HasSubstr(string)`    |`argument` contains `string` as a sub-string.   | |`MatchesRegex(string)` |`argument` matches the given regular expression with the match starting at the first character and ending at the last character.| |`StartsWith(prefix)`   |`argument` starts with string `prefix`.         | |`StrCaseEq(string)`    |`argument` is equal to `string`, ignoring case. | |`StrCaseNe(string)`    |`argument` is not equal to `string`, ignoring case.| |`StrEq(string)`        |`argument` is equal to `string`.                | |`StrNe(string)`        |`argument` is not equal to `string`.            |
`ContainsRegex()` and `MatchesRegex()` use the regular expression syntax defined [here](../../googletest/docs/AdvancedGuide.md#regular-expression-syntax). `StrCaseEq()`, `StrCaseNe()`, `StrEq()`, and `StrNe()` work for wide strings as well.
Most STL-style containers support `==`, so you can use `Eq(expected_container)` or simply `expected_container` to match a container exactly.   If you want to write the elements in-line, match them more flexibly, or get more informative messages, you can use:
| `ContainerEq(container)` | The same as `Eq(container)` except that the failure message also includes which elements are in one container but not the other. | |:-------------------------|:---------------------------------------------------------------------------------------------------------------------------------| | `Contains(e)`            | `argument` contains an element that matches `e`, which can be either a value or a matcher.                                       | | `Each(e)`                | `argument` is a container where _every_ element matches `e`, which can be either a value or a matcher.                           | | `ElementsAre(e0, e1, ..., en)` | `argument` has `n + 1` elements, where the i-th element matches `ei`, which can be a value or a matcher. 0 to 10 arguments are allowed. | | `ElementsAreArray({ e0, e1, ..., en })`, `ElementsAreArray(array)`, or `ElementsAreArray(array, count)` | The same as `ElementsAre()` except that the expected element values/matchers come from an initializer list, STL-style container, or C-style array. | | `IsEmpty()`              | `argument` is an empty container (`container.empty()`).                                                                          | | `Pointwise(m, container)` | `argument` contains the same number of elements as in `container`, and for all i, (the i-th element in `argument`, the i-th element in `container`) match `m`, which is a matcher on 2-tuples. E.g. `Pointwise(Le(), upper_bounds)` verifies that each element in `argument` doesn't exceed the corresponding element in `upper_bounds`. See more detail below. | | `SizeIs(m)`              | `argument` is a container whose size matches `m`. E.g. `SizeIs(2)` or `SizeIs(Lt(2))`.                                           | | `UnorderedElementsAre(e0, e1, ..., en)` | `argument` has `n + 1` elements, and under some permutation each element matches an `ei` (for a different `i`), which can be a value or a matcher. 0 to 10 arguments are allowed. | | `UnorderedElementsAreArray({ e0, e1, ..., en })`, `UnorderedElementsAreArray(array)`, or `UnorderedElementsAreArray(array, count)` | The same as `UnorderedElementsAre()` except that the expected element values/matchers come from an initializer list, STL-style container, or C-style array. | | `WhenSorted(m)`          | When `argument` is sorted using the `<` operator, it matches container matcher `m`. E.g. `WhenSorted(UnorderedElementsAre(1, 2, 3))` verifies that `argument` contains elements `1`, `2`, and `3`, ignoring order. | | `WhenSortedBy(comparator, m)` | The same as `WhenSorted(m)`, except that the given comparator instead of `<` is used to sort `argument`. E.g. `WhenSortedBy(std::greater<int>(), ElementsAre(3, 2, 1))`. |
Notes:
* These matchers can also match:     1. a native array passed by reference (e.g. in `Foo(const int (&a)[5])`), and     1. an array passed as a pointer and a count (e.g. in `Bar(const T* buffer, int len)` -- see [Multi-argument Matchers](#Multiargument_Matchers.md)).   * The array being matched may be multi-dimensional (i.e. its elements can be arrays).   * `m` in `Pointwise(m, ...)` should be a matcher for `::testing::tuple<T, U>` where `T` and `U` are the element type of the actual container and the expected container, respectively. For example, to compare two `Foo` containers where `Foo` doesn't support `operator==` but has an `Equals()` method, one might write:
``` using ::testing::get; MATCHER(FooEq, "") {   return get<0>(arg).Equals(get<1>(arg)); } ... EXPECT_THAT(actual_foos, Pointwise(FooEq(), expected_foos)); ```
|`Field(&class::field, m)`|`argument.field` (or `argument->field` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_.| |:------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------| |`Key(e)`                 |`argument.first` matches `e`, which can be either a value or a matcher. E.g. `Contains(Key(Le(5)))` can verify that a `map` contains a key `<= 5`.| |`Pair(m1, m2)`           |`argument` is an `std::pair` whose `first` field matches `m1` and `second` field matches `m2`.                                                | |`Property(&class::property, m)`|`argument.property()` (or `argument->property()` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_.|
|`ResultOf(f, m)`|`f(argument)` matches matcher `m`, where `f` is a function or functor.| |:---------------|:---------------------------------------------------------------------|
|`Pointee(m)`|`argument` (either a smart pointer or a raw pointer) points to a value that matches matcher `m`.| |:-----------|:-----------------------------------------------------------------------------------------------| |`WhenDynamicCastTo<T>(m)`| when `argument` is passed through `dynamic_cast<T>()`, it matches matcher `m`.                 |
Technically, all matchers match a _single_ value. A "multi-argument" matcher is just one that matches a _tuple_. The following matchers can be used to match a tuple `(x, y)`:
|`Eq()`|`x == y`| |:-----|:-------| |`Ge()`|`x >= y`| |`Gt()`|`x > y` | |`Le()`|`x <= y`| |`Lt()`|`x < y` | |`Ne()`|`x != y`|
You can use the following selectors to pick a subset of the arguments (or reorder them) to participate in the matching:
|`AllArgs(m)`|Equivalent to `m`. Useful as syntactic sugar in `.With(AllArgs(m))`.| |:-----------|:-------------------------------------------------------------------| |`Args<N1, N2, ..., Nk>(m)`|The tuple of the `k` selected (using 0-based indices) arguments matches `m`, e.g. `Args<1, 2>(Eq())`.|
You can make a matcher from one or more other matchers:
|`AllOf(m1, m2, ..., mn)`|`argument` matches all of the matchers `m1` to `mn`.| |:-----------------------|:---------------------------------------------------| |`AnyOf(m1, m2, ..., mn)`|`argument` matches at least one of the matchers `m1` to `mn`.| |`Not(m)`                |`argument` doesn't match matcher `m`.               |
|`MatcherCast<T>(m)`|casts matcher `m` to type `Matcher<T>`.| |:------------------|:--------------------------------------| |`SafeMatcherCast<T>(m)`| [safely casts](CookBook.md#casting-matchers) matcher `m` to type `Matcher<T>`. | |`Truly(predicate)` |`predicate(argument)` returns something considered by C++ to be true, where `predicate` is a function or functor.|
|`Matches(m)(value)`|evaluates to `true` if `value` matches `m`. You can use `Matches(m)` alone as a unary functor.| |:------------------|:---------------------------------------------------------------------------------------------| |`ExplainMatchResult(m, value, result_listener)`|evaluates to `true` if `value` matches `m`, explaining the result to `result_listener`.       | |`Value(value, m)`  |evaluates to `true` if `value` matches `m`.                                                   |
| `MATCHER(IsEven, "") { return (arg % 2) == 0; }` | Defines a matcher `IsEven()` to match an even number. | |:-------------------------------------------------|:------------------------------------------------------| | `MATCHER_P(IsDivisibleBy, n, "") { *result_listener << "where the remainder is " << (arg % n); return (arg % n) == 0; }` | Defines a macher `IsDivisibleBy(n)` to match a number divisible by `n`. | | `MATCHER_P2(IsBetween, a, b, std::string(negation ? "isn't" : "is") + " between " + PrintToString(a) + " and " + PrintToString(b)) { return a <= arg && arg <= b; }` | Defines a matcher `IsBetween(a, b)` to match a value in the range [`a`, `b`]. |
**Notes:**
1. The `MATCHER*` macros cannot be used inside a function or class.   1. The matcher body must be _purely functional_ (i.e. it cannot have any side effect, and the result must not depend on anything other than the value being matched and the matcher parameters).   1. You can use `PrintToString(x)` to convert a value `x` of any type to a string.
|`ASSERT_THAT(expression, m)`|Generates a [fatal failure](../../googletest/docs/Primer.md#assertions) if the value of `expression` doesn't match matcher `m`.| |:---------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------| |`EXPECT_THAT(expression, m)`|Generates a non-fatal failure if the value of `expression` doesn't match matcher `m`.                                                          |
**Actions** specify what a mock function should do when invoked.
|`Return()`|Return from a `void` mock function.| |:---------|:----------------------------------| |`Return(value)`|Return `value`. If the type of `value` is different to the mock function's return type, `value` is converted to the latter type <i>at the time the expectation is set</i>, not when the action is executed.| |`ReturnArg<N>()`|Return the `N`-th (0-based) argument.| |`ReturnNew<T>(a1, ..., ak)`|Return `new T(a1, ..., ak)`; a different object is created each time.| |`ReturnNull()`|Return a null pointer.             | |`ReturnPointee(ptr)`|Return the value pointed to by `ptr`.| |`ReturnRef(variable)`|Return a reference to `variable`.  | |`ReturnRefOfCopy(value)`|Return a reference to a copy of `value`; the copy lives as long as the action.|
|`Assign(&variable, value)`|Assign `value` to variable.| |:-------------------------|:--------------------------| | `DeleteArg<N>()`         | Delete the `N`-th (0-based) argument, which must be a pointer. | | `SaveArg<N>(pointer)`    | Save the `N`-th (0-based) argument to `*pointer`. | | `SaveArgPointee<N>(pointer)` | Save the value pointed to by the `N`-th (0-based) argument to `*pointer`. | | `SetArgReferee<N>(value)` |	Assign value to the variable referenced by the `N`-th (0-based) argument. | |`SetArgPointee<N>(value)` |Assign `value` to the variable pointed by the `N`-th (0-based) argument.| |`SetArgumentPointee<N>(value)`|Same as `SetArgPointee<N>(value)`. Deprecated. Will be removed in v1.7.0.| |`SetArrayArgument<N>(first, last)`|Copies the elements in source range [`first`, `last`) to the array pointed to by the `N`-th (0-based) argument, which can be either a pointer or an iterator. The action does not take ownership of the elements in the source range.| |`SetErrnoAndReturn(error, value)`|Set `errno` to `error` and return `value`.| |`Throw(exception)`        |Throws the given exception, which can be any copyable value. Available since v1.1.0.|
|`Invoke(f)`|Invoke `f` with the arguments passed to the mock function, where `f` can be a global/static function or a functor.| |:----------|:-----------------------------------------------------------------------------------------------------------------| |`Invoke(object_pointer, &class::method)`|Invoke the {method on the object with the arguments passed to the mock function.                                  | |`InvokeWithoutArgs(f)`|Invoke `f`, which can be a global/static function or a functor. `f` must take no arguments.                       | |`InvokeWithoutArgs(object_pointer, &class::method)`|Invoke the method on the object, which takes no arguments.                                                        | |`InvokeArgument<N>(arg1, arg2, ..., argk)`|Invoke the mock function's `N`-th (0-based) argument, which must be a function or a functor, with the `k` arguments.|
The return value of the invoked function is used as the return value of the action.
When defining a function or functor to be used with `Invoke*()`, you can declare any unused parameters as `Unused`: ```   double Distance(Unused, double x, double y) { return sqrt(x*x + y*y); }   ...   EXPECT_CALL(mock, Foo("Hi", _, _)).WillOnce(Invoke(Distance)); ```
In `InvokeArgument<N>(...)`, if an argument needs to be passed by reference, wrap it inside `ByRef()`. For example, ```   InvokeArgument<2>(5, string("Hi"), ByRef(foo)) ``` calls the mock function's #2 argument, passing to it `5` and `string("Hi")` by value, and `foo` by reference.
|`DoDefault()`|Do the default action (specified by `ON_CALL()` or the built-in one).| |:------------|:--------------------------------------------------------------------|
**Note:** due to technical reasons, `DoDefault()` cannot be used inside  a composite action - trying to do so will result in a run-time error.
|`DoAll(a1, a2, ..., an)`|Do all actions `a1` to `an` and return the result of `an` in each invocation. The first `n - 1` sub-actions must return void. | |:-----------------------|:-----------------------------------------------------------------------------------------------------------------------------| |`IgnoreResult(a)`       |Perform action `a` and ignore its result. `a` must not return void.                                                           | |`WithArg<N>(a)`         |Pass the `N`-th (0-based) argument of the mock function to action `a` and perform it.                                         | |`WithArgs<N1, N2, ..., Nk>(a)`|Pass the selected (0-based) arguments of the mock function to action `a` and perform it.                                      | |`WithoutArgs(a)`        |Perform action `a` without any arguments.                                                                                     |
| `ACTION(Sum) { return arg0 + arg1; }` | Defines an action `Sum()` to return the sum of the mock function's argument #0 and #1. | |:--------------------------------------|:---------------------------------------------------------------------------------------| | `ACTION_P(Plus, n) { return arg0 + n; }` | Defines an action `Plus(n)` to return the sum of the mock function's argument #0 and `n`. | | `ACTION_Pk(Foo, p1, ..., pk) { statements; }` | Defines a parameterized action `Foo(p1, ..., pk)` to execute the given `statements`.   |
The `ACTION*` macros cannot be used inside a function or class.
These are used in `Times()` to specify how many times a mock function will be called:
|`AnyNumber()`|The function can be called any number of times.| |:------------|:----------------------------------------------| |`AtLeast(n)` |The call is expected at least `n` times.       | |`AtMost(n)`  |The call is expected at most `n` times.        | |`Between(m, n)`|The call is expected between `m` and `n` (inclusive) times.| |`Exactly(n) or n`|The call is expected exactly `n` times. In particular, the call should never happen when `n` is 0.|
By default, the expectations can be matched in _any_ order.  If some or all expectations must be matched in a given order, there are two ways to specify it.  They can be used either independently or together.
``` using ::testing::Expectation; ... Expectation init_x = EXPECT_CALL(foo, InitX()); Expectation init_y = EXPECT_CALL(foo, InitY()); EXPECT_CALL(foo, Bar())     .After(init_x, init_y); ``` says that `Bar()` can be called only after both `InitX()` and `InitY()` have been called.
If you don't know how many pre-requisites an expectation has when you write it, you can use an `ExpectationSet` to collect them:
``` using ::testing::ExpectationSet; ... ExpectationSet all_inits; for (int i = 0; i < element_count; i++) {   all_inits += EXPECT_CALL(foo, InitElement(i)); } EXPECT_CALL(foo, Bar())     .After(all_inits); ``` says that `Bar()` can be called only after all elements have been initialized (but we don't care about which elements get initialized before the others).
Modifying an `ExpectationSet` after using it in an `.After()` doesn't affect the meaning of the `.After()`.
When you have a long chain of sequential expectations, it's easier to specify the order using **sequences**, which don't require you to given each expectation in the chain a different name.  <i>All expected<br> calls</i> in the same sequence must occur in the order they are specified.
``` using ::testing::Sequence; Sequence s1, s2; ... EXPECT_CALL(foo, Reset())     .InSequence(s1, s2)     .WillOnce(Return(true)); EXPECT_CALL(foo, GetSize())     .InSequence(s1)     .WillOnce(Return(1)); EXPECT_CALL(foo, Describe(A<const char*>()))     .InSequence(s2)     .WillOnce(Return("dummy")); ``` says that `Reset()` must be called before _both_ `GetSize()` _and_ `Describe()`, and the latter two can occur in any order.
To put many expectations in a sequence conveniently: ``` using ::testing::InSequence; {   InSequence dummy;
EXPECT_CALL(...)...;   EXPECT_CALL(...)...;   ...   EXPECT_CALL(...)...; } ``` says that all expected calls in the scope of `dummy` must occur in strict order. The name `dummy` is irrelevant.)
Google Mock will verify the expectations on a mock object when it is destructed, or you can do it earlier: ``` using ::testing::Mock; ... // Verifies and removes the expectations on mock_obj; // returns true iff successful. Mock::VerifyAndClearExpectations(&mock_obj); ... // Verifies and removes the expectations on mock_obj; // also removes the default actions set by ON_CALL(); // returns true iff successful. Mock::VerifyAndClear(&mock_obj); ```
You can also tell Google Mock that a mock object can be leaked and doesn't need to be verified: ``` Mock::AllowLeak(&mock_obj); ```
Google Mock defines a convenient mock class template ``` class MockFunction<R(A1, ..., An)> {  public:   MOCK_METHODn(Call, R(A1, ..., An)); }; ``` See this [recipe](CookBook.md#using-check-points) for one application of it.
| `--gmock_catch_leaked_mocks=0` | Don't report leaked mock objects as failures. | |:-------------------------------|:----------------------------------------------| | `--gmock_verbose=LEVEL`        | Sets the default verbosity level (`info`, `warning`, or `error`) of Google Mock messages. |

You can find recipes for using Google Mock here. If you haven't yet, please read the [ForDummies](ForDummies.md) document first to make sure you understand the basics.
**Note:** Google Mock lives in the `testing` name space. For readability, it is recommended to write `using ::testing::Foo;` once in your file before using the name `Foo` defined by Google Mock. We omit such `using` statements in this page for brevity, but you should do it in your own code.
You must always put a mock method definition (`MOCK_METHOD*`) in a `public:` section of the mock class, regardless of the method being mocked being `public`, `protected`, or `private` in the base class. This allows `ON_CALL` and `EXPECT_CALL` to reference the mock function from outside of the mock class.  (Yes, C++ allows a subclass to change the access level of a virtual function in the base class.)  Example:
``` class Foo {  public:   ...   virtual bool Transform(Gadget* g) = 0;
protected:   virtual void Resume();
private:   virtual int GetTimeOut(); };
class MockFoo : public Foo {  public:   ...   MOCK_METHOD1(Transform, bool(Gadget* g));
// The following must be in the public section, even though the   // methods are protected or private in the base class.   MOCK_METHOD0(Resume, void());   MOCK_METHOD0(GetTimeOut, int()); }; ```
You can mock overloaded functions as usual. No special attention is required:
``` class Foo {   ...
// Must be virtual as we'll inherit from Foo.   virtual ~Foo();
// Overloaded on the types and/or numbers of arguments.   virtual int Add(Element x);   virtual int Add(int times, Element x);
// Overloaded on the const-ness of this object.   virtual Bar& GetBar();   virtual const Bar& GetBar() const; };
class MockFoo : public Foo {   ...   MOCK_METHOD1(Add, int(Element x));   MOCK_METHOD2(Add, int(int times, Element x);
MOCK_METHOD0(GetBar, Bar&());   MOCK_CONST_METHOD0(GetBar, const Bar&()); }; ```
**Note:** if you don't mock all versions of the overloaded method, the compiler will give you a warning about some methods in the base class being hidden. To fix that, use `using` to bring them in scope:
``` class MockFoo : public Foo {   ...   using Foo::Add;   MOCK_METHOD1(Add, int(Element x));   // We don't want to mock int Add(int times, Element x);   ... }; ```
To mock a class template, append `_T` to the `MOCK_*` macros:
``` template <typename Elem> class StackInterface {   ...   // Must be virtual as we'll inherit from StackInterface.   virtual ~StackInterface();
virtual int GetSize() const = 0;   virtual void Push(const Elem& x) = 0; };
template <typename Elem> class MockStack : public StackInterface<Elem> {   ...   MOCK_CONST_METHOD0_T(GetSize, int());   MOCK_METHOD1_T(Push, void(const Elem& x)); }; ```
Google Mock can mock non-virtual functions to be used in what we call _hi-perf dependency injection_.
In this case, instead of sharing a common base class with the real class, your mock class will be _unrelated_ to the real class, but contain methods with the same signatures.  The syntax for mocking non-virtual methods is the _same_ as mocking virtual methods:
``` // A simple packet stream class.  None of its members is virtual. class ConcretePacketStream {  public:   void AppendPacket(Packet* new_packet);   const Packet* GetPacket(size_t packet_number) const;   size_t NumberOfPackets() const;   ... };
// A mock packet stream class.  It inherits from no other, but defines // GetPacket() and NumberOfPackets(). class MockPacketStream {  public:   MOCK_CONST_METHOD1(GetPacket, const Packet*(size_t packet_number));   MOCK_CONST_METHOD0(NumberOfPackets, size_t());   ... }; ```
Note that the mock class doesn't define `AppendPacket()`, unlike the real class. That's fine as long as the test doesn't need to call it.
Next, you need a way to say that you want to use `ConcretePacketStream` in production code, and use `MockPacketStream` in tests.  Since the functions are not virtual and the two classes are unrelated, you must specify your choice at _compile time_ (as opposed to run time).
One way to do it is to templatize your code that needs to use a packet stream.  More specifically, you will give your code a template type argument for the type of the packet stream.  In production, you will instantiate your template with `ConcretePacketStream` as the type argument.  In tests, you will instantiate the same template with `MockPacketStream`.  For example, you may write:
``` template <class PacketStream> void CreateConnection(PacketStream* stream) { ... }
template <class PacketStream> class PacketReader {  public:   void ReadPackets(PacketStream* stream, size_t packet_num); }; ```
Then you can use `CreateConnection<ConcretePacketStream>()` and `PacketReader<ConcretePacketStream>` in production code, and use `CreateConnection<MockPacketStream>()` and `PacketReader<MockPacketStream>` in tests.
```   MockPacketStream mock_stream;   EXPECT_CALL(mock_stream, ...)...;   .. set more expectations on mock_stream ...   PacketReader<MockPacketStream> reader(&mock_stream);   ... exercise reader ... ```
It's possible to use Google Mock to mock a free function (i.e. a C-style function or a static method).  You just need to rewrite your code to use an interface (abstract class).
Instead of calling a free function (say, `OpenFile`) directly, introduce an interface for it and have a concrete subclass that calls the free function:
``` class FileInterface {  public:   ...   virtual bool Open(const char* path, const char* mode) = 0; };
class File : public FileInterface {  public:   ...   virtual bool Open(const char* path, const char* mode) {     return OpenFile(path, mode);   } }; ```
Your code should talk to `FileInterface` to open a file.  Now it's easy to mock out the function.
This may seem much hassle, but in practice you often have multiple related functions that you can put in the same interface, so the per-function syntactic overhead will be much lower.
If you are concerned about the performance overhead incurred by virtual functions, and profiling confirms your concern, you can combine this with the recipe for [mocking non-virtual methods](#Mocking_Nonvirtual_Methods.md).
If a mock method has no `EXPECT_CALL` spec but is called, Google Mock will print a warning about the "uninteresting call". The rationale is:
* New methods may be added to an interface after a test is written. We shouldn't fail a test just because a method it doesn't know about is called.   * However, this may also mean there's a bug in the test, so Google Mock shouldn't be silent either. If the user believes these calls are harmless, he can add an `EXPECT_CALL()` to suppress the warning.
However, sometimes you may want to suppress all "uninteresting call" warnings, while sometimes you may want the opposite, i.e. to treat all of them as errors. Google Mock lets you make the decision on a per-mock-object basis.
Suppose your test uses a mock class `MockFoo`:
``` TEST(...) {   MockFoo mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
If a method of `mock_foo` other than `DoThis()` is called, it will be reported by Google Mock as a warning. However, if you rewrite your test to use `NiceMock<MockFoo>` instead, the warning will be gone, resulting in a cleaner test output:
``` using ::testing::NiceMock;
TEST(...) {   NiceMock<MockFoo> mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
`NiceMock<MockFoo>` is a subclass of `MockFoo`, so it can be used wherever `MockFoo` is accepted.
It also works if `MockFoo`'s constructor takes some arguments, as `NiceMock<MockFoo>` "inherits" `MockFoo`'s constructors:
``` using ::testing::NiceMock;
TEST(...) {   NiceMock<MockFoo> mock_foo(5, "hi");  // Calls MockFoo(5, "hi").   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
The usage of `StrictMock` is similar, except that it makes all uninteresting calls failures:
``` using ::testing::StrictMock;
TEST(...) {   StrictMock<MockFoo> mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ...
// The test will fail if a method of mock_foo other than DoThis()   // is called. } ```
There are some caveats though (I don't like them just as much as the next guy, but sadly they are side effects of C++'s limitations):
1. `NiceMock<MockFoo>` and `StrictMock<MockFoo>` only work for mock methods defined using the `MOCK_METHOD*` family of macros **directly** in the `MockFoo` class. If a mock method is defined in a **base class** of `MockFoo`, the "nice" or "strict" modifier may not affect it, depending on the compiler. In particular, nesting `NiceMock` and `StrictMock` (e.g. `NiceMock<StrictMock<MockFoo> >`) is **not** supported.   1. The constructors of the base mock (`MockFoo`) cannot have arguments passed by non-const reference, which happens to be banned by the [Google C++ style guide](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml).   1. During the constructor or destructor of `MockFoo`, the mock object is _not_ nice or strict.  This may cause surprises if the constructor or destructor calls a mock method on `this` object. (This behavior, however, is consistent with C++'s general rule: if a constructor or destructor calls a virtual method of `this` object, that method is treated as non-virtual.  In other words, to the base class's constructor or destructor, `this` object behaves like an instance of the base class, not the derived class.  This rule is required for safety.  Otherwise a base constructor may use members of a derived class before they are initialized, or a base destructor may use members of a derived class after they have been destroyed.)
Finally, you should be **very cautious** about when to use naggy or strict mocks, as they tend to make tests more brittle and harder to maintain. When you refactor your code without changing its externally visible behavior, ideally you should't need to update any tests. If your code interacts with a naggy mock, however, you may start to get spammed with warnings as the result of your change. Worse, if your code interacts with a strict mock, your tests may start to fail and you'll be forced to fix them. Our general recommendation is to use nice mocks (not yet the default) most of the time, use naggy mocks (the current default) when developing or debugging tests, and use strict mocks only as the last resort.
Sometimes a method has a long list of arguments that is mostly uninteresting. For example,
``` class LogSink {  public:   ...   virtual void send(LogSeverity severity, const char* full_filename,                     const char* base_filename, int line,                     const struct tm* tm_time,                     const char* message, size_t message_len) = 0; }; ```
This method's argument list is lengthy and hard to work with (let's say that the `message` argument is not even 0-terminated). If we mock it as is, using the mock will be awkward. If, however, we try to simplify this interface, we'll need to fix all clients depending on it, which is often infeasible.
The trick is to re-dispatch the method in the mock class:
``` class ScopedMockLog : public LogSink {  public:   ...   virtual void send(LogSeverity severity, const char* full_filename,                     const char* base_filename, int line, const tm* tm_time,                     const char* message, size_t message_len) {     // We are only interested in the log severity, full file name, and     // log message.     Log(severity, full_filename, std::string(message, message_len));   }
// Implements the mock method:   //   //   void Log(LogSeverity severity,   //            const string& file_path,   //            const string& message);   MOCK_METHOD3(Log, void(LogSeverity severity, const string& file_path,                          const string& message)); }; ```
By defining a new mock method with a trimmed argument list, we make the mock class much more user-friendly.
Often you may find yourself using classes that don't implement interfaces. In order to test your code that uses such a class (let's call it `Concrete`), you may be tempted to make the methods of `Concrete` virtual and then mock it.
Try not to do that.
Making a non-virtual function virtual is a big decision. It creates an extension point where subclasses can tweak your class' behavior. This weakens your control on the class because now it's harder to maintain the class' invariants. You should make a function virtual only when there is a valid reason for a subclass to override it.
Mocking concrete classes directly is problematic as it creates a tight coupling between the class and the tests - any small change in the class may invalidate your tests and make test maintenance a pain.
To avoid such problems, many programmers have been practicing "coding to interfaces": instead of talking to the `Concrete` class, your code would define an interface and talk to it. Then you implement that interface as an adaptor on top of `Concrete`. In tests, you can easily mock that interface to observe how your code is doing.
This technique incurs some overhead:
* You pay the cost of virtual function calls (usually not a problem).   * There is more abstraction for the programmers to learn.
However, it can also bring significant benefits in addition to better testability:
* `Concrete`'s API may not fit your problem domain very well, as you may not be the only client it tries to serve. By designing your own interface, you have a chance to tailor it to your need - you may add higher-level functionalities, rename stuff, etc instead of just trimming the class. This allows you to write your code (user of the interface) in a more natural way, which means it will be more readable, more maintainable, and you'll be more productive.   * If `Concrete`'s implementation ever has to change, you don't have to rewrite everywhere it is used. Instead, you can absorb the change in your implementation of the interface, and your other code and tests will be insulated from this change.
Some people worry that if everyone is practicing this technique, they will end up writing lots of redundant code. This concern is totally understandable. However, there are two reasons why it may not be the case:
* Different projects may need to use `Concrete` in different ways, so the best interfaces for them will be different. Therefore, each of them will have its own domain-specific interface on top of `Concrete`, and they will not be the same code.   * If enough projects want to use the same interface, they can always share it, just like they have been sharing `Concrete`. You can check in the interface and the adaptor somewhere near `Concrete` (perhaps in a `contrib` sub-directory) and let many projects use it.
You need to weigh the pros and cons carefully for your particular problem, but I'd like to assure you that the Java community has been practicing this for a long time and it's a proven effective technique applicable in a wide variety of situations. :-)
Some times you have a non-trivial fake implementation of an interface. For example:
``` class Foo {  public:   virtual ~Foo() {}   virtual char DoThis(int n) = 0;   virtual void DoThat(const char* s, int* p) = 0; };
class FakeFoo : public Foo {  public:   virtual char DoThis(int n) {     return (n > 0) ? '+' :         (n < 0) ? '-' : '0';   }
virtual void DoThat(const char* s, int* p) {     *p = strlen(s);   } }; ```
Now you want to mock this interface such that you can set expectations on it. However, you also want to use `FakeFoo` for the default behavior, as duplicating it in the mock object is, well, a lot of work.
When you define the mock class using Google Mock, you can have it delegate its default action to a fake class you already have, using this pattern:
``` using ::testing::_; using ::testing::Invoke;
class MockFoo : public Foo {  public:   // Normal mock method definitions using Google Mock.   MOCK_METHOD1(DoThis, char(int n));   MOCK_METHOD2(DoThat, void(const char* s, int* p));
// Delegates the default actions of the methods to a FakeFoo object.   // This must be called *before* the custom ON_CALL() statements.   void DelegateToFake() {     ON_CALL(*this, DoThis(_))         .WillByDefault(Invoke(&fake_, &FakeFoo::DoThis));     ON_CALL(*this, DoThat(_, _))         .WillByDefault(Invoke(&fake_, &FakeFoo::DoThat));   }  private:   FakeFoo fake_;  // Keeps an instance of the fake in the mock. }; ```
With that, you can use `MockFoo` in your tests as usual. Just remember that if you don't explicitly set an action in an `ON_CALL()` or `EXPECT_CALL()`, the fake will be called upon to do it:
``` using ::testing::_;
TEST(AbcTest, Xyz) {   MockFoo foo;   foo.DelegateToFake(); // Enables the fake for delegation.
// Put your ON_CALL(foo, ...)s here, if any.
// No action specified, meaning to use the default action.   EXPECT_CALL(foo, DoThis(5));   EXPECT_CALL(foo, DoThat(_, _));
int n = 0;   EXPECT_EQ('+', foo.DoThis(5));  // FakeFoo::DoThis() is invoked.   foo.DoThat("Hi", &n);           // FakeFoo::DoThat() is invoked.   EXPECT_EQ(2, n); } ```
**Some tips:**
* If you want, you can still override the default action by providing your own `ON_CALL()` or using `.WillOnce()` / `.WillRepeatedly()` in `EXPECT_CALL()`.   * In `DelegateToFake()`, you only need to delegate the methods whose fake implementation you intend to use.   * The general technique discussed here works for overloaded methods, but you'll need to tell the compiler which version you mean. To disambiguate a mock function (the one you specify inside the parentheses of `ON_CALL()`), see the "Selecting Between Overloaded Functions" section on this page; to disambiguate a fake function (the one you place inside `Invoke()`), use a `static_cast` to specify the function's type. For instance, if class `Foo` has methods `char DoThis(int n)` and `bool DoThis(double x) const`, and you want to invoke the latter, you need to write `Invoke(&fake_, static_cast<bool (FakeFoo::*)(double) const>(&FakeFoo::DoThis))` instead of `Invoke(&fake_, &FakeFoo::DoThis)` (The strange-looking thing inside the angled brackets of `static_cast` is the type of a function pointer to the second `DoThis()` method.).   * Having to mix a mock and a fake is often a sign of something gone wrong. Perhaps you haven't got used to the interaction-based way of testing yet. Or perhaps your interface is taking on too many roles and should be split up. Therefore, **don't abuse this**. We would only recommend to do it as an intermediate step when you are refactoring your code.
Regarding the tip on mixing a mock and a fake, here's an example on why it may be a bad sign: Suppose you have a class `System` for low-level system operations. In particular, it does file and I/O operations. And suppose you want to test how your code uses `System` to do I/O, and you just want the file operations to work normally. If you mock out the entire `System` class, you'll have to provide a fake implementation for the file operation part, which suggests that `System` is taking on too many roles.
Instead, you can define a `FileOps` interface and an `IOOps` interface and split `System`'s functionalities into the two. Then you can mock `IOOps` without mocking `FileOps`.
When using testing doubles (mocks, fakes, stubs, and etc), sometimes their behaviors will differ from those of the real objects. This difference could be either intentional (as in simulating an error such that you can test the error handling code) or unintentional. If your mocks have different behaviors than the real objects by mistake, you could end up with code that passes the tests but fails in production.
You can use the _delegating-to-real_ technique to ensure that your mock has the same behavior as the real object while retaining the ability to validate calls. This technique is very similar to the delegating-to-fake technique, the difference being that we use a real object instead of a fake. Here's an example:
``` using ::testing::_; using ::testing::AtLeast; using ::testing::Invoke;
class MockFoo : public Foo {  public:   MockFoo() {     // By default, all calls are delegated to the real object.     ON_CALL(*this, DoThis())         .WillByDefault(Invoke(&real_, &Foo::DoThis));     ON_CALL(*this, DoThat(_))         .WillByDefault(Invoke(&real_, &Foo::DoThat));     ...   }   MOCK_METHOD0(DoThis, ...);   MOCK_METHOD1(DoThat, ...);   ...  private:   Foo real_; }; ...
MockFoo mock;
EXPECT_CALL(mock, DoThis())       .Times(3);   EXPECT_CALL(mock, DoThat("Hi"))       .Times(AtLeast(1));   ... use mock in test ... ```
With this, Google Mock will verify that your code made the right calls (with the right arguments, in the right order, called the right number of times, etc), and a real object will answer the calls (so the behavior will be the same as in production). This gives you the best of both worlds.
Ideally, you should code to interfaces, whose methods are all pure virtual. In reality, sometimes you do need to mock a virtual method that is not pure (i.e, it already has an implementation). For example:
``` class Foo {  public:   virtual ~Foo();
virtual void Pure(int n) = 0;   virtual int Concrete(const char* str) { ... } };
class MockFoo : public Foo {  public:   // Mocking a pure method.   MOCK_METHOD1(Pure, void(int n));   // Mocking a concrete method.  Foo::Concrete() is shadowed.   MOCK_METHOD1(Concrete, int(const char* str)); }; ```
Sometimes you may want to call `Foo::Concrete()` instead of `MockFoo::Concrete()`. Perhaps you want to do it as part of a stub action, or perhaps your test doesn't need to mock `Concrete()` at all (but it would be oh-so painful to have to define a new mock class whenever you don't need to mock one of its methods).
The trick is to leave a back door in your mock class for accessing the real methods in the base class:
``` class MockFoo : public Foo {  public:   // Mocking a pure method.   MOCK_METHOD1(Pure, void(int n));   // Mocking a concrete method.  Foo::Concrete() is shadowed.   MOCK_METHOD1(Concrete, int(const char* str));
// Use this to call Concrete() defined in Foo.   int FooConcrete(const char* str) { return Foo::Concrete(str); } }; ```
Now, you can call `Foo::Concrete()` inside an action by:
``` using ::testing::_; using ::testing::Invoke; ...   EXPECT_CALL(foo, Concrete(_))       .WillOnce(Invoke(&foo, &MockFoo::FooConcrete)); ```
or tell the mock object that you don't want to mock `Concrete()`:
``` using ::testing::Invoke; ...   ON_CALL(foo, Concrete(_))       .WillByDefault(Invoke(&foo, &MockFoo::FooConcrete)); ```
(Why don't we just write `Invoke(&foo, &Foo::Concrete)`? If you do that, `MockFoo::Concrete()` will be called (and cause an infinite recursion) since `Foo::Concrete()` is virtual. That's just how C++ works.)
You can specify exactly which arguments a mock method is expecting:
``` using ::testing::Return; ...   EXPECT_CALL(foo, DoThis(5))       .WillOnce(Return('a'));   EXPECT_CALL(foo, DoThat("Hello", bar)); ```
You can use matchers to match arguments that have a certain property:
``` using ::testing::Ge; using ::testing::NotNull; using ::testing::Return; ...   EXPECT_CALL(foo, DoThis(Ge(5)))  // The argument must be >= 5.       .WillOnce(Return('a'));   EXPECT_CALL(foo, DoThat("Hello", NotNull()));   // The second argument must not be NULL. ```
A frequently used matcher is `_`, which matches anything:
``` using ::testing::_; using ::testing::NotNull; ...   EXPECT_CALL(foo, DoThat(_, NotNull())); ```
You can build complex matchers from existing ones using `AllOf()`, `AnyOf()`, and `Not()`:
``` using ::testing::AllOf; using ::testing::Gt; using ::testing::HasSubstr; using ::testing::Ne; using ::testing::Not; ...   // The argument must be > 5 and != 10.   EXPECT_CALL(foo, DoThis(AllOf(Gt(5),                                 Ne(10))));
// The first argument must not contain sub-string "blah".   EXPECT_CALL(foo, DoThat(Not(HasSubstr("blah")),                           NULL)); ```
Google Mock matchers are statically typed, meaning that the compiler can catch your mistake if you use a matcher of the wrong type (for example, if you use `Eq(5)` to match a `string` argument). Good for you!
Sometimes, however, you know what you're doing and want the compiler to give you some slack. One example is that you have a matcher for `long` and the argument you want to match is `int`. While the two types aren't exactly the same, there is nothing really wrong with using a `Matcher<long>` to match an `int` - after all, we can first convert the `int` argument to a `long` before giving it to the matcher.
To support this need, Google Mock gives you the `SafeMatcherCast<T>(m)` function. It casts a matcher `m` to type `Matcher<T>`. To ensure safety, Google Mock checks that (let `U` be the type `m` accepts):
1. Type `T` can be implicitly cast to type `U`;   1. When both `T` and `U` are built-in arithmetic types (`bool`, integers, and floating-point numbers), the conversion from `T` to `U` is not lossy (in other words, any value representable by `T` can also be represented by `U`); and   1. When `U` is a reference, `T` must also be a reference (as the underlying matcher may be interested in the address of the `U` value).
The code won't compile if any of these conditions isn't met.
Here's one example:
``` using ::testing::SafeMatcherCast;
// A base class and a child class. class Base { ... }; class Derived : public Base { ... };
class MockFoo : public Foo {  public:   MOCK_METHOD1(DoThis, void(Derived* derived)); }; ...
MockFoo foo;   // m is a Matcher<Base*> we got from somewhere.   EXPECT_CALL(foo, DoThis(SafeMatcherCast<Derived*>(m))); ```
If you find `SafeMatcherCast<T>(m)` too limiting, you can use a similar function `MatcherCast<T>(m)`. The difference is that `MatcherCast` works as long as you can `static_cast` type `T` to type `U`.
`MatcherCast` essentially lets you bypass C++'s type system (`static_cast` isn't always safe as it could throw away information, for example), so be careful not to misuse/abuse it.
If you expect an overloaded function to be called, the compiler may need some help on which overloaded version it is.
To disambiguate functions overloaded on the const-ness of this object, use the `Const()` argument wrapper.
``` using ::testing::ReturnRef;
class MockFoo : public Foo {   ...   MOCK_METHOD0(GetBar, Bar&());   MOCK_CONST_METHOD0(GetBar, const Bar&()); }; ...
MockFoo foo;   Bar bar1, bar2;   EXPECT_CALL(foo, GetBar())         // The non-const GetBar().       .WillOnce(ReturnRef(bar1));   EXPECT_CALL(Const(foo), GetBar())  // The const GetBar().       .WillOnce(ReturnRef(bar2)); ```
(`Const()` is defined by Google Mock and returns a `const` reference to its argument.)
To disambiguate overloaded functions with the same number of arguments but different argument types, you may need to specify the exact type of a matcher, either by wrapping your matcher in `Matcher<type>()`, or using a matcher whose type is fixed (`TypedEq<type>`, `An<type>()`, etc):
``` using ::testing::An; using ::testing::Lt; using ::testing::Matcher; using ::testing::TypedEq;
class MockPrinter : public Printer {  public:   MOCK_METHOD1(Print, void(int n));   MOCK_METHOD1(Print, void(char c)); };
TEST(PrinterTest, Print) {   MockPrinter printer;
EXPECT_CALL(printer, Print(An<int>()));            // void Print(int);   EXPECT_CALL(printer, Print(Matcher<int>(Lt(5))));  // void Print(int);   EXPECT_CALL(printer, Print(TypedEq<char>('a')));   // void Print(char);
printer.Print(3);   printer.Print(6);   printer.Print('a'); } ```
When a mock method is called, the _last_ matching expectation that's still active will be selected (think "newer overrides older"). So, you can make a method do different things depending on its argument values like this:
``` using ::testing::_; using ::testing::Lt; using ::testing::Return; ...   // The default case.   EXPECT_CALL(foo, DoThis(_))       .WillRepeatedly(Return('b'));
// The more specific case.   EXPECT_CALL(foo, DoThis(Lt(5)))       .WillRepeatedly(Return('a')); ```
Now, if `foo.DoThis()` is called with a value less than 5, `'a'` will be returned; otherwise `'b'` will be returned.
Sometimes it's not enough to match the arguments individually. For example, we may want to say that the first argument must be less than the second argument. The `With()` clause allows us to match all arguments of a mock function as a whole. For example,
``` using ::testing::_; using ::testing::Lt; using ::testing::Ne; ...   EXPECT_CALL(foo, InRange(Ne(0), _))       .With(Lt()); ```
says that the first argument of `InRange()` must not be 0, and must be less than the second argument.
The expression inside `With()` must be a matcher of type `Matcher< ::testing::tuple<A1, ..., An> >`, where `A1`, ..., `An` are the types of the function arguments.
You can also write `AllArgs(m)` instead of `m` inside `.With()`. The two forms are equivalent, but `.With(AllArgs(Lt()))` is more readable than `.With(Lt())`.
You can use `Args<k1, ..., kn>(m)` to match the `n` selected arguments (as a tuple) against `m`. For example,
``` using ::testing::_; using ::testing::AllOf; using ::testing::Args; using ::testing::Lt; ...   EXPECT_CALL(foo, Blah(_, _, _))       .With(AllOf(Args<0, 1>(Lt()), Args<1, 2>(Lt()))); ```
says that `Blah()` will be called with arguments `x`, `y`, and `z` where `x < y < z`.
As a convenience and example, Google Mock provides some matchers for 2-tuples, including the `Lt()` matcher above. See the [CheatSheet](CheatSheet.md) for the complete list.
Note that if you want to pass the arguments to a predicate of your own (e.g. `.With(Args<0, 1>(Truly(&MyPredicate)))`), that predicate MUST be written to take a `::testing::tuple` as its argument; Google Mock will pass the `n` selected arguments as _one_ single tuple to the predicate.
Have you noticed that a matcher is just a fancy predicate that also knows how to describe itself? Many existing algorithms take predicates as arguments (e.g. those defined in STL's `<algorithm>` header), and it would be a shame if Google Mock matchers are not allowed to participate.
Luckily, you can use a matcher where a unary predicate functor is expected by wrapping it inside the `Matches()` function. For example,
``` #include <algorithm> #include <vector>
std::vector<int> v; ... // How many elements in v are >= 10? const int count = count_if(v.begin(), v.end(), Matches(Ge(10))); ```
Since you can build complex matchers from simpler ones easily using Google Mock, this gives you a way to conveniently construct composite predicates (doing the same using STL's `<functional>` header is just painful). For example, here's a predicate that's satisfied by any number that is >= 0, <= 100, and != 50:
``` Matches(AllOf(Ge(0), Le(100), Ne(50))) ```
Since matchers are basically predicates that also know how to describe themselves, there is a way to take advantage of them in [Google Test](../../googletest/) assertions. It's called `ASSERT_THAT` and `EXPECT_THAT`:
```   ASSERT_THAT(value, matcher);  // Asserts that value matches matcher.   EXPECT_THAT(value, matcher);  // The non-fatal version. ```
For example, in a Google Test test you can write:
``` #include "gmock/gmock.h"
using ::testing::AllOf; using ::testing::Ge; using ::testing::Le; using ::testing::MatchesRegex; using ::testing::StartsWith; ...
EXPECT_THAT(Foo(), StartsWith("Hello"));   EXPECT_THAT(Bar(), MatchesRegex("Line \\d+"));   ASSERT_THAT(Baz(), AllOf(Ge(5), Le(10))); ```
which (as you can probably guess) executes `Foo()`, `Bar()`, and `Baz()`, and verifies that:
* `Foo()` returns a string that starts with `"Hello"`.   * `Bar()` returns a string that matches regular expression `"Line \\d+"`.   * `Baz()` returns a number in the range [5, 10].
The nice thing about these macros is that _they read like English_. They generate informative messages too. For example, if the first `EXPECT_THAT()` above fails, the message will be something like:
``` Value of: Foo()   Actual: "Hi, world!" Expected: starts with "Hello" ```
**Credit:** The idea of `(ASSERT|EXPECT)_THAT` was stolen from the [Hamcrest](https://github.com/hamcrest/) project, which adds `assertThat()` to JUnit.
Google Mock provides a built-in set of matchers. In case you find them lacking, you can use an arbitray unary predicate function or functor as a matcher - as long as the predicate accepts a value of the type you want. You do this by wrapping the predicate inside the `Truly()` function, for example:
``` using ::testing::Truly;
int IsEven(int n) { return (n % 2) == 0 ? 1 : 0; } ...
// Bar() must be called with an even number.   EXPECT_CALL(foo, Bar(Truly(IsEven))); ```
Note that the predicate function / functor doesn't have to return `bool`. It works as long as the return value can be used as the condition in statement `if (condition) ...`.
When you do an `EXPECT_CALL(mock_obj, Foo(bar))`, Google Mock saves away a copy of `bar`. When `Foo()` is called later, Google Mock compares the argument to `Foo()` with the saved copy of `bar`. This way, you don't need to worry about `bar` being modified or destroyed after the `EXPECT_CALL()` is executed. The same is true when you use matchers like `Eq(bar)`, `Le(bar)`, and so on.
But what if `bar` cannot be copied (i.e. has no copy constructor)? You could define your own matcher function and use it with `Truly()`, as the previous couple of recipes have shown. Or, you may be able to get away from it if you can guarantee that `bar` won't be changed after the `EXPECT_CALL()` is executed. Just tell Google Mock that it should save a reference to `bar`, instead of a copy of it. Here's how:
``` using ::testing::Eq; using ::testing::ByRef; using ::testing::Lt; ...   // Expects that Foo()'s argument == bar.   EXPECT_CALL(mock_obj, Foo(Eq(ByRef(bar))));
// Expects that Foo()'s argument < bar.   EXPECT_CALL(mock_obj, Foo(Lt(ByRef(bar)))); ```
Remember: if you do this, don't change `bar` after the `EXPECT_CALL()`, or the result is undefined.
Often a mock function takes a reference to object as an argument. When matching the argument, you may not want to compare the entire object against a fixed object, as that may be over-specification. Instead, you may need to validate a certain member variable or the result of a certain getter method of the object. You can do this with `Field()` and `Property()`. More specifically,
``` Field(&Foo::bar, m) ```
is a matcher that matches a `Foo` object whose `bar` member variable satisfies matcher `m`.
``` Property(&Foo::baz, m) ```
is a matcher that matches a `Foo` object whose `baz()` method returns a value that satisfies matcher `m`.
For example:
> | `Field(&Foo::number, Ge(3))` | Matches `x` where `x.number >= 3`. | |:-----------------------------|:-----------------------------------| > | `Property(&Foo::name, StartsWith("John "))` | Matches `x` where `x.name()` starts with `"John "`. |
Note that in `Property(&Foo::baz, ...)`, method `baz()` must take no argument and be declared as `const`.
BTW, `Field()` and `Property()` can also match plain pointers to objects. For instance,
``` Field(&Foo::number, Ge(3)) ```
matches a plain pointer `p` where `p->number >= 3`. If `p` is `NULL`, the match will always fail regardless of the inner matcher.
What if you want to validate more than one members at the same time? Remember that there is `AllOf()`.
C++ functions often take pointers as arguments. You can use matchers like `IsNull()`, `NotNull()`, and other comparison matchers to match a pointer, but what if you want to make sure the value _pointed to_ by the pointer, instead of the pointer itself, has a certain property? Well, you can use the `Pointee(m)` matcher.
`Pointee(m)` matches a pointer iff `m` matches the value the pointer points to. For example:
``` using ::testing::Ge; using ::testing::Pointee; ...   EXPECT_CALL(foo, Bar(Pointee(Ge(3)))); ```
expects `foo.Bar()` to be called with a pointer that points to a value greater than or equal to 3.
One nice thing about `Pointee()` is that it treats a `NULL` pointer as a match failure, so you can write `Pointee(m)` instead of
```   AllOf(NotNull(), Pointee(m)) ```
without worrying that a `NULL` pointer will crash your test.
Also, did we tell you that `Pointee()` works with both raw pointers **and** smart pointers (`linked_ptr`, `shared_ptr`, `scoped_ptr`, and etc)?
What if you have a pointer to pointer? You guessed it - you can use nested `Pointee()` to probe deeper inside the value. For example, `Pointee(Pointee(Lt(3)))` matches a pointer that points to a pointer that points to a number less than 3 (what a mouthful...).
Sometimes you want to specify that an object argument has a certain property, but there is no existing matcher that does this. If you want good error messages, you should define a matcher. If you want to do it quick and dirty, you could get away with writing an ordinary function.
Let's say you have a mock function that takes an object of type `Foo`, which has an `int bar()` method and an `int baz()` method, and you want to constrain that the argument's `bar()` value plus its `baz()` value is a given number. Here's how you can define a matcher to do it:
``` using ::testing::MatcherInterface; using ::testing::MatchResultListener;
class BarPlusBazEqMatcher : public MatcherInterface<const Foo&> {  public:   explicit BarPlusBazEqMatcher(int expected_sum)       : expected_sum_(expected_sum) {}
virtual bool MatchAndExplain(const Foo& foo,                                MatchResultListener* listener) const {     return (foo.bar() + foo.baz()) == expected_sum_;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "bar() + baz() equals " << expected_sum_;   }
virtual void DescribeNegationTo(::std::ostream* os) const {     *os << "bar() + baz() does not equal " << expected_sum_;   }  private:   const int expected_sum_; };
inline Matcher<const Foo&> BarPlusBazEq(int expected_sum) {   return MakeMatcher(new BarPlusBazEqMatcher(expected_sum)); }
...
EXPECT_CALL(..., DoThis(BarPlusBazEq(5)))...; ```
Sometimes an STL container (e.g. list, vector, map, ...) is passed to a mock function and you may want to validate it. Since most STL containers support the `==` operator, you can write `Eq(expected_container)` or simply `expected_container` to match a container exactly.
Sometimes, though, you may want to be more flexible (for example, the first element must be an exact match, but the second element can be any positive number, and so on). Also, containers used in tests often have a small number of elements, and having to define the expected container out-of-line is a bit of a hassle.
You can use the `ElementsAre()` or `UnorderedElementsAre()` matcher in such cases:
``` using ::testing::_; using ::testing::ElementsAre; using ::testing::Gt; ...
MOCK_METHOD1(Foo, void(const vector<int>& numbers)); ...
EXPECT_CALL(mock, Foo(ElementsAre(1, Gt(0), _, 5))); ```
The above matcher says that the container must have 4 elements, which must be 1, greater than 0, anything, and 5 respectively.
If you instead write:
``` using ::testing::_; using ::testing::Gt; using ::testing::UnorderedElementsAre; ...
MOCK_METHOD1(Foo, void(const vector<int>& numbers)); ...
EXPECT_CALL(mock, Foo(UnorderedElementsAre(1, Gt(0), _, 5))); ```
It means that the container must have 4 elements, which under some permutation must be 1, greater than 0, anything, and 5 respectively.
`ElementsAre()` and `UnorderedElementsAre()` are overloaded to take 0 to 10 arguments. If more are needed, you can place them in a C-style array and use `ElementsAreArray()` or `UnorderedElementsAreArray()` instead:
``` using ::testing::ElementsAreArray; ...
// ElementsAreArray accepts an array of element values.   const int expected_vector1[] = { 1, 5, 2, 4, ... };   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector1)));
// Or, an array of element matchers.   Matcher<int> expected_vector2 = { 1, Gt(2), _, 3, ... };   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector2))); ```
In case the array needs to be dynamically created (and therefore the array size cannot be inferred by the compiler), you can give `ElementsAreArray()` an additional argument to specify the array size:
``` using ::testing::ElementsAreArray; ...   int* const expected_vector3 = new int[count];   ... fill expected_vector3 with values ...   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector3, count))); ```
**Tips:**
* `ElementsAre*()` can be used to match _any_ container that implements the STL iterator pattern (i.e. it has a `const_iterator` type and supports `begin()/end()`), not just the ones defined in STL. It will even work with container types yet to be written - as long as they follows the above pattern.   * You can use nested `ElementsAre*()` to match nested (multi-dimensional) containers.   * If the container is passed by pointer instead of by reference, just write `Pointee(ElementsAre*(...))`.   * The order of elements _matters_ for `ElementsAre*()`. Therefore don't use it with containers whose element order is undefined (e.g. `hash_map`).
Under the hood, a Google Mock matcher object consists of a pointer to a ref-counted implementation object. Copying matchers is allowed and very efficient, as only the pointer is copied. When the last matcher that references the implementation object dies, the implementation object will be deleted.
Therefore, if you have some complex matcher that you want to use again and again, there is no need to build it everytime. Just assign it to a matcher variable and use that variable repeatedly! For example,
```   Matcher<int> in_range = AllOf(Gt(5), Le(10));   ... use in_range as a matcher in multiple EXPECT_CALLs ... ```
`ON_CALL` is likely the single most under-utilized construct in Google Mock.
There are basically two constructs for defining the behavior of a mock object: `ON_CALL` and `EXPECT_CALL`. The difference? `ON_CALL` defines what happens when a mock method is called, but _doesn't imply any expectation on the method being called._ `EXPECT_CALL` not only defines the behavior, but also sets an expectation that _the method will be called with the given arguments, for the given number of times_ (and _in the given order_ when you specify the order too).
Since `EXPECT_CALL` does more, isn't it better than `ON_CALL`? Not really. Every `EXPECT_CALL` adds a constraint on the behavior of the code under test. Having more constraints than necessary is _baaad_ - even worse than not having enough constraints.
This may be counter-intuitive. How could tests that verify more be worse than tests that verify less? Isn't verification the whole point of tests?
The answer, lies in _what_ a test should verify. **A good test verifies the contract of the code.** If a test over-specifies, it doesn't leave enough freedom to the implementation. As a result, changing the implementation without breaking the contract (e.g. refactoring and optimization), which should be perfectly fine to do, can break such tests. Then you have to spend time fixing them, only to see them broken again the next time the implementation is changed.
Keep in mind that one doesn't have to verify more than one property in one test. In fact, **it's a good style to verify only one thing in one test.** If you do that, a bug will likely break only one or two tests instead of dozens (which case would you rather debug?). If you are also in the habit of giving tests descriptive names that tell what they verify, you can often easily guess what's wrong just from the test log itself.
So use `ON_CALL` by default, and only use `EXPECT_CALL` when you actually intend to verify that the call is made. For example, you may have a bunch of `ON_CALL`s in your test fixture to set the common mock behavior shared by all tests in the same group, and write (scarcely) different `EXPECT_CALL`s in different `TEST_F`s to verify different aspects of the code's behavior. Compared with the style where each `TEST` has many `EXPECT_CALL`s, this leads to tests that are more resilient to implementational changes (and thus less likely to require maintenance) and makes the intent of the tests more obvious (so they are easier to maintain when you do need to maintain them).
If you are bothered by the "Uninteresting mock function call" message printed when a mock method without an `EXPECT_CALL` is called, you may use a `NiceMock` instead to suppress all such messages for the mock object, or suppress the message for specific methods by adding `EXPECT_CALL(...).Times(AnyNumber())`. DO NOT suppress it by blindly adding an `EXPECT_CALL(...)`, or you'll have a test that's a pain to maintain.
If you are not interested in how a mock method is called, just don't say anything about it. In this case, if the method is ever called, Google Mock will perform its default action to allow the test program to continue. If you are not happy with the default action taken by Google Mock, you can override it using `DefaultValue<T>::Set()` (described later in this document) or `ON_CALL()`.
Please note that once you expressed interest in a particular mock method (via `EXPECT_CALL()`), all invocations to it must match some expectation. If this function is called but the arguments don't match any `EXPECT_CALL()` statement, it will be an error.
If a mock method shouldn't be called at all, explicitly say so:
``` using ::testing::_; ...   EXPECT_CALL(foo, Bar(_))       .Times(0); ```
If some calls to the method are allowed, but the rest are not, just list all the expected calls:
``` using ::testing::AnyNumber; using ::testing::Gt; ...   EXPECT_CALL(foo, Bar(5));   EXPECT_CALL(foo, Bar(Gt(10)))       .Times(AnyNumber()); ```
A call to `foo.Bar()` that doesn't match any of the `EXPECT_CALL()` statements will be an error.
_Uninteresting_ calls and _unexpected_ calls are different concepts in Google Mock. _Very_ different.
A call `x.Y(...)` is **uninteresting** if there's _not even a single_ `EXPECT_CALL(x, Y(...))` set. In other words, the test isn't interested in the `x.Y()` method at all, as evident in that the test doesn't care to say anything about it.
A call `x.Y(...)` is **unexpected** if there are some `EXPECT_CALL(x, Y(...))s` set, but none of them matches the call. Put another way, the test is interested in the `x.Y()` method (therefore it _explicitly_ sets some `EXPECT_CALL` to verify how it's called); however, the verification fails as the test doesn't expect this particular call to happen.
**An unexpected call is always an error,** as the code under test doesn't behave the way the test expects it to behave.
**By default, an uninteresting call is not an error,** as it violates no constraint specified by the test. (Google Mock's philosophy is that saying nothing means there is no constraint.) However, it leads to a warning, as it _might_ indicate a problem (e.g. the test author might have forgotten to specify a constraint).
In Google Mock, `NiceMock` and `StrictMock` can be used to make a mock class "nice" or "strict". How does this affect uninteresting calls and unexpected calls?
A **nice mock** suppresses uninteresting call warnings. It is less chatty than the default mock, but otherwise is the same. If a test fails with a default mock, it will also fail using a nice mock instead. And vice versa. Don't expect making a mock nice to change the test's result.
A **strict mock** turns uninteresting call warnings into errors. So making a mock strict may change the test's result.
Let's look at an example:
``` TEST(...) {   NiceMock<MockDomainRegistry> mock_registry;   EXPECT_CALL(mock_registry, GetDomainOwner("google.com"))           .WillRepeatedly(Return("Larry Page"));
// Use mock_registry in code under test.   ... &mock_registry ... } ```
The sole `EXPECT_CALL` here says that all calls to `GetDomainOwner()` must have `"google.com"` as the argument. If `GetDomainOwner("yahoo.com")` is called, it will be an unexpected call, and thus an error. Having a nice mock doesn't change the severity of an unexpected call.
So how do we tell Google Mock that `GetDomainOwner()` can be called with some other arguments as well? The standard technique is to add a "catch all" `EXPECT_CALL`:
```   EXPECT_CALL(mock_registry, GetDomainOwner(_))         .Times(AnyNumber());  // catches all other calls to this method.   EXPECT_CALL(mock_registry, GetDomainOwner("google.com"))         .WillRepeatedly(Return("Larry Page")); ```
Remember that `_` is the wildcard matcher that matches anything. With this, if `GetDomainOwner("google.com")` is called, it will do what the second `EXPECT_CALL` says; if it is called with a different argument, it will do what the first `EXPECT_CALL` says.
Note that the order of the two `EXPECT_CALLs` is important, as a newer `EXPECT_CALL` takes precedence over an older one.
For more on uninteresting calls, nice mocks, and strict mocks, read ["The Nice, the Strict, and the Naggy"](#the-nice-the-strict-and-the-naggy).
Although an `EXPECT_CALL()` statement defined earlier takes precedence when Google Mock tries to match a function call with an expectation, by default calls don't have to happen in the order `EXPECT_CALL()` statements are written. For example, if the arguments match the matchers in the third `EXPECT_CALL()`, but not those in the first two, then the third expectation will be used.
If you would rather have all calls occur in the order of the expectations, put the `EXPECT_CALL()` statements in a block where you define a variable of type `InSequence`:
```   using ::testing::_;   using ::testing::InSequence;
{     InSequence s;
EXPECT_CALL(foo, DoThis(5));     EXPECT_CALL(bar, DoThat(_))         .Times(2);     EXPECT_CALL(foo, DoThis(6));   } ```
In this example, we expect a call to `foo.DoThis(5)`, followed by two calls to `bar.DoThat()` where the argument can be anything, which are in turn followed by a call to `foo.DoThis(6)`. If a call occurred out-of-order, Google Mock will report an error.
Sometimes requiring everything to occur in a predetermined order can lead to brittle tests. For example, we may care about `A` occurring before both `B` and `C`, but aren't interested in the relative order of `B` and `C`. In this case, the test should reflect our real intent, instead of being overly constraining.
Google Mock allows you to impose an arbitrary DAG (directed acyclic graph) on the calls. One way to express the DAG is to use the [After](CheatSheet.md#the-after-clause) clause of `EXPECT_CALL`.
Another way is via the `InSequence()` clause (not the same as the `InSequence` class), which we borrowed from jMock 2. It's less flexible than `After()`, but more convenient when you have long chains of sequential calls, as it doesn't require you to come up with different names for the expectations in the chains.  Here's how it works:
If we view `EXPECT_CALL()` statements as nodes in a graph, and add an edge from node A to node B wherever A must occur before B, we can get a DAG. We use the term "sequence" to mean a directed path in this DAG. Now, if we decompose the DAG into sequences, we just need to know which sequences each `EXPECT_CALL()` belongs to in order to be able to reconstruct the orginal DAG.
So, to specify the partial order on the expectations we need to do two things: first to define some `Sequence` objects, and then for each `EXPECT_CALL()` say which `Sequence` objects it is part of. Expectations in the same sequence must occur in the order they are written. For example,
```   using ::testing::Sequence;
Sequence s1, s2;
EXPECT_CALL(foo, A())       .InSequence(s1, s2);   EXPECT_CALL(bar, B())       .InSequence(s1);   EXPECT_CALL(bar, C())       .InSequence(s2);   EXPECT_CALL(foo, D())       .InSequence(s2); ```
specifies the following DAG (where `s1` is `A -> B`, and `s2` is `A -> C -> D`):
```        +---> B        |   A ---|        |        +---> C ---> D ```
This means that A must occur before B and C, and C must occur before D. There's no restriction about the order other than these.
When a mock method is called, Google Mock only consider expectations that are still active. An expectation is active when created, and becomes inactive (aka _retires_) when a call that has to occur later has occurred. For example, in
```   using ::testing::_;   using ::testing::Sequence;
Sequence s1, s2;
EXPECT_CALL(log, Log(WARNING, _, "File too large."))     // #1       .Times(AnyNumber())       .InSequence(s1, s2);   EXPECT_CALL(log, Log(WARNING, _, "Data set is empty."))  // #2       .InSequence(s1);   EXPECT_CALL(log, Log(WARNING, _, "User not found."))     // #3       .InSequence(s2); ```
as soon as either #2 or #3 is matched, #1 will retire. If a warning `"File too large."` is logged after this, it will be an error.
Note that an expectation doesn't retire automatically when it's saturated. For example,
``` using ::testing::_; ...   EXPECT_CALL(log, Log(WARNING, _, _));                  // #1   EXPECT_CALL(log, Log(WARNING, _, "File too large."));  // #2 ```
says that there will be exactly one warning with the message `"File too large."`. If the second warning contains this message too, #2 will match again and result in an upper-bound-violated error.
If this is not what you want, you can ask an expectation to retire as soon as it becomes saturated:
``` using ::testing::_; ...   EXPECT_CALL(log, Log(WARNING, _, _));                 // #1   EXPECT_CALL(log, Log(WARNING, _, "File too large."))  // #2       .RetiresOnSaturation(); ```
Here #2 can be used only once, so if you have two warnings with the message `"File too large."`, the first will match #2 and the second will match #1 - there will be no error.
If a mock function's return type is a reference, you need to use `ReturnRef()` instead of `Return()` to return a result:
``` using ::testing::ReturnRef;
class MockFoo : public Foo {  public:   MOCK_METHOD0(GetBar, Bar&()); }; ...
MockFoo foo;   Bar bar;   EXPECT_CALL(foo, GetBar())       .WillOnce(ReturnRef(bar)); ```
The `Return(x)` action saves a copy of `x` when the action is _created_, and always returns the same value whenever it's executed. Sometimes you may want to instead return the _live_ value of `x` (i.e. its value at the time when the action is _executed_.).
If the mock function's return type is a reference, you can do it using `ReturnRef(x)`, as shown in the previous recipe ("Returning References from Mock Methods"). However, Google Mock doesn't let you use `ReturnRef()` in a mock function whose return type is not a reference, as doing that usually indicates a user error. So, what shall you do?
You may be tempted to try `ByRef()`:
``` using testing::ByRef; using testing::Return;
class MockFoo : public Foo {  public:   MOCK_METHOD0(GetValue, int()); }; ...   int x = 0;   MockFoo foo;   EXPECT_CALL(foo, GetValue())       .WillRepeatedly(Return(ByRef(x)));   x = 42;   EXPECT_EQ(42, foo.GetValue()); ```
Unfortunately, it doesn't work here. The above code will fail with error:
``` Value of: foo.GetValue()   Actual: 0 Expected: 42 ```
The reason is that `Return(value)` converts `value` to the actual return type of the mock function at the time when the action is _created_, not when it is _executed_. (This behavior was chosen for the action to be safe when `value` is a proxy object that references some temporary objects.) As a result, `ByRef(x)` is converted to an `int` value (instead of a `const int&`) when the expectation is set, and `Return(ByRef(x))` will always return 0.
`ReturnPointee(pointer)` was provided to solve this problem specifically. It returns the value pointed to by `pointer` at the time the action is _executed_:
``` using testing::ReturnPointee; ...   int x = 0;   MockFoo foo;   EXPECT_CALL(foo, GetValue())       .WillRepeatedly(ReturnPointee(&x));  // Note the & here.   x = 42;   EXPECT_EQ(42, foo.GetValue());  // This will succeed now. ```
Want to do more than one thing when a function is called? That's fine. `DoAll()` allow you to do sequence of actions every time. Only the return value of the last action in the sequence will be used.
``` using ::testing::DoAll;
class MockFoo : public Foo {  public:   MOCK_METHOD1(Bar, bool(int n)); }; ...
EXPECT_CALL(foo, Bar(_))       .WillOnce(DoAll(action_1,                       action_2,                       ...                       action_n)); ```
Sometimes a method exhibits its effect not via returning a value but via side effects. For example, it may change some global state or modify an output argument. To mock side effects, in general you can define your own action by implementing `::testing::ActionInterface`.
If all you need to do is to change an output argument, the built-in `SetArgPointee()` action is convenient:
``` using ::testing::SetArgPointee;
class MockMutator : public Mutator {  public:   MOCK_METHOD2(Mutate, void(bool mutate, int* value));   ... }; ...
MockMutator mutator;   EXPECT_CALL(mutator, Mutate(true, _))       .WillOnce(SetArgPointee<1>(5)); ```
In this example, when `mutator.Mutate()` is called, we will assign 5 to the `int` variable pointed to by argument #1 (0-based).
`SetArgPointee()` conveniently makes an internal copy of the value you pass to it, removing the need to keep the value in scope and alive. The implication however is that the value must have a copy constructor and assignment operator.
If the mock method also needs to return a value as well, you can chain `SetArgPointee()` with `Return()` using `DoAll()`:
``` using ::testing::_; using ::testing::Return; using ::testing::SetArgPointee;
class MockMutator : public Mutator {  public:   ...   MOCK_METHOD1(MutateInt, bool(int* value)); }; ...
MockMutator mutator;   EXPECT_CALL(mutator, MutateInt(_))       .WillOnce(DoAll(SetArgPointee<0>(5),                       Return(true))); ```
If the output argument is an array, use the `SetArrayArgument<N>(first, last)` action instead. It copies the elements in source range `[first, last)` to the array pointed to by the `N`-th (0-based) argument:
``` using ::testing::NotNull; using ::testing::SetArrayArgument;
class MockArrayMutator : public ArrayMutator {  public:   MOCK_METHOD2(Mutate, void(int* values, int num_values));   ... }; ...
MockArrayMutator mutator;   int values[5] = { 1, 2, 3, 4, 5 };   EXPECT_CALL(mutator, Mutate(NotNull(), 5))       .WillOnce(SetArrayArgument<0>(values, values + 5)); ```
This also works when the argument is an output iterator:
``` using ::testing::_; using ::testing::SeArrayArgument;
class MockRolodex : public Rolodex {  public:   MOCK_METHOD1(GetNames, void(std::back_insert_iterator<vector<string> >));   ... }; ...
MockRolodex rolodex;   vector<string> names;   names.push_back("George");   names.push_back("John");   names.push_back("Thomas");   EXPECT_CALL(rolodex, GetNames(_))       .WillOnce(SetArrayArgument<0>(names.begin(), names.end())); ```
If you expect a call to change the behavior of a mock object, you can use `::testing::InSequence` to specify different behaviors before and after the call:
``` using ::testing::InSequence; using ::testing::Return;
...   {     InSequence seq;     EXPECT_CALL(my_mock, IsDirty())         .WillRepeatedly(Return(true));     EXPECT_CALL(my_mock, Flush());     EXPECT_CALL(my_mock, IsDirty())         .WillRepeatedly(Return(false));   }   my_mock.FlushIfDirty(); ```
This makes `my_mock.IsDirty()` return `true` before `my_mock.Flush()` is called and return `false` afterwards.
If the behavior change is more complex, you can store the effects in a variable and make a mock method get its return value from that variable:
``` using ::testing::_; using ::testing::SaveArg; using ::testing::Return;
ACTION_P(ReturnPointee, p) { return *p; } ...   int previous_value = 0;   EXPECT_CALL(my_mock, GetPrevValue())       .WillRepeatedly(ReturnPointee(&previous_value));   EXPECT_CALL(my_mock, UpdateValue(_))       .WillRepeatedly(SaveArg<0>(&previous_value));   my_mock.DoSomethingToUpdateValue(); ```
Here `my_mock.GetPrevValue()` will always return the argument of the last `UpdateValue()` call.
If a mock method's return type is a built-in C++ type or pointer, by default it will return 0 when invoked. Also, in C++ 11 and above, a mock method whose return type has a default constructor will return a default-constructed value by default.  You only need to specify an action if this default value doesn't work for you.
Sometimes, you may want to change this default value, or you may want to specify a default value for types Google Mock doesn't know about. You can do this using the `::testing::DefaultValue` class template:
``` class MockFoo : public Foo {  public:   MOCK_METHOD0(CalculateBar, Bar()); }; ...
Bar default_bar;   // Sets the default return value for type Bar.   DefaultValue<Bar>::Set(default_bar);
MockFoo foo;
// We don't need to specify an action here, as the default   // return value works for us.   EXPECT_CALL(foo, CalculateBar());
foo.CalculateBar();  // This should return default_bar.
// Unsets the default return value.   DefaultValue<Bar>::Clear(); ```
Please note that changing the default value for a type can make you tests hard to understand. We recommend you to use this feature judiciously. For example, you may want to make sure the `Set()` and `Clear()` calls are right next to the code that uses your mock.
You've learned how to change the default value of a given type. However, this may be too coarse for your purpose: perhaps you have two mock methods with the same return type and you want them to have different behaviors. The `ON_CALL()` macro allows you to customize your mock's behavior at the method level:
``` using ::testing::_; using ::testing::AnyNumber; using ::testing::Gt; using ::testing::Return; ...   ON_CALL(foo, Sign(_))       .WillByDefault(Return(-1));   ON_CALL(foo, Sign(0))       .WillByDefault(Return(0));   ON_CALL(foo, Sign(Gt(0)))       .WillByDefault(Return(1));
EXPECT_CALL(foo, Sign(_))       .Times(AnyNumber());
foo.Sign(5);   // This should return 1.   foo.Sign(-9);  // This should return -1.   foo.Sign(0);   // This should return 0. ```
As you may have guessed, when there are more than one `ON_CALL()` statements, the news order take precedence over the older ones. In other words, the **last** one that matches the function arguments will be used. This matching order allows you to set up the common behavior in a mock object's constructor or the test fixture's set-up phase and specialize the mock's behavior later.
If the built-in actions don't suit you, you can easily use an existing function, method, or functor as an action:
``` using ::testing::_; using ::testing::Invoke;
class MockFoo : public Foo {  public:   MOCK_METHOD2(Sum, int(int x, int y));   MOCK_METHOD1(ComplexJob, bool(int x)); };
int CalculateSum(int x, int y) { return x + y; }
class Helper {  public:   bool ComplexJob(int x); }; ...
MockFoo foo;   Helper helper;   EXPECT_CALL(foo, Sum(_, _))       .WillOnce(Invoke(CalculateSum));   EXPECT_CALL(foo, ComplexJob(_))       .WillOnce(Invoke(&helper, &Helper::ComplexJob));
foo.Sum(5, 6);       // Invokes CalculateSum(5, 6).   foo.ComplexJob(10);  // Invokes helper.ComplexJob(10); ```
The only requirement is that the type of the function, etc must be _compatible_ with the signature of the mock function, meaning that the latter's arguments can be implicitly converted to the corresponding arguments of the former, and the former's return type can be implicitly converted to that of the latter. So, you can invoke something whose type is _not_ exactly the same as the mock function, as long as it's safe to do so - nice, huh?
`Invoke()` is very useful for doing actions that are more complex. It passes the mock function's arguments to the function or functor being invoked such that the callee has the full context of the call to work with. If the invoked function is not interested in some or all of the arguments, it can simply ignore them.
Yet, a common pattern is that a test author wants to invoke a function without the arguments of the mock function. `Invoke()` allows her to do that using a wrapper function that throws away the arguments before invoking an underlining nullary function. Needless to say, this can be tedious and obscures the intent of the test.
`InvokeWithoutArgs()` solves this problem. It's like `Invoke()` except that it doesn't pass the mock function's arguments to the callee. Here's an example:
``` using ::testing::_; using ::testing::InvokeWithoutArgs;
class MockFoo : public Foo {  public:   MOCK_METHOD1(ComplexJob, bool(int n)); };
bool Job1() { ... } ...
MockFoo foo;   EXPECT_CALL(foo, ComplexJob(_))       .WillOnce(InvokeWithoutArgs(Job1));
foo.ComplexJob(10);  // Invokes Job1(). ```
Sometimes a mock function will receive a function pointer or a functor (in other words, a "callable") as an argument, e.g.
``` class MockFoo : public Foo {  public:   MOCK_METHOD2(DoThis, bool(int n, bool (*fp)(int))); }; ```
and you may want to invoke this callable argument:
``` using ::testing::_; ...   MockFoo foo;   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(...);   // Will execute (*fp)(5), where fp is the   // second argument DoThis() receives. ```
Arghh, you need to refer to a mock function argument but C++ has no lambda (yet), so you have to define your own action. :-( Or do you really?
Well, Google Mock has an action to solve _exactly_ this problem:
```   InvokeArgument<N>(arg_1, arg_2, ..., arg_m) ```
will invoke the `N`-th (0-based) argument the mock function receives, with `arg_1`, `arg_2`, ..., and `arg_m`. No matter if the argument is a function pointer or a functor, Google Mock handles them both.
With that, you could write:
``` using ::testing::_; using ::testing::InvokeArgument; ...   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(InvokeArgument<1>(5));   // Will execute (*fp)(5), where fp is the   // second argument DoThis() receives. ```
What if the callable takes an argument by reference? No problem - just wrap it inside `ByRef()`:
``` ...   MOCK_METHOD1(Bar, bool(bool (*fp)(int, const Helper&))); ... using ::testing::_; using ::testing::ByRef; using ::testing::InvokeArgument; ...
MockFoo foo;   Helper helper;   ...   EXPECT_CALL(foo, Bar(_))       .WillOnce(InvokeArgument<0>(5, ByRef(helper)));   // ByRef(helper) guarantees that a reference to helper, not a copy of it,   // will be passed to the callable. ```
What if the callable takes an argument by reference and we do **not** wrap the argument in `ByRef()`? Then `InvokeArgument()` will _make a copy_ of the argument, and pass a _reference to the copy_, instead of a reference to the original value, to the callable. This is especially handy when the argument is a temporary value:
``` ...   MOCK_METHOD1(DoThat, bool(bool (*f)(const double& x, const string& s))); ... using ::testing::_; using ::testing::InvokeArgument; ...
MockFoo foo;   ...   EXPECT_CALL(foo, DoThat(_))       .WillOnce(InvokeArgument<0>(5.0, string("Hi")));   // Will execute (*f)(5.0, string("Hi")), where f is the function pointer   // DoThat() receives.  Note that the values 5.0 and string("Hi") are   // temporary and dead once the EXPECT_CALL() statement finishes.  Yet   // it's fine to perform this action later, since a copy of the values   // are kept inside the InvokeArgument action. ```
Sometimes you have an action that returns _something_, but you need an action that returns `void` (perhaps you want to use it in a mock function that returns `void`, or perhaps it needs to be used in `DoAll()` and it's not the last in the list). `IgnoreResult()` lets you do that. For example:
``` using ::testing::_; using ::testing::Invoke; using ::testing::Return;
int Process(const MyData& data); string DoSomething();
class MockFoo : public Foo {  public:   MOCK_METHOD1(Abc, void(const MyData& data));   MOCK_METHOD0(Xyz, bool()); }; ...
MockFoo foo;   EXPECT_CALL(foo, Abc(_))   // .WillOnce(Invoke(Process));   // The above line won't compile as Process() returns int but Abc() needs   // to return void.       .WillOnce(IgnoreResult(Invoke(Process)));
EXPECT_CALL(foo, Xyz())       .WillOnce(DoAll(IgnoreResult(Invoke(DoSomething)),       // Ignores the string DoSomething() returns.                       Return(true))); ```
Note that you **cannot** use `IgnoreResult()` on an action that already returns `void`. Doing so will lead to ugly compiler errors.
Say you have a mock function `Foo()` that takes seven arguments, and you have a custom action that you want to invoke when `Foo()` is called. Trouble is, the custom action only wants three arguments:
``` using ::testing::_; using ::testing::Invoke; ...   MOCK_METHOD7(Foo, bool(bool visible, const string& name, int x, int y,                          const map<pair<int, int>, double>& weight,                          double min_weight, double max_wight)); ...
bool IsVisibleInQuadrant1(bool visible, int x, int y) {   return visible && x >= 0 && y >= 0; } ...
EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(Invoke(IsVisibleInQuadrant1));  // Uh, won't compile. :-( ```
To please the compiler God, you can to define an "adaptor" that has the same signature as `Foo()` and calls the custom action with the right arguments:
``` using ::testing::_; using ::testing::Invoke;
bool MyIsVisibleInQuadrant1(bool visible, const string& name, int x, int y,                             const map<pair<int, int>, double>& weight,                             double min_weight, double max_wight) {   return IsVisibleInQuadrant1(visible, x, y); } ...
EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(Invoke(MyIsVisibleInQuadrant1));  // Now it works. ```
But isn't this awkward?
Google Mock provides a generic _action adaptor_, so you can spend your time minding more important business than writing your own adaptors. Here's the syntax:
```   WithArgs<N1, N2, ..., Nk>(action) ```
creates an action that passes the arguments of the mock function at the given indices (0-based) to the inner `action` and performs it. Using `WithArgs`, our original example can be written as:
``` using ::testing::_; using ::testing::Invoke; using ::testing::WithArgs; ...   EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(WithArgs<0, 2, 3>(Invoke(IsVisibleInQuadrant1)));       // No need to define your own adaptor. ```
For better readability, Google Mock also gives you:
* `WithoutArgs(action)` when the inner `action` takes _no_ argument, and   * `WithArg<N>(action)` (no `s` after `Arg`) when the inner `action` takes _one_ argument.
As you may have realized, `InvokeWithoutArgs(...)` is just syntactic sugar for `WithoutArgs(Invoke(...))`.
Here are more tips:
* The inner action used in `WithArgs` and friends does not have to be `Invoke()` -- it can be anything.   * You can repeat an argument in the argument list if necessary, e.g. `WithArgs<2, 3, 3, 5>(...)`.   * You can change the order of the arguments, e.g. `WithArgs<3, 2, 1>(...)`.   * The types of the selected arguments do _not_ have to match the signature of the inner action exactly. It works as long as they can be implicitly converted to the corresponding arguments of the inner action. For example, if the 4-th argument of the mock function is an `int` and `my_action` takes a `double`, `WithArg<4>(my_action)` will work.
The selecting-an-action's-arguments recipe showed us one way to make a mock function and an action with incompatible argument lists fit together. The downside is that wrapping the action in `WithArgs<...>()` can get tedious for people writing the tests.
If you are defining a function, method, or functor to be used with `Invoke*()`, and you are not interested in some of its arguments, an alternative to `WithArgs` is to declare the uninteresting arguments as `Unused`. This makes the definition less cluttered and less fragile in case the types of the uninteresting arguments change. It could also increase the chance the action function can be reused. For example, given
```   MOCK_METHOD3(Foo, double(const string& label, double x, double y));   MOCK_METHOD3(Bar, double(int index, double x, double y)); ```
instead of
``` using ::testing::_; using ::testing::Invoke;
double DistanceToOriginWithLabel(const string& label, double x, double y) {   return sqrt(x*x + y*y); }
double DistanceToOriginWithIndex(int index, double x, double y) {   return sqrt(x*x + y*y); } ...
EXEPCT_CALL(mock, Foo("abc", _, _))       .WillOnce(Invoke(DistanceToOriginWithLabel));   EXEPCT_CALL(mock, Bar(5, _, _))       .WillOnce(Invoke(DistanceToOriginWithIndex)); ```
you could write
``` using ::testing::_; using ::testing::Invoke; using ::testing::Unused;
double DistanceToOrigin(Unused, double x, double y) {   return sqrt(x*x + y*y); } ...
EXEPCT_CALL(mock, Foo("abc", _, _))       .WillOnce(Invoke(DistanceToOrigin));   EXEPCT_CALL(mock, Bar(5, _, _))       .WillOnce(Invoke(DistanceToOrigin)); ```
Just like matchers, a Google Mock action object consists of a pointer to a ref-counted implementation object. Therefore copying actions is also allowed and very efficient. When the last action that references the implementation object dies, the implementation object will be deleted.
If you have some complex action that you want to use again and again, you may not have to build it from scratch everytime. If the action doesn't have an internal state (i.e. if it always does the same thing no matter how many times it has been called), you can assign it to an action variable and use that variable repeatedly. For example:
```   Action<bool(int*)> set_flag = DoAll(SetArgPointee<0>(5),                                       Return(true));   ... use set_flag in .WillOnce() and .WillRepeatedly() ... ```
However, if the action has its own state, you may be surprised if you share the action object. Suppose you have an action factory `IncrementCounter(init)` which creates an action that increments and returns a counter whose initial value is `init`, using two actions created from the same expression and using a shared action will exihibit different behaviors. Example:
```   EXPECT_CALL(foo, DoThis())       .WillRepeatedly(IncrementCounter(0));   EXPECT_CALL(foo, DoThat())       .WillRepeatedly(IncrementCounter(0));   foo.DoThis();  // Returns 1.   foo.DoThis();  // Returns 2.   foo.DoThat();  // Returns 1 - Blah() uses a different                  // counter than Bar()'s. ```
versus
```   Action<int()> increment = IncrementCounter(0);
EXPECT_CALL(foo, DoThis())       .WillRepeatedly(increment);   EXPECT_CALL(foo, DoThat())       .WillRepeatedly(increment);   foo.DoThis();  // Returns 1.   foo.DoThis();  // Returns 2.   foo.DoThat();  // Returns 3 - the counter is shared. ```
C++11 introduced <em>move-only types</em>.  A move-only-typed value can be moved from one object to another, but cannot be copied.  `std::unique_ptr<T>` is probably the most commonly used move-only type.
Mocking a method that takes and/or returns move-only types presents some challenges, but nothing insurmountable.  This recipe shows you how you can do it.
Lets say we are working on a fictional project that lets one post and share snippets called buzzes.  Your code uses these types:
``` enum class AccessLevel { kInternal, kPublic };
class Buzz {  public:   explicit Buzz(AccessLevel access) {  }   ... };
class Buzzer {  public:   virtual ~Buzzer() {}   virtual std::unique_ptr<Buzz> MakeBuzz(const std::string& text) = 0;   virtual bool ShareBuzz(std::unique_ptr<Buzz> buzz, Time timestamp) = 0;   ... }; ```
A `Buzz` object represents a snippet being posted.  A class that implements the `Buzzer` interface is capable of creating and sharing `Buzz`.  Methods in `Buzzer` may return a `unique_ptr<Buzz>` or take a `unique_ptr<Buzz>`.  Now we need to mock `Buzzer` in our tests.
To mock a method that returns a move-only type, you just use the familiar `MOCK_METHOD` syntax as usual:
``` class MockBuzzer : public Buzzer {  public:   MOCK_METHOD1(MakeBuzz, std::unique_ptr<Buzz>(const std::string& text));    }; ```
However, if you attempt to use the same `MOCK_METHOD` pattern to mock a method that takes a move-only parameter, youll get a compiler error currently:
```   // Does NOT compile!   MOCK_METHOD2(ShareBuzz, bool(std::unique_ptr<Buzz> buzz, Time timestamp)); ```
While its highly desirable to make this syntax just work, its not trivial and the work hasnt been done yet.  Fortunately, there is a trick you can apply today to get something that works nearly as well as this.
The trick, is to delegate the `ShareBuzz()` method to a mock method (lets call it `DoShareBuzz()`) that does not take move-only parameters:
``` class MockBuzzer : public Buzzer {  public:   MOCK_METHOD1(MakeBuzz, std::unique_ptr<Buzz>(const std::string& text));   MOCK_METHOD2(DoShareBuzz, bool(Buzz* buzz, Time timestamp));   bool ShareBuzz(std::unique_ptr<Buzz> buzz, Time timestamp) {     return DoShareBuzz(buzz.get(), timestamp);   } }; ```
Note that there's no need to define or declare `DoShareBuzz()` in a base class.  You only need to define it as a `MOCK_METHOD` in the mock class.
Now that we have the mock class defined, we can use it in tests.  In the following code examples, we assume that we have defined a `MockBuzzer` object named `mock_buzzer_`:
```   MockBuzzer mock_buzzer_; ```
First lets see how we can set expectations on the `MakeBuzz()` method, which returns a `unique_ptr<Buzz>`.
As usual, if you set an expectation without an action (i.e. the `.WillOnce()` or `.WillRepeated()` clause), when that expectation fires, the default action for that method will be taken.  Since `unique_ptr<>` has a default constructor that returns a null `unique_ptr`, thats what youll get if you dont specify an action:
```   // Use the default action.   EXPECT_CALL(mock_buzzer_, MakeBuzz("hello"));
// Triggers the previous EXPECT_CALL.   EXPECT_EQ(nullptr, mock_buzzer_.MakeBuzz("hello")); ```
If you are not happy with the default action, you can tweak it.  Depending on what you need, you may either tweak the default action for a specific (mock object, mock method) combination using `ON_CALL()`, or you may tweak the default action for all mock methods that return a specific type.  The usage of `ON_CALL()` is similar to `EXPECT_CALL()`, so well skip it and just explain how to do the latter (tweaking the default action for a specific return type).  You do this via the `DefaultValue<>::SetFactory()` and `DefaultValue<>::Clear()` API:
```   // Sets the default action for return type std::unique_ptr<Buzz> to   // creating a new Buzz every time.   DefaultValue<std::unique_ptr<Buzz>>::SetFactory(       [] { return MakeUnique<Buzz>(AccessLevel::kInternal); });
// When this fires, the default action of MakeBuzz() will run, which   // will return a new Buzz object.   EXPECT_CALL(mock_buzzer_, MakeBuzz("hello")).Times(AnyNumber());
auto buzz1 = mock_buzzer_.MakeBuzz("hello");   auto buzz2 = mock_buzzer_.MakeBuzz("hello");   EXPECT_NE(nullptr, buzz1);   EXPECT_NE(nullptr, buzz2);   EXPECT_NE(buzz1, buzz2);
// Resets the default action for return type std::unique_ptr<Buzz>,   // to avoid interfere with other tests.   DefaultValue<std::unique_ptr<Buzz>>::Clear(); ```
What if you want the method to do something other than the default action?  If you just need to return a pre-defined move-only value, you can use the `Return(ByMove(...))` action:
```   // When this fires, the unique_ptr<> specified by ByMove(...) will   // be returned.   EXPECT_CALL(mock_buzzer_, MakeBuzz("world"))       .WillOnce(Return(ByMove(MakeUnique<Buzz>(AccessLevel::kInternal))));
EXPECT_NE(nullptr, mock_buzzer_.MakeBuzz("world")); ```
Note that `ByMove()` is essential here - if you drop it, the code wont compile.
Quiz time!  What do you think will happen if a `Return(ByMove(...))` action is performed more than once (e.g. you write `.WillRepeatedly(Return(ByMove(...)));`)?  Come think of it, after the first time the action runs, the source value will be consumed (since its a move-only value), so the next time around, theres no value to move from -- youll get a run-time error that `Return(ByMove(...))` can only be run once.
If you need your mock method to do more than just moving a pre-defined value, remember that you can always use `Invoke()` to call a lambda or a callable object, which can do pretty much anything you want:
```   EXPECT_CALL(mock_buzzer_, MakeBuzz("x"))       .WillRepeatedly(Invoke([](const std::string& text) {         return std::make_unique<Buzz>(AccessLevel::kInternal);       }));
EXPECT_NE(nullptr, mock_buzzer_.MakeBuzz("x"));   EXPECT_NE(nullptr, mock_buzzer_.MakeBuzz("x")); ```
Every time this `EXPECT_CALL` fires, a new `unique_ptr<Buzz>` will be created and returned.  You cannot do this with `Return(ByMove(...))`.
Now theres one topic we havent covered: how do you set expectations on `ShareBuzz()`, which takes a move-only-typed parameter?  The answer is you dont.  Instead, you set expectations on the `DoShareBuzz()` mock method (remember that we defined a `MOCK_METHOD` for `DoShareBuzz()`, not `ShareBuzz()`):
```   EXPECT_CALL(mock_buzzer_, DoShareBuzz(NotNull(), _));
// When one calls ShareBuzz() on the MockBuzzer like this, the call is   // forwarded to DoShareBuzz(), which is mocked.  Therefore this statement   // will trigger the above EXPECT_CALL.   mock_buzzer_.ShareBuzz(MakeUnique&lt;Buzz&gt;(AccessLevel::kInternal),                          ::base::Now()); ```
Some of you may have spotted one problem with this approach: the `DoShareBuzz()` mock method differs from the real `ShareBuzz()` method in that it cannot take ownership of the buzz parameter - `ShareBuzz()` will always delete buzz after `DoShareBuzz()` returns.  What if you need to save the buzz object somewhere for later use when `ShareBuzz()` is called?  Indeed, you'd be stuck.
Another problem with the `DoShareBuzz()` we had is that it can surprise people reading or maintaining the test, as one would expect that `DoShareBuzz()` has (logically) the same contract as `ShareBuzz()`.
Fortunately, these problems can be fixed with a bit more code.  Let's try to get it right this time:
``` class MockBuzzer : public Buzzer {  public:   MockBuzzer() {     // Since DoShareBuzz(buzz, time) is supposed to take ownership of     // buzz, define a default behavior for DoShareBuzz(buzz, time) to     // delete buzz.     ON_CALL(*this, DoShareBuzz(_, _))         .WillByDefault(Invoke([](Buzz* buzz, Time timestamp) {           delete buzz;           return true;         }));   }
MOCK_METHOD1(MakeBuzz, std::unique_ptr<Buzz>(const std::string& text));
// Takes ownership of buzz.   MOCK_METHOD2(DoShareBuzz, bool(Buzz* buzz, Time timestamp));   bool ShareBuzz(std::unique_ptr<Buzz> buzz, Time timestamp) {     return DoShareBuzz(buzz.release(), timestamp);   } }; ```
Now, the mock `DoShareBuzz()` method is free to save the buzz argument for later use if this is what you want:
```   std::unique_ptr<Buzz> intercepted_buzz;   EXPECT_CALL(mock_buzzer_, DoShareBuzz(NotNull(), _))       .WillOnce(Invoke([&amp;intercepted_buzz](Buzz* buzz, Time timestamp) {         // Save buzz in intercepted_buzz for analysis later.         intercepted_buzz.reset(buzz);         return false;       }));
mock_buzzer_.ShareBuzz(std::make_unique<Buzz>(AccessLevel::kInternal),                          Now());   EXPECT_NE(nullptr, intercepted_buzz); ```
Using the tricks covered in this recipe, you are now able to mock methods that take and/or return move-only types.  Put your newly-acquired power to good use - when you design a new API, you can now feel comfortable using `unique_ptrs` as appropriate, without fearing that doing so will compromise your tests.
Believe it or not, the _vast majority_ of the time spent on compiling a mock class is in generating its constructor and destructor, as they perform non-trivial tasks (e.g. verification of the expectations). What's more, mock methods with different signatures have different types and thus their constructors/destructors need to be generated by the compiler separately. As a result, if you mock many different types of methods, compiling your mock class can get really slow.
If you are experiencing slow compilation, you can move the definition of your mock class' constructor and destructor out of the class body and into a `.cpp` file. This way, even if you `#include` your mock class in N files, the compiler only needs to generate its constructor and destructor once, resulting in a much faster compilation.
Let's illustrate the idea using an example. Here's the definition of a mock class before applying this recipe:
``` // File mock_foo.h. ... class MockFoo : public Foo {  public:   // Since we don't declare the constructor or the destructor,   // the compiler will generate them in every translation unit   // where this mock class is used.
MOCK_METHOD0(DoThis, int());   MOCK_METHOD1(DoThat, bool(const char* str));   ... more mock methods ... }; ```
After the change, it would look like:
``` // File mock_foo.h. ... class MockFoo : public Foo {  public:   // The constructor and destructor are declared, but not defined, here.   MockFoo();   virtual ~MockFoo();
MOCK_METHOD0(DoThis, int());   MOCK_METHOD1(DoThat, bool(const char* str));   ... more mock methods ... }; ``` and ``` // File mock_foo.cpp. #include "path/to/mock_foo.h"
// The definitions may appear trivial, but the functions actually do a // lot of things through the constructors/destructors of the member // variables used to implement the mock methods. MockFoo::MockFoo() {} MockFoo::~MockFoo() {} ```
When it's being destoyed, your friendly mock object will automatically verify that all expectations on it have been satisfied, and will generate [Google Test](../../googletest/) failures if not. This is convenient as it leaves you with one less thing to worry about. That is, unless you are not sure if your mock object will be destoyed.
How could it be that your mock object won't eventually be destroyed? Well, it might be created on the heap and owned by the code you are testing. Suppose there's a bug in that code and it doesn't delete the mock object properly - you could end up with a passing test when there's actually a bug.
Using a heap checker is a good idea and can alleviate the concern, but its implementation may not be 100% reliable. So, sometimes you do want to _force_ Google Mock to verify a mock object before it is (hopefully) destructed. You can do this with `Mock::VerifyAndClearExpectations(&mock_object)`:
``` TEST(MyServerTest, ProcessesRequest) {   using ::testing::Mock;
MockFoo* const foo = new MockFoo;   EXPECT_CALL(*foo, ...)...;   // ... other expectations ...
// server now owns foo.   MyServer server(foo);   server.ProcessRequest(...);
// In case that server's destructor will forget to delete foo,   // this will verify the expectations anyway.   Mock::VerifyAndClearExpectations(foo); }  // server is destroyed when it goes out of scope here. ```
**Tip:** The `Mock::VerifyAndClearExpectations()` function returns a `bool` to indicate whether the verification was successful (`true` for yes), so you can wrap that function call inside a `ASSERT_TRUE()` if there is no point going further when the verification has failed.
Sometimes you may want to "reset" a mock object at various check points in your test: at each check point, you verify that all existing expectations on the mock object have been satisfied, and then you set some new expectations on it as if it's newly created. This allows you to work with a mock object in "phases" whose sizes are each manageable.
One such scenario is that in your test's `SetUp()` function, you may want to put the object you are testing into a certain state, with the help from a mock object. Once in the desired state, you want to clear all expectations on the mock, such that in the `TEST_F` body you can set fresh expectations on it.
As you may have figured out, the `Mock::VerifyAndClearExpectations()` function we saw in the previous recipe can help you here. Or, if you are using `ON_CALL()` to set default actions on the mock object and want to clear the default actions as well, use `Mock::VerifyAndClear(&mock_object)` instead. This function does what `Mock::VerifyAndClearExpectations(&mock_object)` does and returns the same `bool`, **plus** it clears the `ON_CALL()` statements on `mock_object` too.
Another trick you can use to achieve the same effect is to put the expectations in sequences and insert calls to a dummy "check-point" function at specific places. Then you can verify that the mock function calls do happen at the right time. For example, if you are exercising code:
``` Foo(1); Foo(2); Foo(3); ```
and want to verify that `Foo(1)` and `Foo(3)` both invoke `mock.Bar("a")`, but `Foo(2)` doesn't invoke anything. You can write:
``` using ::testing::MockFunction;
TEST(FooTest, InvokesBarCorrectly) {   MyMock mock;   // Class MockFunction<F> has exactly one mock method.  It is named   // Call() and has type F.   MockFunction<void(string check_point_name)> check;   {     InSequence s;
EXPECT_CALL(mock, Bar("a"));     EXPECT_CALL(check, Call("1"));     EXPECT_CALL(check, Call("2"));     EXPECT_CALL(mock, Bar("a"));   }   Foo(1);   check.Call("1");   Foo(2);   check.Call("2");   Foo(3); } ```
The expectation spec says that the first `Bar("a")` must happen before check point "1", the second `Bar("a")` must happen after check point "2", and nothing should happen between the two check points. The explicit check points make it easy to tell which `Bar("a")` is called by which call to `Foo()`.
Sometimes you want to make sure a mock object is destructed at the right time, e.g. after `bar->A()` is called but before `bar->B()` is called. We already know that you can specify constraints on the order of mock function calls, so all we need to do is to mock the destructor of the mock function.
This sounds simple, except for one problem: a destructor is a special function with special syntax and special semantics, and the `MOCK_METHOD0` macro doesn't work for it:
```   MOCK_METHOD0(~MockFoo, void());  // Won't compile! ```
The good news is that you can use a simple pattern to achieve the same effect. First, add a mock function `Die()` to your mock class and call it in the destructor, like this:
``` class MockFoo : public Foo {   ...   // Add the following two lines to the mock class.   MOCK_METHOD0(Die, void());   virtual ~MockFoo() { Die(); } }; ```
(If the name `Die()` clashes with an existing symbol, choose another name.) Now, we have translated the problem of testing when a `MockFoo` object dies to testing when its `Die()` method is called:
```   MockFoo* foo = new MockFoo;   MockBar* bar = new MockBar;   ...   {     InSequence s;
// Expects *foo to die after bar->A() and before bar->B().     EXPECT_CALL(*bar, A());     EXPECT_CALL(*foo, Die());     EXPECT_CALL(*bar, B());   } ```
And that's that.
**IMPORTANT NOTE:** What we describe in this recipe is **ONLY** true on platforms where Google Mock is thread-safe. Currently these are only platforms that support the pthreads library (this includes Linux and Mac). To make it thread-safe on other platforms we only need to implement some synchronization operations in `"gtest/internal/gtest-port.h"`.
In a **unit** test, it's best if you could isolate and test a piece of code in a single-threaded context. That avoids race conditions and dead locks, and makes debugging your test much easier.
Yet many programs are multi-threaded, and sometimes to test something we need to pound on it from more than one thread. Google Mock works for this purpose too.
Remember the steps for using a mock:
1. Create a mock object `foo`.   1. Set its default actions and expectations using `ON_CALL()` and `EXPECT_CALL()`.   1. The code under test calls methods of `foo`.   1. Optionally, verify and reset the mock.   1. Destroy the mock yourself, or let the code under test destroy it. The destructor will automatically verify it.
If you follow the following simple rules, your mocks and threads can live happily together:
* Execute your _test code_ (as opposed to the code being tested) in _one_ thread. This makes your test easy to follow.   * Obviously, you can do step #1 without locking.   * When doing step #2 and #5, make sure no other thread is accessing `foo`. Obvious too, huh?   * #3 and #4 can be done either in one thread or in multiple threads - anyway you want. Google Mock takes care of the locking, so you don't have to do any - unless required by your test logic.
If you violate the rules (for example, if you set expectations on a mock while another thread is calling its methods), you get undefined behavior. That's not fun, so don't do it.
Google Mock guarantees that the action for a mock function is done in the same thread that called the mock function. For example, in
```   EXPECT_CALL(mock, Foo(1))       .WillOnce(action1);   EXPECT_CALL(mock, Foo(2))       .WillOnce(action2); ```
if `Foo(1)` is called in thread 1 and `Foo(2)` is called in thread 2, Google Mock will execute `action1` in thread 1 and `action2` in thread 2.
Google Mock does _not_ impose a sequence on actions performed in different threads (doing so may create deadlocks as the actions may need to cooperate). This means that the execution of `action1` and `action2` in the above example _may_ interleave. If this is a problem, you should add proper synchronization logic to `action1` and `action2` to make the test thread-safe.
Also, remember that `DefaultValue<T>` is a global resource that potentially affects _all_ living mock objects in your program. Naturally, you won't want to mess with it from multiple threads or when there still are mocks in action.
When Google Mock sees something that has the potential of being an error (e.g. a mock function with no expectation is called, a.k.a. an uninteresting call, which is allowed but perhaps you forgot to explicitly ban the call), it prints some warning messages, including the arguments of the function and the return value. Hopefully this will remind you to take a look and see if there is indeed a problem.
Sometimes you are confident that your tests are correct and may not appreciate such friendly messages. Some other times, you are debugging your tests or learning about the behavior of the code you are testing, and wish you could observe every mock call that happens (including argument values and the return value). Clearly, one size doesn't fit all.
You can control how much Google Mock tells you using the `--gmock_verbose=LEVEL` command-line flag, where `LEVEL` is a string with three possible values:
* `info`: Google Mock will print all informational messages, warnings, and errors (most verbose). At this setting, Google Mock will also log any calls to the `ON_CALL/EXPECT_CALL` macros.   * `warning`: Google Mock will print both warnings and errors (less verbose). This is the default.   * `error`: Google Mock will print errors only (least verbose).
Alternatively, you can adjust the value of that flag from within your tests like so:
```   ::testing::FLAGS_gmock_verbose = "error"; ```
Now, judiciously use the right flag to enable Google Mock serve you better!
You have a test using Google Mock. It fails: Google Mock tells you that some expectations aren't satisfied. However, you aren't sure why: Is there a typo somewhere in the matchers? Did you mess up the order of the `EXPECT_CALL`s? Or is the code under test doing something wrong?  How can you find out the cause?
Won't it be nice if you have X-ray vision and can actually see the trace of all `EXPECT_CALL`s and mock method calls as they are made? For each call, would you like to see its actual argument values and which `EXPECT_CALL` Google Mock thinks it matches?
You can unlock this power by running your test with the `--gmock_verbose=info` flag. For example, given the test program:
``` using testing::_; using testing::HasSubstr; using testing::Return;
class MockFoo {  public:   MOCK_METHOD2(F, void(const string& x, const string& y)); };
TEST(Foo, Bar) {   MockFoo mock;   EXPECT_CALL(mock, F(_, _)).WillRepeatedly(Return());   EXPECT_CALL(mock, F("a", "b"));   EXPECT_CALL(mock, F("c", HasSubstr("d")));
mock.F("a", "good");   mock.F("a", "b"); } ```
if you run it with `--gmock_verbose=info`, you will see this output:
``` [ RUN      ] Foo.Bar
foo_test.cc:14: EXPECT_CALL(mock, F(_, _)) invoked foo_test.cc:15: EXPECT_CALL(mock, F("a", "b")) invoked foo_test.cc:16: EXPECT_CALL(mock, F("c", HasSubstr("d"))) invoked foo_test.cc:14: Mock function call matches EXPECT_CALL(mock, F(_, _))...     Function call: F(@0x7fff7c8dad40"a", @0x7fff7c8dad10"good") foo_test.cc:15: Mock function call matches EXPECT_CALL(mock, F("a", "b"))...     Function call: F(@0x7fff7c8dada0"a", @0x7fff7c8dad70"b") foo_test.cc:16: Failure Actual function call count doesn't match EXPECT_CALL(mock, F("c", HasSubstr("d")))...          Expected: to be called once            Actual: never called - unsatisfied and active [  FAILED  ] Foo.Bar ```
Suppose the bug is that the `"c"` in the third `EXPECT_CALL` is a typo and should actually be `"a"`. With the above message, you should see that the actual `F("a", "good")` call is matched by the first `EXPECT_CALL`, not the third as you thought. From that it should be obvious that the third `EXPECT_CALL` is written wrong. Case solved.
If you build and run your tests in Emacs, the source file locations of Google Mock and [Google Test](../../googletest/) errors will be highlighted. Just press `<Enter>` on one of them and you'll be taken to the offending line. Or, you can just type `C-x `` to jump to the next error.
To make it even easier, you can add the following lines to your `~/.emacs` file:
``` (global-set-key "\M-m"   'compile)  ; m is for make (global-set-key [M-down] 'next-error) (global-set-key [M-up]   '(lambda () (interactive) (next-error -1))) ```
Then you can type `M-m` to start a build, or `M-up`/`M-down` to move back and forth between errors.
Google Mock's implementation consists of dozens of files (excluding its own tests).  Sometimes you may want them to be packaged up in fewer files instead, such that you can easily copy them to a new machine and start hacking there.  For this we provide an experimental Python script `fuse_gmock_files.py` in the `scripts/` directory (starting with release 1.2.0).  Assuming you have Python 2.4 or above installed on your machine, just go to that directory and run ``` python fuse_gmock_files.py OUTPUT_DIR ```
and you should see an `OUTPUT_DIR` directory being created with files `gtest/gtest.h`, `gmock/gmock.h`, and `gmock-gtest-all.cc` in it. These three files contain everything you need to use Google Mock (and Google Test).  Just copy them to anywhere you want and you are ready to write tests and use mocks.  You can use the [scrpts/test/Makefile](../scripts/test/Makefile) file as an example on how to compile your tests against them.
The `MATCHER*` family of macros can be used to define custom matchers easily.  The syntax:
``` MATCHER(name, description_string_expression) { statements; } ```
will define a matcher with the given name that executes the statements, which must return a `bool` to indicate if the match succeeds.  Inside the statements, you can refer to the value being matched by `arg`, and refer to its type by `arg_type`.
The description string is a `string`-typed expression that documents what the matcher does, and is used to generate the failure message when the match fails.  It can (and should) reference the special `bool` variable `negation`, and should evaluate to the description of the matcher when `negation` is `false`, or that of the matcher's negation when `negation` is `true`.
For convenience, we allow the description string to be empty (`""`), in which case Google Mock will use the sequence of words in the matcher name as the description.
For example: ``` MATCHER(IsDivisibleBy7, "") { return (arg % 7) == 0; } ``` allows you to write ```   // Expects mock_foo.Bar(n) to be called where n is divisible by 7.   EXPECT_CALL(mock_foo, Bar(IsDivisibleBy7())); ``` or, ``` using ::testing::Not; ...   EXPECT_THAT(some_expression, IsDivisibleBy7());   EXPECT_THAT(some_other_expression, Not(IsDivisibleBy7())); ``` If the above assertions fail, they will print something like: ```   Value of: some_expression   Expected: is divisible by 7     Actual: 27 ...   Value of: some_other_expression   Expected: not (is divisible by 7)     Actual: 21 ``` where the descriptions `"is divisible by 7"` and `"not (is divisible by 7)"` are automatically calculated from the matcher name `IsDivisibleBy7`.
As you may have noticed, the auto-generated descriptions (especially those for the negation) may not be so great. You can always override them with a string expression of your own: ``` MATCHER(IsDivisibleBy7, std::string(negation ? "isn't" : "is") +                         " divisible by 7") {   return (arg % 7) == 0; } ```
Optionally, you can stream additional information to a hidden argument named `result_listener` to explain the match result. For example, a better definition of `IsDivisibleBy7` is: ``` MATCHER(IsDivisibleBy7, "") {   if ((arg % 7) == 0)     return true;
*result_listener << "the remainder is " << (arg % 7);   return false; } ```
With this definition, the above assertion will give a better message: ```   Value of: some_expression   Expected: is divisible by 7     Actual: 27 (the remainder is 6) ```
You should let `MatchAndExplain()` print _any additional information_ that can help a user understand the match result. Note that it should explain why the match succeeds in case of a success (unless it's obvious) - this is useful when the matcher is used inside `Not()`. There is no need to print the argument value itself, as Google Mock already prints it for you.
**Notes:**
1. The type of the value being matched (`arg_type`) is determined by the context in which you use the matcher and is supplied to you by the compiler, so you don't need to worry about declaring it (nor can you).  This allows the matcher to be polymorphic.  For example, `IsDivisibleBy7()` can be used to match any type where the value of `(arg % 7) == 0` can be implicitly converted to a `bool`.  In the `Bar(IsDivisibleBy7())` example above, if method `Bar()` takes an `int`, `arg_type` will be `int`; if it takes an `unsigned long`, `arg_type` will be `unsigned long`; and so on.   1. Google Mock doesn't guarantee when or how many times a matcher will be invoked. Therefore the matcher logic must be _purely functional_ (i.e. it cannot have any side effect, and the result must not depend on anything other than the value being matched and the matcher parameters). This requirement must be satisfied no matter how you define the matcher (e.g. using one of the methods described in the following recipes). In particular, a matcher can never call a mock function, as that will affect the state of the mock object and Google Mock.
Sometimes you'll want to define a matcher that has parameters.  For that you can use the macro: ``` MATCHER_P(name, param_name, description_string) { statements; } ``` where the description string can be either `""` or a string expression that references `negation` and `param_name`.
For example: ``` MATCHER_P(HasAbsoluteValue, value, "") { return abs(arg) == value; } ``` will allow you to write: ```   EXPECT_THAT(Blah("a"), HasAbsoluteValue(n)); ``` which may lead to this message (assuming `n` is 10): ```   Value of: Blah("a")   Expected: has absolute value 10     Actual: -9 ```
Note that both the matcher description and its parameter are printed, making the message human-friendly.
In the matcher definition body, you can write `foo_type` to reference the type of a parameter named `foo`.  For example, in the body of `MATCHER_P(HasAbsoluteValue, value)` above, you can write `value_type` to refer to the type of `value`.
Google Mock also provides `MATCHER_P2`, `MATCHER_P3`, ..., up to `MATCHER_P10` to support multi-parameter matchers: ``` MATCHER_Pk(name, param_1, ..., param_k, description_string) { statements; } ```
Please note that the custom description string is for a particular **instance** of the matcher, where the parameters have been bound to actual values.  Therefore usually you'll want the parameter values to be part of the description.  Google Mock lets you do that by referencing the matcher parameters in the description string expression.
For example, ```   using ::testing::PrintToString;   MATCHER_P2(InClosedRange, low, hi,              std::string(negation ? "isn't" : "is") + " in range [" +              PrintToString(low) + ", " + PrintToString(hi) + "]") {     return low <= arg && arg <= hi;   }   ...   EXPECT_THAT(3, InClosedRange(4, 6)); ``` would generate a failure that contains the message: ```   Expected: is in range [4, 6] ```
If you specify `""` as the description, the failure message will contain the sequence of words in the matcher name followed by the parameter values printed as a tuple.  For example, ```   MATCHER_P2(InClosedRange, low, hi, "") { ... }   ...   EXPECT_THAT(3, InClosedRange(4, 6)); ``` would generate a failure that contains the text: ```   Expected: in closed range (4, 6) ```
For the purpose of typing, you can view ``` MATCHER_Pk(Foo, p1, ..., pk, description_string) { ... } ``` as shorthand for ``` template <typename p1_type, ..., typename pk_type> FooMatcherPk<p1_type, ..., pk_type> Foo(p1_type p1, ..., pk_type pk) { ... } ```
When you write `Foo(v1, ..., vk)`, the compiler infers the types of the parameters `v1`, ..., and `vk` for you.  If you are not happy with the result of the type inference, you can specify the types by explicitly instantiating the template, as in `Foo<long, bool>(5, false)`. As said earlier, you don't get to (or need to) specify `arg_type` as that's determined by the context in which the matcher is used.
You can assign the result of expression `Foo(p1, ..., pk)` to a variable of type `FooMatcherPk<p1_type, ..., pk_type>`.  This can be useful when composing matchers.  Matchers that don't have a parameter or have only one parameter have special types: you can assign `Foo()` to a `FooMatcher`-typed variable, and assign `Foo(p)` to a `FooMatcherP<p_type>`-typed variable.
While you can instantiate a matcher template with reference types, passing the parameters by pointer usually makes your code more readable.  If, however, you still want to pass a parameter by reference, be aware that in the failure message generated by the matcher you will see the value of the referenced object but not its address.
You can overload matchers with different numbers of parameters: ``` MATCHER_P(Blah, a, description_string_1) { ... } MATCHER_P2(Blah, a, b, description_string_2) { ... } ```
While it's tempting to always use the `MATCHER*` macros when defining a new matcher, you should also consider implementing `MatcherInterface` or using `MakePolymorphicMatcher()` instead (see the recipes that follow), especially if you need to use the matcher a lot.  While these approaches require more work, they give you more control on the types of the value being matched and the matcher parameters, which in general leads to better compiler error messages that pay off in the long run.  They also allow overloading matchers based on parameter types (as opposed to just based on the number of parameters).
A matcher of argument type `T` implements `::testing::MatcherInterface<T>` and does two things: it tests whether a value of type `T` matches the matcher, and can describe what kind of values it matches. The latter ability is used for generating readable error messages when expectations are violated.
The interface looks like this:
``` class MatchResultListener {  public:   ...   // Streams x to the underlying ostream; does nothing if the ostream   // is NULL.   template <typename T>   MatchResultListener& operator<<(const T& x);
// Returns the underlying ostream.   ::std::ostream* stream(); };
template <typename T> class MatcherInterface {  public:   virtual ~MatcherInterface();
// Returns true iff the matcher matches x; also explains the match   // result to 'listener'.   virtual bool MatchAndExplain(T x, MatchResultListener* listener) const = 0;
// Describes this matcher to an ostream.   virtual void DescribeTo(::std::ostream* os) const = 0;
// Describes the negation of this matcher to an ostream.   virtual void DescribeNegationTo(::std::ostream* os) const; }; ```
If you need a custom matcher but `Truly()` is not a good option (for example, you may not be happy with the way `Truly(predicate)` describes itself, or you may want your matcher to be polymorphic as `Eq(value)` is), you can define a matcher to do whatever you want in two steps: first implement the matcher interface, and then define a factory function to create a matcher instance. The second step is not strictly needed but it makes the syntax of using the matcher nicer.
For example, you can define a matcher to test whether an `int` is divisible by 7 and then use it like this: ``` using ::testing::MakeMatcher; using ::testing::Matcher; using ::testing::MatcherInterface; using ::testing::MatchResultListener;
class DivisibleBy7Matcher : public MatcherInterface<int> {  public:   virtual bool MatchAndExplain(int n, MatchResultListener* listener) const {     return (n % 7) == 0;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "is divisible by 7";   }
virtual void DescribeNegationTo(::std::ostream* os) const {     *os << "is not divisible by 7";   } };
inline Matcher<int> DivisibleBy7() {   return MakeMatcher(new DivisibleBy7Matcher); } ...
EXPECT_CALL(foo, Bar(DivisibleBy7())); ```
You may improve the matcher message by streaming additional information to the `listener` argument in `MatchAndExplain()`:
``` class DivisibleBy7Matcher : public MatcherInterface<int> {  public:   virtual bool MatchAndExplain(int n,                                MatchResultListener* listener) const {     const int remainder = n % 7;     if (remainder != 0) {       *listener << "the remainder is " << remainder;     }     return remainder == 0;   }   ... }; ```
Then, `EXPECT_THAT(x, DivisibleBy7());` may general a message like this: ``` Value of: x Expected: is divisible by 7   Actual: 23 (the remainder is 2) ```
You've learned how to write your own matchers in the previous recipe. Just one problem: a matcher created using `MakeMatcher()` only works for one particular type of arguments. If you want a _polymorphic_ matcher that works with arguments of several types (for instance, `Eq(x)` can be used to match a `value` as long as `value` == `x` compiles -- `value` and `x` don't have to share the same type), you can learn the trick from `"gmock/gmock-matchers.h"` but it's a bit involved.
Fortunately, most of the time you can define a polymorphic matcher easily with the help of `MakePolymorphicMatcher()`. Here's how you can define `NotNull()` as an example:
``` using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; using ::testing::NotNull; using ::testing::PolymorphicMatcher;
class NotNullMatcher {  public:   // To implement a polymorphic matcher, first define a COPYABLE class   // that has three members MatchAndExplain(), DescribeTo(), and   // DescribeNegationTo(), like the following.
// In this example, we want to use NotNull() with any pointer, so   // MatchAndExplain() accepts a pointer of any type as its first argument.   // In general, you can define MatchAndExplain() as an ordinary method or   // a method template, or even overload it.   template <typename T>   bool MatchAndExplain(T* p,                        MatchResultListener* /* listener */) const {     return p != NULL;   }
// Describes the property of a value matching this matcher.   void DescribeTo(::std::ostream* os) const { *os << "is not NULL"; }
// Describes the property of a value NOT matching this matcher.   void DescribeNegationTo(::std::ostream* os) const { *os << "is NULL"; } };
// To construct a polymorphic matcher, pass an instance of the class // to MakePolymorphicMatcher().  Note the return type. inline PolymorphicMatcher<NotNullMatcher> NotNull() {   return MakePolymorphicMatcher(NotNullMatcher()); } ...
EXPECT_CALL(foo, Bar(NotNull()));  // The argument must be a non-NULL pointer. ```
**Note:** Your polymorphic matcher class does **not** need to inherit from `MatcherInterface` or any other class, and its methods do **not** need to be virtual.
Like in a monomorphic matcher, you may explain the match result by streaming additional information to the `listener` argument in `MatchAndExplain()`.
A cardinality is used in `Times()` to tell Google Mock how many times you expect a call to occur. It doesn't have to be exact. For example, you can say `AtLeast(5)` or `Between(2, 4)`.
If the built-in set of cardinalities doesn't suit you, you are free to define your own by implementing the following interface (in namespace `testing`):
``` class CardinalityInterface {  public:   virtual ~CardinalityInterface();
// Returns true iff call_count calls will satisfy this cardinality.   virtual bool IsSatisfiedByCallCount(int call_count) const = 0;
// Returns true iff call_count calls will saturate this cardinality.   virtual bool IsSaturatedByCallCount(int call_count) const = 0;
// Describes self to an ostream.   virtual void DescribeTo(::std::ostream* os) const = 0; }; ```
For example, to specify that a call must occur even number of times, you can write
``` using ::testing::Cardinality; using ::testing::CardinalityInterface; using ::testing::MakeCardinality;
class EvenNumberCardinality : public CardinalityInterface {  public:   virtual bool IsSatisfiedByCallCount(int call_count) const {     return (call_count % 2) == 0;   }
virtual bool IsSaturatedByCallCount(int call_count) const {     return false;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "called even number of times";   } };
Cardinality EvenNumber() {   return MakeCardinality(new EvenNumberCardinality); } ...
EXPECT_CALL(foo, Bar(3))       .Times(EvenNumber()); ```
If the built-in actions don't work for you, and you find it inconvenient to use `Invoke()`, you can use a macro from the `ACTION*` family to quickly define a new action that can be used in your code as if it's a built-in action.
By writing ``` ACTION(name) { statements; } ``` in a namespace scope (i.e. not inside a class or function), you will define an action with the given name that executes the statements. The value returned by `statements` will be used as the return value of the action.  Inside the statements, you can refer to the K-th (0-based) argument of the mock function as `argK`.  For example: ``` ACTION(IncrementArg1) { return ++(*arg1); } ``` allows you to write ``` ... WillOnce(IncrementArg1()); ```
Note that you don't need to specify the types of the mock function arguments.  Rest assured that your code is type-safe though: you'll get a compiler error if `*arg1` doesn't support the `++` operator, or if the type of `++(*arg1)` isn't compatible with the mock function's return type.
Another example: ``` ACTION(Foo) {   (*arg2)(5);   Blah();   *arg1 = 0;   return arg0; } ``` defines an action `Foo()` that invokes argument #2 (a function pointer) with 5, calls function `Blah()`, sets the value pointed to by argument #1 to 0, and returns argument #0.
For more convenience and flexibility, you can also use the following pre-defined symbols in the body of `ACTION`:
| `argK_type` | The type of the K-th (0-based) argument of the mock function | |:------------|:-------------------------------------------------------------| | `args`      | All arguments of the mock function as a tuple                | | `args_type` | The type of all arguments of the mock function as a tuple    | | `return_type` | The return type of the mock function                         | | `function_type` | The type of the mock function                                |
For example, when using an `ACTION` as a stub action for mock function: ``` int DoSomething(bool flag, int* ptr); ``` we have: | **Pre-defined Symbol** | **Is Bound To** | |:-----------------------|:----------------| | `arg0`                 | the value of `flag` | | `arg0_type`            | the type `bool` | | `arg1`                 | the value of `ptr` | | `arg1_type`            | the type `int*` | | `args`                 | the tuple `(flag, ptr)` | | `args_type`            | the type `::testing::tuple<bool, int*>` | | `return_type`          | the type `int`  | | `function_type`        | the type `int(bool, int*)` |
Sometimes you'll want to parameterize an action you define.  For that we have another macro ``` ACTION_P(name, param) { statements; } ```
For example, ``` ACTION_P(Add, n) { return arg0 + n; } ``` will allow you to write ``` // Returns argument #0 + 5. ... WillOnce(Add(5)); ```
For convenience, we use the term _arguments_ for the values used to invoke the mock function, and the term _parameters_ for the values used to instantiate an action.
Note that you don't need to provide the type of the parameter either. Suppose the parameter is named `param`, you can also use the Google-Mock-defined symbol `param_type` to refer to the type of the parameter as inferred by the compiler.  For example, in the body of `ACTION_P(Add, n)` above, you can write `n_type` for the type of `n`.
Google Mock also provides `ACTION_P2`, `ACTION_P3`, and etc to support multi-parameter actions.  For example, ``` ACTION_P2(ReturnDistanceTo, x, y) {   double dx = arg0 - x;   double dy = arg1 - y;   return sqrt(dx*dx + dy*dy); } ``` lets you write ``` ... WillOnce(ReturnDistanceTo(5.0, 26.5)); ```
You can view `ACTION` as a degenerated parameterized action where the number of parameters is 0.
You can also easily define actions overloaded on the number of parameters: ``` ACTION_P(Plus, a) { ... } ACTION_P2(Plus, a, b) { ... } ```
For maximum brevity and reusability, the `ACTION*` macros don't ask you to provide the types of the mock function arguments and the action parameters.  Instead, we let the compiler infer the types for us.
Sometimes, however, we may want to be more explicit about the types. There are several tricks to do that.  For example: ``` ACTION(Foo) {   // Makes sure arg0 can be converted to int.   int n = arg0;   ... use n instead of arg0 here ... }
ACTION_P(Bar, param) {   // Makes sure the type of arg1 is const char*.   ::testing::StaticAssertTypeEq<const char*, arg1_type>();
// Makes sure param can be converted to bool.   bool flag = param; } ``` where `StaticAssertTypeEq` is a compile-time assertion in Google Test that verifies two types are the same.
Sometimes you want to give an action explicit template parameters that cannot be inferred from its value parameters.  `ACTION_TEMPLATE()` supports that and can be viewed as an extension to `ACTION()` and `ACTION_P*()`.
The syntax: ``` ACTION_TEMPLATE(ActionName,                 HAS_m_TEMPLATE_PARAMS(kind1, name1, ..., kind_m, name_m),                 AND_n_VALUE_PARAMS(p1, ..., p_n)) { statements; } ```
defines an action template that takes _m_ explicit template parameters and _n_ value parameters, where _m_ is between 1 and 10, and _n_ is between 0 and 10.  `name_i` is the name of the i-th template parameter, and `kind_i` specifies whether it's a `typename`, an integral constant, or a template.  `p_i` is the name of the i-th value parameter.
Example: ``` // DuplicateArg<k, T>(output) converts the k-th argument of the mock // function to type T and copies it to *output. ACTION_TEMPLATE(DuplicateArg,                 // Note the comma between int and k:                 HAS_2_TEMPLATE_PARAMS(int, k, typename, T),                 AND_1_VALUE_PARAMS(output)) {   *output = T(::testing::get<k>(args)); } ```
To create an instance of an action template, write: ```   ActionName<t1, ..., t_m>(v1, ..., v_n) ``` where the `t`s are the template arguments and the `v`s are the value arguments.  The value argument types are inferred by the compiler.  For example: ``` using ::testing::_; ...   int n;   EXPECT_CALL(mock, Foo(_, _))       .WillOnce(DuplicateArg<1, unsigned char>(&n)); ```
If you want to explicitly specify the value argument types, you can provide additional template arguments: ```   ActionName<t1, ..., t_m, u1, ..., u_k>(v1, ..., v_n) ``` where `u_i` is the desired type of `v_i`.
`ACTION_TEMPLATE` and `ACTION`/`ACTION_P*` can be overloaded on the number of value parameters, but not on the number of template parameters.  Without the restriction, the meaning of the following is unclear:
```   OverloadedAction<int, bool>(x); ```
Are we using a single-template-parameter action where `bool` refers to the type of `x`, or a two-template-parameter action where the compiler is asked to infer the type of `x`?
If you are writing a function that returns an `ACTION` object, you'll need to know its type.  The type depends on the macro used to define the action and the parameter types.  The rule is relatively simple: | **Given Definition** | **Expression** | **Has Type** | |:---------------------|:---------------|:-------------| | `ACTION(Foo)`        | `Foo()`        | `FooAction`  | | `ACTION_TEMPLATE(Foo, HAS_m_TEMPLATE_PARAMS(...), AND_0_VALUE_PARAMS())` |	`Foo<t1, ..., t_m>()` | `FooAction<t1, ..., t_m>` | | `ACTION_P(Bar, param)` | `Bar(int_value)` | `BarActionP<int>` | | `ACTION_TEMPLATE(Bar, HAS_m_TEMPLATE_PARAMS(...), AND_1_VALUE_PARAMS(p1))` | `Bar<t1, ..., t_m>(int_value)` | `FooActionP<t1, ..., t_m, int>` | | `ACTION_P2(Baz, p1, p2)` | `Baz(bool_value, int_value)` | `BazActionP2<bool, int>` | | `ACTION_TEMPLATE(Baz, HAS_m_TEMPLATE_PARAMS(...), AND_2_VALUE_PARAMS(p1, p2))` | `Baz<t1, ..., t_m>(bool_value, int_value)` | `FooActionP2<t1, ..., t_m, bool, int>` | | ...                  | ...            | ...          |
Note that we have to pick different suffixes (`Action`, `ActionP`, `ActionP2`, and etc) for actions with different numbers of value parameters, or the action definitions cannot be overloaded on the number of them.
While the `ACTION*` macros are very convenient, sometimes they are inappropriate.  For example, despite the tricks shown in the previous recipes, they don't let you directly specify the types of the mock function arguments and the action parameters, which in general leads to unoptimized compiler error messages that can baffle unfamiliar users.  They also don't allow overloading actions based on parameter types without jumping through some hoops.
An alternative to the `ACTION*` macros is to implement `::testing::ActionInterface<F>`, where `F` is the type of the mock function in which the action will be used. For example:
``` template <typename F>class ActionInterface {  public:   virtual ~ActionInterface();
// Performs the action.  Result is the return type of function type   // F, and ArgumentTuple is the tuple of arguments of F.   //   // For example, if F is int(bool, const string&), then Result would   // be int, and ArgumentTuple would be ::testing::tuple<bool, const string&>.   virtual Result Perform(const ArgumentTuple& args) = 0; };
using ::testing::_; using ::testing::Action; using ::testing::ActionInterface; using ::testing::MakeAction;
typedef int IncrementMethod(int*);
class IncrementArgumentAction : public ActionInterface<IncrementMethod> {  public:   virtual int Perform(const ::testing::tuple<int*>& args) {     int* p = ::testing::get<0>(args);  // Grabs the first argument.     return *p++;   } };
Action<IncrementMethod> IncrementArgument() {   return MakeAction(new IncrementArgumentAction); } ...
EXPECT_CALL(foo, Baz(_))       .WillOnce(IncrementArgument());
int n = 5;   foo.Baz(&n);  // Should return 5 and change n to 6. ```
The previous recipe showed you how to define your own action. This is all good, except that you need to know the type of the function in which the action will be used. Sometimes that can be a problem. For example, if you want to use the action in functions with _different_ types (e.g. like `Return()` and `SetArgPointee()`).
If an action can be used in several types of mock functions, we say it's _polymorphic_. The `MakePolymorphicAction()` function template makes it easy to define such an action:
``` namespace testing {
template <typename Impl> PolymorphicAction<Impl> MakePolymorphicAction(const Impl& impl);
}  // namespace testing ```
As an example, let's define an action that returns the second argument in the mock function's argument list. The first step is to define an implementation class:
``` class ReturnSecondArgumentAction {  public:   template <typename Result, typename ArgumentTuple>   Result Perform(const ArgumentTuple& args) const {     // To get the i-th (0-based) argument, use ::testing::get<i>(args).     return ::testing::get<1>(args);   } }; ```
This implementation class does _not_ need to inherit from any particular class. What matters is that it must have a `Perform()` method template. This method template takes the mock function's arguments as a tuple in a **single** argument, and returns the result of the action. It can be either `const` or not, but must be invokable with exactly one template argument, which is the result type. In other words, you must be able to call `Perform<R>(args)` where `R` is the mock function's return type and `args` is its arguments in a tuple.
Next, we use `MakePolymorphicAction()` to turn an instance of the implementation class into the polymorphic action we need. It will be convenient to have a wrapper for this:
``` using ::testing::MakePolymorphicAction; using ::testing::PolymorphicAction;
PolymorphicAction<ReturnSecondArgumentAction> ReturnSecondArgument() {   return MakePolymorphicAction(ReturnSecondArgumentAction()); } ```
Now, you can use this polymorphic action the same way you use the built-in ones:
``` using ::testing::_;
class MockFoo : public Foo {  public:   MOCK_METHOD2(DoThis, int(bool flag, int n));   MOCK_METHOD3(DoThat, string(int x, const char* str1, const char* str2)); }; ...
MockFoo foo;   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(ReturnSecondArgument());   EXPECT_CALL(foo, DoThat(_, _, _))       .WillOnce(ReturnSecondArgument());   ...   foo.DoThis(true, 5);         // Will return 5.   foo.DoThat(1, "Hi", "Bye");  // Will return "Hi". ```
When an uninteresting or unexpected call occurs, Google Mock prints the argument values and the stack trace to help you debug.  Assertion macros like `EXPECT_THAT` and `EXPECT_EQ` also print the values in question when the assertion fails.  Google Mock and Google Test do this using Google Test's user-extensible value printer.
This printer knows how to print built-in C++ types, native arrays, STL containers, and any type that supports the `<<` operator.  For other types, it prints the raw bytes in the value and hopes that you the user can figure it out. [Google Test's advanced guide](../../googletest/docs/AdvancedGuide.md#teaching-google-test-how-to-print-your-values) explains how to extend the printer to do a better job at printing your particular type than to dump the bytes.
This page discusses the design of new Google Mock features.

Due to the lack of closures in C++, it currently requires some non-trivial effort to define a custom action in Google Mock.  For example, suppose you want to "increment the value pointed to by the second argument of the mock function and return it", you could write:
``` int IncrementArg1(Unused, int* p, Unused) {   return ++(*p); }
... WillOnce(Invoke(IncrementArg1)); ```
There are several things unsatisfactory about this approach:
* Even though the action only cares about the second argument of the mock function, its definition needs to list other arguments as dummies.  This is tedious.   * The defined action is usable only in mock functions that takes exactly 3 arguments - an unnecessary restriction.   * To use the action, one has to say `Invoke(IncrementArg1)`, which isn't as nice as `IncrementArg1()`.
The latter two problems can be overcome using `MakePolymorphicAction()`, but it requires much more boilerplate code:
``` class IncrementArg1Action {  public:   template <typename Result, typename ArgumentTuple>   Result Perform(const ArgumentTuple& args) const {     return ++(*tr1::get<1>(args));   } };
PolymorphicAction<IncrementArg1Action> IncrementArg1() {   return MakePolymorphicAction(IncrementArg1Action()); }
... WillOnce(IncrementArg1()); ```
Our goal is to allow defining custom actions with the least amount of boiler-plate C++ requires.
We propose to introduce a new macro: ``` ACTION(name) { statements; } ```
Using this in a namespace scope will define an action with the given name that executes the statements.  Inside the statements, you can refer to the K-th (0-based) argument of the mock function as `argK`. For example: ``` ACTION(IncrementArg1) { return ++(*arg1); } ``` allows you to write ``` ... WillOnce(IncrementArg1()); ```
Note that you don't need to specify the types of the mock function arguments, as brevity is a top design goal here.  Rest assured that your code is still type-safe though: you'll get a compiler error if `*arg1` doesn't support the `++` operator, or if the type of `++(*arg1)` isn't compatible with the mock function's return type.
Another example: ``` ACTION(Foo) {   (*arg2)(5);   Blah();   *arg1 = 0;   return arg0; } ``` defines an action `Foo()` that invokes argument #2 (a function pointer) with 5, calls function `Blah()`, sets the value pointed to by argument #1 to 0, and returns argument #0.
For more convenience and flexibility, you can also use the following pre-defined symbols in the body of `ACTION`:
| `argK_type` | The type of the K-th (0-based) argument of the mock function | |:------------|:-------------------------------------------------------------| | `args`      | All arguments of the mock function as a tuple                | | `args_type` | The type of all arguments of the mock function as a tuple    | | `return_type` | The return type of the mock function                         | | `function_type` | The type of the mock function                                |
For example, when using an `ACTION` as a stub action for mock function: ``` int DoSomething(bool flag, int* ptr); ``` we have: | **Pre-defined Symbol** | **Is Bound To** | |:-----------------------|:----------------| | `arg0`                 | the value of `flag` | | `arg0_type`            | the type `bool` | | `arg1`                 | the value of `ptr` | | `arg1_type`            | the type `int*` | | `args`                 | the tuple `(flag, ptr)` | | `args_type`            | the type `std::tr1::tuple<bool, int*>` | | `return_type`          | the type `int`  | | `function_type`        | the type `int(bool, int*)` |
Sometimes you'll want to parameterize the action.   For that we propose another macro ``` ACTION_P(name, param) { statements; } ```
For example, ``` ACTION_P(Add, n) { return arg0 + n; } ``` will allow you to write ``` // Returns argument #0 + 5. ... WillOnce(Add(5)); ```
For convenience, we use the term _arguments_ for the values used to invoke the mock function, and the term _parameters_ for the values used to instantiate an action.
Note that you don't need to provide the type of the parameter either. Suppose the parameter is named `param`, you can also use the Google-Mock-defined symbol `param_type` to refer to the type of the parameter as inferred by the compiler.
We will also provide `ACTION_P2`, `ACTION_P3`, and etc to support multi-parameter actions.  For example, ``` ACTION_P2(ReturnDistanceTo, x, y) {   double dx = arg0 - x;   double dy = arg1 - y;   return sqrt(dx*dx + dy*dy); } ``` lets you write ``` ... WillOnce(ReturnDistanceTo(5.0, 26.5)); ```
You can view `ACTION` as a degenerated parameterized action where the number of parameters is 0.
You can easily define actions overloaded on the number of parameters: ``` ACTION_P(Plus, a) { ... } ACTION_P2(Plus, a, b) { ... } ```
For maximum brevity and reusability, the `ACTION*` macros don't let you specify the types of the mock function arguments and the action parameters.  Instead, we let the compiler infer the types for us.
Sometimes, however, we may want to be more explicit about the types. There are several tricks to do that.  For example: ``` ACTION(Foo) {   // Makes sure arg0 can be converted to int.   int n = arg0;   ... use n instead of arg0 here ... }
ACTION_P(Bar, param) {   // Makes sure the type of arg1 is const char*.   ::testing::StaticAssertTypeEq<const char*, arg1_type>();
// Makes sure param can be converted to bool.   bool flag = param; } ``` where `StaticAssertTypeEq` is a compile-time assertion we plan to add to Google Test (the name is chosen to match `static_assert` in C++0x).
If you are writing a function that returns an `ACTION` object, you'll need to know its type.  The type depends on the macro used to define the action and the parameter types.  The rule is relatively simple: | **Given Definition** | **Expression** | **Has Type** | |:---------------------|:---------------|:-------------| | `ACTION(Foo)`        | `Foo()`        | `FooAction`  | | `ACTION_P(Bar, param)` | `Bar(int_value)` | `BarActionP<int>` | | `ACTION_P2(Baz, p1, p2)` | `Baz(bool_value, int_value)` | `BazActionP2<bool, int>` | | ...                  | ...            | ...          |
Note that we have to pick different suffixes (`Action`, `ActionP`, `ActionP2`, and etc) for actions with different numbers of parameters, or the action definitions cannot be overloaded on the number of parameters.
While the new macros are very convenient, please also consider other means of implementing actions (e.g. via `ActionInterface` or `MakePolymorphicAction()`), especially if you need to use the defined action a lot.  While the other approaches require more work, they give you more control on the types of the mock function arguments and the action parameters, which in general leads to better compiler error messages that pay off in the long run.  They also allow overloading actions based on parameter types, as opposed to just the number of parameters.
As you may have realized, the `ACTION*` macros resemble closures (also known as lambda expressions or anonymous functions).  Indeed, both of them seek to lower the syntactic overhead for defining a function.
C++0x will support lambdas, but they are not part of C++ right now. Some non-standard libraries (most notably BLL or Boost Lambda Library) try to alleviate this problem.  However, they are not a good choice for defining actions as:
* They are non-standard and not widely installed.  Google Mock only depends on standard libraries and `tr1::tuple`, which is part of the new C++ standard and comes with gcc 4+.  We want to keep it that way.   * They are not trivial to learn.   * They will become obsolete when C++0x's lambda feature is widely supported.  We don't want to make our users use a dying library.   * Since they are based on operators, they are rather ad hoc: you cannot use statements, and you cannot pass the lambda arguments to a function, for example.   * They have subtle semantics that easily confuses new users.  For example, in expression `_1++ + foo++`, `foo` will be incremented only once where the expression is evaluated, while `_1` will be incremented every time the unnamed function is invoked.  This is far from intuitive.
`ACTION*` avoid all these problems.
There may be a need for composing `ACTION*` definitions (i.e. invoking another `ACTION` inside the definition of one `ACTION*`).  We are not sure we want it yet, as one can get a similar effect by putting `ACTION` definitions in function templates and composing the function templates.  We'll revisit this based on user feedback.
The reason we don't allow `ACTION*()` inside a function body is that the current C++ standard doesn't allow function-local types to be used to instantiate templates.  The upcoming C++0x standard will lift this restriction.  Once this feature is widely supported by compilers, we can revisit the implementation and add support for using `ACTION*()` inside a function.
C++0x will also support lambda expressions.  When they become available, we may want to support using lambdas as actions.
Once the macros for defining actions are implemented, we plan to do the same for matchers:
``` MATCHER(name) { statements; } ```
where you can refer to the value being matched as `arg`.  For example, given:
``` MATCHER(IsPositive) { return arg > 0; } ```
you can use `IsPositive()` as a matcher that matches a value iff it is greater than 0.
We will also add `MATCHER_P`, `MATCHER_P2`, and etc for parameterized matchers.

If you are interested in understanding the internals of Google Mock, building from source, or contributing ideas or modifications to the project, then this document is for you.
First, let's give you some background of the project.
All Google Mock source and pre-built packages are provided under the [New BSD License](http://www.opensource.org/licenses/bsd-license.php).
The Google Mock community exists primarily through the [discussion group](http://groups.google.com/group/googlemock), the [issue tracker](https://github.com/google/googletest/issues) and, to a lesser extent, the [source control repository](../). You are definitely encouraged to contribute to the discussion and you can also help us to keep the effectiveness of the group high by following and promoting the guidelines listed here.
Showing courtesy and respect to others is a vital part of the Google culture, and we strongly encourage everyone participating in Google Mock development to join us in accepting nothing less. Of course, being courteous is not the same as failing to constructively disagree with each other, but it does mean that we should be respectful of each other when enumerating the 42 technical reasons that a particular proposal may not be the best choice. There's never a reason to be antagonistic or dismissive toward anyone who is sincerely trying to contribute to a discussion.
Sure, C++ testing is serious business and all that, but it's also a lot of fun. Let's keep it that way. Let's strive to be one of the friendliest communities in all of open source.
As always, discuss Google Mock in the official [Google C++ Mocking Framework discussion group](http://groups.google.com/group/googlemock).  You don't have to actually submit code in order to sign up. Your participation itself is a valuable contribution.
If you want to get your hands dirty with the code inside Google Mock, this is the section for you.
Checking out the Google Mock source is most useful if you plan to tweak it yourself.  You check out the source for Google Mock using a [Subversion](http://subversion.tigris.org/) client as you would for any other project hosted on Google Code.  Please see the instruction on the [source code access page](../) for how to do it.
Once you check out the code, you can find instructions on how to compile it in the [README](../README.md) file.
A mocking framework is of no good if itself is not thoroughly tested. Tests should be written for any new code, and changes should be verified to not break existing tests before they are submitted for review. To perform the tests, follow the instructions in [README](http://code.google.com/p/googlemock/source/browse/trunk/README) and verify that there are no failures.
We are excited that Google Mock is now open source, and hope to get great patches from the community. Before you fire up your favorite IDE and begin hammering away at that new feature, though, please take the time to read this section and understand the process. While it seems rigorous, we want to keep a high standard of quality in the code base.
You must sign a Contributor License Agreement (CLA) before we can accept any code.  The CLA protects you and us.
* If you are an individual writing original source code and you're sure you own the intellectual property, then you'll need to sign an [individual CLA](http://code.google.com/legal/individual-cla-v1.0.html).   * If you work for a company that wants to allow you to contribute your work to Google Mock, then you'll need to sign a [corporate CLA](http://code.google.com/legal/corporate-cla-v1.0.html).
Follow either of the two links above to access the appropriate CLA and instructions for how to sign and return it.
To keep the source consistent, readable, diffable and easy to merge, we use a fairly rigid coding style, as defined by the [google-styleguide](https://github.com/google/styleguide) project.  All patches will be expected to conform to the style outlined [here](https://github.com/google/styleguide/blob/gh-pages/cppguide.xml).
Please do submit code. Here's what you need to do:
1. Normally you should make your change against the SVN trunk instead of a branch or a tag, as the latter two are for release control and should be treated mostly as read-only.   1. Decide which code you want to submit. A submission should be a set of changes that addresses one issue in the [Google Mock issue tracker](http://code.google.com/p/googlemock/issues/list). Please don't mix more than one logical change per submittal, because it makes the history hard to follow. If you want to make a change that doesn't have a corresponding issue in the issue tracker, please create one.   1. Also, coordinate with team members that are listed on the issue in question. This ensures that work isn't being duplicated and communicating your plan early also generally leads to better patches.   1. Ensure that your code adheres to the [Google Mock source code style](#Coding_Style.md).   1. Ensure that there are unit tests for your code.   1. Sign a Contributor License Agreement.   1. Create a patch file using `svn diff`.   1. We use [Rietveld](http://codereview.appspot.com/) to do web-based code reviews.  You can read about the tool [here](https://github.com/rietveld-codereview/rietveld/wiki).  When you are ready, upload your patch via Rietveld and notify `googlemock@googlegroups.com` to review it.  There are several ways to upload the patch.  We recommend using the [upload\_gmock.py](../scripts/upload_gmock.py) script, which you can find in the `scripts/` folder in the SVN trunk.
The current members of the Google Mock engineering team are the only committers at present. In the great tradition of eating one's own dogfood, we will be requiring each new Google Mock engineering team member to earn the right to become a committer by following the procedures in this document, writing consistently great code, and demonstrating repeatedly that he or she truly gets the zen of Google Mock.
We follow the typical release process for Subversion-based projects:
1. A release branch named `release-X.Y` is created.   1. Bugs are fixed and features are added in trunk; those individual patches are merged into the release branch until it's stable.   1. An individual point release (the `Z` in `X.Y.Z`) is made by creating a tag from the branch.   1. Repeat steps 2 and 3 throughout one release cycle (as determined by features or time).   1. Go back to step 1 to create another release branch and so on.
---
This page is based on the [Making GWT Better](http://code.google.com/webtoolkit/makinggwtbetter.html) guide from the [Google Web Toolkit](http://code.google.com/webtoolkit/) project.  Except as otherwise [noted](http://code.google.com/policies.html#restrictions), the content of this page is licensed under the [Creative Commons Attribution 2.5 License](http://creativecommons.org/licenses/by/2.5/).
This page lists all documentation wiki pages for Google Mock **(the SVN trunk version)** - **if you use a released version of Google Mock, please read the documentation for that specific version instead.**
* [ForDummies](ForDummies.md) -- start here if you are new to Google Mock.   * [CheatSheet](CheatSheet.md) -- a quick reference.   * [CookBook](CookBook.md) -- recipes for doing various tasks using Google Mock.   * [FrequentlyAskedQuestions](FrequentlyAskedQuestions.md) -- check here before asking a question on the mailing list.
To contribute code to Google Mock, read:
* [DevGuide](DevGuide.md) -- read this _before_ writing your first patch.   * [Pump Manual](../googletest/docs/PumpManual.md) -- how we generate some of Google Mock's source files.

(**Note:** If you get compiler errors that you don't understand, be sure to consult [Google Mock Doctor](FrequentlyAskedQuestions.md#how-am-i-supposed-to-make-sense-of-these-horrible-template-errors).)
**Note:** It is easy to confuse the term _fake objects_ with mock objects. Fakes and mocks actually mean very different things in the Test-Driven Development (TDD) community:
* **Fake** objects have working implementations, but usually take some shortcut (perhaps to make the operations less expensive), which makes them not suitable for production. An in-memory file system would be an example of a fake.   * **Mocks** are objects pre-programmed with _expectations_, which form a specification of the calls they are expected to receive.
If all this seems too abstract for you, don't worry - the most important thing to remember is that a mock allows you to check the _interaction_ between itself and code that uses it. The difference between fakes and mocks will become much clearer once you start to use mocks.
**Google C++ Mocking Framework** (or **Google Mock** for short) is a library (sometimes we also call it a "framework" to make it sound cool) for creating mock classes and using them. It does to C++ what [jMock](http://www.jmock.org/) and [EasyMock](http://www.easymock.org/) do to Java.
Using Google Mock involves three basic steps:
1. Use some simple macros to describe the interface you want to mock, and they will expand to the implementation of your mock class;   1. Create some mock objects and specify its expectations and behavior using an intuitive syntax;   1. Exercise code that uses the mock objects. Google Mock will catch any violation of the expectations as soon as it arises.
* Someone has to implement the mocks. The job is usually tedious and error-prone. No wonder people go great distance to avoid it.   * The quality of those manually written mocks is a bit, uh, unpredictable. You may see some really polished ones, but you may also see some that were hacked up in a hurry and have all sorts of ad hoc restrictions.   * The knowledge you gained from using one mock doesn't transfer to the next.
In contrast, Java and Python programmers have some fine mock frameworks, which automate the creation of mocks. As a result, mocking is a proven effective technique and widely adopted practice in those communities. Having the right tool absolutely makes the difference.
Google Mock was built to help C++ programmers. It was inspired by [jMock](http://www.jmock.org/) and [EasyMock](http://www.easymock.org/), but designed with C++'s specifics in mind. It is your friend if any of the following problems is bothering you:
* You are stuck with a sub-optimal design and wish you had done more prototyping before it was too late, but prototyping in C++ is by no means "rapid".   * Your tests are slow as they depend on too many libraries or use expensive resources (e.g. a database).   * Your tests are brittle as some resources they use are unreliable (e.g. the network).   * You want to test how your code handles a failure (e.g. a file checksum error), but it's not easy to cause one.   * You need to make sure that your module interacts with other modules in the right way, but it's hard to observe the interaction; therefore you resort to observing the side effects at the end of the action, which is awkward at best.   * You want to "mock out" your dependencies, except that they don't have mock implementations yet; and, frankly, you aren't thrilled by some of those hand-written mocks.
We encourage you to use Google Mock as:
* a _design_ tool, for it lets you experiment with your interface design early and often. More iterations lead to better designs!   * a _testing_ tool to cut your tests' outbound dependencies and probe the interaction between your module and its collaborators.
``` class Turtle {   ...   virtual ~Turtle() {}   virtual void PenUp() = 0;   virtual void PenDown() = 0;   virtual void Forward(int distance) = 0;   virtual void Turn(int degrees) = 0;   virtual void GoTo(int x, int y) = 0;   virtual int GetX() const = 0;   virtual int GetY() const = 0; }; ```
(Note that the destructor of `Turtle` **must** be virtual, as is the case for **all** classes you intend to inherit from - otherwise the destructor of the derived class will not be called when you delete an object through a base pointer, and you'll get corrupted program states like memory leaks.)
You can control whether the turtle's movement will leave a trace using `PenUp()` and `PenDown()`, and control its movement using `Forward()`, `Turn()`, and `GoTo()`. Finally, `GetX()` and `GetY()` tell you the current position of the turtle.
Your program will normally use a real implementation of this interface. In tests, you can use a mock implementation instead. This allows you to easily check what drawing primitives your program is calling, with what arguments, and in which order. Tests written this way are much more robust (they won't break because your new machine does anti-aliasing differently), easier to read and maintain (the intent of a test is expressed in the code, not in some binary images), and run _much, much faster_.
1. Derive a class `MockTurtle` from `Turtle`.   1. Take a _virtual_ function of `Turtle` (while it's possible to [mock non-virtual methods using templates](CookBook.md#mocking-nonvirtual-methods), it's much more involved). Count how many arguments it has.   1. In the `public:` section of the child class, write `MOCK_METHODn();` (or `MOCK_CONST_METHODn();` if you are mocking a `const` method), where `n` is the number of the arguments; if you counted wrong, shame on you, and a compiler error will tell you so.   1. Now comes the fun part: you take the function signature, cut-and-paste the _function name_ as the _first_ argument to the macro, and leave what's left as the _second_ argument (in case you're curious, this is the _type of the function_).   1. Repeat until all virtual functions you want to mock are done.
After the process, you should have something like:
``` #include "gmock/gmock.h"  // Brings in Google Mock. class MockTurtle : public Turtle {  public:   ...   MOCK_METHOD0(PenUp, void());   MOCK_METHOD0(PenDown, void());   MOCK_METHOD1(Forward, void(int distance));   MOCK_METHOD1(Turn, void(int degrees));   MOCK_METHOD2(GoTo, void(int x, int y));   MOCK_CONST_METHOD0(GetX, int());   MOCK_CONST_METHOD0(GetY, int()); }; ```
You don't need to define these mock methods somewhere else - the `MOCK_METHOD*` macros will generate the definitions for you. It's that simple! Once you get the hang of it, you can pump out mock classes faster than your source-control system can handle your check-ins.
**Tip:** If even this is too much work for you, you'll find the `gmock_gen.py` tool in Google Mock's `scripts/generator/` directory (courtesy of the [cppclean](http://code.google.com/p/cppclean/) project) useful.  This command-line tool requires that you have Python 2.4 installed.  You give it a C++ file and the name of an abstract class defined in it, and it will print the definition of the mock class for you.  Due to the complexity of the C++ language, this script may not always work, but it can be quite handy when it does.  For more details, read the [user documentation](../scripts/generator/README).
So, the rule of thumb is: if you need to mock `Foo` and it's owned by others, define the mock class in `Foo`'s package (better, in a `testing` sub-package such that you can clearly separate production code and testing utilities), and put it in a `mock_foo.h`. Then everyone can reference `mock_foo.h` from their tests. If `Foo` ever changes, there is only one copy of `MockFoo` to change, and only tests that depend on the changed methods need to be fixed.
Another way to do it: you can introduce a thin layer `FooAdaptor` on top of `Foo` and code to this new interface. Since you own `FooAdaptor`, you can absorb changes in `Foo` much more easily. While this is more work initially, carefully choosing the adaptor interface can make your code easier to write and more readable (a net win in the long run), as you can choose `FooAdaptor` to fit your specific domain much better than `Foo` does.
1. Import the Google Mock names from the `testing` namespace such that you can use them unqualified (You only have to do it once per file. Remember that namespaces are a good idea and good for your health.).   1. Create some mock objects.   1. Specify your expectations on them (How many times will a method be called? With what arguments? What should it do? etc.).   1. Exercise some code that uses the mocks; optionally, check the result using Google Test assertions. If a mock method is called more than expected or with wrong arguments, you'll get an error immediately.   1. When a mock is destructed, Google Mock will automatically check whether all expectations on it have been satisfied.
Here's an example:
``` #include "path/to/mock-turtle.h" #include "gmock/gmock.h" #include "gtest/gtest.h" using ::testing::AtLeast;                     // #1
TEST(PainterTest, CanDrawSomething) {   MockTurtle turtle;                          // #2   EXPECT_CALL(turtle, PenDown())              // #3       .Times(AtLeast(1));
Painter painter(&turtle);                   // #4
EXPECT_TRUE(painter.DrawCircle(0, 0, 10)); }                                             // #5
int main(int argc, char** argv) {   // The following line must be executed to initialize Google Mock   // (and Google Test) before running the tests.   ::testing::InitGoogleMock(&argc, argv);   return RUN_ALL_TESTS(); } ```
As you might have guessed, this test checks that `PenDown()` is called at least once. If the `painter` object didn't call this method, your test will fail with a message like this:
``` path/to/my_test.cc:119: Failure Actual function call count doesn't match this expectation: Actually: never called; Expected: called at least once. ```
**Tip 1:** If you run the test from an Emacs buffer, you can hit `<Enter>` on the line number displayed in the error message to jump right to the failed expectation.
**Tip 2:** If your mock objects are never deleted, the final verification won't happen. Therefore it's a good idea to use a heap leak checker in your tests when you allocate mocks on the heap.
**Important note:** Google Mock requires expectations to be set **before** the mock functions are called, otherwise the behavior is **undefined**. In particular, you mustn't interleave `EXPECT_CALL()`s and calls to the mock functions.
This means `EXPECT_CALL()` should be read as expecting that a call will occur _in the future_, not that a call has occurred. Why does Google Mock work like that? Well, specifying the expectation beforehand allows Google Mock to report a violation as soon as it arises, when the context (stack trace, etc) is still available. This makes debugging much easier.
Admittedly, this test is contrived and doesn't do much. You can easily achieve the same effect without using Google Mock. However, as we shall reveal soon, Google Mock allows you to do _much more_ with the mocks.
This approach has a catch: it makes Google Mock throw an exception from a mock object's destructor sometimes.  With some compilers, this sometimes causes the test program to crash.  You'll still be able to notice that the test has failed, but it's not a graceful failure.
A better solution is to use Google Test's [event listener API](../../googletest/docs/AdvancedGuide.md#extending-google-test-by-handling-test-events) to report a test failure to your testing framework properly.  You'll need to implement the `OnTestPartResult()` method of the event listener interface, but it should be straightforward.
If this turns out to be too much work, we suggest that you stick with Google Test, which works with Google Mock seamlessly (in fact, it is technically part of Google Mock.).  If there is a reason that you cannot use Google Test, please let us know.
``` EXPECT_CALL(mock_object, method(matchers))     .Times(cardinality)     .WillOnce(action)     .WillRepeatedly(action); ```
The macro has two arguments: first the mock object, and then the method and its arguments. Note that the two are separated by a comma (`,`), not a period (`.`). (Why using a comma? The answer is that it was necessary for technical reasons.)
The macro can be followed by some optional _clauses_ that provide more information about the expectation. We'll discuss how each clause works in the coming sections.
This syntax is designed to make an expectation read like English. For example, you can probably guess that
``` using ::testing::Return;... EXPECT_CALL(turtle, GetX())     .Times(5)     .WillOnce(Return(100))     .WillOnce(Return(150))     .WillRepeatedly(Return(200)); ```
says that the `turtle` object's `GetX()` method will be called five times, it will return 100 the first time, 150 the second time, and then 200 every time. Some people like to call this style of syntax a Domain-Specific Language (DSL).
**Note:** Why do we use a macro to do this? It serves two purposes: first it makes expectations easily identifiable (either by `grep` or by a human reader), and second it allows Google Mock to include the source file location of a failed expectation in messages, making debugging easier.
``` // Expects the turtle to move forward by 100 units. EXPECT_CALL(turtle, Forward(100)); ```
Sometimes you may not want to be too specific (Remember that talk about tests being too rigid? Over specification leads to brittle tests and obscures the intent of tests. Therefore we encourage you to specify only what's necessary - no more, no less.). If you care to check that `Forward()` will be called but aren't interested in its actual argument, write `_` as the argument, which means "anything goes":
``` using ::testing::_; ... // Expects the turtle to move forward. EXPECT_CALL(turtle, Forward(_)); ```
`_` is an instance of what we call **matchers**. A matcher is like a predicate and can test whether an argument is what we'd expect. You can use a matcher inside `EXPECT_CALL()` wherever a function argument is expected.
A list of built-in matchers can be found in the [CheatSheet](CheatSheet.md). For example, here's the `Ge` (greater than or equal) matcher:
``` using ::testing::Ge;... EXPECT_CALL(turtle, Forward(Ge(100))); ```
This checks that the turtle will be told to go forward by at least 100 units.
An interesting special case is when we say `Times(0)`. You may have guessed - it means that the function shouldn't be called with the given arguments at all, and Google Mock will report a Google Test failure whenever the function is (wrongfully) called.
We've seen `AtLeast(n)` as an example of fuzzy cardinalities earlier. For the list of built-in cardinalities you can use, see the [CheatSheet](CheatSheet.md).
The `Times()` clause can be omitted. **If you omit `Times()`, Google Mock will infer the cardinality for you.** The rules are easy to remember:
* If **neither** `WillOnce()` **nor** `WillRepeatedly()` is in the `EXPECT_CALL()`, the inferred cardinality is `Times(1)`.   * If there are `n WillOnce()`'s but **no** `WillRepeatedly()`, where `n` >= 1, the cardinality is `Times(n)`.   * If there are `n WillOnce()`'s and **one** `WillRepeatedly()`, where `n` >= 0, the cardinality is `Times(AtLeast(n))`.
**Quick quiz:** what do you think will happen if a function is expected to be called twice but actually called four times?
First, if the return type of a mock function is a built-in type or a pointer, the function has a **default action** (a `void` function will just return, a `bool` function will return `false`, and other functions will return 0). In addition, in C++ 11 and above, a mock function whose return type is default-constructible (i.e. has a default constructor) has a default action of returning a default-constructed value.  If you don't say anything, this behavior will be used.
Second, if a mock function doesn't have a default action, or the default action doesn't suit you, you can specify the action to be taken each time the expectation matches using a series of `WillOnce()` clauses followed by an optional `WillRepeatedly()`. For example,
``` using ::testing::Return;... EXPECT_CALL(turtle, GetX())     .WillOnce(Return(100))     .WillOnce(Return(200))     .WillOnce(Return(300)); ```
This says that `turtle.GetX()` will be called _exactly three times_ (Google Mock inferred this from how many `WillOnce()` clauses we've written, since we didn't explicitly write `Times()`), and will return 100, 200, and 300 respectively.
``` using ::testing::Return;... EXPECT_CALL(turtle, GetY())     .WillOnce(Return(100))     .WillOnce(Return(200))     .WillRepeatedly(Return(300)); ```
says that `turtle.GetY()` will be called _at least twice_ (Google Mock knows this as we've written two `WillOnce()` clauses and a `WillRepeatedly()` while having no explicit `Times()`), will return 100 the first time, 200 the second time, and 300 from the third time on.
Of course, if you explicitly write a `Times()`, Google Mock will not try to infer the cardinality itself. What if the number you specified is larger than there are `WillOnce()` clauses? Well, after all `WillOnce()`s are used up, Google Mock will do the _default_ action for the function every time (unless, of course, you have a `WillRepeatedly()`.).
What can we do inside `WillOnce()` besides `Return()`? You can return a reference using `ReturnRef(variable)`, or invoke a pre-defined function, among [others](CheatSheet.md#actions).
**Important note:** The `EXPECT_CALL()` statement evaluates the action clause only once, even though the action may be performed many times. Therefore you must be careful about side effects. The following may not do what you want:
``` int n = 100; EXPECT_CALL(turtle, GetX()) .Times(4) .WillRepeatedly(Return(n++)); ```
Instead of returning 100, 101, 102, ..., consecutively, this mock function will always return 100 as `n++` is only evaluated once. Similarly, `Return(new Foo)` will create a new `Foo` object when the `EXPECT_CALL()` is executed, and will return the same pointer every time. If you want the side effect to happen every time, you need to define a custom action, which we'll teach in the [CookBook](CookBook.md).
Time for another quiz! What do you think the following means?
``` using ::testing::Return;... EXPECT_CALL(turtle, GetY()) .Times(4) .WillOnce(Return(100)); ```
Obviously `turtle.GetY()` is expected to be called four times. But if you think it will return 100 every time, think twice! Remember that one `WillOnce()` clause will be consumed each time the function is invoked and the default action will be taken afterwards. So the right answer is that `turtle.GetY()` will return 100 the first time, but **return 0 from the second time on**, as returning 0 is the default action for `int` functions.
By default, when a mock method is invoked, Google Mock will search the expectations in the **reverse order** they are defined, and stop when an active expectation that matches the arguments is found (you can think of it as "newer rules override older ones."). If the matching expectation cannot take any more calls, you will get an upper-bound-violated failure. Here's an example:
``` using ::testing::_;... EXPECT_CALL(turtle, Forward(_));  // #1 EXPECT_CALL(turtle, Forward(10))  // #2     .Times(2); ```
If `Forward(10)` is called three times in a row, the third time it will be an error, as the last matching expectation (#2) has been saturated. If, however, the third `Forward(10)` call is replaced by `Forward(20)`, then it would be OK, as now #1 will be the matching expectation.
**Side note:** Why does Google Mock search for a match in the _reverse_ order of the expectations? The reason is that this allows a user to set up the default expectations in a mock object's constructor or the test fixture's set-up phase and then customize the mock by writing more specific expectations in the test body. So, if you have two expectations on the same method, you want to put the one with more specific matchers **after** the other, or the more specific rule would be shadowed by the more general one that comes after it.
Sometimes, you may want all the expected calls to occur in a strict order. To say this in Google Mock is easy:
``` using ::testing::InSequence;... TEST(FooTest, DrawsLineSegment) {   ...   {     InSequence dummy;
EXPECT_CALL(turtle, PenDown());     EXPECT_CALL(turtle, Forward(100));     EXPECT_CALL(turtle, PenUp());   }   Foo(); } ```
By creating an object of type `InSequence`, all expectations in its scope are put into a _sequence_ and have to occur _sequentially_. Since we are just relying on the constructor and destructor of this object to do the actual work, its name is really irrelevant.
In this example, we test that `Foo()` calls the three expected functions in the order as written. If a call is made out-of-order, it will be an error.
(What if you care about the relative order of some of the calls, but not all of them? Can you specify an arbitrary partial order? The answer is ... yes! If you are impatient, the details can be found in the [CookBook](CookBook#Expecting_Partially_Ordered_Calls.md).)
After you've come up with your answer, take a look at ours and compare notes (solve it yourself first - don't cheat!):
``` using ::testing::_;... EXPECT_CALL(turtle, GoTo(_, _))  // #1     .Times(AnyNumber()); EXPECT_CALL(turtle, GoTo(0, 0))  // #2     .Times(2); ```
Suppose `turtle.GoTo(0, 0)` is called three times. In the third time, Google Mock will see that the arguments match expectation #2 (remember that we always pick the last matching expectation). Now, since we said that there should be only two such calls, Google Mock will report an error immediately. This is basically what we've told you in the "Using Multiple Expectations" section above.
This example shows that **expectations in Google Mock are "sticky" by default**, in the sense that they remain active even after we have reached their invocation upper bounds. This is an important rule to remember, as it affects the meaning of the spec, and is **different** to how it's done in many other mocking frameworks (Why'd we do that? Because we think our rule makes the common cases easier to express and understand.).
Simple? Let's see if you've really understood it: what does the following code say?
``` using ::testing::Return; ... for (int i = n; i > 0; i--) {   EXPECT_CALL(turtle, GetX())       .WillOnce(Return(10*i)); } ```
If you think it says that `turtle.GetX()` will be called `n` times and will return 10, 20, 30, ..., consecutively, think twice! The problem is that, as we said, expectations are sticky. So, the second time `turtle.GetX()` is called, the last (latest) `EXPECT_CALL()` statement will match, and will immediately lead to an "upper bound exceeded" error - this piece of code is not very useful!
One correct way of saying that `turtle.GetX()` will return 10, 20, 30, ..., is to explicitly say that the expectations are _not_ sticky. In other words, they should _retire_ as soon as they are saturated:
``` using ::testing::Return; ... for (int i = n; i > 0; i--) {   EXPECT_CALL(turtle, GetX())     .WillOnce(Return(10*i))     .RetiresOnSaturation(); } ```
And, there's a better way to do it: in this case, we expect the calls to occur in a specific order, and we line up the actions to match the order. Since the order is important here, we should make it explicit using a sequence:
``` using ::testing::InSequence; using ::testing::Return; ... {   InSequence s;
for (int i = 1; i <= n; i++) {     EXPECT_CALL(turtle, GetX())         .WillOnce(Return(10*i))         .RetiresOnSaturation();   } } ```
By the way, the other situation where an expectation may _not_ be sticky is when it's in a sequence - as soon as another expectation that comes after it in the sequence has been used, it automatically retires (and will never be used to match any call).
In Google Mock, if you are not interested in a method, just don't say anything about it. If a call to this method occurs, you'll see a warning in the test output, but it won't be a failure.
Then, if you feel like increasing your mock quotient, you should move on to the [CookBook](CookBook.md). You can learn many advanced features of Google Mock there -- and advance your level of enjoyment and testing bliss.

Please send your questions to the [googlemock](http://groups.google.com/group/googlemock) discussion group. If you need help with compiler errors, make sure you have tried [Google Mock Doctor](#How_am_I_supposed_to_make_sense_of_these_horrible_template_error.md) first.
In order for a method to be mocked, it must be _virtual_, unless you use the [high-perf dependency injection technique](CookBook.md#mocking-nonvirtual-methods).
After version 1.4.0 of Google Mock was released, we had an idea on how to make it easier to write matchers that can generate informative messages efficiently.  We experimented with this idea and liked what we saw.  Therefore we decided to implement it.
Unfortunately, this means that if you have defined your own matchers by implementing `MatcherInterface` or using `MakePolymorphicMatcher()`, your definitions will no longer compile.  Matchers defined using the `MATCHER*` family of macros are not affected.
Sorry for the hassle if your matchers are affected.  We believe it's in everyone's long-term interest to make this change sooner than later.  Fortunately, it's usually not hard to migrate an existing matcher to the new API.  Here's what you need to do:
If you wrote your matcher like this: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MatcherInterface; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }   ... }; ```
you'll need to change it to: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MatcherInterface; using ::testing::MatchResultListener; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool MatchAndExplain(MyType value,                                MatchResultListener* listener) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }   ... }; ``` (i.e. rename `Matches()` to `MatchAndExplain()` and give it a second argument of type `MatchResultListener*`.)
If you were also using `ExplainMatchResultTo()` to improve the matcher message: ``` // Old matcher definition that doesn't work with the lastest // Google Mock. using ::testing::MatcherInterface; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }
virtual void ExplainMatchResultTo(MyType value,                                     ::std::ostream* os) const {     // Prints some helpful information to os to help     // a user understand why value matches (or doesn't match).     *os << "the Foo property is " << value.GetFoo();   }   ... }; ```
you should move the logic of `ExplainMatchResultTo()` into `MatchAndExplain()`, using the `MatchResultListener` argument where the `::std::ostream` was used: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MatcherInterface; using ::testing::MatchResultListener; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool MatchAndExplain(MyType value,                                MatchResultListener* listener) const {     // Returns true if value matches.     *listener << "the Foo property is " << value.GetFoo();     return value.GetFoo() > 5;   }   ... }; ```
If your matcher is defined using `MakePolymorphicMatcher()`: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MakePolymorphicMatcher; ... class MyGreatMatcher {  public:   ...   bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
you should rename the `Matches()` method to `MatchAndExplain()` and add a `MatchResultListener*` argument (the same as what you need to do for matchers defined by implementing `MatcherInterface`): ``` // New matcher definition that works with the latest Google Mock. using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; ... class MyGreatMatcher {  public:   ...   bool MatchAndExplain(MyType value,                        MatchResultListener* listener) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
If your polymorphic matcher uses `ExplainMatchResultTo()` for better failure messages: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MakePolymorphicMatcher; ... class MyGreatMatcher {  public:   ...   bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; void ExplainMatchResultTo(const MyGreatMatcher& matcher,                           MyType value,                           ::std::ostream* os) {   // Prints some helpful information to os to help   // a user understand why value matches (or doesn't match).   *os << "the Bar property is " << value.GetBar(); } ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
you'll need to move the logic inside `ExplainMatchResultTo()` to `MatchAndExplain()`: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; ... class MyGreatMatcher {  public:   ...   bool MatchAndExplain(MyType value,                        MatchResultListener* listener) const {     // Returns true if value matches.     *listener << "the Bar property is " << value.GetBar();     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
For more information, you can read these [two](CookBook.md#writing-new-monomorphic-matchers) [recipes](CookBook.md#writing-new-polymorphic-matchers) from the cookbook.  As always, you are welcome to post questions on `googlemock@googlegroups.com` if you need any help.
Google Mock works out of the box with Google Test.  However, it's easy to configure it to work with any testing framework of your choice. [Here](ForDummies.md#using-google-mock-with-any-testing-framework) is how.
If you are confused by the compiler errors gcc threw at you, try consulting the _Google Mock Doctor_ tool first.  What it does is to scan stdin for gcc error messages, and spit out diagnoses on the problems (we call them diseases) your code has.
To "install", run command: ``` alias gmd='<path to googlemock>/scripts/gmock_doctor.py' ```
To use it, do: ``` <your-favorite-build-command> <your-test> 2>&1 | gmd ```
For example: ``` make my_test 2>&1 | gmd ```
Or you can run `gmd` and copy-n-paste gcc's error messages to it.
You cannot mock a variadic function (i.e. a function taking ellipsis (`...`) arguments) directly in Google Mock.
The problem is that in general, there is _no way_ for a mock object to know how many arguments are passed to the variadic method, and what the arguments' types are.  Only the _author of the base class_ knows the protocol, and we cannot look into his head.
Therefore, to mock such a function, the _user_ must teach the mock object how to figure out the number of arguments and their types.  One way to do it is to provide overloaded versions of the function.
Ellipsis arguments are inherited from C and not really a C++ feature. They are unsafe to use and don't work with arguments that have constructors or destructors.  Therefore we recommend to avoid them in C++ as much as possible.
If you compile this using Microsoft Visual C++ 2005 SP1: ``` class Foo {   ...   virtual void Bar(const int i) = 0; };
class MockFoo : public Foo {   ...   MOCK_METHOD1(Bar, void(const int i)); }; ``` You may get the following warning: ``` warning C4301: 'MockFoo::Bar': overriding virtual function only differs from 'Foo::Bar' by const/volatile qualifier ```
This is a MSVC bug.  The same code compiles fine with gcc ,for example.  If you use Visual C++ 2008 SP1, you would get the warning: ``` warning C4373: 'MockFoo::Bar': virtual function overrides 'Foo::Bar', previous versions of the compiler did not override when parameters only differed by const/volatile qualifiers ```
In C++, if you _declare_ a function with a `const` parameter, the `const` modifier is _ignored_.  Therefore, the `Foo` base class above is equivalent to: ``` class Foo {   ...   virtual void Bar(int i) = 0;  // int or const int?  Makes no difference. }; ```
In fact, you can _declare_ Bar() with an `int` parameter, and _define_ it with a `const int` parameter.  The compiler will still match them up.
Since making a parameter `const` is meaningless in the method _declaration_, we recommend to remove it in both `Foo` and `MockFoo`. That should workaround the VC bug.
Note that we are talking about the _top-level_ `const` modifier here. If the function parameter is passed by pointer or reference, declaring the _pointee_ or _referee_ as `const` is still meaningful.  For example, the following two declarations are _not_ equivalent: ``` void Bar(int* p);        // Neither p nor *p is const. void Bar(const int* p);  // p is not const, but *p is. ```
We've noticed that when the `/clr` compiler flag is used, Visual C++ uses 5~6 times as much memory when compiling a mock class.  We suggest to avoid `/clr` when compiling native C++ mocks.
You might want to run your test with `--gmock_verbose=info`.  This flag lets Google Mock print a trace of every mock function call it receives.  By studying the trace, you'll gain insights on why the expectations you set are not met.
``` EXPECT_CALL(foo, Bar(_))     .Times(0); ```
When Google Mock detects a failure, it prints relevant information (the mock function arguments, the state of relevant expectations, and etc) to help the user debug.  If another failure is detected, Google Mock will do the same, including printing the state of relevant expectations.
Sometimes an expectation's state didn't change between two failures, and you'll see the same description of the state twice.  They are however _not_ redundant, as they refer to _different points in time_. The fact they are the same _is_ interesting information.
Does the class (hopefully a pure interface) you are mocking have a virtual destructor?
Whenever you derive from a base class, make sure its destructor is virtual.  Otherwise Bad Things will happen.  Consider the following code:
``` class Base {  public:   // Not virtual, but should be.   ~Base() { ... }   ... };
class Derived : public Base {  public:   ...  private:   std::string value_; };
...   Base* p = new Derived;   ...   delete p;  // Surprise! ~Base() will be called, but ~Derived() will not              // - value_ is leaked. ```
By changing `~Base()` to virtual, `~Derived()` will be correctly called when `delete p` is executed, and the heap checker will be happy.
When people complain about this, often they are referring to code like:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time.  However, I have to write the expectations in the // reverse order.  This sucks big time!!! EXPECT_CALL(foo, Bar())     .WillOnce(Return(2))     .RetiresOnSaturation(); EXPECT_CALL(foo, Bar())     .WillOnce(Return(1))     .RetiresOnSaturation(); ```
The problem is that they didn't pick the **best** way to express the test's intent.
By default, expectations don't have to be matched in _any_ particular order.  If you want them to match in a certain order, you need to be explicit.  This is Google Mock's (and jMock's) fundamental philosophy: it's easy to accidentally over-specify your tests, and we want to make it harder to do so.
There are two better ways to write the test spec.  You could either put the expectations in sequence:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time.  Using a sequence, we can write the expectations // in their natural order. {   InSequence s;   EXPECT_CALL(foo, Bar())       .WillOnce(Return(1))       .RetiresOnSaturation();   EXPECT_CALL(foo, Bar())       .WillOnce(Return(2))       .RetiresOnSaturation(); } ```
or you can put the sequence of actions in the same expectation:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time. EXPECT_CALL(foo, Bar())     .WillOnce(Return(1))     .WillOnce(Return(2))     .RetiresOnSaturation(); ```
Back to the original questions: why does Google Mock search the expectations (and `ON_CALL`s) from back to front?  Because this allows a user to set up a mock's behavior for the common case early (e.g. in the mock's constructor or the test fixture's set-up phase) and customize it with more specific rules later.  If Google Mock searches from front to back, this very useful pattern won't be possible.
When choosing between being neat and being safe, we lean toward the latter.  So the answer is that we think it's better to show the warning.
Often people write `ON_CALL`s in the mock object's constructor or `SetUp()`, as the default behavior rarely changes from test to test.  Then in the test body they set the expectations, which are often different for each test.  Having an `ON_CALL` in the set-up part of a test doesn't mean that the calls are expected.  If there's no `EXPECT_CALL` and the method is called, it's possibly an error.  If we quietly let the call go through without notifying the user, bugs may creep in unnoticed.
If, however, you are sure that the calls are OK, you can write
``` EXPECT_CALL(foo, Bar(_))     .WillRepeatedly(...); ```
instead of
``` ON_CALL(foo, Bar(_))     .WillByDefault(...); ```
This tells Google Mock that you do expect the calls and no warning should be printed.
Also, you can control the verbosity using the `--gmock_verbose` flag. If you find the output too noisy when debugging, just choose a less verbose level.
If you find yourself needing to perform some action that's not supported by Google Mock directly, remember that you can define your own actions using [MakeAction()](CookBook.md#writing-new-actions) or [MakePolymorphicAction()](CookBook.md#writing_new_polymorphic_actions), or you can write a stub function and invoke it using [Invoke()](CookBook.md#using-functions_methods_functors).
What?!  I think it's beautiful. :-)
While which syntax looks more natural is a subjective matter to some extent, Google Mock's syntax was chosen for several practical advantages it has.
Try to mock a function that takes a map as an argument: ``` virtual int GetSize(const map<int, std::string>& m); ```
Using the proposed syntax, it would be: ``` MOCK_METHOD1(GetSize, int, const map<int, std::string>& m); ```
Guess what?  You'll get a compiler error as the compiler thinks that `const map<int, std::string>& m` are **two**, not one, arguments. To work around this you can use `typedef` to give the map type a name, but that gets in the way of your work.  Google Mock's syntax avoids this problem as the function's argument types are protected inside a pair of parentheses: ``` // This compiles fine. MOCK_METHOD1(GetSize, int(const map<int, std::string>& m)); ```
You still need a `typedef` if the return type contains an unprotected comma, but that's much rarer.
Other advantages include:   1. `MOCK_METHOD1(Foo, int, bool)` can leave a reader wonder whether the method returns `int` or `bool`, while there won't be such confusion using Google Mock's syntax.   1. The way Google Mock describes a function type is nothing new, although many people may not be familiar with it.  The same syntax was used in C, and the `function` library in `tr1` uses this syntax extensively.  Since `tr1` will become a part of the new version of STL, we feel very comfortable to be consistent with it.   1. The function type syntax is also used in other parts of Google Mock's API (e.g. the action interface) in order to make the implementation tractable. A user needs to learn it anyway in order to utilize Google Mock's more advanced features.  We'd as well stick to the same syntax in `MOCK_METHOD*`!
You can, but you need to make some changes.
In general, if you find yourself needing to mock a static function, it's a sign that your modules are too tightly coupled (and less flexible, less reusable, less testable, etc).  You are probably better off defining a small interface and call the function through that interface, which then can be easily mocked.  It's a bit of work initially, but usually pays for itself quickly.
This Google Testing Blog [post](http://googletesting.blogspot.com/2008/06/defeat-static-cling.html) says it excellently.  Check it out.
I know it's not a question, but you get an answer for free any way. :-)
With Google Mock, you can create mocks in C++ easily.  And people might be tempted to use them everywhere. Sometimes they work great, and sometimes you may find them, well, a pain to use. So, what's wrong in the latter case?
When you write a test without using mocks, you exercise the code and assert that it returns the correct value or that the system is in an expected state.  This is sometimes called "state-based testing".
Mocks are great for what some call "interaction-based" testing: instead of checking the system state at the very end, mock objects verify that they are invoked the right way and report an error as soon as it arises, giving you a handle on the precise context in which the error was triggered.  This is often more effective and economical to do than state-based testing.
If you are doing state-based testing and using a test double just to simulate the real object, you are probably better off using a fake. Using a mock in this case causes pain, as it's not a strong point for mocks to perform complex actions.  If you experience this and think that mocks suck, you are just not using the right tool for your problem. Or, you might be trying to solve the wrong problem. :-)
By all means, NO!  It's just an FYI.
What it means is that you have a mock function, you haven't set any expectations on it (by Google Mock's rule this means that you are not interested in calls to this function and therefore it can be called any number of times), and it is called.  That's OK - you didn't say it's not OK to call the function!
What if you actually meant to disallow this function to be called, but forgot to write `EXPECT_CALL(foo, Bar()).Times(0)`?  While one can argue that it's the user's fault, Google Mock tries to be nice and prints you a note.
So, when you see the message and believe that there shouldn't be any uninteresting calls, you should investigate what's going on.  To make your life easier, Google Mock prints the function name and arguments when an uninteresting call is encountered.
Either way is fine - you want to choose the one that's more convenient for your circumstance.
Usually, if your action is for a particular function type, defining it using `Invoke()` should be easier; if your action can be used in functions of different types (e.g. if you are defining `Return(value)`), `MakePolymorphicAction()` is easiest.  Sometimes you want precise control on what types of functions the action can be used in, and implementing `ActionInterface` is the way to go here. See the implementation of `Return()` in `include/gmock/gmock-actions.h` for an example.
You got this error as Google Mock has no idea what value it should return when the mock method is called.  `SetArgPointee()` says what the side effect is, but doesn't say what the return value should be.  You need `DoAll()` to chain a `SetArgPointee()` with a `Return()`.
See this [recipe](CookBook.md#mocking_side_effects) for more details and an example.
If you cannot find the answer to your question in this FAQ, there are some other resources you can use:
1. read other [documentation](Documentation.md),   1. search the mailing list [archive](http://groups.google.com/group/googlemock/topics),   1. ask it on [googlemock@googlegroups.com](mailto:googlemock@googlegroups.com) and someone will answer it (to prevent spam, we require you to join the [discussion group](http://groups.google.com/group/googlemock) before you can post.).
Please note that creating an issue in the [issue tracker](https://github.com/google/googletest/issues) is _not_ a good way to get your answer, as it is monitored infrequently by a very small number of people.
When asking a question, it's helpful to provide as much of the following information as possible (people cannot help you if there's not enough information in your question):
* the version (or the revision number if you check out from SVN directly) of Google Mock you use (Google Mock is under active development, so it's possible that your problem has been solved in a later version),   * your operating system,   * the name and version of your compiler,   * the complete command line flags you give to your compiler,   * the complete compiler error messages (if the question is about compilation),   * the _actual_ code (ideally, a minimal but complete program) that has the problem you encounter.
As any non-trivial software system, Google Mock has some known limitations and problems.  We are working on improving it, and welcome your help!  The follow is a list of issues we know about.

The `README` file in release 1.1.0 still says that Google Mock only works with Google Test.  Actually, you can configure Google Mock to work with any testing framework you choose.
`gmock_output_test` and `gmock-printers_test` are known to fail with Power PC CPUs.  This is due to portability issues with these tests, and is not an indication of problems in Google Mock itself.  You can safely ignore them.
This only applies if you manually built and installed Google Test, and then built a Google Mock against it (either explicitly, or because gtest-config was in your path post-install). In this situation, Libtool has a known issue with certain systems' ldconfig setup:
http://article.gmane.org/gmane.comp.sysutils.automake.general/9025
This requires a manual run of "sudo ldconfig" after the "sudo make install" for Google Test before any binaries which link against it can be executed. This isn't a bug in our install, but we should at least have documented it or hacked a work-around into our install. We should have one of these solutions in our next release.

Given ``` class Foo {   ...   virtual ~Foo();   virtual int GetSize() const = 0;   virtual string Describe(const char* name) = 0;   virtual string Describe(int type) = 0;   virtual bool Process(Bar elem, int count) = 0; }; ``` (note that `~Foo()` **must** be virtual) we can define its mock as ``` #include <gmock/gmock.h>
class MockFoo : public Foo {   MOCK_CONST_METHOD0(GetSize, int());   MOCK_METHOD1(Describe, string(const char* name));   MOCK_METHOD1(Describe, string(int type));   MOCK_METHOD2(Process, bool(Bar elem, int count)); }; ```
To create a "nice" mock object which ignores all uninteresting calls, or a "strict" mock object, which treats them as failures: ``` NiceMock<MockFoo> nice_foo;     // The type is a subclass of MockFoo. StrictMock<MockFoo> strict_foo; // The type is a subclass of MockFoo. ```
To mock ``` template <typename Elem> class StackInterface {  public:   ...   virtual ~StackInterface();   virtual int GetSize() const = 0;   virtual void Push(const Elem& x) = 0; }; ``` (note that `~StackInterface()` **must** be virtual) just append `_T` to the `MOCK_*` macros: ``` template <typename Elem> class MockStack : public StackInterface<Elem> {  public:   ...   MOCK_CONST_METHOD0_T(GetSize, int());   MOCK_METHOD1_T(Push, void(const Elem& x)); }; ```
If your mock function doesn't use the default calling convention, you can specify it by appending `_WITH_CALLTYPE` to any of the macros described in the previous two sections and supplying the calling convention as the first argument to the macro. For example, ```   MOCK_METHOD_1_WITH_CALLTYPE(STDMETHODCALLTYPE, Foo, bool(int n));   MOCK_CONST_METHOD2_WITH_CALLTYPE(STDMETHODCALLTYPE, Bar, int(double x, double y)); ``` where `STDMETHODCALLTYPE` is defined by `<objbase.h>` on Windows.
The typical flow is:   1. Import the Google Mock names you need to use. All Google Mock names are in the `testing` namespace unless they are macros or otherwise noted.   1. Create the mock objects.   1. Optionally, set the default actions of the mock objects.   1. Set your expectations on the mock objects (How will they be called? What wil they do?).   1. Exercise code that uses the mock objects; if necessary, check the result using [Google Test](http://code.google.com/p/googletest/) assertions.   1. When a mock objects is destructed, Google Mock automatically verifies that all expectations on it have been satisfied.
Here is an example: ``` using ::testing::Return;                            // #1
TEST(BarTest, DoesThis) {   MockFoo foo;                                    // #2
ON_CALL(foo, GetSize())                         // #3       .WillByDefault(Return(1));   // ... other default actions ...
EXPECT_CALL(foo, Describe(5))                   // #4       .Times(3)       .WillRepeatedly(Return("Category 5"));   // ... other expectations ...
EXPECT_EQ("good", MyProductionFunction(&foo));  // #5 }                                                 // #6 ```
Google Mock has a **built-in default action** for any function that returns `void`, `bool`, a numeric value, or a pointer.
To customize the default action for functions with return type `T` globally: ``` using ::testing::DefaultValue;
DefaultValue<T>::Set(value);  // Sets the default value to be returned. // ... use the mocks ... DefaultValue<T>::Clear();     // Resets the default value. ```
To customize the default action for a particular method, use `ON_CALL()`: ``` ON_CALL(mock_object, method(matchers))     .With(multi_argument_matcher)  ?     .WillByDefault(action); ```
`EXPECT_CALL()` sets **expectations** on a mock method (How will it be called? What will it do?): ``` EXPECT_CALL(mock_object, method(matchers))     .With(multi_argument_matcher)  ?     .Times(cardinality)            ?     .InSequence(sequences)         *     .After(expectations)           *     .WillOnce(action)              *     .WillRepeatedly(action)        ?     .RetiresOnSaturation();        ? ```
If `Times()` is omitted, the cardinality is assumed to be:
* `Times(1)` when there is neither `WillOnce()` nor `WillRepeatedly()`;   * `Times(n)` when there are `n WillOnce()`s but no `WillRepeatedly()`, where `n` >= 1; or   * `Times(AtLeast(n))` when there are `n WillOnce()`s and a `WillRepeatedly()`, where `n` >= 0.
A method with no `EXPECT_CALL()` is free to be invoked _any number of times_, and the default action will be taken each time.
A **matcher** matches a _single_ argument.  You can use it inside `ON_CALL()` or `EXPECT_CALL()`, or use it to validate a value directly:
| `EXPECT_THAT(value, matcher)` | Asserts that `value` matches `matcher`. | |:------------------------------|:----------------------------------------| | `ASSERT_THAT(value, matcher)` | The same as `EXPECT_THAT(value, matcher)`, except that it generates a **fatal** failure. |
Built-in matchers (where `argument` is the function argument) are divided into several categories:
|`Eq(value)` or `value`|`argument == value`| |:---------------------|:------------------| |`Ge(value)`           |`argument >= value`| |`Gt(value)`           |`argument > value` | |`Le(value)`           |`argument <= value`| |`Lt(value)`           |`argument < value` | |`Ne(value)`           |`argument != value`| |`IsNull()`            |`argument` is a `NULL` pointer (raw or smart).| |`NotNull()`           |`argument` is a non-null pointer (raw or smart).| |`Ref(variable)`       |`argument` is a reference to `variable`.| |`TypedEq<type>(value)`|`argument` has type `type` and is equal to `value`. You may need to use this instead of `Eq(value)` when the mock function is overloaded.|
Except `Ref()`, these matchers make a _copy_ of `value` in case it's modified or destructed later. If the compiler complains that `value` doesn't have a public copy constructor, try wrap it in `ByRef()`, e.g. `Eq(ByRef(non_copyable_value))`. If you do that, make sure `non_copyable_value` is not changed afterwards, or the meaning of your matcher will be changed.
|`DoubleEq(a_double)`|`argument` is a `double` value approximately equal to `a_double`, treating two NaNs as unequal.| |:-------------------|:----------------------------------------------------------------------------------------------| |`FloatEq(a_float)`  |`argument` is a `float` value approximately equal to `a_float`, treating two NaNs as unequal.  | |`NanSensitiveDoubleEq(a_double)`|`argument` is a `double` value approximately equal to `a_double`, treating two NaNs as equal.  | |`NanSensitiveFloatEq(a_float)`|`argument` is a `float` value approximately equal to `a_float`, treating two NaNs as equal.    |
The above matchers use ULP-based comparison (the same as used in [Google Test](http://code.google.com/p/googletest/)). They automatically pick a reasonable error bound based on the absolute value of the expected value.  `DoubleEq()` and `FloatEq()` conform to the IEEE standard, which requires comparing two NaNs for equality to return false. The `NanSensitive*` version instead treats two NaNs as equal, which is often what a user wants.
The `argument` can be either a C string or a C++ string object:
|`ContainsRegex(string)`|`argument` matches the given regular expression.| |:----------------------|:-----------------------------------------------| |`EndsWith(suffix)`     |`argument` ends with string `suffix`.           | |`HasSubstr(string)`    |`argument` contains `string` as a sub-string.   | |`MatchesRegex(string)` |`argument` matches the given regular expression with the match starting at the first character and ending at the last character.| |`StartsWith(prefix)`   |`argument` starts with string `prefix`.         | |`StrCaseEq(string)`    |`argument` is equal to `string`, ignoring case. | |`StrCaseNe(string)`    |`argument` is not equal to `string`, ignoring case.| |`StrEq(string)`        |`argument` is equal to `string`.                | |`StrNe(string)`        |`argument` is not equal to `string`.            |
`StrCaseEq()`, `StrCaseNe()`, `StrEq()`, and `StrNe()` work for wide strings as well.
Most STL-style containers support `==`, so you can use `Eq(expected_container)` or simply `expected_container` to match a container exactly.   If you want to write the elements in-line, match them more flexibly, or get more informative messages, you can use:
| `Contains(e)` | `argument` contains an element that matches `e`, which can be either a value or a matcher. | |:--------------|:-------------------------------------------------------------------------------------------| |`ElementsAre(e0, e1, ..., en)`|`argument` has `n + 1` elements, where the i-th element matches `ei`, which can be a value or a matcher. 0 to 10 arguments are allowed.| |`ElementsAreArray(array)` or `ElementsAreArray(array, count)`|The same as `ElementsAre()` except that the expected element values/matchers come from a C-style array.| | `ContainerEq(container)` | The same as `Eq(container)` except that the failure message also includes which elements are in one container but not the other. |
These matchers can also match:
1. a native array passed by reference (e.g. in `Foo(const int (&a)[5])`), and   1. an array passed as a pointer and a count (e.g. in `Bar(const T* buffer, int len)` -- see [Multi-argument Matchers](#Multiargument_Matchers.md)).
where the array may be multi-dimensional (i.e. its elements can be arrays).
|`Field(&class::field, m)`|`argument.field` (or `argument->field` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_.| |:------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------| |`Key(e)`                 |`argument.first` matches `e`, which can be either a value or a matcher. E.g. `Contains(Key(Le(5)))` can verify that a `map` contains a key `<= 5`.| |`Pair(m1, m2)`           |`argument` is an `std::pair` whose `first` field matches `m1` and `second` field matches `m2`.                                                | |`Property(&class::property, m)`|`argument.property()` (or `argument->property()` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_.|
|`ResultOf(f, m)`|`f(argument)` matches matcher `m`, where `f` is a function or functor.| |:---------------|:---------------------------------------------------------------------|
|`Pointee(m)`|`argument` (either a smart pointer or a raw pointer) points to a value that matches matcher `m`.| |:-----------|:-----------------------------------------------------------------------------------------------|
These are matchers on tuple types. They can be used in `.With()`. The following can be used on functions with <i>two<br> arguments</i> `x` and `y`:
|`Eq()`|`x == y`| |:-----|:-------| |`Ge()`|`x >= y`| |`Gt()`|`x > y` | |`Le()`|`x <= y`| |`Lt()`|`x < y` | |`Ne()`|`x != y`|
You can use the following selectors to pick a subset of the arguments (or reorder them) to participate in the matching:
|`AllArgs(m)`|Equivalent to `m`. Useful as syntactic sugar in `.With(AllArgs(m))`.| |:-----------|:-------------------------------------------------------------------| |`Args<N1, N2, ..., Nk>(m)`|The `k` selected (using 0-based indices) arguments match `m`, e.g. `Args<1, 2>(Contains(5))`.|
You can make a matcher from one or more other matchers:
|`AllOf(m1, m2, ..., mn)`|`argument` matches all of the matchers `m1` to `mn`.| |:-----------------------|:---------------------------------------------------| |`AnyOf(m1, m2, ..., mn)`|`argument` matches at least one of the matchers `m1` to `mn`.| |`Not(m)`                |`argument` doesn't match matcher `m`.               |
|`MatcherCast<T>(m)`|casts matcher `m` to type `Matcher<T>`.| |:------------------|:--------------------------------------| |`SafeMatcherCast<T>(m)`| [safely casts](V1_5_CookBook#Casting_Matchers.md) matcher `m` to type `Matcher<T>`. | |`Truly(predicate)` |`predicate(argument)` returns something considered by C++ to be true, where `predicate` is a function or functor.|
|`Matches(m)`|a unary functor that returns `true` if the argument matches `m`.| |:-----------|:---------------------------------------------------------------| |`ExplainMatchResult(m, value, result_listener)`|returns `true` if `value` matches `m`, explaining the result to `result_listener`.| |`Value(x, m)`|returns `true` if the value of `x` matches `m`.                 |
| `MATCHER(IsEven, "") { return (arg % 2) == 0; }` | Defines a matcher `IsEven()` to match an even number. | |:-------------------------------------------------|:------------------------------------------------------| | `MATCHER_P(IsDivisibleBy, n, "") { *result_listener << "where the remainder is " << (arg % n); return (arg % n) == 0; }` | Defines a macher `IsDivisibleBy(n)` to match a number divisible by `n`. | | `MATCHER_P2(IsBetween, a, b, "is between %(a)s and %(b)s") { return a <= arg && arg <= b; }` | Defines a matcher `IsBetween(a, b)` to match a value in the range [`a`, `b`]. |
**Notes:**
1. The `MATCHER*` macros cannot be used inside a function or class.   1. The matcher body must be _purely functional_ (i.e. it cannot have any side effect, and the result must not depend on anything other than the value being matched and the matcher parameters).   1. You can use `PrintToString(x)` to convert a value `x` of any type to a string.
|`ASSERT_THAT(expression, m)`|Generates a [fatal failure](http://code.google.com/p/googletest/wiki/GoogleTestPrimer#Assertions) if the value of `expression` doesn't match matcher `m`.| |:---------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------| |`EXPECT_THAT(expression, m)`|Generates a non-fatal failure if the value of `expression` doesn't match matcher `m`.                                                                    |
**Actions** specify what a mock function should do when invoked.
|`Return()`|Return from a `void` mock function.| |:---------|:----------------------------------| |`Return(value)`|Return `value`.                    | |`ReturnArg<N>()`|Return the `N`-th (0-based) argument.| |`ReturnNew<T>(a1, ..., ak)`|Return `new T(a1, ..., ak)`; a different object is created each time.| |`ReturnNull()`|Return a null pointer.             | |`ReturnRef(variable)`|Return a reference to `variable`.  |
|`Assign(&variable, value)`|Assign `value` to variable.| |:-------------------------|:--------------------------| | `DeleteArg<N>()`         | Delete the `N`-th (0-based) argument, which must be a pointer. | | `SaveArg<N>(pointer)`    | Save the `N`-th (0-based) argument to `*pointer`. | | `SetArgReferee<N>(value)` |	Assign value to the variable referenced by the `N`-th (0-based) argument. | |`SetArgumentPointee<N>(value)`|Assign `value` to the variable pointed by the `N`-th (0-based) argument.| |`SetArrayArgument<N>(first, last)`|Copies the elements in source range [`first`, `last`) to the array pointed to by the `N`-th (0-based) argument, which can be either a pointer or an iterator. The action does not take ownership of the elements in the source range.| |`SetErrnoAndReturn(error, value)`|Set `errno` to `error` and return `value`.| |`Throw(exception)`        |Throws the given exception, which can be any copyable value. Available since v1.1.0.|
|`Invoke(f)`|Invoke `f` with the arguments passed to the mock function, where `f` can be a global/static function or a functor.| |:----------|:-----------------------------------------------------------------------------------------------------------------| |`Invoke(object_pointer, &class::method)`|Invoke the {method on the object with the arguments passed to the mock function.                                  | |`InvokeWithoutArgs(f)`|Invoke `f`, which can be a global/static function or a functor. `f` must take no arguments.                       | |`InvokeWithoutArgs(object_pointer, &class::method)`|Invoke the method on the object, which takes no arguments.                                                        | |`InvokeArgument<N>(arg1, arg2, ..., argk)`|Invoke the mock function's `N`-th (0-based) argument, which must be a function or a functor, with the `k` arguments.|
The return value of the invoked function is used as the return value of the action.
When defining a function or functor to be used with `Invoke*()`, you can declare any unused parameters as `Unused`: ```   double Distance(Unused, double x, double y) { return sqrt(x*x + y*y); }   ...   EXPECT_CALL(mock, Foo("Hi", _, _)).WillOnce(Invoke(Distance)); ```
In `InvokeArgument<N>(...)`, if an argument needs to be passed by reference, wrap it inside `ByRef()`. For example, ```   InvokeArgument<2>(5, string("Hi"), ByRef(foo)) ``` calls the mock function's #2 argument, passing to it `5` and `string("Hi")` by value, and `foo` by reference.
|`DoDefault()`|Do the default action (specified by `ON_CALL()` or the built-in one).| |:------------|:--------------------------------------------------------------------|
**Note:** due to technical reasons, `DoDefault()` cannot be used inside  a composite action - trying to do so will result in a run-time error.
|`DoAll(a1, a2, ..., an)`|Do all actions `a1` to `an` and return the result of `an` in each invocation. The first `n - 1` sub-actions must return void. | |:-----------------------|:-----------------------------------------------------------------------------------------------------------------------------| |`IgnoreResult(a)`       |Perform action `a` and ignore its result. `a` must not return void.                                                           | |`WithArg<N>(a)`         |Pass the `N`-th (0-based) argument of the mock function to action `a` and perform it.                                         | |`WithArgs<N1, N2, ..., Nk>(a)`|Pass the selected (0-based) arguments of the mock function to action `a` and perform it.                                      | |`WithoutArgs(a)`        |Perform action `a` without any arguments.                                                                                     |
| `ACTION(Sum) { return arg0 + arg1; }` | Defines an action `Sum()` to return the sum of the mock function's argument #0 and #1. | |:--------------------------------------|:---------------------------------------------------------------------------------------| | `ACTION_P(Plus, n) { return arg0 + n; }` | Defines an action `Plus(n)` to return the sum of the mock function's argument #0 and `n`. | | `ACTION_Pk(Foo, p1, ..., pk) { statements; }` | Defines a parameterized action `Foo(p1, ..., pk)` to execute the given `statements`.   |
The `ACTION*` macros cannot be used inside a function or class.
These are used in `Times()` to specify how many times a mock function will be called:
|`AnyNumber()`|The function can be called any number of times.| |:------------|:----------------------------------------------| |`AtLeast(n)` |The call is expected at least `n` times.       | |`AtMost(n)`  |The call is expected at most `n` times.        | |`Between(m, n)`|The call is expected between `m` and `n` (inclusive) times.| |`Exactly(n) or n`|The call is expected exactly `n` times. In particular, the call should never happen when `n` is 0.|
By default, the expectations can be matched in _any_ order.  If some or all expectations must be matched in a given order, there are two ways to specify it.  They can be used either independently or together.
``` using ::testing::Expectation; ... Expectation init_x = EXPECT_CALL(foo, InitX()); Expectation init_y = EXPECT_CALL(foo, InitY()); EXPECT_CALL(foo, Bar())     .After(init_x, init_y); ``` says that `Bar()` can be called only after both `InitX()` and `InitY()` have been called.
If you don't know how many pre-requisites an expectation has when you write it, you can use an `ExpectationSet` to collect them:
``` using ::testing::ExpectationSet; ... ExpectationSet all_inits; for (int i = 0; i < element_count; i++) {   all_inits += EXPECT_CALL(foo, InitElement(i)); } EXPECT_CALL(foo, Bar())     .After(all_inits); ``` says that `Bar()` can be called only after all elements have been initialized (but we don't care about which elements get initialized before the others).
Modifying an `ExpectationSet` after using it in an `.After()` doesn't affect the meaning of the `.After()`.
When you have a long chain of sequential expectations, it's easier to specify the order using **sequences**, which don't require you to given each expectation in the chain a different name.  <i>All expected<br> calls</i> in the same sequence must occur in the order they are specified.
``` using ::testing::Sequence; Sequence s1, s2; ... EXPECT_CALL(foo, Reset())     .InSequence(s1, s2)     .WillOnce(Return(true)); EXPECT_CALL(foo, GetSize())     .InSequence(s1)     .WillOnce(Return(1)); EXPECT_CALL(foo, Describe(A<const char*>()))     .InSequence(s2)     .WillOnce(Return("dummy")); ``` says that `Reset()` must be called before _both_ `GetSize()` _and_ `Describe()`, and the latter two can occur in any order.
To put many expectations in a sequence conveniently: ``` using ::testing::InSequence; {   InSequence dummy;
EXPECT_CALL(...)...;   EXPECT_CALL(...)...;   ...   EXPECT_CALL(...)...; } ``` says that all expected calls in the scope of `dummy` must occur in strict order. The name `dummy` is irrelevant.)
Google Mock will verify the expectations on a mock object when it is destructed, or you can do it earlier: ``` using ::testing::Mock; ... // Verifies and removes the expectations on mock_obj; // returns true iff successful. Mock::VerifyAndClearExpectations(&mock_obj); ... // Verifies and removes the expectations on mock_obj; // also removes the default actions set by ON_CALL(); // returns true iff successful. Mock::VerifyAndClear(&mock_obj); ```
You can also tell Google Mock that a mock object can be leaked and doesn't need to be verified: ``` Mock::AllowLeak(&mock_obj); ```
Google Mock defines a convenient mock class template ``` class MockFunction<R(A1, ..., An)> {  public:   MOCK_METHODn(Call, R(A1, ..., An)); }; ``` See this [recipe](V1_5_CookBook#Using_Check_Points.md) for one application of it.
| `--gmock_catch_leaked_mocks=0` | Don't report leaked mock objects as failures. | |:-------------------------------|:----------------------------------------------| | `--gmock_verbose=LEVEL`        | Sets the default verbosity level (`info`, `warning`, or `error`) of Google Mock messages. |

You can find recipes for using Google Mock here. If you haven't yet, please read the [ForDummies](V1_5_ForDummies.md) document first to make sure you understand the basics.
**Note:** Google Mock lives in the `testing` name space. For readability, it is recommended to write `using ::testing::Foo;` once in your file before using the name `Foo` defined by Google Mock. We omit such `using` statements in this page for brevity, but you should do it in your own code.
You must always put a mock method definition (`MOCK_METHOD*`) in a `public:` section of the mock class, regardless of the method being mocked being `public`, `protected`, or `private` in the base class. This allows `ON_CALL` and `EXPECT_CALL` to reference the mock function from outside of the mock class.  (Yes, C++ allows a subclass to change the access level of a virtual function in the base class.)  Example:
``` class Foo {  public:   ...   virtual bool Transform(Gadget* g) = 0;
protected:   virtual void Resume();
private:   virtual int GetTimeOut(); };
class MockFoo : public Foo {  public:   ...   MOCK_METHOD1(Transform, bool(Gadget* g));
// The following must be in the public section, even though the   // methods are protected or private in the base class.   MOCK_METHOD0(Resume, void());   MOCK_METHOD0(GetTimeOut, int()); }; ```
You can mock overloaded functions as usual. No special attention is required:
``` class Foo {   ...
// Must be virtual as we'll inherit from Foo.   virtual ~Foo();
// Overloaded on the types and/or numbers of arguments.   virtual int Add(Element x);   virtual int Add(int times, Element x);
// Overloaded on the const-ness of this object.   virtual Bar& GetBar();   virtual const Bar& GetBar() const; };
class MockFoo : public Foo {   ...   MOCK_METHOD1(Add, int(Element x));   MOCK_METHOD2(Add, int(int times, Element x);
MOCK_METHOD0(GetBar, Bar&());   MOCK_CONST_METHOD0(GetBar, const Bar&()); }; ```
**Note:** if you don't mock all versions of the overloaded method, the compiler will give you a warning about some methods in the base class being hidden. To fix that, use `using` to bring them in scope:
``` class MockFoo : public Foo {   ...   using Foo::Add;   MOCK_METHOD1(Add, int(Element x));   // We don't want to mock int Add(int times, Element x);   ... }; ```
To mock a class template, append `_T` to the `MOCK_*` macros:
``` template <typename Elem> class StackInterface {   ...   // Must be virtual as we'll inherit from StackInterface.   virtual ~StackInterface();
virtual int GetSize() const = 0;   virtual void Push(const Elem& x) = 0; };
template <typename Elem> class MockStack : public StackInterface<Elem> {   ...   MOCK_CONST_METHOD0_T(GetSize, int());   MOCK_METHOD1_T(Push, void(const Elem& x)); }; ```
Google Mock can mock non-virtual functions to be used in what we call _hi-perf dependency injection_.
In this case, instead of sharing a common base class with the real class, your mock class will be _unrelated_ to the real class, but contain methods with the same signatures.  The syntax for mocking non-virtual methods is the _same_ as mocking virtual methods:
``` // A simple packet stream class.  None of its members is virtual. class ConcretePacketStream {  public:   void AppendPacket(Packet* new_packet);   const Packet* GetPacket(size_t packet_number) const;   size_t NumberOfPackets() const;   ... };
// A mock packet stream class.  It inherits from no other, but defines // GetPacket() and NumberOfPackets(). class MockPacketStream {  public:   MOCK_CONST_METHOD1(GetPacket, const Packet*(size_t packet_number));   MOCK_CONST_METHOD0(NumberOfPackets, size_t());   ... }; ```
Note that the mock class doesn't define `AppendPacket()`, unlike the real class. That's fine as long as the test doesn't need to call it.
Next, you need a way to say that you want to use `ConcretePacketStream` in production code, and use `MockPacketStream` in tests.  Since the functions are not virtual and the two classes are unrelated, you must specify your choice at _compile time_ (as opposed to run time).
One way to do it is to templatize your code that needs to use a packet stream.  More specifically, you will give your code a template type argument for the type of the packet stream.  In production, you will instantiate your template with `ConcretePacketStream` as the type argument.  In tests, you will instantiate the same template with `MockPacketStream`.  For example, you may write:
``` template <class PacketStream> void CreateConnection(PacketStream* stream) { ... }
template <class PacketStream> class PacketReader {  public:   void ReadPackets(PacketStream* stream, size_t packet_num); }; ```
Then you can use `CreateConnection<ConcretePacketStream>()` and `PacketReader<ConcretePacketStream>` in production code, and use `CreateConnection<MockPacketStream>()` and `PacketReader<MockPacketStream>` in tests.
```   MockPacketStream mock_stream;   EXPECT_CALL(mock_stream, ...)...;   .. set more expectations on mock_stream ...   PacketReader<MockPacketStream> reader(&mock_stream);   ... exercise reader ... ```
It's possible to use Google Mock to mock a free function (i.e. a C-style function or a static method).  You just need to rewrite your code to use an interface (abstract class).
Instead of calling a free function (say, `OpenFile`) directly, introduce an interface for it and have a concrete subclass that calls the free function:
``` class FileInterface {  public:   ...   virtual bool Open(const char* path, const char* mode) = 0; };
class File : public FileInterface {  public:   ...   virtual bool Open(const char* path, const char* mode) {     return OpenFile(path, mode);   } }; ```
Your code should talk to `FileInterface` to open a file.  Now it's easy to mock out the function.
This may seem much hassle, but in practice you often have multiple related functions that you can put in the same interface, so the per-function syntactic overhead will be much lower.
If you are concerned about the performance overhead incurred by virtual functions, and profiling confirms your concern, you can combine this with the recipe for [mocking non-virtual methods](#Mocking_Nonvirtual_Methods.md).
If a mock method has no `EXPECT_CALL` spec but is called, Google Mock will print a warning about the "uninteresting call". The rationale is:
* New methods may be added to an interface after a test is written. We shouldn't fail a test just because a method it doesn't know about is called.   * However, this may also mean there's a bug in the test, so Google Mock shouldn't be silent either. If the user believes these calls are harmless, he can add an `EXPECT_CALL()` to suppress the warning.
However, sometimes you may want to suppress all "uninteresting call" warnings, while sometimes you may want the opposite, i.e. to treat all of them as errors. Google Mock lets you make the decision on a per-mock-object basis.
Suppose your test uses a mock class `MockFoo`:
``` TEST(...) {   MockFoo mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
If a method of `mock_foo` other than `DoThis()` is called, it will be reported by Google Mock as a warning. However, if you rewrite your test to use `NiceMock<MockFoo>` instead, the warning will be gone, resulting in a cleaner test output:
``` using ::testing::NiceMock;
TEST(...) {   NiceMock<MockFoo> mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
`NiceMock<MockFoo>` is a subclass of `MockFoo`, so it can be used wherever `MockFoo` is accepted.
It also works if `MockFoo`'s constructor takes some arguments, as `NiceMock<MockFoo>` "inherits" `MockFoo`'s constructors:
``` using ::testing::NiceMock;
TEST(...) {   NiceMock<MockFoo> mock_foo(5, "hi");  // Calls MockFoo(5, "hi").   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
The usage of `StrictMock` is similar, except that it makes all uninteresting calls failures:
``` using ::testing::StrictMock;
TEST(...) {   StrictMock<MockFoo> mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ...
// The test will fail if a method of mock_foo other than DoThis()   // is called. } ```
There are some caveats though (I don't like them just as much as the next guy, but sadly they are side effects of C++'s limitations):
1. `NiceMock<MockFoo>` and `StrictMock<MockFoo>` only work for mock methods defined using the `MOCK_METHOD*` family of macros **directly** in the `MockFoo` class. If a mock method is defined in a **base class** of `MockFoo`, the "nice" or "strict" modifier may not affect it, depending on the compiler. In particular, nesting `NiceMock` and `StrictMock` (e.g. `NiceMock<StrictMock<MockFoo> >`) is **not** supported.   1. The constructors of the base mock (`MockFoo`) cannot have arguments passed by non-const reference, which happens to be banned by the [Google C++ style guide](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml).   1. During the constructor or destructor of `MockFoo`, the mock object is _not_ nice or strict.  This may cause surprises if the constructor or destructor calls a mock method on `this` object. (This behavior, however, is consistent with C++'s general rule: if a constructor or destructor calls a virtual method of `this` object, that method is treated as non-virtual.  In other words, to the base class's constructor or destructor, `this` object behaves like an instance of the base class, not the derived class.  This rule is required for safety.  Otherwise a base constructor may use members of a derived class before they are initialized, or a base destructor may use members of a derived class after they have been destroyed.)
Finally, you should be **very cautious** when using this feature, as the decision you make applies to **all** future changes to the mock class. If an important change is made in the interface you are mocking (and thus in the mock class), it could break your tests (if you use `StrictMock`) or let bugs pass through without a warning (if you use `NiceMock`). Therefore, try to specify the mock's behavior using explicit `EXPECT_CALL` first, and only turn to `NiceMock` or `StrictMock` as the last resort.
Sometimes a method has a long list of arguments that is mostly uninteresting. For example,
``` class LogSink {  public:   ...   virtual void send(LogSeverity severity, const char* full_filename,                     const char* base_filename, int line,                     const struct tm* tm_time,                     const char* message, size_t message_len) = 0; }; ```
This method's argument list is lengthy and hard to work with (let's say that the `message` argument is not even 0-terminated). If we mock it as is, using the mock will be awkward. If, however, we try to simplify this interface, we'll need to fix all clients depending on it, which is often infeasible.
The trick is to re-dispatch the method in the mock class:
``` class ScopedMockLog : public LogSink {  public:   ...   virtual void send(LogSeverity severity, const char* full_filename,                     const char* base_filename, int line, const tm* tm_time,                     const char* message, size_t message_len) {     // We are only interested in the log severity, full file name, and     // log message.     Log(severity, full_filename, std::string(message, message_len));   }
// Implements the mock method:   //   //   void Log(LogSeverity severity,   //            const string& file_path,   //            const string& message);   MOCK_METHOD3(Log, void(LogSeverity severity, const string& file_path,                          const string& message)); }; ```
By defining a new mock method with a trimmed argument list, we make the mock class much more user-friendly.
Often you may find yourself using classes that don't implement interfaces. In order to test your code that uses such a class (let's call it `Concrete`), you may be tempted to make the methods of `Concrete` virtual and then mock it.
Try not to do that.
Making a non-virtual function virtual is a big decision. It creates an extension point where subclasses can tweak your class' behavior. This weakens your control on the class because now it's harder to maintain the class' invariants. You should make a function virtual only when there is a valid reason for a subclass to override it.
Mocking concrete classes directly is problematic as it creates a tight coupling between the class and the tests - any small change in the class may invalidate your tests and make test maintenance a pain.
To avoid such problems, many programmers have been practicing "coding to interfaces": instead of talking to the `Concrete` class, your code would define an interface and talk to it. Then you implement that interface as an adaptor on top of `Concrete`. In tests, you can easily mock that interface to observe how your code is doing.
This technique incurs some overhead:
* You pay the cost of virtual function calls (usually not a problem).   * There is more abstraction for the programmers to learn.
However, it can also bring significant benefits in addition to better testability:
* `Concrete`'s API may not fit your problem domain very well, as you may not be the only client it tries to serve. By designing your own interface, you have a chance to tailor it to your need - you may add higher-level functionalities, rename stuff, etc instead of just trimming the class. This allows you to write your code (user of the interface) in a more natural way, which means it will be more readable, more maintainable, and you'll be more productive.   * If `Concrete`'s implementation ever has to change, you don't have to rewrite everywhere it is used. Instead, you can absorb the change in your implementation of the interface, and your other code and tests will be insulated from this change.
Some people worry that if everyone is practicing this technique, they will end up writing lots of redundant code. This concern is totally understandable. However, there are two reasons why it may not be the case:
* Different projects may need to use `Concrete` in different ways, so the best interfaces for them will be different. Therefore, each of them will have its own domain-specific interface on top of `Concrete`, and they will not be the same code.   * If enough projects want to use the same interface, they can always share it, just like they have been sharing `Concrete`. You can check in the interface and the adaptor somewhere near `Concrete` (perhaps in a `contrib` sub-directory) and let many projects use it.
You need to weigh the pros and cons carefully for your particular problem, but I'd like to assure you that the Java community has been practicing this for a long time and it's a proven effective technique applicable in a wide variety of situations. :-)
Some times you have a non-trivial fake implementation of an interface. For example:
``` class Foo {  public:   virtual ~Foo() {}   virtual char DoThis(int n) = 0;   virtual void DoThat(const char* s, int* p) = 0; };
class FakeFoo : public Foo {  public:   virtual char DoThis(int n) {     return (n > 0) ? '+' :         (n < 0) ? '-' : '0';   }
virtual void DoThat(const char* s, int* p) {     *p = strlen(s);   } }; ```
Now you want to mock this interface such that you can set expectations on it. However, you also want to use `FakeFoo` for the default behavior, as duplicating it in the mock object is, well, a lot of work.
When you define the mock class using Google Mock, you can have it delegate its default action to a fake class you already have, using this pattern:
``` using ::testing::_; using ::testing::Invoke;
class MockFoo : public Foo {  public:   // Normal mock method definitions using Google Mock.   MOCK_METHOD1(DoThis, char(int n));   MOCK_METHOD2(DoThat, void(const char* s, int* p));
// Delegates the default actions of the methods to a FakeFoo object.   // This must be called *before* the custom ON_CALL() statements.   void DelegateToFake() {     ON_CALL(*this, DoThis(_))         .WillByDefault(Invoke(&fake_, &FakeFoo::DoThis));     ON_CALL(*this, DoThat(_, _))         .WillByDefault(Invoke(&fake_, &FakeFoo::DoThat));   }  private:   FakeFoo fake_;  // Keeps an instance of the fake in the mock. }; ```
With that, you can use `MockFoo` in your tests as usual. Just remember that if you don't explicitly set an action in an `ON_CALL()` or `EXPECT_CALL()`, the fake will be called upon to do it:
``` using ::testing::_;
TEST(AbcTest, Xyz) {   MockFoo foo;   foo.DelegateToFake(); // Enables the fake for delegation.
// Put your ON_CALL(foo, ...)s here, if any.
// No action specified, meaning to use the default action.   EXPECT_CALL(foo, DoThis(5));   EXPECT_CALL(foo, DoThat(_, _));
int n = 0;   EXPECT_EQ('+', foo.DoThis(5));  // FakeFoo::DoThis() is invoked.   foo.DoThat("Hi", &n);           // FakeFoo::DoThat() is invoked.   EXPECT_EQ(2, n); } ```
**Some tips:**
* If you want, you can still override the default action by providing your own `ON_CALL()` or using `.WillOnce()` / `.WillRepeatedly()` in `EXPECT_CALL()`.   * In `DelegateToFake()`, you only need to delegate the methods whose fake implementation you intend to use.   * The general technique discussed here works for overloaded methods, but you'll need to tell the compiler which version you mean. To disambiguate a mock function (the one you specify inside the parentheses of `ON_CALL()`), see the "Selecting Between Overloaded Functions" section on this page; to disambiguate a fake function (the one you place inside `Invoke()`), use a `static_cast` to specify the function's type.   * Having to mix a mock and a fake is often a sign of something gone wrong. Perhaps you haven't got used to the interaction-based way of testing yet. Or perhaps your interface is taking on too many roles and should be split up. Therefore, **don't abuse this**. We would only recommend to do it as an intermediate step when you are refactoring your code.
Regarding the tip on mixing a mock and a fake, here's an example on why it may be a bad sign: Suppose you have a class `System` for low-level system operations. In particular, it does file and I/O operations. And suppose you want to test how your code uses `System` to do I/O, and you just want the file operations to work normally. If you mock out the entire `System` class, you'll have to provide a fake implementation for the file operation part, which suggests that `System` is taking on too many roles.
Instead, you can define a `FileOps` interface and an `IOOps` interface and split `System`'s functionalities into the two. Then you can mock `IOOps` without mocking `FileOps`.
When using testing doubles (mocks, fakes, stubs, and etc), sometimes their behaviors will differ from those of the real objects. This difference could be either intentional (as in simulating an error such that you can test the error handling code) or unintentional. If your mocks have different behaviors than the real objects by mistake, you could end up with code that passes the tests but fails in production.
You can use the _delegating-to-real_ technique to ensure that your mock has the same behavior as the real object while retaining the ability to validate calls. This technique is very similar to the delegating-to-fake technique, the difference being that we use a real object instead of a fake. Here's an example:
``` using ::testing::_; using ::testing::AtLeast; using ::testing::Invoke;
class MockFoo : public Foo {  public:   MockFoo() {     // By default, all calls are delegated to the real object.     ON_CALL(*this, DoThis())         .WillByDefault(Invoke(&real_, &Foo::DoThis));     ON_CALL(*this, DoThat(_))         .WillByDefault(Invoke(&real_, &Foo::DoThat));     ...   }   MOCK_METHOD0(DoThis, ...);   MOCK_METHOD1(DoThat, ...);   ...  private:   Foo real_; }; ...
MockFoo mock;
EXPECT_CALL(mock, DoThis())       .Times(3);   EXPECT_CALL(mock, DoThat("Hi"))       .Times(AtLeast(1));   ... use mock in test ... ```
With this, Google Mock will verify that your code made the right calls (with the right arguments, in the right order, called the right number of times, etc), and a real object will answer the calls (so the behavior will be the same as in production). This gives you the best of both worlds.
Ideally, you should code to interfaces, whose methods are all pure virtual. In reality, sometimes you do need to mock a virtual method that is not pure (i.e, it already has an implementation). For example:
``` class Foo {  public:   virtual ~Foo();
virtual void Pure(int n) = 0;   virtual int Concrete(const char* str) { ... } };
class MockFoo : public Foo {  public:   // Mocking a pure method.   MOCK_METHOD1(Pure, void(int n));   // Mocking a concrete method.  Foo::Concrete() is shadowed.   MOCK_METHOD1(Concrete, int(const char* str)); }; ```
Sometimes you may want to call `Foo::Concrete()` instead of `MockFoo::Concrete()`. Perhaps you want to do it as part of a stub action, or perhaps your test doesn't need to mock `Concrete()` at all (but it would be oh-so painful to have to define a new mock class whenever you don't need to mock one of its methods).
The trick is to leave a back door in your mock class for accessing the real methods in the base class:
``` class MockFoo : public Foo {  public:   // Mocking a pure method.   MOCK_METHOD1(Pure, void(int n));   // Mocking a concrete method.  Foo::Concrete() is shadowed.   MOCK_METHOD1(Concrete, int(const char* str));
// Use this to call Concrete() defined in Foo.   int FooConcrete(const char* str) { return Foo::Concrete(str); } }; ```
Now, you can call `Foo::Concrete()` inside an action by:
``` using ::testing::_; using ::testing::Invoke; ...   EXPECT_CALL(foo, Concrete(_))       .WillOnce(Invoke(&foo, &MockFoo::FooConcrete)); ```
or tell the mock object that you don't want to mock `Concrete()`:
``` using ::testing::Invoke; ...   ON_CALL(foo, Concrete(_))       .WillByDefault(Invoke(&foo, &MockFoo::FooConcrete)); ```
(Why don't we just write `Invoke(&foo, &Foo::Concrete)`? If you do that, `MockFoo::Concrete()` will be called (and cause an infinite recursion) since `Foo::Concrete()` is virtual. That's just how C++ works.)
You can specify exactly which arguments a mock method is expecting:
``` using ::testing::Return; ...   EXPECT_CALL(foo, DoThis(5))       .WillOnce(Return('a'));   EXPECT_CALL(foo, DoThat("Hello", bar)); ```
You can use matchers to match arguments that have a certain property:
``` using ::testing::Ge; using ::testing::NotNull; using ::testing::Return; ...   EXPECT_CALL(foo, DoThis(Ge(5)))  // The argument must be >= 5.       .WillOnce(Return('a'));   EXPECT_CALL(foo, DoThat("Hello", NotNull()));   // The second argument must not be NULL. ```
A frequently used matcher is `_`, which matches anything:
``` using ::testing::_; using ::testing::NotNull; ...   EXPECT_CALL(foo, DoThat(_, NotNull())); ```
You can build complex matchers from existing ones using `AllOf()`, `AnyOf()`, and `Not()`:
``` using ::testing::AllOf; using ::testing::Gt; using ::testing::HasSubstr; using ::testing::Ne; using ::testing::Not; ...   // The argument must be > 5 and != 10.   EXPECT_CALL(foo, DoThis(AllOf(Gt(5),                                 Ne(10))));
// The first argument must not contain sub-string "blah".   EXPECT_CALL(foo, DoThat(Not(HasSubstr("blah")),                           NULL)); ```
Google Mock matchers are statically typed, meaning that the compiler can catch your mistake if you use a matcher of the wrong type (for example, if you use `Eq(5)` to match a `string` argument). Good for you!
Sometimes, however, you know what you're doing and want the compiler to give you some slack. One example is that you have a matcher for `long` and the argument you want to match is `int`. While the two types aren't exactly the same, there is nothing really wrong with using a `Matcher<long>` to match an `int` - after all, we can first convert the `int` argument to a `long` before giving it to the matcher.
To support this need, Google Mock gives you the `SafeMatcherCast<T>(m)` function. It casts a matcher `m` to type `Matcher<T>`. To ensure safety, Google Mock checks that (let `U` be the type `m` accepts):
1. Type `T` can be implicitly cast to type `U`;   1. When both `T` and `U` are built-in arithmetic types (`bool`, integers, and floating-point numbers), the conversion from `T` to `U` is not lossy (in other words, any value representable by `T` can also be represented by `U`); and   1. When `U` is a reference, `T` must also be a reference (as the underlying matcher may be interested in the address of the `U` value).
The code won't compile if any of these conditions isn't met.
Here's one example:
``` using ::testing::SafeMatcherCast;
// A base class and a child class. class Base { ... }; class Derived : public Base { ... };
class MockFoo : public Foo {  public:   MOCK_METHOD1(DoThis, void(Derived* derived)); }; ...
MockFoo foo;   // m is a Matcher<Base*> we got from somewhere.   EXPECT_CALL(foo, DoThis(SafeMatcherCast<Derived*>(m))); ```
If you find `SafeMatcherCast<T>(m)` too limiting, you can use a similar function `MatcherCast<T>(m)`. The difference is that `MatcherCast` works as long as you can `static_cast` type `T` to type `U`.
`MatcherCast` essentially lets you bypass C++'s type system (`static_cast` isn't always safe as it could throw away information, for example), so be careful not to misuse/abuse it.
If you expect an overloaded function to be called, the compiler may need some help on which overloaded version it is.
To disambiguate functions overloaded on the const-ness of this object, use the `Const()` argument wrapper.
``` using ::testing::ReturnRef;
class MockFoo : public Foo {   ...   MOCK_METHOD0(GetBar, Bar&());   MOCK_CONST_METHOD0(GetBar, const Bar&()); }; ...
MockFoo foo;   Bar bar1, bar2;   EXPECT_CALL(foo, GetBar())         // The non-const GetBar().       .WillOnce(ReturnRef(bar1));   EXPECT_CALL(Const(foo), GetBar())  // The const GetBar().       .WillOnce(ReturnRef(bar2)); ```
(`Const()` is defined by Google Mock and returns a `const` reference to its argument.)
To disambiguate overloaded functions with the same number of arguments but different argument types, you may need to specify the exact type of a matcher, either by wrapping your matcher in `Matcher<type>()`, or using a matcher whose type is fixed (`TypedEq<type>`, `An<type>()`, etc):
``` using ::testing::An; using ::testing::Lt; using ::testing::Matcher; using ::testing::TypedEq;
class MockPrinter : public Printer {  public:   MOCK_METHOD1(Print, void(int n));   MOCK_METHOD1(Print, void(char c)); };
TEST(PrinterTest, Print) {   MockPrinter printer;
EXPECT_CALL(printer, Print(An<int>()));            // void Print(int);   EXPECT_CALL(printer, Print(Matcher<int>(Lt(5))));  // void Print(int);   EXPECT_CALL(printer, Print(TypedEq<char>('a')));   // void Print(char);
printer.Print(3);   printer.Print(6);   printer.Print('a'); } ```
When a mock method is called, the _last_ matching expectation that's still active will be selected (think "newer overrides older"). So, you can make a method do different things depending on its argument values like this:
``` using ::testing::_; using ::testing::Lt; using ::testing::Return; ...   // The default case.   EXPECT_CALL(foo, DoThis(_))       .WillRepeatedly(Return('b'));
// The more specific case.   EXPECT_CALL(foo, DoThis(Lt(5)))       .WillRepeatedly(Return('a')); ```
Now, if `foo.DoThis()` is called with a value less than 5, `'a'` will be returned; otherwise `'b'` will be returned.
Sometimes it's not enough to match the arguments individually. For example, we may want to say that the first argument must be less than the second argument. The `With()` clause allows us to match all arguments of a mock function as a whole. For example,
``` using ::testing::_; using ::testing::Lt; using ::testing::Ne; ...   EXPECT_CALL(foo, InRange(Ne(0), _))       .With(Lt()); ```
says that the first argument of `InRange()` must not be 0, and must be less than the second argument.
The expression inside `With()` must be a matcher of type `Matcher<tr1::tuple<A1, ..., An> >`, where `A1`, ..., `An` are the types of the function arguments.
You can also write `AllArgs(m)` instead of `m` inside `.With()`. The two forms are equivalent, but `.With(AllArgs(Lt()))` is more readable than `.With(Lt())`.
You can use `Args<k1, ..., kn>(m)` to match the `n` selected arguments against `m`. For example,
``` using ::testing::_; using ::testing::AllOf; using ::testing::Args; using ::testing::Lt; ...   EXPECT_CALL(foo, Blah(_, _, _))       .With(AllOf(Args<0, 1>(Lt()), Args<1, 2>(Lt()))); ```
says that `Blah()` will be called with arguments `x`, `y`, and `z` where `x < y < z`.
As a convenience and example, Google Mock provides some matchers for 2-tuples, including the `Lt()` matcher above. See the [CheatSheet](V1_5_CheatSheet.md) for the complete list.
Have you noticed that a matcher is just a fancy predicate that also knows how to describe itself? Many existing algorithms take predicates as arguments (e.g. those defined in STL's `<algorithm>` header), and it would be a shame if Google Mock matchers are not allowed to participate.
Luckily, you can use a matcher where a unary predicate functor is expected by wrapping it inside the `Matches()` function. For example,
``` #include <algorithm> #include <vector>
std::vector<int> v; ... // How many elements in v are >= 10? const int count = count_if(v.begin(), v.end(), Matches(Ge(10))); ```
Since you can build complex matchers from simpler ones easily using Google Mock, this gives you a way to conveniently construct composite predicates (doing the same using STL's `<functional>` header is just painful). For example, here's a predicate that's satisfied by any number that is >= 0, <= 100, and != 50:
``` Matches(AllOf(Ge(0), Le(100), Ne(50))) ```
Since matchers are basically predicates that also know how to describe themselves, there is a way to take advantage of them in [Google Test](http://code.google.com/p/googletest/) assertions. It's called `ASSERT_THAT` and `EXPECT_THAT`:
```   ASSERT_THAT(value, matcher);  // Asserts that value matches matcher.   EXPECT_THAT(value, matcher);  // The non-fatal version. ```
For example, in a Google Test test you can write:
``` #include <gmock/gmock.h>
using ::testing::AllOf; using ::testing::Ge; using ::testing::Le; using ::testing::MatchesRegex; using ::testing::StartsWith; ...
EXPECT_THAT(Foo(), StartsWith("Hello"));   EXPECT_THAT(Bar(), MatchesRegex("Line \\d+"));   ASSERT_THAT(Baz(), AllOf(Ge(5), Le(10))); ```
which (as you can probably guess) executes `Foo()`, `Bar()`, and `Baz()`, and verifies that:
* `Foo()` returns a string that starts with `"Hello"`.   * `Bar()` returns a string that matches regular expression `"Line \\d+"`.   * `Baz()` returns a number in the range [5, 10].
The nice thing about these macros is that _they read like English_. They generate informative messages too. For example, if the first `EXPECT_THAT()` above fails, the message will be something like:
``` Value of: Foo()   Actual: "Hi, world!" Expected: starts with "Hello" ```
**Credit:** The idea of `(ASSERT|EXPECT)_THAT` was stolen from the [Hamcrest](http://code.google.com/p/hamcrest/) project, which adds `assertThat()` to JUnit.
Google Mock provides a built-in set of matchers. In case you find them lacking, you can use an arbitray unary predicate function or functor as a matcher - as long as the predicate accepts a value of the type you want. You do this by wrapping the predicate inside the `Truly()` function, for example:
``` using ::testing::Truly;
int IsEven(int n) { return (n % 2) == 0 ? 1 : 0; } ...
// Bar() must be called with an even number.   EXPECT_CALL(foo, Bar(Truly(IsEven))); ```
Note that the predicate function / functor doesn't have to return `bool`. It works as long as the return value can be used as the condition in statement `if (condition) ...`.
When you do an `EXPECT_CALL(mock_obj, Foo(bar))`, Google Mock saves away a copy of `bar`. When `Foo()` is called later, Google Mock compares the argument to `Foo()` with the saved copy of `bar`. This way, you don't need to worry about `bar` being modified or destroyed after the `EXPECT_CALL()` is executed. The same is true when you use matchers like `Eq(bar)`, `Le(bar)`, and so on.
But what if `bar` cannot be copied (i.e. has no copy constructor)? You could define your own matcher function and use it with `Truly()`, as the previous couple of recipes have shown. Or, you may be able to get away from it if you can guarantee that `bar` won't be changed after the `EXPECT_CALL()` is executed. Just tell Google Mock that it should save a reference to `bar`, instead of a copy of it. Here's how:
``` using ::testing::Eq; using ::testing::ByRef; using ::testing::Lt; ...   // Expects that Foo()'s argument == bar.   EXPECT_CALL(mock_obj, Foo(Eq(ByRef(bar))));
// Expects that Foo()'s argument < bar.   EXPECT_CALL(mock_obj, Foo(Lt(ByRef(bar)))); ```
Remember: if you do this, don't change `bar` after the `EXPECT_CALL()`, or the result is undefined.
Often a mock function takes a reference to object as an argument. When matching the argument, you may not want to compare the entire object against a fixed object, as that may be over-specification. Instead, you may need to validate a certain member variable or the result of a certain getter method of the object. You can do this with `Field()` and `Property()`. More specifically,
``` Field(&Foo::bar, m) ```
is a matcher that matches a `Foo` object whose `bar` member variable satisfies matcher `m`.
``` Property(&Foo::baz, m) ```
is a matcher that matches a `Foo` object whose `baz()` method returns a value that satisfies matcher `m`.
For example:
> | `Field(&Foo::number, Ge(3))` | Matches `x` where `x.number >= 3`. | |:-----------------------------|:-----------------------------------| > | `Property(&Foo::name, StartsWith("John "))` | Matches `x` where `x.name()` starts with `"John "`. |
Note that in `Property(&Foo::baz, ...)`, method `baz()` must take no argument and be declared as `const`.
BTW, `Field()` and `Property()` can also match plain pointers to objects. For instance,
``` Field(&Foo::number, Ge(3)) ```
matches a plain pointer `p` where `p->number >= 3`. If `p` is `NULL`, the match will always fail regardless of the inner matcher.
What if you want to validate more than one members at the same time? Remember that there is `AllOf()`.
C++ functions often take pointers as arguments. You can use matchers like `NULL`, `NotNull()`, and other comparison matchers to match a pointer, but what if you want to make sure the value _pointed to_ by the pointer, instead of the pointer itself, has a certain property? Well, you can use the `Pointee(m)` matcher.
`Pointee(m)` matches a pointer iff `m` matches the value the pointer points to. For example:
``` using ::testing::Ge; using ::testing::Pointee; ...   EXPECT_CALL(foo, Bar(Pointee(Ge(3)))); ```
expects `foo.Bar()` to be called with a pointer that points to a value greater than or equal to 3.
One nice thing about `Pointee()` is that it treats a `NULL` pointer as a match failure, so you can write `Pointee(m)` instead of
```   AllOf(NotNull(), Pointee(m)) ```
without worrying that a `NULL` pointer will crash your test.
Also, did we tell you that `Pointee()` works with both raw pointers **and** smart pointers (`linked_ptr`, `shared_ptr`, `scoped_ptr`, and etc)?
What if you have a pointer to pointer? You guessed it - you can use nested `Pointee()` to probe deeper inside the value. For example, `Pointee(Pointee(Lt(3)))` matches a pointer that points to a pointer that points to a number less than 3 (what a mouthful...).
Sometimes you want to specify that an object argument has a certain property, but there is no existing matcher that does this. If you want good error messages, you should define a matcher. If you want to do it quick and dirty, you could get away with writing an ordinary function.
Let's say you have a mock function that takes an object of type `Foo`, which has an `int bar()` method and an `int baz()` method, and you want to constrain that the argument's `bar()` value plus its `baz()` value is a given number. Here's how you can define a matcher to do it:
``` using ::testing::MatcherInterface; using ::testing::MatchResultListener;
class BarPlusBazEqMatcher : public MatcherInterface<const Foo&> {  public:   explicit BarPlusBazEqMatcher(int expected_sum)       : expected_sum_(expected_sum) {}
virtual bool MatchAndExplain(const Foo& foo,                                MatchResultListener* listener) const {     return (foo.bar() + foo.baz()) == expected_sum_;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "bar() + baz() equals " << expected_sum_;   }
virtual void DescribeNegationTo(::std::ostream* os) const {     *os << "bar() + baz() does not equal " << expected_sum_;   }  private:   const int expected_sum_; };
inline Matcher<const Foo&> BarPlusBazEq(int expected_sum) {   return MakeMatcher(new BarPlusBazEqMatcher(expected_sum)); }
...
EXPECT_CALL(..., DoThis(BarPlusBazEq(5)))...; ```
Sometimes an STL container (e.g. list, vector, map, ...) is passed to a mock function and you may want to validate it. Since most STL containers support the `==` operator, you can write `Eq(expected_container)` or simply `expected_container` to match a container exactly.
Sometimes, though, you may want to be more flexible (for example, the first element must be an exact match, but the second element can be any positive number, and so on). Also, containers used in tests often have a small number of elements, and having to define the expected container out-of-line is a bit of a hassle.
You can use the `ElementsAre()` matcher in such cases:
``` using ::testing::_; using ::testing::ElementsAre; using ::testing::Gt; ...
MOCK_METHOD1(Foo, void(const vector<int>& numbers)); ...
EXPECT_CALL(mock, Foo(ElementsAre(1, Gt(0), _, 5))); ```
The above matcher says that the container must have 4 elements, which must be 1, greater than 0, anything, and 5 respectively.
`ElementsAre()` is overloaded to take 0 to 10 arguments. If more are needed, you can place them in a C-style array and use `ElementsAreArray()` instead:
``` using ::testing::ElementsAreArray; ...
// ElementsAreArray accepts an array of element values.   const int expected_vector1[] = { 1, 5, 2, 4, ... };   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector1)));
// Or, an array of element matchers.   Matcher<int> expected_vector2 = { 1, Gt(2), _, 3, ... };   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector2))); ```
In case the array needs to be dynamically created (and therefore the array size cannot be inferred by the compiler), you can give `ElementsAreArray()` an additional argument to specify the array size:
``` using ::testing::ElementsAreArray; ...   int* const expected_vector3 = new int[count];   ... fill expected_vector3 with values ...   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector3, count))); ```
**Tips:**
* `ElementAre*()` works with _any_ container that implements the STL iterator concept (i.e. it has a `const_iterator` type and supports `begin()/end()`) and supports `size()`, not just the ones defined in STL. It will even work with container types yet to be written - as long as they follows the above pattern.   * You can use nested `ElementAre*()` to match nested (multi-dimensional) containers.   * If the container is passed by pointer instead of by reference, just write `Pointee(ElementsAre*(...))`.   * The order of elements _matters_ for `ElementsAre*()`. Therefore don't use it with containers whose element order is undefined (e.g. `hash_map`).
Under the hood, a Google Mock matcher object consists of a pointer to a ref-counted implementation object. Copying matchers is allowed and very efficient, as only the pointer is copied. When the last matcher that references the implementation object dies, the implementation object will be deleted.
Therefore, if you have some complex matcher that you want to use again and again, there is no need to build it everytime. Just assign it to a matcher variable and use that variable repeatedly! For example,
```   Matcher<int> in_range = AllOf(Gt(5), Le(10));   ... use in_range as a matcher in multiple EXPECT_CALLs ... ```
If you are not interested in how a mock method is called, just don't say anything about it. In this case, if the method is ever called, Google Mock will perform its default action to allow the test program to continue. If you are not happy with the default action taken by Google Mock, you can override it using `DefaultValue<T>::Set()` (described later in this document) or `ON_CALL()`.
Please note that once you expressed interest in a particular mock method (via `EXPECT_CALL()`), all invocations to it must match some expectation. If this function is called but the arguments don't match any `EXPECT_CALL()` statement, it will be an error.
If a mock method shouldn't be called at all, explicitly say so:
``` using ::testing::_; ...   EXPECT_CALL(foo, Bar(_))       .Times(0); ```
If some calls to the method are allowed, but the rest are not, just list all the expected calls:
``` using ::testing::AnyNumber; using ::testing::Gt; ...   EXPECT_CALL(foo, Bar(5));   EXPECT_CALL(foo, Bar(Gt(10)))       .Times(AnyNumber()); ```
A call to `foo.Bar()` that doesn't match any of the `EXPECT_CALL()` statements will be an error.
Although an `EXPECT_CALL()` statement defined earlier takes precedence when Google Mock tries to match a function call with an expectation, by default calls don't have to happen in the order `EXPECT_CALL()` statements are written. For example, if the arguments match the matchers in the third `EXPECT_CALL()`, but not those in the first two, then the third expectation will be used.
If you would rather have all calls occur in the order of the expectations, put the `EXPECT_CALL()` statements in a block where you define a variable of type `InSequence`:
```   using ::testing::_;   using ::testing::InSequence;
{     InSequence s;
EXPECT_CALL(foo, DoThis(5));     EXPECT_CALL(bar, DoThat(_))         .Times(2);     EXPECT_CALL(foo, DoThis(6));   } ```
In this example, we expect a call to `foo.DoThis(5)`, followed by two calls to `bar.DoThat()` where the argument can be anything, which are in turn followed by a call to `foo.DoThis(6)`. If a call occurred out-of-order, Google Mock will report an error.
Sometimes requiring everything to occur in a predetermined order can lead to brittle tests. For example, we may care about `A` occurring before both `B` and `C`, but aren't interested in the relative order of `B` and `C`. In this case, the test should reflect our real intent, instead of being overly constraining.
Google Mock allows you to impose an arbitrary DAG (directed acyclic graph) on the calls. One way to express the DAG is to use the [After](V1_5_CheatSheet#The_After_Clause.md) clause of `EXPECT_CALL`.
Another way is via the `InSequence()` clause (not the same as the `InSequence` class), which we borrowed from jMock 2. It's less flexible than `After()`, but more convenient when you have long chains of sequential calls, as it doesn't require you to come up with different names for the expectations in the chains.  Here's how it works:
If we view `EXPECT_CALL()` statements as nodes in a graph, and add an edge from node A to node B wherever A must occur before B, we can get a DAG. We use the term "sequence" to mean a directed path in this DAG. Now, if we decompose the DAG into sequences, we just need to know which sequences each `EXPECT_CALL()` belongs to in order to be able to reconstruct the orginal DAG.
So, to specify the partial order on the expectations we need to do two things: first to define some `Sequence` objects, and then for each `EXPECT_CALL()` say which `Sequence` objects it is part of. Expectations in the same sequence must occur in the order they are written. For example,
```   using ::testing::Sequence;
Sequence s1, s2;
EXPECT_CALL(foo, A())       .InSequence(s1, s2);   EXPECT_CALL(bar, B())       .InSequence(s1);   EXPECT_CALL(bar, C())       .InSequence(s2);   EXPECT_CALL(foo, D())       .InSequence(s2); ```
specifies the following DAG (where `s1` is `A -> B`, and `s2` is `A -> C -> D`):
```        +---> B        |   A ---|        |        +---> C ---> D ```
This means that A must occur before B and C, and C must occur before D. There's no restriction about the order other than these.
When a mock method is called, Google Mock only consider expectations that are still active. An expectation is active when created, and becomes inactive (aka _retires_) when a call that has to occur later has occurred. For example, in
```   using ::testing::_;   using ::testing::Sequence;
Sequence s1, s2;
EXPECT_CALL(log, Log(WARNING, _, "File too large."))     // #1       .Times(AnyNumber())       .InSequence(s1, s2);   EXPECT_CALL(log, Log(WARNING, _, "Data set is empty."))  // #2       .InSequence(s1);   EXPECT_CALL(log, Log(WARNING, _, "User not found."))     // #3       .InSequence(s2); ```
as soon as either #2 or #3 is matched, #1 will retire. If a warning `"File too large."` is logged after this, it will be an error.
Note that an expectation doesn't retire automatically when it's saturated. For example,
``` using ::testing::_; ...   EXPECT_CALL(log, Log(WARNING, _, _));                  // #1   EXPECT_CALL(log, Log(WARNING, _, "File too large."));  // #2 ```
says that there will be exactly one warning with the message `"File too large."`. If the second warning contains this message too, #2 will match again and result in an upper-bound-violated error.
If this is not what you want, you can ask an expectation to retire as soon as it becomes saturated:
``` using ::testing::_; ...   EXPECT_CALL(log, Log(WARNING, _, _));                 // #1   EXPECT_CALL(log, Log(WARNING, _, "File too large."))  // #2       .RetiresOnSaturation(); ```
Here #2 can be used only once, so if you have two warnings with the message `"File too large."`, the first will match #2 and the second will match #1 - there will be no error.
If a mock function's return type is a reference, you need to use `ReturnRef()` instead of `Return()` to return a result:
``` using ::testing::ReturnRef;
class MockFoo : public Foo {  public:   MOCK_METHOD0(GetBar, Bar&()); }; ...
MockFoo foo;   Bar bar;   EXPECT_CALL(foo, GetBar())       .WillOnce(ReturnRef(bar)); ```
Want to do more than one thing when a function is called? That's fine. `DoAll()` allow you to do sequence of actions every time. Only the return value of the last action in the sequence will be used.
``` using ::testing::DoAll;
class MockFoo : public Foo {  public:   MOCK_METHOD1(Bar, bool(int n)); }; ...
EXPECT_CALL(foo, Bar(_))       .WillOnce(DoAll(action_1,                       action_2,                       ...                       action_n)); ```
Sometimes a method exhibits its effect not via returning a value but via side effects. For example, it may change some global state or modify an output argument. To mock side effects, in general you can define your own action by implementing `::testing::ActionInterface`.
If all you need to do is to change an output argument, the built-in `SetArgumentPointee()` action is convenient:
``` using ::testing::SetArgumentPointee;
class MockMutator : public Mutator {  public:   MOCK_METHOD2(Mutate, void(bool mutate, int* value));   ... }; ...
MockMutator mutator;   EXPECT_CALL(mutator, Mutate(true, _))       .WillOnce(SetArgumentPointee<1>(5)); ```
In this example, when `mutator.Mutate()` is called, we will assign 5 to the `int` variable pointed to by argument #1 (0-based).
`SetArgumentPointee()` conveniently makes an internal copy of the value you pass to it, removing the need to keep the value in scope and alive. The implication however is that the value must have a copy constructor and assignment operator.
If the mock method also needs to return a value as well, you can chain `SetArgumentPointee()` with `Return()` using `DoAll()`:
``` using ::testing::_; using ::testing::Return; using ::testing::SetArgumentPointee;
class MockMutator : public Mutator {  public:   ...   MOCK_METHOD1(MutateInt, bool(int* value)); }; ...
MockMutator mutator;   EXPECT_CALL(mutator, MutateInt(_))       .WillOnce(DoAll(SetArgumentPointee<0>(5),                       Return(true))); ```
If the output argument is an array, use the `SetArrayArgument<N>(first, last)` action instead. It copies the elements in source range `[first, last)` to the array pointed to by the `N`-th (0-based) argument:
``` using ::testing::NotNull; using ::testing::SetArrayArgument;
class MockArrayMutator : public ArrayMutator {  public:   MOCK_METHOD2(Mutate, void(int* values, int num_values));   ... }; ...
MockArrayMutator mutator;   int values[5] = { 1, 2, 3, 4, 5 };   EXPECT_CALL(mutator, Mutate(NotNull(), 5))       .WillOnce(SetArrayArgument<0>(values, values + 5)); ```
This also works when the argument is an output iterator:
``` using ::testing::_; using ::testing::SeArrayArgument;
class MockRolodex : public Rolodex {  public:   MOCK_METHOD1(GetNames, void(std::back_insert_iterator<vector<string> >));   ... }; ...
MockRolodex rolodex;   vector<string> names;   names.push_back("George");   names.push_back("John");   names.push_back("Thomas");   EXPECT_CALL(rolodex, GetNames(_))       .WillOnce(SetArrayArgument<0>(names.begin(), names.end())); ```
If you expect a call to change the behavior of a mock object, you can use `::testing::InSequence` to specify different behaviors before and after the call:
``` using ::testing::InSequence; using ::testing::Return;
...   {     InSequence seq;     EXPECT_CALL(my_mock, IsDirty())         .WillRepeatedly(Return(true));     EXPECT_CALL(my_mock, Flush());     EXPECT_CALL(my_mock, IsDirty())         .WillRepeatedly(Return(false));   }   my_mock.FlushIfDirty(); ```
This makes `my_mock.IsDirty()` return `true` before `my_mock.Flush()` is called and return `false` afterwards.
If the behavior change is more complex, you can store the effects in a variable and make a mock method get its return value from that variable:
``` using ::testing::_; using ::testing::SaveArg; using ::testing::Return;
ACTION_P(ReturnPointee, p) { return *p; } ...   int previous_value = 0;   EXPECT_CALL(my_mock, GetPrevValue())       .WillRepeatedly(ReturnPointee(&previous_value));   EXPECT_CALL(my_mock, UpdateValue(_))       .WillRepeatedly(SaveArg<0>(&previous_value));   my_mock.DoSomethingToUpdateValue(); ```
Here `my_mock.GetPrevValue()` will always return the argument of the last `UpdateValue()` call.
If a mock method's return type is a built-in C++ type or pointer, by default it will return 0 when invoked. You only need to specify an action if this default value doesn't work for you.
Sometimes, you may want to change this default value, or you may want to specify a default value for types Google Mock doesn't know about. You can do this using the `::testing::DefaultValue` class template:
``` class MockFoo : public Foo {  public:   MOCK_METHOD0(CalculateBar, Bar()); }; ...
Bar default_bar;   // Sets the default return value for type Bar.   DefaultValue<Bar>::Set(default_bar);
MockFoo foo;
// We don't need to specify an action here, as the default   // return value works for us.   EXPECT_CALL(foo, CalculateBar());
foo.CalculateBar();  // This should return default_bar.
// Unsets the default return value.   DefaultValue<Bar>::Clear(); ```
Please note that changing the default value for a type can make you tests hard to understand. We recommend you to use this feature judiciously. For example, you may want to make sure the `Set()` and `Clear()` calls are right next to the code that uses your mock.
You've learned how to change the default value of a given type. However, this may be too coarse for your purpose: perhaps you have two mock methods with the same return type and you want them to have different behaviors. The `ON_CALL()` macro allows you to customize your mock's behavior at the method level:
``` using ::testing::_; using ::testing::AnyNumber; using ::testing::Gt; using ::testing::Return; ...   ON_CALL(foo, Sign(_))       .WillByDefault(Return(-1));   ON_CALL(foo, Sign(0))       .WillByDefault(Return(0));   ON_CALL(foo, Sign(Gt(0)))       .WillByDefault(Return(1));
EXPECT_CALL(foo, Sign(_))       .Times(AnyNumber());
foo.Sign(5);   // This should return 1.   foo.Sign(-9);  // This should return -1.   foo.Sign(0);   // This should return 0. ```
As you may have guessed, when there are more than one `ON_CALL()` statements, the news order take precedence over the older ones. In other words, the **last** one that matches the function arguments will be used. This matching order allows you to set up the common behavior in a mock object's constructor or the test fixture's set-up phase and specialize the mock's behavior later.
If the built-in actions don't suit you, you can easily use an existing function, method, or functor as an action:
``` using ::testing::_; using ::testing::Invoke;
class MockFoo : public Foo {  public:   MOCK_METHOD2(Sum, int(int x, int y));   MOCK_METHOD1(ComplexJob, bool(int x)); };
int CalculateSum(int x, int y) { return x + y; }
class Helper {  public:   bool ComplexJob(int x); }; ...
MockFoo foo;   Helper helper;   EXPECT_CALL(foo, Sum(_, _))       .WillOnce(Invoke(CalculateSum));   EXPECT_CALL(foo, ComplexJob(_))       .WillOnce(Invoke(&helper, &Helper::ComplexJob));
foo.Sum(5, 6);       // Invokes CalculateSum(5, 6).   foo.ComplexJob(10);  // Invokes helper.ComplexJob(10); ```
The only requirement is that the type of the function, etc must be _compatible_ with the signature of the mock function, meaning that the latter's arguments can be implicitly converted to the corresponding arguments of the former, and the former's return type can be implicitly converted to that of the latter. So, you can invoke something whose type is _not_ exactly the same as the mock function, as long as it's safe to do so - nice, huh?
`Invoke()` is very useful for doing actions that are more complex. It passes the mock function's arguments to the function or functor being invoked such that the callee has the full context of the call to work with. If the invoked function is not interested in some or all of the arguments, it can simply ignore them.
Yet, a common pattern is that a test author wants to invoke a function without the arguments of the mock function. `Invoke()` allows her to do that using a wrapper function that throws away the arguments before invoking an underlining nullary function. Needless to say, this can be tedious and obscures the intent of the test.
`InvokeWithoutArgs()` solves this problem. It's like `Invoke()` except that it doesn't pass the mock function's arguments to the callee. Here's an example:
``` using ::testing::_; using ::testing::InvokeWithoutArgs;
class MockFoo : public Foo {  public:   MOCK_METHOD1(ComplexJob, bool(int n)); };
bool Job1() { ... } ...
MockFoo foo;   EXPECT_CALL(foo, ComplexJob(_))       .WillOnce(InvokeWithoutArgs(Job1));
foo.ComplexJob(10);  // Invokes Job1(). ```
Sometimes a mock function will receive a function pointer or a functor (in other words, a "callable") as an argument, e.g.
``` class MockFoo : public Foo {  public:   MOCK_METHOD2(DoThis, bool(int n, bool (*fp)(int))); }; ```
and you may want to invoke this callable argument:
``` using ::testing::_; ...   MockFoo foo;   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(...);   // Will execute (*fp)(5), where fp is the   // second argument DoThis() receives. ```
Arghh, you need to refer to a mock function argument but C++ has no lambda (yet), so you have to define your own action. :-( Or do you really?
Well, Google Mock has an action to solve _exactly_ this problem:
```   InvokeArgument<N>(arg_1, arg_2, ..., arg_m) ```
will invoke the `N`-th (0-based) argument the mock function receives, with `arg_1`, `arg_2`, ..., and `arg_m`. No matter if the argument is a function pointer or a functor, Google Mock handles them both.
With that, you could write:
``` using ::testing::_; using ::testing::InvokeArgument; ...   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(InvokeArgument<1>(5));   // Will execute (*fp)(5), where fp is the   // second argument DoThis() receives. ```
What if the callable takes an argument by reference? No problem - just wrap it inside `ByRef()`:
``` ...   MOCK_METHOD1(Bar, bool(bool (*fp)(int, const Helper&))); ... using ::testing::_; using ::testing::ByRef; using ::testing::InvokeArgument; ...
MockFoo foo;   Helper helper;   ...   EXPECT_CALL(foo, Bar(_))       .WillOnce(InvokeArgument<0>(5, ByRef(helper)));   // ByRef(helper) guarantees that a reference to helper, not a copy of it,   // will be passed to the callable. ```
What if the callable takes an argument by reference and we do **not** wrap the argument in `ByRef()`? Then `InvokeArgument()` will _make a copy_ of the argument, and pass a _reference to the copy_, instead of a reference to the original value, to the callable. This is especially handy when the argument is a temporary value:
``` ...   MOCK_METHOD1(DoThat, bool(bool (*f)(const double& x, const string& s))); ... using ::testing::_; using ::testing::InvokeArgument; ...
MockFoo foo;   ...   EXPECT_CALL(foo, DoThat(_))       .WillOnce(InvokeArgument<0>(5.0, string("Hi")));   // Will execute (*f)(5.0, string("Hi")), where f is the function pointer   // DoThat() receives.  Note that the values 5.0 and string("Hi") are   // temporary and dead once the EXPECT_CALL() statement finishes.  Yet   // it's fine to perform this action later, since a copy of the values   // are kept inside the InvokeArgument action. ```
Sometimes you have an action that returns _something_, but you need an action that returns `void` (perhaps you want to use it in a mock function that returns `void`, or perhaps it needs to be used in `DoAll()` and it's not the last in the list). `IgnoreResult()` lets you do that. For example:
``` using ::testing::_; using ::testing::Invoke; using ::testing::Return;
int Process(const MyData& data); string DoSomething();
class MockFoo : public Foo {  public:   MOCK_METHOD1(Abc, void(const MyData& data));   MOCK_METHOD0(Xyz, bool()); }; ...
MockFoo foo;   EXPECT_CALL(foo, Abc(_))   // .WillOnce(Invoke(Process));   // The above line won't compile as Process() returns int but Abc() needs   // to return void.       .WillOnce(IgnoreResult(Invoke(Process)));
EXPECT_CALL(foo, Xyz())       .WillOnce(DoAll(IgnoreResult(Invoke(DoSomething)),       // Ignores the string DoSomething() returns.                       Return(true))); ```
Note that you **cannot** use `IgnoreResult()` on an action that already returns `void`. Doing so will lead to ugly compiler errors.
Say you have a mock function `Foo()` that takes seven arguments, and you have a custom action that you want to invoke when `Foo()` is called. Trouble is, the custom action only wants three arguments:
``` using ::testing::_; using ::testing::Invoke; ...   MOCK_METHOD7(Foo, bool(bool visible, const string& name, int x, int y,                          const map<pair<int, int>, double>& weight,                          double min_weight, double max_wight)); ...
bool IsVisibleInQuadrant1(bool visible, int x, int y) {   return visible && x >= 0 && y >= 0; } ...
EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(Invoke(IsVisibleInQuadrant1));  // Uh, won't compile. :-( ```
To please the compiler God, you can to define an "adaptor" that has the same signature as `Foo()` and calls the custom action with the right arguments:
``` using ::testing::_; using ::testing::Invoke;
bool MyIsVisibleInQuadrant1(bool visible, const string& name, int x, int y,                             const map<pair<int, int>, double>& weight,                             double min_weight, double max_wight) {   return IsVisibleInQuadrant1(visible, x, y); } ...
EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(Invoke(MyIsVisibleInQuadrant1));  // Now it works. ```
But isn't this awkward?
Google Mock provides a generic _action adaptor_, so you can spend your time minding more important business than writing your own adaptors. Here's the syntax:
```   WithArgs<N1, N2, ..., Nk>(action) ```
creates an action that passes the arguments of the mock function at the given indices (0-based) to the inner `action` and performs it. Using `WithArgs`, our original example can be written as:
``` using ::testing::_; using ::testing::Invoke; using ::testing::WithArgs; ...   EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(WithArgs<0, 2, 3>(Invoke(IsVisibleInQuadrant1)));       // No need to define your own adaptor. ```
For better readability, Google Mock also gives you:
* `WithoutArgs(action)` when the inner `action` takes _no_ argument, and   * `WithArg<N>(action)` (no `s` after `Arg`) when the inner `action` takes _one_ argument.
As you may have realized, `InvokeWithoutArgs(...)` is just syntactic sugar for `WithoutArgs(Inovke(...))`.
Here are more tips:
* The inner action used in `WithArgs` and friends does not have to be `Invoke()` -- it can be anything.   * You can repeat an argument in the argument list if necessary, e.g. `WithArgs<2, 3, 3, 5>(...)`.   * You can change the order of the arguments, e.g. `WithArgs<3, 2, 1>(...)`.   * The types of the selected arguments do _not_ have to match the signature of the inner action exactly. It works as long as they can be implicitly converted to the corresponding arguments of the inner action. For example, if the 4-th argument of the mock function is an `int` and `my_action` takes a `double`, `WithArg<4>(my_action)` will work.
The selecting-an-action's-arguments recipe showed us one way to make a mock function and an action with incompatible argument lists fit together. The downside is that wrapping the action in `WithArgs<...>()` can get tedious for people writing the tests.
If you are defining a function, method, or functor to be used with `Invoke*()`, and you are not interested in some of its arguments, an alternative to `WithArgs` is to declare the uninteresting arguments as `Unused`. This makes the definition less cluttered and less fragile in case the types of the uninteresting arguments change. It could also increase the chance the action function can be reused. For example, given
```   MOCK_METHOD3(Foo, double(const string& label, double x, double y));   MOCK_METHOD3(Bar, double(int index, double x, double y)); ```
instead of
``` using ::testing::_; using ::testing::Invoke;
double DistanceToOriginWithLabel(const string& label, double x, double y) {   return sqrt(x*x + y*y); }
double DistanceToOriginWithIndex(int index, double x, double y) {   return sqrt(x*x + y*y); } ...
EXEPCT_CALL(mock, Foo("abc", _, _))       .WillOnce(Invoke(DistanceToOriginWithLabel));   EXEPCT_CALL(mock, Bar(5, _, _))       .WillOnce(Invoke(DistanceToOriginWithIndex)); ```
you could write
``` using ::testing::_; using ::testing::Invoke; using ::testing::Unused;
double DistanceToOrigin(Unused, double x, double y) {   return sqrt(x*x + y*y); } ...
EXEPCT_CALL(mock, Foo("abc", _, _))       .WillOnce(Invoke(DistanceToOrigin));   EXEPCT_CALL(mock, Bar(5, _, _))       .WillOnce(Invoke(DistanceToOrigin)); ```
Just like matchers, a Google Mock action object consists of a pointer to a ref-counted implementation object. Therefore copying actions is also allowed and very efficient. When the last action that references the implementation object dies, the implementation object will be deleted.
If you have some complex action that you want to use again and again, you may not have to build it from scratch everytime. If the action doesn't have an internal state (i.e. if it always does the same thing no matter how many times it has been called), you can assign it to an action variable and use that variable repeatedly. For example:
```   Action<bool(int*)> set_flag = DoAll(SetArgumentPointee<0>(5),                                       Return(true));   ... use set_flag in .WillOnce() and .WillRepeatedly() ... ```
However, if the action has its own state, you may be surprised if you share the action object. Suppose you have an action factory `IncrementCounter(init)` which creates an action that increments and returns a counter whose initial value is `init`, using two actions created from the same expression and using a shared action will exihibit different behaviors. Example:
```   EXPECT_CALL(foo, DoThis())       .WillRepeatedly(IncrementCounter(0));   EXPECT_CALL(foo, DoThat())       .WillRepeatedly(IncrementCounter(0));   foo.DoThis();  // Returns 1.   foo.DoThis();  // Returns 2.   foo.DoThat();  // Returns 1 - Blah() uses a different                  // counter than Bar()'s. ```
versus
```   Action<int()> increment = IncrementCounter(0);
EXPECT_CALL(foo, DoThis())       .WillRepeatedly(increment);   EXPECT_CALL(foo, DoThat())       .WillRepeatedly(increment);   foo.DoThis();  // Returns 1.   foo.DoThis();  // Returns 2.   foo.DoThat();  // Returns 3 - the counter is shared. ```
When it's being destoyed, your friendly mock object will automatically verify that all expectations on it have been satisfied, and will generate [Google Test](http://code.google.com/p/googletest/) failures if not. This is convenient as it leaves you with one less thing to worry about. That is, unless you are not sure if your mock object will be destoyed.
How could it be that your mock object won't eventually be destroyed? Well, it might be created on the heap and owned by the code you are testing. Suppose there's a bug in that code and it doesn't delete the mock object properly - you could end up with a passing test when there's actually a bug.
Using a heap checker is a good idea and can alleviate the concern, but its implementation may not be 100% reliable. So, sometimes you do want to _force_ Google Mock to verify a mock object before it is (hopefully) destructed. You can do this with `Mock::VerifyAndClearExpectations(&mock_object)`:
``` TEST(MyServerTest, ProcessesRequest) {   using ::testing::Mock;
MockFoo* const foo = new MockFoo;   EXPECT_CALL(*foo, ...)...;   // ... other expectations ...
// server now owns foo.   MyServer server(foo);   server.ProcessRequest(...);
// In case that server's destructor will forget to delete foo,   // this will verify the expectations anyway.   Mock::VerifyAndClearExpectations(foo); }  // server is destroyed when it goes out of scope here. ```
**Tip:** The `Mock::VerifyAndClearExpectations()` function returns a `bool` to indicate whether the verification was successful (`true` for yes), so you can wrap that function call inside a `ASSERT_TRUE()` if there is no point going further when the verification has failed.
Sometimes you may want to "reset" a mock object at various check points in your test: at each check point, you verify that all existing expectations on the mock object have been satisfied, and then you set some new expectations on it as if it's newly created. This allows you to work with a mock object in "phases" whose sizes are each manageable.
One such scenario is that in your test's `SetUp()` function, you may want to put the object you are testing into a certain state, with the help from a mock object. Once in the desired state, you want to clear all expectations on the mock, such that in the `TEST_F` body you can set fresh expectations on it.
As you may have figured out, the `Mock::VerifyAndClearExpectations()` function we saw in the previous recipe can help you here. Or, if you are using `ON_CALL()` to set default actions on the mock object and want to clear the default actions as well, use `Mock::VerifyAndClear(&mock_object)` instead. This function does what `Mock::VerifyAndClearExpectations(&mock_object)` does and returns the same `bool`, **plus** it clears the `ON_CALL()` statements on `mock_object` too.
Another trick you can use to achieve the same effect is to put the expectations in sequences and insert calls to a dummy "check-point" function at specific places. Then you can verify that the mock function calls do happen at the right time. For example, if you are exercising code:
``` Foo(1); Foo(2); Foo(3); ```
and want to verify that `Foo(1)` and `Foo(3)` both invoke `mock.Bar("a")`, but `Foo(2)` doesn't invoke anything. You can write:
``` using ::testing::MockFunction;
TEST(FooTest, InvokesBarCorrectly) {   MyMock mock;   // Class MockFunction<F> has exactly one mock method.  It is named   // Call() and has type F.   MockFunction<void(string check_point_name)> check;   {     InSequence s;
EXPECT_CALL(mock, Bar("a"));     EXPECT_CALL(check, Call("1"));     EXPECT_CALL(check, Call("2"));     EXPECT_CALL(mock, Bar("a"));   }   Foo(1);   check.Call("1");   Foo(2);   check.Call("2");   Foo(3); } ```
The expectation spec says that the first `Bar("a")` must happen before check point "1", the second `Bar("a")` must happen after check point "2", and nothing should happen between the two check points. The explicit check points make it easy to tell which `Bar("a")` is called by which call to `Foo()`.
Sometimes you want to make sure a mock object is destructed at the right time, e.g. after `bar->A()` is called but before `bar->B()` is called. We already know that you can specify constraints on the order of mock function calls, so all we need to do is to mock the destructor of the mock function.
This sounds simple, except for one problem: a destructor is a special function with special syntax and special semantics, and the `MOCK_METHOD0` macro doesn't work for it:
```   MOCK_METHOD0(~MockFoo, void());  // Won't compile! ```
The good news is that you can use a simple pattern to achieve the same effect. First, add a mock function `Die()` to your mock class and call it in the destructor, like this:
``` class MockFoo : public Foo {   ...   // Add the following two lines to the mock class.   MOCK_METHOD0(Die, void());   virtual ~MockFoo() { Die(); } }; ```
(If the name `Die()` clashes with an existing symbol, choose another name.) Now, we have translated the problem of testing when a `MockFoo` object dies to testing when its `Die()` method is called:
```   MockFoo* foo = new MockFoo;   MockBar* bar = new MockBar;   ...   {     InSequence s;
// Expects *foo to die after bar->A() and before bar->B().     EXPECT_CALL(*bar, A());     EXPECT_CALL(*foo, Die());     EXPECT_CALL(*bar, B());   } ```
And that's that.
**IMPORTANT NOTE:** What we describe in this recipe is **NOT** true yet, as Google Mock is not currently thread-safe.  However, all we need to make it thread-safe is to implement some synchronization operations in `<gtest/internal/gtest-port.h>` - and then the information below will become true.
In a **unit** test, it's best if you could isolate and test a piece of code in a single-threaded context. That avoids race conditions and dead locks, and makes debugging your test much easier.
Yet many programs are multi-threaded, and sometimes to test something we need to pound on it from more than one thread. Google Mock works for this purpose too.
Remember the steps for using a mock:
1. Create a mock object `foo`.   1. Set its default actions and expectations using `ON_CALL()` and `EXPECT_CALL()`.   1. The code under test calls methods of `foo`.   1. Optionally, verify and reset the mock.   1. Destroy the mock yourself, or let the code under test destroy it. The destructor will automatically verify it.
If you follow the following simple rules, your mocks and threads can live happily togeter:
* Execute your _test code_ (as opposed to the code being tested) in _one_ thread. This makes your test easy to follow.   * Obviously, you can do step #1 without locking.   * When doing step #2 and #5, make sure no other thread is accessing `foo`. Obvious too, huh?   * #3 and #4 can be done either in one thread or in multiple threads - anyway you want. Google Mock takes care of the locking, so you don't have to do any - unless required by your test logic.
If you violate the rules (for example, if you set expectations on a mock while another thread is calling its methods), you get undefined behavior. That's not fun, so don't do it.
Google Mock guarantees that the action for a mock function is done in the same thread that called the mock function. For example, in
```   EXPECT_CALL(mock, Foo(1))       .WillOnce(action1);   EXPECT_CALL(mock, Foo(2))       .WillOnce(action2); ```
if `Foo(1)` is called in thread 1 and `Foo(2)` is called in thread 2, Google Mock will execute `action1` in thread 1 and `action2` in thread 2.
Google Mock does _not_ impose a sequence on actions performed in different threads (doing so may create deadlocks as the actions may need to cooperate). This means that the execution of `action1` and `action2` in the above example _may_ interleave. If this is a problem, you should add proper synchronization logic to `action1` and `action2` to make the test thread-safe.
Also, remember that `DefaultValue<T>` is a global resource that potentially affects _all_ living mock objects in your program. Naturally, you won't want to mess with it from multiple threads or when there still are mocks in action.
When Google Mock sees something that has the potential of being an error (e.g. a mock function with no expectation is called, a.k.a. an uninteresting call, which is allowed but perhaps you forgot to explicitly ban the call), it prints some warning messages, including the arguments of the function and the return value. Hopefully this will remind you to take a look and see if there is indeed a problem.
Sometimes you are confident that your tests are correct and may not appreciate such friendly messages. Some other times, you are debugging your tests or learning about the behavior of the code you are testing, and wish you could observe every mock call that happens (including argument values and the return value). Clearly, one size doesn't fit all.
You can control how much Google Mock tells you using the `--gmock_verbose=LEVEL` command-line flag, where `LEVEL` is a string with three possible values:
* `info`: Google Mock will print all informational messages, warnings, and errors (most verbose). At this setting, Google Mock will also log any calls to the `ON_CALL/EXPECT_CALL` macros.   * `warning`: Google Mock will print both warnings and errors (less verbose). This is the default.   * `error`: Google Mock will print errors only (least verbose).
Alternatively, you can adjust the value of that flag from within your tests like so:
```   ::testing::FLAGS_gmock_verbose = "error"; ```
Now, judiciously use the right flag to enable Google Mock serve you better!
If you build and run your tests in Emacs, the source file locations of Google Mock and [Google Test](http://code.google.com/p/googletest/) errors will be highlighted. Just press `<Enter>` on one of them and you'll be taken to the offending line. Or, you can just type `C-x `` to jump to the next error.
To make it even easier, you can add the following lines to your `~/.emacs` file:
``` (global-set-key "\M-m"   'compile)  ; m is for make (global-set-key [M-down] 'next-error) (global-set-key [M-up]   '(lambda () (interactive) (next-error -1))) ```
Then you can type `M-m` to start a build, or `M-up`/`M-down` to move back and forth between errors.
Google Mock's implementation consists of dozens of files (excluding its own tests).  Sometimes you may want them to be packaged up in fewer files instead, such that you can easily copy them to a new machine and start hacking there.  For this we provide an experimental Python script `fuse_gmock_files.py` in the `scripts/` directory (starting with release 1.2.0).  Assuming you have Python 2.4 or above installed on your machine, just go to that directory and run ``` python fuse_gmock_files.py OUTPUT_DIR ```
and you should see an `OUTPUT_DIR` directory being created with files `gtest/gtest.h`, `gmock/gmock.h`, and `gmock-gtest-all.cc` in it. These three files contain everything you need to use Google Mock (and Google Test).  Just copy them to anywhere you want and you are ready to write tests and use mocks.  You can use the [scrpts/test/Makefile](http://code.google.com/p/googlemock/source/browse/trunk/scripts/test/Makefile) file as an example on how to compile your tests against them.
The `MATCHER*` family of macros can be used to define custom matchers easily.  The syntax:
``` MATCHER(name, "description string") { statements; } ```
will define a matcher with the given name that executes the statements, which must return a `bool` to indicate if the match succeeds.  Inside the statements, you can refer to the value being matched by `arg`, and refer to its type by `arg_type`.
The description string documents what the matcher does, and is used to generate the failure message when the match fails.  Since a `MATCHER()` is usually defined in a header file shared by multiple C++ source files, we require the description to be a C-string _literal_ to avoid possible side effects.  It can be empty (`""`), in which case Google Mock will use the sequence of words in the matcher name as the description.
For example: ``` MATCHER(IsDivisibleBy7, "") { return (arg % 7) == 0; } ``` allows you to write ```   // Expects mock_foo.Bar(n) to be called where n is divisible by 7.   EXPECT_CALL(mock_foo, Bar(IsDivisibleBy7())); ``` or, ```   // Verifies that the value of some_expression is divisible by 7.   EXPECT_THAT(some_expression, IsDivisibleBy7()); ``` If the above assertion fails, it will print something like: ```   Value of: some_expression   Expected: is divisible by 7     Actual: 27 ``` where the description `"is divisible by 7"` is automatically calculated from the matcher name `IsDivisibleBy7`.
Optionally, you can stream additional information to a hidden argument named `result_listener` to explain the match result. For example, a better definition of `IsDivisibleBy7` is: ``` MATCHER(IsDivisibleBy7, "") {   if ((arg % 7) == 0)     return true;
*result_listener << "the remainder is " << (arg % 7);   return false; } ```
With this definition, the above assertion will give a better message: ```   Value of: some_expression   Expected: is divisible by 7     Actual: 27 (the remainder is 6) ```
You should let `MatchAndExplain()` print _any additional information_ that can help a user understand the match result. Note that it should explain why the match succeeds in case of a success (unless it's obvious) - this is useful when the matcher is used inside `Not()`. There is no need to print the argument value itself, as Google Mock already prints it for you.
**Notes:**
1. The type of the value being matched (`arg_type`) is determined by the context in which you use the matcher and is supplied to you by the compiler, so you don't need to worry about declaring it (nor can you).  This allows the matcher to be polymorphic.  For example, `IsDivisibleBy7()` can be used to match any type where the value of `(arg % 7) == 0` can be implicitly converted to a `bool`.  In the `Bar(IsDivisibleBy7())` example above, if method `Bar()` takes an `int`, `arg_type` will be `int`; if it takes an `unsigned long`, `arg_type` will be `unsigned long`; and so on.   1. Google Mock doesn't guarantee when or how many times a matcher will be invoked. Therefore the matcher logic must be _purely functional_ (i.e. it cannot have any side effect, and the result must not depend on anything other than the value being matched and the matcher parameters). This requirement must be satisfied no matter how you define the matcher (e.g. using one of the methods described in the following recipes). In particular, a matcher can never call a mock function, as that will affect the state of the mock object and Google Mock.
Sometimes you'll want to define a matcher that has parameters.  For that you can use the macro: ``` MATCHER_P(name, param_name, "description string") { statements; } ```
For example: ``` MATCHER_P(HasAbsoluteValue, value, "") { return abs(arg) == value; } ``` will allow you to write: ```   EXPECT_THAT(Blah("a"), HasAbsoluteValue(n)); ``` which may lead to this message (assuming `n` is 10): ```   Value of: Blah("a")   Expected: has absolute value 10     Actual: -9 ```
Note that both the matcher description and its parameter are printed, making the message human-friendly.
In the matcher definition body, you can write `foo_type` to reference the type of a parameter named `foo`.  For example, in the body of `MATCHER_P(HasAbsoluteValue, value)` above, you can write `value_type` to refer to the type of `value`.
Google Mock also provides `MATCHER_P2`, `MATCHER_P3`, ..., up to `MATCHER_P10` to support multi-parameter matchers: ``` MATCHER_Pk(name, param_1, ..., param_k, "description string") { statements; } ```
Please note that the custom description string is for a particular **instance** of the matcher, where the parameters have been bound to actual values.  Therefore usually you'll want the parameter values to be part of the description.  Google Mock lets you do that using Python-style interpolations.  The following syntaxes are supported currently:
| `%%` | a single `%` character | |:-----|:-----------------------| | `%(*)s` | all parameters of the matcher printed as a tuple | | `%(foo)s` | value of the matcher parameter named `foo` |
For example, ```   MATCHER_P2(InClosedRange, low, hi, "is in range [%(low)s, %(hi)s]") {     return low <= arg && arg <= hi;   }   ...   EXPECT_THAT(3, InClosedRange(4, 6)); ``` would generate a failure that contains the message: ```   Expected: is in range [4, 6] ```
If you specify `""` as the description, the failure message will contain the sequence of words in the matcher name followed by the parameter values printed as a tuple.  For example, ```   MATCHER_P2(InClosedRange, low, hi, "") { ... }   ...   EXPECT_THAT(3, InClosedRange(4, 6)); ``` would generate a failure that contains the text: ```   Expected: in closed range (4, 6) ```
For the purpose of typing, you can view ``` MATCHER_Pk(Foo, p1, ..., pk, "description string") { ... } ``` as shorthand for ``` template <typename p1_type, ..., typename pk_type> FooMatcherPk<p1_type, ..., pk_type> Foo(p1_type p1, ..., pk_type pk) { ... } ```
When you write `Foo(v1, ..., vk)`, the compiler infers the types of the parameters `v1`, ..., and `vk` for you.  If you are not happy with the result of the type inference, you can specify the types by explicitly instantiating the template, as in `Foo<long, bool>(5, false)`. As said earlier, you don't get to (or need to) specify `arg_type` as that's determined by the context in which the matcher is used.
You can assign the result of expression `Foo(p1, ..., pk)` to a variable of type `FooMatcherPk<p1_type, ..., pk_type>`.  This can be useful when composing matchers.  Matchers that don't have a parameter or have only one parameter have special types: you can assign `Foo()` to a `FooMatcher`-typed variable, and assign `Foo(p)` to a `FooMatcherP<p_type>`-typed variable.
While you can instantiate a matcher template with reference types, passing the parameters by pointer usually makes your code more readable.  If, however, you still want to pass a parameter by reference, be aware that in the failure message generated by the matcher you will see the value of the referenced object but not its address.
You can overload matchers with different numbers of parameters: ``` MATCHER_P(Blah, a, "description string 1") { ... } MATCHER_P2(Blah, a, b, "description string 2") { ... } ```
While it's tempting to always use the `MATCHER*` macros when defining a new matcher, you should also consider implementing `MatcherInterface` or using `MakePolymorphicMatcher()` instead (see the recipes that follow), especially if you need to use the matcher a lot.  While these approaches require more work, they give you more control on the types of the value being matched and the matcher parameters, which in general leads to better compiler error messages that pay off in the long run.  They also allow overloading matchers based on parameter types (as opposed to just based on the number of parameters).
A matcher of argument type `T` implements `::testing::MatcherInterface<T>` and does two things: it tests whether a value of type `T` matches the matcher, and can describe what kind of values it matches. The latter ability is used for generating readable error messages when expectations are violated.
The interface looks like this:
``` class MatchResultListener {  public:   ...   // Streams x to the underlying ostream; does nothing if the ostream   // is NULL.   template <typename T>   MatchResultListener& operator<<(const T& x);
// Returns the underlying ostream.   ::std::ostream* stream(); };
template <typename T> class MatcherInterface {  public:   virtual ~MatcherInterface();
// Returns true iff the matcher matches x; also explains the match   // result to 'listener'.   virtual bool MatchAndExplain(T x, MatchResultListener* listener) const = 0;
// Describes this matcher to an ostream.   virtual void DescribeTo(::std::ostream* os) const = 0;
// Describes the negation of this matcher to an ostream.   virtual void DescribeNegationTo(::std::ostream* os) const; }; ```
If you need a custom matcher but `Truly()` is not a good option (for example, you may not be happy with the way `Truly(predicate)` describes itself, or you may want your matcher to be polymorphic as `Eq(value)` is), you can define a matcher to do whatever you want in two steps: first implement the matcher interface, and then define a factory function to create a matcher instance. The second step is not strictly needed but it makes the syntax of using the matcher nicer.
For example, you can define a matcher to test whether an `int` is divisible by 7 and then use it like this: ``` using ::testing::MakeMatcher; using ::testing::Matcher; using ::testing::MatcherInterface; using ::testing::MatchResultListener;
class DivisibleBy7Matcher : public MatcherInterface<int> {  public:   virtual bool MatchAndExplain(int n, MatchResultListener* listener) const {     return (n % 7) == 0;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "is divisible by 7";   }
virtual void DescribeNegationTo(::std::ostream* os) const {     *os << "is not divisible by 7";   } };
inline Matcher<int> DivisibleBy7() {   return MakeMatcher(new DivisibleBy7Matcher); } ...
EXPECT_CALL(foo, Bar(DivisibleBy7())); ```
You may improve the matcher message by streaming additional information to the `listener` argument in `MatchAndExplain()`:
``` class DivisibleBy7Matcher : public MatcherInterface<int> {  public:   virtual bool MatchAndExplain(int n,                                MatchResultListener* listener) const {     const int remainder = n % 7;     if (remainder != 0) {       *listener << "the remainder is " << remainder;     }     return remainder == 0;   }   ... }; ```
Then, `EXPECT_THAT(x, DivisibleBy7());` may general a message like this: ``` Value of: x Expected: is divisible by 7   Actual: 23 (the remainder is 2) ```
You've learned how to write your own matchers in the previous recipe. Just one problem: a matcher created using `MakeMatcher()` only works for one particular type of arguments. If you want a _polymorphic_ matcher that works with arguments of several types (for instance, `Eq(x)` can be used to match a `value` as long as `value` == `x` compiles -- `value` and `x` don't have to share the same type), you can learn the trick from `<gmock/gmock-matchers.h>` but it's a bit involved.
Fortunately, most of the time you can define a polymorphic matcher easily with the help of `MakePolymorphicMatcher()`. Here's how you can define `NotNull()` as an example:
``` using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; using ::testing::NotNull; using ::testing::PolymorphicMatcher;
class NotNullMatcher {  public:   // To implement a polymorphic matcher, first define a COPYABLE class   // that has three members MatchAndExplain(), DescribeTo(), and   // DescribeNegationTo(), like the following.
// In this example, we want to use NotNull() with any pointer, so   // MatchAndExplain() accepts a pointer of any type as its first argument.   // In general, you can define MatchAndExplain() as an ordinary method or   // a method template, or even overload it.   template <typename T>   bool MatchAndExplain(T* p,                        MatchResultListener* /* listener */) const {     return p != NULL;   }
// Describes the property of a value matching this matcher.   void DescribeTo(::std::ostream* os) const { *os << "is not NULL"; }
// Describes the property of a value NOT matching this matcher.   void DescribeNegationTo(::std::ostream* os) const { *os << "is NULL"; } };
// To construct a polymorphic matcher, pass an instance of the class // to MakePolymorphicMatcher().  Note the return type. inline PolymorphicMatcher<NotNullMatcher> NotNull() {   return MakePolymorphicMatcher(NotNullMatcher()); } ...
EXPECT_CALL(foo, Bar(NotNull()));  // The argument must be a non-NULL pointer. ```
**Note:** Your polymorphic matcher class does **not** need to inherit from `MatcherInterface` or any other class, and its methods do **not** need to be virtual.
Like in a monomorphic matcher, you may explain the match result by streaming additional information to the `listener` argument in `MatchAndExplain()`.
A cardinality is used in `Times()` to tell Google Mock how many times you expect a call to occur. It doesn't have to be exact. For example, you can say `AtLeast(5)` or `Between(2, 4)`.
If the built-in set of cardinalities doesn't suit you, you are free to define your own by implementing the following interface (in namespace `testing`):
``` class CardinalityInterface {  public:   virtual ~CardinalityInterface();
// Returns true iff call_count calls will satisfy this cardinality.   virtual bool IsSatisfiedByCallCount(int call_count) const = 0;
// Returns true iff call_count calls will saturate this cardinality.   virtual bool IsSaturatedByCallCount(int call_count) const = 0;
// Describes self to an ostream.   virtual void DescribeTo(::std::ostream* os) const = 0; }; ```
For example, to specify that a call must occur even number of times, you can write
``` using ::testing::Cardinality; using ::testing::CardinalityInterface; using ::testing::MakeCardinality;
class EvenNumberCardinality : public CardinalityInterface {  public:   virtual bool IsSatisfiedByCallCount(int call_count) const {     return (call_count % 2) == 0;   }
virtual bool IsSaturatedByCallCount(int call_count) const {     return false;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "called even number of times";   } };
Cardinality EvenNumber() {   return MakeCardinality(new EvenNumberCardinality); } ...
EXPECT_CALL(foo, Bar(3))       .Times(EvenNumber()); ```
If the built-in actions don't work for you, and you find it inconvenient to use `Invoke()`, you can use a macro from the `ACTION*` family to quickly define a new action that can be used in your code as if it's a built-in action.
By writing ``` ACTION(name) { statements; } ``` in a namespace scope (i.e. not inside a class or function), you will define an action with the given name that executes the statements. The value returned by `statements` will be used as the return value of the action.  Inside the statements, you can refer to the K-th (0-based) argument of the mock function as `argK`.  For example: ``` ACTION(IncrementArg1) { return ++(*arg1); } ``` allows you to write ``` ... WillOnce(IncrementArg1()); ```
Note that you don't need to specify the types of the mock function arguments.  Rest assured that your code is type-safe though: you'll get a compiler error if `*arg1` doesn't support the `++` operator, or if the type of `++(*arg1)` isn't compatible with the mock function's return type.
Another example: ``` ACTION(Foo) {   (*arg2)(5);   Blah();   *arg1 = 0;   return arg0; } ``` defines an action `Foo()` that invokes argument #2 (a function pointer) with 5, calls function `Blah()`, sets the value pointed to by argument #1 to 0, and returns argument #0.
For more convenience and flexibility, you can also use the following pre-defined symbols in the body of `ACTION`:
| `argK_type` | The type of the K-th (0-based) argument of the mock function | |:------------|:-------------------------------------------------------------| | `args`      | All arguments of the mock function as a tuple                | | `args_type` | The type of all arguments of the mock function as a tuple    | | `return_type` | The return type of the mock function                         | | `function_type` | The type of the mock function                                |
For example, when using an `ACTION` as a stub action for mock function: ``` int DoSomething(bool flag, int* ptr); ``` we have: | **Pre-defined Symbol** | **Is Bound To** | |:-----------------------|:----------------| | `arg0`                 | the value of `flag` | | `arg0_type`            | the type `bool` | | `arg1`                 | the value of `ptr` | | `arg1_type`            | the type `int*` | | `args`                 | the tuple `(flag, ptr)` | | `args_type`            | the type `std::tr1::tuple<bool, int*>` | | `return_type`          | the type `int`  | | `function_type`        | the type `int(bool, int*)` |
Sometimes you'll want to parameterize an action you define.  For that we have another macro ``` ACTION_P(name, param) { statements; } ```
For example, ``` ACTION_P(Add, n) { return arg0 + n; } ``` will allow you to write ``` // Returns argument #0 + 5. ... WillOnce(Add(5)); ```
For convenience, we use the term _arguments_ for the values used to invoke the mock function, and the term _parameters_ for the values used to instantiate an action.
Note that you don't need to provide the type of the parameter either. Suppose the parameter is named `param`, you can also use the Google-Mock-defined symbol `param_type` to refer to the type of the parameter as inferred by the compiler.  For example, in the body of `ACTION_P(Add, n)` above, you can write `n_type` for the type of `n`.
Google Mock also provides `ACTION_P2`, `ACTION_P3`, and etc to support multi-parameter actions.  For example, ``` ACTION_P2(ReturnDistanceTo, x, y) {   double dx = arg0 - x;   double dy = arg1 - y;   return sqrt(dx*dx + dy*dy); } ``` lets you write ``` ... WillOnce(ReturnDistanceTo(5.0, 26.5)); ```
You can view `ACTION` as a degenerated parameterized action where the number of parameters is 0.
You can also easily define actions overloaded on the number of parameters: ``` ACTION_P(Plus, a) { ... } ACTION_P2(Plus, a, b) { ... } ```
For maximum brevity and reusability, the `ACTION*` macros don't ask you to provide the types of the mock function arguments and the action parameters.  Instead, we let the compiler infer the types for us.
Sometimes, however, we may want to be more explicit about the types. There are several tricks to do that.  For example: ``` ACTION(Foo) {   // Makes sure arg0 can be converted to int.   int n = arg0;   ... use n instead of arg0 here ... }
ACTION_P(Bar, param) {   // Makes sure the type of arg1 is const char*.   ::testing::StaticAssertTypeEq<const char*, arg1_type>();
// Makes sure param can be converted to bool.   bool flag = param; } ``` where `StaticAssertTypeEq` is a compile-time assertion in Google Test that verifies two types are the same.
Sometimes you want to give an action explicit template parameters that cannot be inferred from its value parameters.  `ACTION_TEMPLATE()` supports that and can be viewed as an extension to `ACTION()` and `ACTION_P*()`.
The syntax: ``` ACTION_TEMPLATE(ActionName,                 HAS_m_TEMPLATE_PARAMS(kind1, name1, ..., kind_m, name_m),                 AND_n_VALUE_PARAMS(p1, ..., p_n)) { statements; } ```
defines an action template that takes _m_ explicit template parameters and _n_ value parameters, where _m_ is between 1 and 10, and _n_ is between 0 and 10.  `name_i` is the name of the i-th template parameter, and `kind_i` specifies whether it's a `typename`, an integral constant, or a template.  `p_i` is the name of the i-th value parameter.
Example: ``` // DuplicateArg<k, T>(output) converts the k-th argument of the mock // function to type T and copies it to *output. ACTION_TEMPLATE(DuplicateArg,                 // Note the comma between int and k:                 HAS_2_TEMPLATE_PARAMS(int, k, typename, T),                 AND_1_VALUE_PARAMS(output)) {   *output = T(std::tr1::get<k>(args)); } ```
To create an instance of an action template, write: ```   ActionName<t1, ..., t_m>(v1, ..., v_n) ``` where the `t`s are the template arguments and the `v`s are the value arguments.  The value argument types are inferred by the compiler.  For example: ``` using ::testing::_; ...   int n;   EXPECT_CALL(mock, Foo(_, _))       .WillOnce(DuplicateArg<1, unsigned char>(&n)); ```
If you want to explicitly specify the value argument types, you can provide additional template arguments: ```   ActionName<t1, ..., t_m, u1, ..., u_k>(v1, ..., v_n) ``` where `u_i` is the desired type of `v_i`.
`ACTION_TEMPLATE` and `ACTION`/`ACTION_P*` can be overloaded on the number of value parameters, but not on the number of template parameters.  Without the restriction, the meaning of the following is unclear:
```   OverloadedAction<int, bool>(x); ```
Are we using a single-template-parameter action where `bool` refers to the type of `x`, or a two-template-parameter action where the compiler is asked to infer the type of `x`?
If you are writing a function that returns an `ACTION` object, you'll need to know its type.  The type depends on the macro used to define the action and the parameter types.  The rule is relatively simple: | **Given Definition** | **Expression** | **Has Type** | |:---------------------|:---------------|:-------------| | `ACTION(Foo)`        | `Foo()`        | `FooAction`  | | `ACTION_TEMPLATE(Foo, HAS_m_TEMPLATE_PARAMS(...), AND_0_VALUE_PARAMS())` |	`Foo<t1, ..., t_m>()` | `FooAction<t1, ..., t_m>` | | `ACTION_P(Bar, param)` | `Bar(int_value)` | `BarActionP<int>` | | `ACTION_TEMPLATE(Bar, HAS_m_TEMPLATE_PARAMS(...), AND_1_VALUE_PARAMS(p1))` | `Bar<t1, ..., t_m>(int_value)` | `FooActionP<t1, ..., t_m, int>` | | `ACTION_P2(Baz, p1, p2)` | `Baz(bool_value, int_value)` | `BazActionP2<bool, int>` | | `ACTION_TEMPLATE(Baz, HAS_m_TEMPLATE_PARAMS(...), AND_2_VALUE_PARAMS(p1, p2))` | `Baz<t1, ..., t_m>(bool_value, int_value)` | `FooActionP2<t1, ..., t_m, bool, int>` | | ...                  | ...            | ...          |
Note that we have to pick different suffixes (`Action`, `ActionP`, `ActionP2`, and etc) for actions with different numbers of value parameters, or the action definitions cannot be overloaded on the number of them.
While the `ACTION*` macros are very convenient, sometimes they are inappropriate.  For example, despite the tricks shown in the previous recipes, they don't let you directly specify the types of the mock function arguments and the action parameters, which in general leads to unoptimized compiler error messages that can baffle unfamiliar users.  They also don't allow overloading actions based on parameter types without jumping through some hoops.
An alternative to the `ACTION*` macros is to implement `::testing::ActionInterface<F>`, where `F` is the type of the mock function in which the action will be used. For example:
``` template <typename F>class ActionInterface {  public:   virtual ~ActionInterface();
// Performs the action.  Result is the return type of function type   // F, and ArgumentTuple is the tuple of arguments of F.   //   // For example, if F is int(bool, const string&), then Result would   // be int, and ArgumentTuple would be tr1::tuple<bool, const string&>.   virtual Result Perform(const ArgumentTuple& args) = 0; };
using ::testing::_; using ::testing::Action; using ::testing::ActionInterface; using ::testing::MakeAction;
typedef int IncrementMethod(int*);
class IncrementArgumentAction : public ActionInterface<IncrementMethod> {  public:   virtual int Perform(const tr1::tuple<int*>& args) {     int* p = tr1::get<0>(args);  // Grabs the first argument.     return *p++;   } };
Action<IncrementMethod> IncrementArgument() {   return MakeAction(new IncrementArgumentAction); } ...
EXPECT_CALL(foo, Baz(_))       .WillOnce(IncrementArgument());
int n = 5;   foo.Baz(&n);  // Should return 5 and change n to 6. ```
The previous recipe showed you how to define your own action. This is all good, except that you need to know the type of the function in which the action will be used. Sometimes that can be a problem. For example, if you want to use the action in functions with _different_ types (e.g. like `Return()` and `SetArgumentPointee()`).
If an action can be used in several types of mock functions, we say it's _polymorphic_. The `MakePolymorphicAction()` function template makes it easy to define such an action:
``` namespace testing {
template <typename Impl> PolymorphicAction<Impl> MakePolymorphicAction(const Impl& impl);
}  // namespace testing ```
As an example, let's define an action that returns the second argument in the mock function's argument list. The first step is to define an implementation class:
``` class ReturnSecondArgumentAction {  public:   template <typename Result, typename ArgumentTuple>   Result Perform(const ArgumentTuple& args) const {     // To get the i-th (0-based) argument, use tr1::get<i>(args).     return tr1::get<1>(args);   } }; ```
This implementation class does _not_ need to inherit from any particular class. What matters is that it must have a `Perform()` method template. This method template takes the mock function's arguments as a tuple in a **single** argument, and returns the result of the action. It can be either `const` or not, but must be invokable with exactly one template argument, which is the result type. In other words, you must be able to call `Perform<R>(args)` where `R` is the mock function's return type and `args` is its arguments in a tuple.
Next, we use `MakePolymorphicAction()` to turn an instance of the implementation class into the polymorphic action we need. It will be convenient to have a wrapper for this:
``` using ::testing::MakePolymorphicAction; using ::testing::PolymorphicAction;
PolymorphicAction<ReturnSecondArgumentAction> ReturnSecondArgument() {   return MakePolymorphicAction(ReturnSecondArgumentAction()); } ```
Now, you can use this polymorphic action the same way you use the built-in ones:
``` using ::testing::_;
class MockFoo : public Foo {  public:   MOCK_METHOD2(DoThis, int(bool flag, int n));   MOCK_METHOD3(DoThat, string(int x, const char* str1, const char* str2)); }; ...
MockFoo foo;   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(ReturnSecondArgument());   EXPECT_CALL(foo, DoThat(_, _, _))       .WillOnce(ReturnSecondArgument());   ...   foo.DoThis(true, 5);         // Will return 5.   foo.DoThat(1, "Hi", "Bye");  // Will return "Hi". ```
When an uninteresting or unexpected call occurs, Google Mock prints the argument values to help you debug.  The `EXPECT_THAT` and `ASSERT_THAT` assertions also print the value being validated when the test fails.  Google Mock does this using the user-extensible value printer defined in `<gmock/gmock-printers.h>`.
This printer knows how to print the built-in C++ types, native arrays, STL containers, and any type that supports the `<<` operator. For other types, it prints the raw bytes in the value and hope you the user can figure it out.
Did I say that the printer is `extensible`? That means you can teach it to do a better job at printing your particular type than to dump the bytes. To do that, you just need to define `<<` for your type:
``` #include <iostream>
namespace foo {
class Foo { ... };
// It's important that the << operator is defined in the SAME // namespace that defines Foo.  C++'s look-up rules rely on that. ::std::ostream& operator<<(::std::ostream& os, const Foo& foo) {   return os << foo.DebugString();  // Whatever needed to print foo to os. }
}  // namespace foo ```
Sometimes, this might not be an option. For example, your team may consider it dangerous or bad style to have a `<<` operator for `Foo`, or `Foo` may already have a `<<` operator that doesn't do what you want (and you cannot change it). Don't despair though - Google Mock gives you a second chance to get it right. Namely, you can define a `PrintTo()` function like this:
``` #include <iostream>
namespace foo {
class Foo { ... };
// It's important that PrintTo() is defined in the SAME // namespace that defines Foo.  C++'s look-up rules rely on that. void PrintTo(const Foo& foo, ::std::ostream* os) {   *os << foo.DebugString();  // Whatever needed to print foo to os. }
}  // namespace foo ```
What if you have both `<<` and `PrintTo()`? In this case, the latter will override the former when Google Mock is concerned. This allows you to customize how the value should appear in Google Mock's output without affecting code that relies on the behavior of its `<<` operator.
**Note:** When printing a pointer of type `T*`, Google Mock calls `PrintTo(T*, std::ostream* os)` instead of `operator<<(std::ostream&, T*)`. Therefore the only way to affect how a pointer is printed by Google Mock is to define `PrintTo()` for it. Also note that `T*` and `const T*` are different types, so you may need to define `PrintTo()` for both.
Why does Google Mock treat pointers specially? There are several reasons:
* We cannot use `operator<<` to print a `signed char*` or `unsigned char*`, since it will print the pointer as a NUL-terminated C string, which likely will cause an access violation.   * We want `NULL` pointers to be printed as `"NULL"`, but `operator<<` prints it as `"0"`, `"nullptr"`, or something else, depending on the compiler.   * With some compilers, printing a `NULL` `char*` using `operator<<` will segfault.   * `operator<<` prints a function pointer as a `bool` (hence it always prints `"1"`), which is not very useful.
This page lists all documentation wiki pages for Google Mock **version 1.5.0** -- **if you use a different version of Google Mock, please read the documentation for that specific version instead.**
* [ForDummies](V1_5_ForDummies.md) -- start here if you are new to Google Mock.   * [CheatSheet](V1_5_CheatSheet.md) -- a quick reference.   * [CookBook](V1_5_CookBook.md) -- recipes for doing various tasks using Google Mock.   * [FrequentlyAskedQuestions](V1_5_FrequentlyAskedQuestions.md) -- check here before asking a question on the mailing list.
To contribute code to Google Mock, read:
* DevGuide -- read this _before_ writing your first patch.   * [Pump Manual](http://code.google.com/p/googletest/wiki/PumpManual) -- how we generate some of Google Mock's source files.

(**Note:** If you get compiler errors that you don't understand, be sure to consult [Google Mock Doctor](V1_5_FrequentlyAskedQuestions#How_am_I_supposed_to_make_sense_of_these_horrible_template_error.md).)
**Note:** It is easy to confuse the term _fake objects_ with mock objects. Fakes and mocks actually mean very different things in the Test-Driven Development (TDD) community:
* **Fake** objects have working implementations, but usually take some shortcut (perhaps to make the operations less expensive), which makes them not suitable for production. An in-memory file system would be an example of a fake.   * **Mocks** are objects pre-programmed with _expectations_, which form a specification of the calls they are expected to receive.
If all this seems too abstract for you, don't worry - the most important thing to remember is that a mock allows you to check the _interaction_ between itself and code that uses it. The difference between fakes and mocks will become much clearer once you start to use mocks.
**Google C++ Mocking Framework** (or **Google Mock** for short) is a library (sometimes we also call it a "framework" to make it sound cool) for creating mock classes and using them. It does to C++ what [jMock](http://www.jmock.org/) and [EasyMock](http://www.easymock.org/) do to Java.
Using Google Mock involves three basic steps:
1. Use some simple macros to describe the interface you want to mock, and they will expand to the implementation of your mock class;   1. Create some mock objects and specify its expectations and behavior using an intuitive syntax;   1. Exercise code that uses the mock objects. Google Mock will catch any violation of the expectations as soon as it arises.
* Someone has to implement the mocks. The job is usually tedious and error-prone. No wonder people go great distance to avoid it.   * The quality of those manually written mocks is a bit, uh, unpredictable. You may see some really polished ones, but you may also see some that were hacked up in a hurry and have all sorts of ad hoc restrictions.   * The knowledge you gained from using one mock doesn't transfer to the next.
In contrast, Java and Python programmers have some fine mock frameworks, which automate the creation of mocks. As a result, mocking is a proven effective technique and widely adopted practice in those communities. Having the right tool absolutely makes the difference.
Google Mock was built to help C++ programmers. It was inspired by [jMock](http://www.jmock.org/) and [EasyMock](http://www.easymock.org/), but designed with C++'s specifics in mind. It is your friend if any of the following problems is bothering you:
* You are stuck with a sub-optimal design and wish you had done more prototyping before it was too late, but prototyping in C++ is by no means "rapid".   * Your tests are slow as they depend on too many libraries or use expensive resources (e.g. a database).   * Your tests are brittle as some resources they use are unreliable (e.g. the network).   * You want to test how your code handles a failure (e.g. a file checksum error), but it's not easy to cause one.   * You need to make sure that your module interacts with other modules in the right way, but it's hard to observe the interaction; therefore you resort to observing the side effects at the end of the action, which is awkward at best.   * You want to "mock out" your dependencies, except that they don't have mock implementations yet; and, frankly, you aren't thrilled by some of those hand-written mocks.
We encourage you to use Google Mock as:
* a _design_ tool, for it lets you experiment with your interface design early and often. More iterations lead to better designs!   * a _testing_ tool to cut your tests' outbound dependencies and probe the interaction between your module and its collaborators.
``` class Turtle {   ...   virtual ~Turtle() {}   virtual void PenUp() = 0;   virtual void PenDown() = 0;   virtual void Forward(int distance) = 0;   virtual void Turn(int degrees) = 0;   virtual void GoTo(int x, int y) = 0;   virtual int GetX() const = 0;   virtual int GetY() const = 0; }; ```
(Note that the destructor of `Turtle` **must** be virtual, as is the case for **all** classes you intend to inherit from - otherwise the destructor of the derived class will not be called when you delete an object through a base pointer, and you'll get corrupted program states like memory leaks.)
You can control whether the turtle's movement will leave a trace using `PenUp()` and `PenDown()`, and control its movement using `Forward()`, `Turn()`, and `GoTo()`. Finally, `GetX()` and `GetY()` tell you the current position of the turtle.
Your program will normally use a real implementation of this interface. In tests, you can use a mock implementation instead. This allows you to easily check what drawing primitives your program is calling, with what arguments, and in which order. Tests written this way are much more robust (they won't break because your new machine does anti-aliasing differently), easier to read and maintain (the intent of a test is expressed in the code, not in some binary images), and run _much, much faster_.
1. Derive a class `MockTurtle` from `Turtle`.   1. Take a virtual function of `Turtle`. Count how many arguments it has.   1. In the `public:` section of the child class, write `MOCK_METHODn();` (or `MOCK_CONST_METHODn();` if you are mocking a `const` method), where `n` is the number of the arguments; if you counted wrong, shame on you, and a compiler error will tell you so.   1. Now comes the fun part: you take the function signature, cut-and-paste the _function name_ as the _first_ argument to the macro, and leave what's left as the _second_ argument (in case you're curious, this is the _type of the function_).   1. Repeat until all virtual functions you want to mock are done.
After the process, you should have something like:
``` #include <gmock/gmock.h>  // Brings in Google Mock. class MockTurtle : public Turtle {  public:   ...   MOCK_METHOD0(PenUp, void());   MOCK_METHOD0(PenDown, void());   MOCK_METHOD1(Forward, void(int distance));   MOCK_METHOD1(Turn, void(int degrees));   MOCK_METHOD2(GoTo, void(int x, int y));   MOCK_CONST_METHOD0(GetX, int());   MOCK_CONST_METHOD0(GetY, int()); }; ```
You don't need to define these mock methods somewhere else - the `MOCK_METHOD*` macros will generate the definitions for you. It's that simple! Once you get the hang of it, you can pump out mock classes faster than your source-control system can handle your check-ins.
**Tip:** If even this is too much work for you, you'll find the `gmock_gen.py` tool in Google Mock's `scripts/generator/` directory (courtesy of the [cppclean](http://code.google.com/p/cppclean/) project) useful.  This command-line tool requires that you have Python 2.4 installed.  You give it a C++ file and the name of an abstract class defined in it, and it will print the definition of the mock class for you.  Due to the complexity of the C++ language, this script may not always work, but it can be quite handy when it does.  For more details, read the [user documentation](http://code.google.com/p/googlemock/source/browse/trunk/scripts/generator/README).
So, the rule of thumb is: if you need to mock `Foo` and it's owned by others, define the mock class in `Foo`'s package (better, in a `testing` sub-package such that you can clearly separate production code and testing utilities), and put it in a `mock_foo.h`. Then everyone can reference `mock_foo.h` from their tests. If `Foo` ever changes, there is only one copy of `MockFoo` to change, and only tests that depend on the changed methods need to be fixed.
Another way to do it: you can introduce a thin layer `FooAdaptor` on top of `Foo` and code to this new interface. Since you own `FooAdaptor`, you can absorb changes in `Foo` much more easily. While this is more work initially, carefully choosing the adaptor interface can make your code easier to write and more readable (a net win in the long run), as you can choose `FooAdaptor` to fit your specific domain much better than `Foo` does.
1. Import the Google Mock names from the `testing` namespace such that you can use them unqualified (You only have to do it once per file. Remember that namespaces are a good idea and good for your health.).   1. Create some mock objects.   1. Specify your expectations on them (How many times will a method be called? With what arguments? What should it do? etc.).   1. Exercise some code that uses the mocks; optionally, check the result using Google Test assertions. If a mock method is called more than expected or with wrong arguments, you'll get an error immediately.   1. When a mock is destructed, Google Mock will automatically check whether all expectations on it have been satisfied.
Here's an example:
``` #include "path/to/mock-turtle.h" #include <gmock/gmock.h> #include <gtest/gtest.h> using ::testing::AtLeast;                     // #1
TEST(PainterTest, CanDrawSomething) {   MockTurtle turtle;                          // #2   EXPECT_CALL(turtle, PenDown())              // #3       .Times(AtLeast(1));
Painter painter(&turtle);                   // #4
EXPECT_TRUE(painter.DrawCircle(0, 0, 10)); }                                             // #5
int main(int argc, char** argv) {   // The following line must be executed to initialize Google Mock   // (and Google Test) before running the tests.   ::testing::InitGoogleMock(&argc, argv);   return RUN_ALL_TESTS(); } ```
As you might have guessed, this test checks that `PenDown()` is called at least once. If the `painter` object didn't call this method, your test will fail with a message like this:
``` path/to/my_test.cc:119: Failure Actual function call count doesn't match this expectation: Actually: never called; Expected: called at least once. ```
**Tip 1:** If you run the test from an Emacs buffer, you can hit `<Enter>` on the line number displayed in the error message to jump right to the failed expectation.
**Tip 2:** If your mock objects are never deleted, the final verification won't happen. Therefore it's a good idea to use a heap leak checker in your tests when you allocate mocks on the heap.
**Important note:** Google Mock requires expectations to be set **before** the mock functions are called, otherwise the behavior is **undefined**. In particular, you mustn't interleave `EXPECT_CALL()`s and calls to the mock functions.
This means `EXPECT_CALL()` should be read as expecting that a call will occur _in the future_, not that a call has occurred. Why does Google Mock work like that? Well, specifying the expectation beforehand allows Google Mock to report a violation as soon as it arises, when the context (stack trace, etc) is still available. This makes debugging much easier.
Admittedly, this test is contrived and doesn't do much. You can easily achieve the same effect without using Google Mock. However, as we shall reveal soon, Google Mock allows you to do _much more_ with the mocks.
This approach has a catch: it makes Google Mock throw an exception from a mock object's destructor sometimes.  With some compilers, this sometimes causes the test program to crash.  You'll still be able to notice that the test has failed, but it's not a graceful failure.
A better solution is to use Google Test's [event listener API](http://code.google.com/p/googletest/wiki/GoogleTestAdvancedGuide#Extending_Google_Test_by_Handling_Test_Events) to report a test failure to your testing framework properly.  You'll need to implement the `OnTestPartResult()` method of the event listener interface, but it should be straightforward.
If this turns out to be too much work, we suggest that you stick with Google Test, which works with Google Mock seamlessly (in fact, it is technically part of Google Mock.).  If there is a reason that you cannot use Google Test, please let us know.
``` EXPECT_CALL(mock_object, method(matchers))     .Times(cardinality)     .WillOnce(action)     .WillRepeatedly(action); ```
The macro has two arguments: first the mock object, and then the method and its arguments. Note that the two are separated by a comma (`,`), not a period (`.`). (Why using a comma? The answer is that it was necessary for technical reasons.)
The macro can be followed by some optional _clauses_ that provide more information about the expectation. We'll discuss how each clause works in the coming sections.
This syntax is designed to make an expectation read like English. For example, you can probably guess that
``` using ::testing::Return;... EXPECT_CALL(turtle, GetX())     .Times(5)     .WillOnce(Return(100))     .WillOnce(Return(150))     .WillRepeatedly(Return(200)); ```
says that the `turtle` object's `GetX()` method will be called five times, it will return 100 the first time, 150 the second time, and then 200 every time. Some people like to call this style of syntax a Domain-Specific Language (DSL).
**Note:** Why do we use a macro to do this? It serves two purposes: first it makes expectations easily identifiable (either by `grep` or by a human reader), and second it allows Google Mock to include the source file location of a failed expectation in messages, making debugging easier.
``` // Expects the turtle to move forward by 100 units. EXPECT_CALL(turtle, Forward(100)); ```
Sometimes you may not want to be too specific (Remember that talk about tests being too rigid? Over specification leads to brittle tests and obscures the intent of tests. Therefore we encourage you to specify only what's necessary - no more, no less.). If you care to check that `Forward()` will be called but aren't interested in its actual argument, write `_` as the argument, which means "anything goes":
``` using ::testing::_; ... // Expects the turtle to move forward. EXPECT_CALL(turtle, Forward(_)); ```
`_` is an instance of what we call **matchers**. A matcher is like a predicate and can test whether an argument is what we'd expect. You can use a matcher inside `EXPECT_CALL()` wherever a function argument is expected.
A list of built-in matchers can be found in the [CheatSheet](V1_5_CheatSheet.md). For example, here's the `Ge` (greater than or equal) matcher:
``` using ::testing::Ge;... EXPECT_CALL(turtle, Forward(Ge(100))); ```
This checks that the turtle will be told to go forward by at least 100 units.
An interesting special case is when we say `Times(0)`. You may have guessed - it means that the function shouldn't be called with the given arguments at all, and Google Mock will report a Google Test failure whenever the function is (wrongfully) called.
We've seen `AtLeast(n)` as an example of fuzzy cardinalities earlier. For the list of built-in cardinalities you can use, see the [CheatSheet](V1_5_CheatSheet.md).
The `Times()` clause can be omitted. **If you omit `Times()`, Google Mock will infer the cardinality for you.** The rules are easy to remember:
* If **neither** `WillOnce()` **nor** `WillRepeatedly()` is in the `EXPECT_CALL()`, the inferred cardinality is `Times(1)`.   * If there are `n WillOnce()`'s but **no** `WillRepeatedly()`, where `n` >= 1, the cardinality is `Times(n)`.   * If there are `n WillOnce()`'s and **one** `WillRepeatedly()`, where `n` >= 0, the cardinality is `Times(AtLeast(n))`.
**Quick quiz:** what do you think will happen if a function is expected to be called twice but actually called four times?
First, if the return type of a mock function is a built-in type or a pointer, the function has a **default action** (a `void` function will just return, a `bool` function will return `false`, and other functions will return 0). If you don't say anything, this behavior will be used.
Second, if a mock function doesn't have a default action, or the default action doesn't suit you, you can specify the action to be taken each time the expectation matches using a series of `WillOnce()` clauses followed by an optional `WillRepeatedly()`. For example,
``` using ::testing::Return;... EXPECT_CALL(turtle, GetX())     .WillOnce(Return(100))     .WillOnce(Return(200))     .WillOnce(Return(300)); ```
This says that `turtle.GetX()` will be called _exactly three times_ (Google Mock inferred this from how many `WillOnce()` clauses we've written, since we didn't explicitly write `Times()`), and will return 100, 200, and 300 respectively.
``` using ::testing::Return;... EXPECT_CALL(turtle, GetY())     .WillOnce(Return(100))     .WillOnce(Return(200))     .WillRepeatedly(Return(300)); ```
says that `turtle.GetY()` will be called _at least twice_ (Google Mock knows this as we've written two `WillOnce()` clauses and a `WillRepeatedly()` while having no explicit `Times()`), will return 100 the first time, 200 the second time, and 300 from the third time on.
Of course, if you explicitly write a `Times()`, Google Mock will not try to infer the cardinality itself. What if the number you specified is larger than there are `WillOnce()` clauses? Well, after all `WillOnce()`s are used up, Google Mock will do the _default_ action for the function every time (unless, of course, you have a `WillRepeatedly()`.).
What can we do inside `WillOnce()` besides `Return()`? You can return a reference using `ReturnRef(variable)`, or invoke a pre-defined function, among [others](V1_5_CheatSheet#Actions.md).
**Important note:** The `EXPECT_CALL()` statement evaluates the action clause only once, even though the action may be performed many times. Therefore you must be careful about side effects. The following may not do what you want:
``` int n = 100; EXPECT_CALL(turtle, GetX()) .Times(4) .WillOnce(Return(n++)); ```
Instead of returning 100, 101, 102, ..., consecutively, this mock function will always return 100 as `n++` is only evaluated once. Similarly, `Return(new Foo)` will create a new `Foo` object when the `EXPECT_CALL()` is executed, and will return the same pointer every time. If you want the side effect to happen every time, you need to define a custom action, which we'll teach in the [CookBook](V1_5_CookBook.md).
Time for another quiz! What do you think the following means?
``` using ::testing::Return;... EXPECT_CALL(turtle, GetY()) .Times(4) .WillOnce(Return(100)); ```
Obviously `turtle.GetY()` is expected to be called four times. But if you think it will return 100 every time, think twice! Remember that one `WillOnce()` clause will be consumed each time the function is invoked and the default action will be taken afterwards. So the right answer is that `turtle.GetY()` will return 100 the first time, but **return 0 from the second time on**, as returning 0 is the default action for `int` functions.
By default, when a mock method is invoked, Google Mock will search the expectations in the **reverse order** they are defined, and stop when an active expectation that matches the arguments is found (you can think of it as "newer rules override older ones."). If the matching expectation cannot take any more calls, you will get an upper-bound-violated failure. Here's an example:
``` using ::testing::_;... EXPECT_CALL(turtle, Forward(_));  // #1 EXPECT_CALL(turtle, Forward(10))  // #2     .Times(2); ```
If `Forward(10)` is called three times in a row, the third time it will be an error, as the last matching expectation (#2) has been saturated. If, however, the third `Forward(10)` call is replaced by `Forward(20)`, then it would be OK, as now #1 will be the matching expectation.
**Side note:** Why does Google Mock search for a match in the _reverse_ order of the expectations? The reason is that this allows a user to set up the default expectations in a mock object's constructor or the test fixture's set-up phase and then customize the mock by writing more specific expectations in the test body. So, if you have two expectations on the same method, you want to put the one with more specific matchers **after** the other, or the more specific rule would be shadowed by the more general one that comes after it.
Sometimes, you may want all the expected calls to occur in a strict order. To say this in Google Mock is easy:
``` using ::testing::InSequence;... TEST(FooTest, DrawsLineSegment) {   ...   {     InSequence dummy;
EXPECT_CALL(turtle, PenDown());     EXPECT_CALL(turtle, Forward(100));     EXPECT_CALL(turtle, PenUp());   }   Foo(); } ```
By creating an object of type `InSequence`, all expectations in its scope are put into a _sequence_ and have to occur _sequentially_. Since we are just relying on the constructor and destructor of this object to do the actual work, its name is really irrelevant.
In this example, we test that `Foo()` calls the three expected functions in the order as written. If a call is made out-of-order, it will be an error.
(What if you care about the relative order of some of the calls, but not all of them? Can you specify an arbitrary partial order? The answer is ... yes! If you are impatient, the details can be found in the [CookBook](V1_5_CookBook.md).)
After you've come up with your answer, take a look at ours and compare notes (solve it yourself first - don't cheat!):
``` using ::testing::_;... EXPECT_CALL(turtle, GoTo(_, _))  // #1     .Times(AnyNumber()); EXPECT_CALL(turtle, GoTo(0, 0))  // #2     .Times(2); ```
Suppose `turtle.GoTo(0, 0)` is called three times. In the third time, Google Mock will see that the arguments match expectation #2 (remember that we always pick the last matching expectation). Now, since we said that there should be only two such calls, Google Mock will report an error immediately. This is basically what we've told you in the "Using Multiple Expectations" section above.
This example shows that **expectations in Google Mock are "sticky" by default**, in the sense that they remain active even after we have reached their invocation upper bounds. This is an important rule to remember, as it affects the meaning of the spec, and is **different** to how it's done in many other mocking frameworks (Why'd we do that? Because we think our rule makes the common cases easier to express and understand.).
Simple? Let's see if you've really understood it: what does the following code say?
``` using ::testing::Return; ... for (int i = n; i > 0; i--) {   EXPECT_CALL(turtle, GetX())       .WillOnce(Return(10*i)); } ```
If you think it says that `turtle.GetX()` will be called `n` times and will return 10, 20, 30, ..., consecutively, think twice! The problem is that, as we said, expectations are sticky. So, the second time `turtle.GetX()` is called, the last (latest) `EXPECT_CALL()` statement will match, and will immediately lead to an "upper bound exceeded" error - this piece of code is not very useful!
One correct way of saying that `turtle.GetX()` will return 10, 20, 30, ..., is to explicitly say that the expectations are _not_ sticky. In other words, they should _retire_ as soon as they are saturated:
``` using ::testing::Return; ... for (int i = n; i > 0; i--) {   EXPECT_CALL(turtle, GetX())     .WillOnce(Return(10*i))     .RetiresOnSaturation(); } ```
And, there's a better way to do it: in this case, we expect the calls to occur in a specific order, and we line up the actions to match the order. Since the order is important here, we should make it explicit using a sequence:
``` using ::testing::InSequence; using ::testing::Return; ... {   InSequence s;
for (int i = 1; i <= n; i++) {     EXPECT_CALL(turtle, GetX())         .WillOnce(Return(10*i))         .RetiresOnSaturation();   } } ```
By the way, the other situation where an expectation may _not_ be sticky is when it's in a sequence - as soon as another expectation that comes after it in the sequence has been used, it automatically retires (and will never be used to match any call).
In Google Mock, if you are not interested in a method, just don't say anything about it. If a call to this method occurs, you'll see a warning in the test output, but it won't be a failure.
Then, if you feel like increasing your mock quotient, you should move on to the [CookBook](V1_5_CookBook.md). You can learn many advanced features of Google Mock there -- and advance your level of enjoyment and testing bliss.

Please send your questions to the [googlemock](http://groups.google.com/group/googlemock) discussion group. If you need help with compiler errors, make sure you have tried [Google Mock Doctor](#How_am_I_supposed_to_make_sense_of_these_horrible_template_error.md) first.
After version 1.4.0 of Google Mock was released, we had an idea on how to make it easier to write matchers that can generate informative messages efficiently.  We experimented with this idea and liked what we saw.  Therefore we decided to implement it.
Unfortunately, this means that if you have defined your own matchers by implementing `MatcherInterface` or using `MakePolymorphicMatcher()`, your definitions will no longer compile.  Matchers defined using the `MATCHER*` family of macros are not affected.
Sorry for the hassle if your matchers are affected.  We believe it's in everyone's long-term interest to make this change sooner than later.  Fortunately, it's usually not hard to migrate an existing matcher to the new API.  Here's what you need to do:
If you wrote your matcher like this: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MatcherInterface; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }   ... }; ```
you'll need to change it to: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MatcherInterface; using ::testing::MatchResultListener; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool MatchAndExplain(MyType value,                                MatchResultListener* listener) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }   ... }; ``` (i.e. rename `Matches()` to `MatchAndExplain()` and give it a second argument of type `MatchResultListener*`.)
If you were also using `ExplainMatchResultTo()` to improve the matcher message: ``` // Old matcher definition that doesn't work with the lastest // Google Mock. using ::testing::MatcherInterface; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }
virtual void ExplainMatchResultTo(MyType value,                                     ::std::ostream* os) const {     // Prints some helpful information to os to help     // a user understand why value matches (or doesn't match).     *os << "the Foo property is " << value.GetFoo();   }   ... }; ```
you should move the logic of `ExplainMatchResultTo()` into `MatchAndExplain()`, using the `MatchResultListener` argument where the `::std::ostream` was used: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MatcherInterface; using ::testing::MatchResultListener; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool MatchAndExplain(MyType value,                                MatchResultListener* listener) const {     // Returns true if value matches.     *listener << "the Foo property is " << value.GetFoo();     return value.GetFoo() > 5;   }   ... }; ```
If your matcher is defined using `MakePolymorphicMatcher()`: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MakePolymorphicMatcher; ... class MyGreatMatcher {  public:   ...   bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
you should rename the `Matches()` method to `MatchAndExplain()` and add a `MatchResultListener*` argument (the same as what you need to do for matchers defined by implementing `MatcherInterface`): ``` // New matcher definition that works with the latest Google Mock. using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; ... class MyGreatMatcher {  public:   ...   bool MatchAndExplain(MyType value,                        MatchResultListener* listener) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
If your polymorphic matcher uses `ExplainMatchResultTo()` for better failure messages: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MakePolymorphicMatcher; ... class MyGreatMatcher {  public:   ...   bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; void ExplainMatchResultTo(const MyGreatMatcher& matcher,                           MyType value,                           ::std::ostream* os) {   // Prints some helpful information to os to help   // a user understand why value matches (or doesn't match).   *os << "the Bar property is " << value.GetBar(); } ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
you'll need to move the logic inside `ExplainMatchResultTo()` to `MatchAndExplain()`: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; ... class MyGreatMatcher {  public:   ...   bool MatchAndExplain(MyType value,                        MatchResultListener* listener) const {     // Returns true if value matches.     *listener << "the Bar property is " << value.GetBar();     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
For more information, you can read these [two](V1_5_CookBook#Writing_New_Monomorphic_Matchers.md) [recipes](V1_5_CookBook#Writing_New_Polymorphic_Matchers.md) from the cookbook.  As always, you are welcome to post questions on `googlemock@googlegroups.com` if you need any help.
Google Mock works out of the box with Google Test.  However, it's easy to configure it to work with any testing framework of your choice. [Here](V1_5_ForDummies#Using_Google_Mock_with_Any_Testing_Framework.md) is how.
If you are confused by the compiler errors gcc threw at you, try consulting the _Google Mock Doctor_ tool first.  What it does is to scan stdin for gcc error messages, and spit out diagnoses on the problems (we call them diseases) your code has.
To "install", run command: ``` alias gmd='<path to googlemock>/scripts/gmock_doctor.py' ```
To use it, do: ``` <your-favorite-build-command> <your-test> 2>&1 | gmd ```
For example: ``` make my_test 2>&1 | gmd ```
Or you can run `gmd` and copy-n-paste gcc's error messages to it.
You cannot mock a variadic function (i.e. a function taking ellipsis (`...`) arguments) directly in Google Mock.
The problem is that in general, there is _no way_ for a mock object to know how many arguments are passed to the variadic method, and what the arguments' types are.  Only the _author of the base class_ knows the protocol, and we cannot look into his head.
Therefore, to mock such a function, the _user_ must teach the mock object how to figure out the number of arguments and their types.  One way to do it is to provide overloaded versions of the function.
Ellipsis arguments are inherited from C and not really a C++ feature. They are unsafe to use and don't work with arguments that have constructors or destructors.  Therefore we recommend to avoid them in C++ as much as possible.
If you compile this using Microsoft Visual C++ 2005 SP1: ``` class Foo {   ...   virtual void Bar(const int i) = 0; };
class MockFoo : public Foo {   ...   MOCK_METHOD1(Bar, void(const int i)); }; ``` You may get the following warning: ``` warning C4301: 'MockFoo::Bar': overriding virtual function only differs from 'Foo::Bar' by const/volatile qualifier ```
This is a MSVC bug.  The same code compiles fine with gcc ,for example.  If you use Visual C++ 2008 SP1, you would get the warning: ``` warning C4373: 'MockFoo::Bar': virtual function overrides 'Foo::Bar', previous versions of the compiler did not override when parameters only differed by const/volatile qualifiers ```
In C++, if you _declare_ a function with a `const` parameter, the `const` modifier is _ignored_.  Therefore, the `Foo` base class above is equivalent to: ``` class Foo {   ...   virtual void Bar(int i) = 0;  // int or const int?  Makes no difference. }; ```
In fact, you can _declare_ Bar() with an `int` parameter, and _define_ it with a `const int` parameter.  The compiler will still match them up.
Since making a parameter `const` is meaningless in the method _declaration_, we recommend to remove it in both `Foo` and `MockFoo`. That should workaround the VC bug.
Note that we are talking about the _top-level_ `const` modifier here. If the function parameter is passed by pointer or reference, declaring the _pointee_ or _referee_ as `const` is still meaningful.  For example, the following two declarations are _not_ equivalent: ``` void Bar(int* p);        // Neither p nor *p is const. void Bar(const int* p);  // p is not const, but *p is. ```
We've noticed that when the `/clr` compiler flag is used, Visual C++ uses 5~6 times as much memory when compiling a mock class.  We suggest to avoid `/clr` when compiling native C++ mocks.
You might want to run your test with `--gmock_verbose=info`.  This flag lets Google Mock print a trace of every mock function call it receives.  By studying the trace, you'll gain insights on why the expectations you set are not met.
``` EXPECT_CALL(foo, Bar(_))     .Times(0); ```
When Google Mock detects a failure, it prints relevant information (the mock function arguments, the state of relevant expectations, and etc) to help the user debug.  If another failure is detected, Google Mock will do the same, including printing the state of relevant expectations.
Sometimes an expectation's state didn't change between two failures, and you'll see the same description of the state twice.  They are however _not_ redundant, as they refer to _different points in time_. The fact they are the same _is_ interesting information.
Does the class (hopefully a pure interface) you are mocking have a virtual destructor?
Whenever you derive from a base class, make sure its destructor is virtual.  Otherwise Bad Things will happen.  Consider the following code:
``` class Base {  public:   // Not virtual, but should be.   ~Base() { ... }   ... };
class Derived : public Base {  public:   ...  private:   std::string value_; };
...   Base* p = new Derived;   ...   delete p;  // Surprise! ~Base() will be called, but ~Derived() will not              // - value_ is leaked. ```
By changing `~Base()` to virtual, `~Derived()` will be correctly called when `delete p` is executed, and the heap checker will be happy.
When people complain about this, often they are referring to code like:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time.  However, I have to write the expectations in the // reverse order.  This sucks big time!!! EXPECT_CALL(foo, Bar())     .WillOnce(Return(2))     .RetiresOnSaturation(); EXPECT_CALL(foo, Bar())     .WillOnce(Return(1))     .RetiresOnSaturation(); ```
The problem is that they didn't pick the **best** way to express the test's intent.
By default, expectations don't have to be matched in _any_ particular order.  If you want them to match in a certain order, you need to be explicit.  This is Google Mock's (and jMock's) fundamental philosophy: it's easy to accidentally over-specify your tests, and we want to make it harder to do so.
There are two better ways to write the test spec.  You could either put the expectations in sequence:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time.  Using a sequence, we can write the expectations // in their natural order. {   InSequence s;   EXPECT_CALL(foo, Bar())       .WillOnce(Return(1))       .RetiresOnSaturation();   EXPECT_CALL(foo, Bar())       .WillOnce(Return(2))       .RetiresOnSaturation(); } ```
or you can put the sequence of actions in the same expectation:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time. EXPECT_CALL(foo, Bar())     .WillOnce(Return(1))     .WillOnce(Return(2))     .RetiresOnSaturation(); ```
Back to the original questions: why does Google Mock search the expectations (and `ON_CALL`s) from back to front?  Because this allows a user to set up a mock's behavior for the common case early (e.g. in the mock's constructor or the test fixture's set-up phase) and customize it with more specific rules later.  If Google Mock searches from front to back, this very useful pattern won't be possible.
When choosing between being neat and being safe, we lean toward the latter.  So the answer is that we think it's better to show the warning.
Often people write `ON_CALL`s in the mock object's constructor or `SetUp()`, as the default behavior rarely changes from test to test.  Then in the test body they set the expectations, which are often different for each test.  Having an `ON_CALL` in the set-up part of a test doesn't mean that the calls are expected.  If there's no `EXPECT_CALL` and the method is called, it's possibly an error.  If we quietly let the call go through without notifying the user, bugs may creep in unnoticed.
If, however, you are sure that the calls are OK, you can write
``` EXPECT_CALL(foo, Bar(_))     .WillRepeatedly(...); ```
instead of
``` ON_CALL(foo, Bar(_))     .WillByDefault(...); ```
This tells Google Mock that you do expect the calls and no warning should be printed.
Also, you can control the verbosity using the `--gmock_verbose` flag. If you find the output too noisy when debugging, just choose a less verbose level.
If you find yourself needing to perform some action that's not supported by Google Mock directly, remember that you can define your own actions using [MakeAction()](V1_5_CookBook#Writing_New_Actions.md) or [MakePolymorphicAction()](V1_5_CookBook#Writing_New_Polymorphic_Actions.md), or you can write a stub function and invoke it using [Invoke()](V1_5_CookBook#Using_Functions_Methods_Functors.md).
What?!  I think it's beautiful. :-)
While which syntax looks more natural is a subjective matter to some extent, Google Mock's syntax was chosen for several practical advantages it has.
Try to mock a function that takes a map as an argument: ``` virtual int GetSize(const map<int, std::string>& m); ```
Using the proposed syntax, it would be: ``` MOCK_METHOD1(GetSize, int, const map<int, std::string>& m); ```
Guess what?  You'll get a compiler error as the compiler thinks that `const map<int, std::string>& m` are **two**, not one, arguments. To work around this you can use `typedef` to give the map type a name, but that gets in the way of your work.  Google Mock's syntax avoids this problem as the function's argument types are protected inside a pair of parentheses: ``` // This compiles fine. MOCK_METHOD1(GetSize, int(const map<int, std::string>& m)); ```
You still need a `typedef` if the return type contains an unprotected comma, but that's much rarer.
Other advantages include:   1. `MOCK_METHOD1(Foo, int, bool)` can leave a reader wonder whether the method returns `int` or `bool`, while there won't be such confusion using Google Mock's syntax.   1. The way Google Mock describes a function type is nothing new, although many people may not be familiar with it.  The same syntax was used in C, and the `function` library in `tr1` uses this syntax extensively.  Since `tr1` will become a part of the new version of STL, we feel very comfortable to be consistent with it.   1. The function type syntax is also used in other parts of Google Mock's API (e.g. the action interface) in order to make the implementation tractable. A user needs to learn it anyway in order to utilize Google Mock's more advanced features.  We'd as well stick to the same syntax in `MOCK_METHOD*`!
You can, but you need to make some changes.
In general, if you find yourself needing to mock a static function, it's a sign that your modules are too tightly coupled (and less flexible, less reusable, less testable, etc).  You are probably better off defining a small interface and call the function through that interface, which then can be easily mocked.  It's a bit of work initially, but usually pays for itself quickly.
This Google Testing Blog [post](http://googletesting.blogspot.com/2008/06/defeat-static-cling.html) says it excellently.  Check it out.
I know it's not a question, but you get an answer for free any way. :-)
With Google Mock, you can create mocks in C++ easily.  And people might be tempted to use them everywhere. Sometimes they work great, and sometimes you may find them, well, a pain to use. So, what's wrong in the latter case?
When you write a test without using mocks, you exercise the code and assert that it returns the correct value or that the system is in an expected state.  This is sometimes called "state-based testing".
Mocks are great for what some call "interaction-based" testing: instead of checking the system state at the very end, mock objects verify that they are invoked the right way and report an error as soon as it arises, giving you a handle on the precise context in which the error was triggered.  This is often more effective and economical to do than state-based testing.
If you are doing state-based testing and using a test double just to simulate the real object, you are probably better off using a fake. Using a mock in this case causes pain, as it's not a strong point for mocks to perform complex actions.  If you experience this and think that mocks suck, you are just not using the right tool for your problem. Or, you might be trying to solve the wrong problem. :-)
By all means, NO!  It's just an FYI.
What it means is that you have a mock function, you haven't set any expectations on it (by Google Mock's rule this means that you are not interested in calls to this function and therefore it can be called any number of times), and it is called.  That's OK - you didn't say it's not OK to call the function!
What if you actually meant to disallow this function to be called, but forgot to write `EXPECT_CALL(foo, Bar()).Times(0)`?  While one can argue that it's the user's fault, Google Mock tries to be nice and prints you a note.
So, when you see the message and believe that there shouldn't be any uninteresting calls, you should investigate what's going on.  To make your life easier, Google Mock prints the function name and arguments when an uninteresting call is encountered.
Either way is fine - you want to choose the one that's more convenient for your circumstance.
Usually, if your action is for a particular function type, defining it using `Invoke()` should be easier; if your action can be used in functions of different types (e.g. if you are defining `Return(value)`), `MakePolymorphicAction()` is easiest.  Sometimes you want precise control on what types of functions the action can be used in, and implementing `ActionInterface` is the way to go here. See the implementation of `Return()` in `include/gmock/gmock-actions.h` for an example.
You got this error as Google Mock has no idea what value it should return when the mock method is called.  `SetArgumentPointee()` says what the side effect is, but doesn't say what the return value should be.  You need `DoAll()` to chain a `SetArgumentPointee()` with a `Return()`.
See this [recipe](V1_5_CookBook#Mocking_Side_Effects.md) for more details and an example.
If you cannot find the answer to your question in this FAQ, there are some other resources you can use:
1. read other [wiki pages](http://code.google.com/p/googlemock/w/list),   1. search the mailing list [archive](http://groups.google.com/group/googlemock/topics),   1. ask it on [googlemock@googlegroups.com](mailto:googlemock@googlegroups.com) and someone will answer it (to prevent spam, we require you to join the [discussion group](http://groups.google.com/group/googlemock) before you can post.).
Please note that creating an issue in the [issue tracker](http://code.google.com/p/googlemock/issues/list) is _not_ a good way to get your answer, as it is monitored infrequently by a very small number of people.
When asking a question, it's helpful to provide as much of the following information as possible (people cannot help you if there's not enough information in your question):
* the version (or the revision number if you check out from SVN directly) of Google Mock you use (Google Mock is under active development, so it's possible that your problem has been solved in a later version),   * your operating system,   * the name and version of your compiler,   * the complete command line flags you give to your compiler,   * the complete compiler error messages (if the question is about compilation),   * the _actual_ code (ideally, a minimal but complete program) that has the problem you encounter.

Given ``` class Foo {   ...   virtual ~Foo();   virtual int GetSize() const = 0;   virtual string Describe(const char* name) = 0;   virtual string Describe(int type) = 0;   virtual bool Process(Bar elem, int count) = 0; }; ``` (note that `~Foo()` **must** be virtual) we can define its mock as ``` #include "gmock/gmock.h"
class MockFoo : public Foo {   MOCK_CONST_METHOD0(GetSize, int());   MOCK_METHOD1(Describe, string(const char* name));   MOCK_METHOD1(Describe, string(int type));   MOCK_METHOD2(Process, bool(Bar elem, int count)); }; ```
To create a "nice" mock object which ignores all uninteresting calls, or a "strict" mock object, which treats them as failures: ``` NiceMock<MockFoo> nice_foo;     // The type is a subclass of MockFoo. StrictMock<MockFoo> strict_foo; // The type is a subclass of MockFoo. ```
To mock ``` template <typename Elem> class StackInterface {  public:   ...   virtual ~StackInterface();   virtual int GetSize() const = 0;   virtual void Push(const Elem& x) = 0; }; ``` (note that `~StackInterface()` **must** be virtual) just append `_T` to the `MOCK_*` macros: ``` template <typename Elem> class MockStack : public StackInterface<Elem> {  public:   ...   MOCK_CONST_METHOD0_T(GetSize, int());   MOCK_METHOD1_T(Push, void(const Elem& x)); }; ```
If your mock function doesn't use the default calling convention, you can specify it by appending `_WITH_CALLTYPE` to any of the macros described in the previous two sections and supplying the calling convention as the first argument to the macro. For example, ```   MOCK_METHOD_1_WITH_CALLTYPE(STDMETHODCALLTYPE, Foo, bool(int n));   MOCK_CONST_METHOD2_WITH_CALLTYPE(STDMETHODCALLTYPE, Bar, int(double x, double y)); ``` where `STDMETHODCALLTYPE` is defined by `<objbase.h>` on Windows.
The typical flow is:   1. Import the Google Mock names you need to use. All Google Mock names are in the `testing` namespace unless they are macros or otherwise noted.   1. Create the mock objects.   1. Optionally, set the default actions of the mock objects.   1. Set your expectations on the mock objects (How will they be called? What wil they do?).   1. Exercise code that uses the mock objects; if necessary, check the result using [Google Test](http://code.google.com/p/googletest/) assertions.   1. When a mock objects is destructed, Google Mock automatically verifies that all expectations on it have been satisfied.
Here is an example: ``` using ::testing::Return;                            // #1
TEST(BarTest, DoesThis) {   MockFoo foo;                                    // #2
ON_CALL(foo, GetSize())                         // #3       .WillByDefault(Return(1));   // ... other default actions ...
EXPECT_CALL(foo, Describe(5))                   // #4       .Times(3)       .WillRepeatedly(Return("Category 5"));   // ... other expectations ...
EXPECT_EQ("good", MyProductionFunction(&foo));  // #5 }                                                 // #6 ```
Google Mock has a **built-in default action** for any function that returns `void`, `bool`, a numeric value, or a pointer.
To customize the default action for functions with return type `T` globally: ``` using ::testing::DefaultValue;
DefaultValue<T>::Set(value);  // Sets the default value to be returned. // ... use the mocks ... DefaultValue<T>::Clear();     // Resets the default value. ```
To customize the default action for a particular method, use `ON_CALL()`: ``` ON_CALL(mock_object, method(matchers))     .With(multi_argument_matcher)  ?     .WillByDefault(action); ```
`EXPECT_CALL()` sets **expectations** on a mock method (How will it be called? What will it do?): ``` EXPECT_CALL(mock_object, method(matchers))     .With(multi_argument_matcher)  ?     .Times(cardinality)            ?     .InSequence(sequences)         *     .After(expectations)           *     .WillOnce(action)              *     .WillRepeatedly(action)        ?     .RetiresOnSaturation();        ? ```
If `Times()` is omitted, the cardinality is assumed to be:
* `Times(1)` when there is neither `WillOnce()` nor `WillRepeatedly()`;   * `Times(n)` when there are `n WillOnce()`s but no `WillRepeatedly()`, where `n` >= 1; or   * `Times(AtLeast(n))` when there are `n WillOnce()`s and a `WillRepeatedly()`, where `n` >= 0.
A method with no `EXPECT_CALL()` is free to be invoked _any number of times_, and the default action will be taken each time.
A **matcher** matches a _single_ argument.  You can use it inside `ON_CALL()` or `EXPECT_CALL()`, or use it to validate a value directly:
| `EXPECT_THAT(value, matcher)` | Asserts that `value` matches `matcher`. | |:------------------------------|:----------------------------------------| | `ASSERT_THAT(value, matcher)` | The same as `EXPECT_THAT(value, matcher)`, except that it generates a **fatal** failure. |
Built-in matchers (where `argument` is the function argument) are divided into several categories:
|`Eq(value)` or `value`|`argument == value`| |:---------------------|:------------------| |`Ge(value)`           |`argument >= value`| |`Gt(value)`           |`argument > value` | |`Le(value)`           |`argument <= value`| |`Lt(value)`           |`argument < value` | |`Ne(value)`           |`argument != value`| |`IsNull()`            |`argument` is a `NULL` pointer (raw or smart).| |`NotNull()`           |`argument` is a non-null pointer (raw or smart).| |`Ref(variable)`       |`argument` is a reference to `variable`.| |`TypedEq<type>(value)`|`argument` has type `type` and is equal to `value`. You may need to use this instead of `Eq(value)` when the mock function is overloaded.|
Except `Ref()`, these matchers make a _copy_ of `value` in case it's modified or destructed later. If the compiler complains that `value` doesn't have a public copy constructor, try wrap it in `ByRef()`, e.g. `Eq(ByRef(non_copyable_value))`. If you do that, make sure `non_copyable_value` is not changed afterwards, or the meaning of your matcher will be changed.
|`DoubleEq(a_double)`|`argument` is a `double` value approximately equal to `a_double`, treating two NaNs as unequal.| |:-------------------|:----------------------------------------------------------------------------------------------| |`FloatEq(a_float)`  |`argument` is a `float` value approximately equal to `a_float`, treating two NaNs as unequal.  | |`NanSensitiveDoubleEq(a_double)`|`argument` is a `double` value approximately equal to `a_double`, treating two NaNs as equal.  | |`NanSensitiveFloatEq(a_float)`|`argument` is a `float` value approximately equal to `a_float`, treating two NaNs as equal.    |
These matchers use ULP-based comparison (the same as used in [Google Test](http://code.google.com/p/googletest/)). They automatically pick a reasonable error bound based on the absolute value of the expected value.  `DoubleEq()` and `FloatEq()` conform to the IEEE standard, which requires comparing two NaNs for equality to return false. The `NanSensitive*` version instead treats two NaNs as equal, which is often what a user wants.
The `argument` can be either a C string or a C++ string object:
|`ContainsRegex(string)`|`argument` matches the given regular expression.| |:----------------------|:-----------------------------------------------| |`EndsWith(suffix)`     |`argument` ends with string `suffix`.           | |`HasSubstr(string)`    |`argument` contains `string` as a sub-string.   | |`MatchesRegex(string)` |`argument` matches the given regular expression with the match starting at the first character and ending at the last character.| |`StartsWith(prefix)`   |`argument` starts with string `prefix`.         | |`StrCaseEq(string)`    |`argument` is equal to `string`, ignoring case. | |`StrCaseNe(string)`    |`argument` is not equal to `string`, ignoring case.| |`StrEq(string)`        |`argument` is equal to `string`.                | |`StrNe(string)`        |`argument` is not equal to `string`.            |
`ContainsRegex()` and `MatchesRegex()` use the regular expression syntax defined [here](http://code.google.com/p/googletest/wiki/V1_6_AdvancedGuide#Regular_Expression_Syntax). `StrCaseEq()`, `StrCaseNe()`, `StrEq()`, and `StrNe()` work for wide strings as well.
Most STL-style containers support `==`, so you can use `Eq(expected_container)` or simply `expected_container` to match a container exactly.   If you want to write the elements in-line, match them more flexibly, or get more informative messages, you can use:
| `Contains(e)` | `argument` contains an element that matches `e`, which can be either a value or a matcher. | |:--------------|:-------------------------------------------------------------------------------------------| | `Each(e)`     | `argument` is a container where _every_ element matches `e`, which can be either a value or a matcher. | | `ElementsAre(e0, e1, ..., en)` | `argument` has `n + 1` elements, where the i-th element matches `ei`, which can be a value or a matcher. 0 to 10 arguments are allowed. | | `ElementsAreArray(array)` or `ElementsAreArray(array, count)` | The same as `ElementsAre()` except that the expected element values/matchers come from a C-style array. | | `ContainerEq(container)` | The same as `Eq(container)` except that the failure message also includes which elements are in one container but not the other. | | `Pointwise(m, container)` | `argument` contains the same number of elements as in `container`, and for all i, (the i-th element in `argument`, the i-th element in `container`) match `m`, which is a matcher on 2-tuples. E.g. `Pointwise(Le(), upper_bounds)` verifies that each element in `argument` doesn't exceed the corresponding element in `upper_bounds`. |
These matchers can also match:
1. a native array passed by reference (e.g. in `Foo(const int (&a)[5])`), and   1. an array passed as a pointer and a count (e.g. in `Bar(const T* buffer, int len)` -- see [Multi-argument Matchers](#Multiargument_Matchers.md)).
where the array may be multi-dimensional (i.e. its elements can be arrays).
|`Field(&class::field, m)`|`argument.field` (or `argument->field` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_.| |:------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------| |`Key(e)`                 |`argument.first` matches `e`, which can be either a value or a matcher. E.g. `Contains(Key(Le(5)))` can verify that a `map` contains a key `<= 5`.| |`Pair(m1, m2)`           |`argument` is an `std::pair` whose `first` field matches `m1` and `second` field matches `m2`.                                                | |`Property(&class::property, m)`|`argument.property()` (or `argument->property()` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_.|
|`ResultOf(f, m)`|`f(argument)` matches matcher `m`, where `f` is a function or functor.| |:---------------|:---------------------------------------------------------------------|
|`Pointee(m)`|`argument` (either a smart pointer or a raw pointer) points to a value that matches matcher `m`.| |:-----------|:-----------------------------------------------------------------------------------------------|
Technically, all matchers match a _single_ value. A "multi-argument" matcher is just one that matches a _tuple_. The following matchers can be used to match a tuple `(x, y)`:
|`Eq()`|`x == y`| |:-----|:-------| |`Ge()`|`x >= y`| |`Gt()`|`x > y` | |`Le()`|`x <= y`| |`Lt()`|`x < y` | |`Ne()`|`x != y`|
You can use the following selectors to pick a subset of the arguments (or reorder them) to participate in the matching:
|`AllArgs(m)`|Equivalent to `m`. Useful as syntactic sugar in `.With(AllArgs(m))`.| |:-----------|:-------------------------------------------------------------------| |`Args<N1, N2, ..., Nk>(m)`|The tuple of the `k` selected (using 0-based indices) arguments matches `m`, e.g. `Args<1, 2>(Eq())`.|
You can make a matcher from one or more other matchers:
|`AllOf(m1, m2, ..., mn)`|`argument` matches all of the matchers `m1` to `mn`.| |:-----------------------|:---------------------------------------------------| |`AnyOf(m1, m2, ..., mn)`|`argument` matches at least one of the matchers `m1` to `mn`.| |`Not(m)`                |`argument` doesn't match matcher `m`.               |
|`MatcherCast<T>(m)`|casts matcher `m` to type `Matcher<T>`.| |:------------------|:--------------------------------------| |`SafeMatcherCast<T>(m)`| [safely casts](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Casting_Matchers) matcher `m` to type `Matcher<T>`. | |`Truly(predicate)` |`predicate(argument)` returns something considered by C++ to be true, where `predicate` is a function or functor.|
|`Matches(m)(value)`|evaluates to `true` if `value` matches `m`. You can use `Matches(m)` alone as a unary functor.| |:------------------|:---------------------------------------------------------------------------------------------| |`ExplainMatchResult(m, value, result_listener)`|evaluates to `true` if `value` matches `m`, explaining the result to `result_listener`.       | |`Value(value, m)`  |evaluates to `true` if `value` matches `m`.                                                   |
| `MATCHER(IsEven, "") { return (arg % 2) == 0; }` | Defines a matcher `IsEven()` to match an even number. | |:-------------------------------------------------|:------------------------------------------------------| | `MATCHER_P(IsDivisibleBy, n, "") { *result_listener << "where the remainder is " << (arg % n); return (arg % n) == 0; }` | Defines a macher `IsDivisibleBy(n)` to match a number divisible by `n`. | | `MATCHER_P2(IsBetween, a, b, std::string(negation ? "isn't" : "is") + " between " + PrintToString(a) + " and " + PrintToString(b)) { return a <= arg && arg <= b; }` | Defines a matcher `IsBetween(a, b)` to match a value in the range [`a`, `b`]. |
**Notes:**
1. The `MATCHER*` macros cannot be used inside a function or class.   1. The matcher body must be _purely functional_ (i.e. it cannot have any side effect, and the result must not depend on anything other than the value being matched and the matcher parameters).   1. You can use `PrintToString(x)` to convert a value `x` of any type to a string.
|`ASSERT_THAT(expression, m)`|Generates a [fatal failure](http://code.google.com/p/googletest/wiki/V1_6_Primer#Assertions) if the value of `expression` doesn't match matcher `m`.| |:---------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------| |`EXPECT_THAT(expression, m)`|Generates a non-fatal failure if the value of `expression` doesn't match matcher `m`.                                                               |
**Actions** specify what a mock function should do when invoked.
|`Return()`|Return from a `void` mock function.| |:---------|:----------------------------------| |`Return(value)`|Return `value`. If the type of `value` is different to the mock function's return type, `value` is converted to the latter type <i>at the time the expectation is set</i>, not when the action is executed.| |`ReturnArg<N>()`|Return the `N`-th (0-based) argument.| |`ReturnNew<T>(a1, ..., ak)`|Return `new T(a1, ..., ak)`; a different object is created each time.| |`ReturnNull()`|Return a null pointer.             | |`ReturnPointee(ptr)`|Return the value pointed to by `ptr`.| |`ReturnRef(variable)`|Return a reference to `variable`.  | |`ReturnRefOfCopy(value)`|Return a reference to a copy of `value`; the copy lives as long as the action.|
|`Assign(&variable, value)`|Assign `value` to variable.| |:-------------------------|:--------------------------| | `DeleteArg<N>()`         | Delete the `N`-th (0-based) argument, which must be a pointer. | | `SaveArg<N>(pointer)`    | Save the `N`-th (0-based) argument to `*pointer`. | | `SaveArgPointee<N>(pointer)` | Save the value pointed to by the `N`-th (0-based) argument to `*pointer`. | | `SetArgReferee<N>(value)` |	Assign value to the variable referenced by the `N`-th (0-based) argument. | |`SetArgPointee<N>(value)` |Assign `value` to the variable pointed by the `N`-th (0-based) argument.| |`SetArgumentPointee<N>(value)`|Same as `SetArgPointee<N>(value)`. Deprecated. Will be removed in v1.7.0.| |`SetArrayArgument<N>(first, last)`|Copies the elements in source range [`first`, `last`) to the array pointed to by the `N`-th (0-based) argument, which can be either a pointer or an iterator. The action does not take ownership of the elements in the source range.| |`SetErrnoAndReturn(error, value)`|Set `errno` to `error` and return `value`.| |`Throw(exception)`        |Throws the given exception, which can be any copyable value. Available since v1.1.0.|
|`Invoke(f)`|Invoke `f` with the arguments passed to the mock function, where `f` can be a global/static function or a functor.| |:----------|:-----------------------------------------------------------------------------------------------------------------| |`Invoke(object_pointer, &class::method)`|Invoke the {method on the object with the arguments passed to the mock function.                                  | |`InvokeWithoutArgs(f)`|Invoke `f`, which can be a global/static function or a functor. `f` must take no arguments.                       | |`InvokeWithoutArgs(object_pointer, &class::method)`|Invoke the method on the object, which takes no arguments.                                                        | |`InvokeArgument<N>(arg1, arg2, ..., argk)`|Invoke the mock function's `N`-th (0-based) argument, which must be a function or a functor, with the `k` arguments.|
The return value of the invoked function is used as the return value of the action.
When defining a function or functor to be used with `Invoke*()`, you can declare any unused parameters as `Unused`: ```   double Distance(Unused, double x, double y) { return sqrt(x*x + y*y); }   ...   EXPECT_CALL(mock, Foo("Hi", _, _)).WillOnce(Invoke(Distance)); ```
In `InvokeArgument<N>(...)`, if an argument needs to be passed by reference, wrap it inside `ByRef()`. For example, ```   InvokeArgument<2>(5, string("Hi"), ByRef(foo)) ``` calls the mock function's #2 argument, passing to it `5` and `string("Hi")` by value, and `foo` by reference.
|`DoDefault()`|Do the default action (specified by `ON_CALL()` or the built-in one).| |:------------|:--------------------------------------------------------------------|
**Note:** due to technical reasons, `DoDefault()` cannot be used inside  a composite action - trying to do so will result in a run-time error.
|`DoAll(a1, a2, ..., an)`|Do all actions `a1` to `an` and return the result of `an` in each invocation. The first `n - 1` sub-actions must return void. | |:-----------------------|:-----------------------------------------------------------------------------------------------------------------------------| |`IgnoreResult(a)`       |Perform action `a` and ignore its result. `a` must not return void.                                                           | |`WithArg<N>(a)`         |Pass the `N`-th (0-based) argument of the mock function to action `a` and perform it.                                         | |`WithArgs<N1, N2, ..., Nk>(a)`|Pass the selected (0-based) arguments of the mock function to action `a` and perform it.                                      | |`WithoutArgs(a)`        |Perform action `a` without any arguments.                                                                                     |
| `ACTION(Sum) { return arg0 + arg1; }` | Defines an action `Sum()` to return the sum of the mock function's argument #0 and #1. | |:--------------------------------------|:---------------------------------------------------------------------------------------| | `ACTION_P(Plus, n) { return arg0 + n; }` | Defines an action `Plus(n)` to return the sum of the mock function's argument #0 and `n`. | | `ACTION_Pk(Foo, p1, ..., pk) { statements; }` | Defines a parameterized action `Foo(p1, ..., pk)` to execute the given `statements`.   |
The `ACTION*` macros cannot be used inside a function or class.
These are used in `Times()` to specify how many times a mock function will be called:
|`AnyNumber()`|The function can be called any number of times.| |:------------|:----------------------------------------------| |`AtLeast(n)` |The call is expected at least `n` times.       | |`AtMost(n)`  |The call is expected at most `n` times.        | |`Between(m, n)`|The call is expected between `m` and `n` (inclusive) times.| |`Exactly(n) or n`|The call is expected exactly `n` times. In particular, the call should never happen when `n` is 0.|
By default, the expectations can be matched in _any_ order.  If some or all expectations must be matched in a given order, there are two ways to specify it.  They can be used either independently or together.
``` using ::testing::Expectation; ... Expectation init_x = EXPECT_CALL(foo, InitX()); Expectation init_y = EXPECT_CALL(foo, InitY()); EXPECT_CALL(foo, Bar())     .After(init_x, init_y); ``` says that `Bar()` can be called only after both `InitX()` and `InitY()` have been called.
If you don't know how many pre-requisites an expectation has when you write it, you can use an `ExpectationSet` to collect them:
``` using ::testing::ExpectationSet; ... ExpectationSet all_inits; for (int i = 0; i < element_count; i++) {   all_inits += EXPECT_CALL(foo, InitElement(i)); } EXPECT_CALL(foo, Bar())     .After(all_inits); ``` says that `Bar()` can be called only after all elements have been initialized (but we don't care about which elements get initialized before the others).
Modifying an `ExpectationSet` after using it in an `.After()` doesn't affect the meaning of the `.After()`.
When you have a long chain of sequential expectations, it's easier to specify the order using **sequences**, which don't require you to given each expectation in the chain a different name.  <i>All expected<br> calls</i> in the same sequence must occur in the order they are specified.
``` using ::testing::Sequence; Sequence s1, s2; ... EXPECT_CALL(foo, Reset())     .InSequence(s1, s2)     .WillOnce(Return(true)); EXPECT_CALL(foo, GetSize())     .InSequence(s1)     .WillOnce(Return(1)); EXPECT_CALL(foo, Describe(A<const char*>()))     .InSequence(s2)     .WillOnce(Return("dummy")); ``` says that `Reset()` must be called before _both_ `GetSize()` _and_ `Describe()`, and the latter two can occur in any order.
To put many expectations in a sequence conveniently: ``` using ::testing::InSequence; {   InSequence dummy;
EXPECT_CALL(...)...;   EXPECT_CALL(...)...;   ...   EXPECT_CALL(...)...; } ``` says that all expected calls in the scope of `dummy` must occur in strict order. The name `dummy` is irrelevant.)
Google Mock will verify the expectations on a mock object when it is destructed, or you can do it earlier: ``` using ::testing::Mock; ... // Verifies and removes the expectations on mock_obj; // returns true iff successful. Mock::VerifyAndClearExpectations(&mock_obj); ... // Verifies and removes the expectations on mock_obj; // also removes the default actions set by ON_CALL(); // returns true iff successful. Mock::VerifyAndClear(&mock_obj); ```
You can also tell Google Mock that a mock object can be leaked and doesn't need to be verified: ``` Mock::AllowLeak(&mock_obj); ```
Google Mock defines a convenient mock class template ``` class MockFunction<R(A1, ..., An)> {  public:   MOCK_METHODn(Call, R(A1, ..., An)); }; ``` See this [recipe](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Using_Check_Points) for one application of it.
| `--gmock_catch_leaked_mocks=0` | Don't report leaked mock objects as failures. | |:-------------------------------|:----------------------------------------------| | `--gmock_verbose=LEVEL`        | Sets the default verbosity level (`info`, `warning`, or `error`) of Google Mock messages. |

You can find recipes for using Google Mock here. If you haven't yet, please read the [ForDummies](V1_6_ForDummies.md) document first to make sure you understand the basics.
**Note:** Google Mock lives in the `testing` name space. For readability, it is recommended to write `using ::testing::Foo;` once in your file before using the name `Foo` defined by Google Mock. We omit such `using` statements in this page for brevity, but you should do it in your own code.
You must always put a mock method definition (`MOCK_METHOD*`) in a `public:` section of the mock class, regardless of the method being mocked being `public`, `protected`, or `private` in the base class. This allows `ON_CALL` and `EXPECT_CALL` to reference the mock function from outside of the mock class.  (Yes, C++ allows a subclass to change the access level of a virtual function in the base class.)  Example:
``` class Foo {  public:   ...   virtual bool Transform(Gadget* g) = 0;
protected:   virtual void Resume();
private:   virtual int GetTimeOut(); };
class MockFoo : public Foo {  public:   ...   MOCK_METHOD1(Transform, bool(Gadget* g));
// The following must be in the public section, even though the   // methods are protected or private in the base class.   MOCK_METHOD0(Resume, void());   MOCK_METHOD0(GetTimeOut, int()); }; ```
You can mock overloaded functions as usual. No special attention is required:
``` class Foo {   ...
// Must be virtual as we'll inherit from Foo.   virtual ~Foo();
// Overloaded on the types and/or numbers of arguments.   virtual int Add(Element x);   virtual int Add(int times, Element x);
// Overloaded on the const-ness of this object.   virtual Bar& GetBar();   virtual const Bar& GetBar() const; };
class MockFoo : public Foo {   ...   MOCK_METHOD1(Add, int(Element x));   MOCK_METHOD2(Add, int(int times, Element x);
MOCK_METHOD0(GetBar, Bar&());   MOCK_CONST_METHOD0(GetBar, const Bar&()); }; ```
**Note:** if you don't mock all versions of the overloaded method, the compiler will give you a warning about some methods in the base class being hidden. To fix that, use `using` to bring them in scope:
``` class MockFoo : public Foo {   ...   using Foo::Add;   MOCK_METHOD1(Add, int(Element x));   // We don't want to mock int Add(int times, Element x);   ... }; ```
To mock a class template, append `_T` to the `MOCK_*` macros:
``` template <typename Elem> class StackInterface {   ...   // Must be virtual as we'll inherit from StackInterface.   virtual ~StackInterface();
virtual int GetSize() const = 0;   virtual void Push(const Elem& x) = 0; };
template <typename Elem> class MockStack : public StackInterface<Elem> {   ...   MOCK_CONST_METHOD0_T(GetSize, int());   MOCK_METHOD1_T(Push, void(const Elem& x)); }; ```
Google Mock can mock non-virtual functions to be used in what we call _hi-perf dependency injection_.
In this case, instead of sharing a common base class with the real class, your mock class will be _unrelated_ to the real class, but contain methods with the same signatures.  The syntax for mocking non-virtual methods is the _same_ as mocking virtual methods:
``` // A simple packet stream class.  None of its members is virtual. class ConcretePacketStream {  public:   void AppendPacket(Packet* new_packet);   const Packet* GetPacket(size_t packet_number) const;   size_t NumberOfPackets() const;   ... };
// A mock packet stream class.  It inherits from no other, but defines // GetPacket() and NumberOfPackets(). class MockPacketStream {  public:   MOCK_CONST_METHOD1(GetPacket, const Packet*(size_t packet_number));   MOCK_CONST_METHOD0(NumberOfPackets, size_t());   ... }; ```
Note that the mock class doesn't define `AppendPacket()`, unlike the real class. That's fine as long as the test doesn't need to call it.
Next, you need a way to say that you want to use `ConcretePacketStream` in production code, and use `MockPacketStream` in tests.  Since the functions are not virtual and the two classes are unrelated, you must specify your choice at _compile time_ (as opposed to run time).
One way to do it is to templatize your code that needs to use a packet stream.  More specifically, you will give your code a template type argument for the type of the packet stream.  In production, you will instantiate your template with `ConcretePacketStream` as the type argument.  In tests, you will instantiate the same template with `MockPacketStream`.  For example, you may write:
``` template <class PacketStream> void CreateConnection(PacketStream* stream) { ... }
template <class PacketStream> class PacketReader {  public:   void ReadPackets(PacketStream* stream, size_t packet_num); }; ```
Then you can use `CreateConnection<ConcretePacketStream>()` and `PacketReader<ConcretePacketStream>` in production code, and use `CreateConnection<MockPacketStream>()` and `PacketReader<MockPacketStream>` in tests.
```   MockPacketStream mock_stream;   EXPECT_CALL(mock_stream, ...)...;   .. set more expectations on mock_stream ...   PacketReader<MockPacketStream> reader(&mock_stream);   ... exercise reader ... ```
It's possible to use Google Mock to mock a free function (i.e. a C-style function or a static method).  You just need to rewrite your code to use an interface (abstract class).
Instead of calling a free function (say, `OpenFile`) directly, introduce an interface for it and have a concrete subclass that calls the free function:
``` class FileInterface {  public:   ...   virtual bool Open(const char* path, const char* mode) = 0; };
class File : public FileInterface {  public:   ...   virtual bool Open(const char* path, const char* mode) {     return OpenFile(path, mode);   } }; ```
Your code should talk to `FileInterface` to open a file.  Now it's easy to mock out the function.
This may seem much hassle, but in practice you often have multiple related functions that you can put in the same interface, so the per-function syntactic overhead will be much lower.
If you are concerned about the performance overhead incurred by virtual functions, and profiling confirms your concern, you can combine this with the recipe for [mocking non-virtual methods](#Mocking_Nonvirtual_Methods.md).
If a mock method has no `EXPECT_CALL` spec but is called, Google Mock will print a warning about the "uninteresting call". The rationale is:
* New methods may be added to an interface after a test is written. We shouldn't fail a test just because a method it doesn't know about is called.   * However, this may also mean there's a bug in the test, so Google Mock shouldn't be silent either. If the user believes these calls are harmless, he can add an `EXPECT_CALL()` to suppress the warning.
However, sometimes you may want to suppress all "uninteresting call" warnings, while sometimes you may want the opposite, i.e. to treat all of them as errors. Google Mock lets you make the decision on a per-mock-object basis.
Suppose your test uses a mock class `MockFoo`:
``` TEST(...) {   MockFoo mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
If a method of `mock_foo` other than `DoThis()` is called, it will be reported by Google Mock as a warning. However, if you rewrite your test to use `NiceMock<MockFoo>` instead, the warning will be gone, resulting in a cleaner test output:
``` using ::testing::NiceMock;
TEST(...) {   NiceMock<MockFoo> mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
`NiceMock<MockFoo>` is a subclass of `MockFoo`, so it can be used wherever `MockFoo` is accepted.
It also works if `MockFoo`'s constructor takes some arguments, as `NiceMock<MockFoo>` "inherits" `MockFoo`'s constructors:
``` using ::testing::NiceMock;
TEST(...) {   NiceMock<MockFoo> mock_foo(5, "hi");  // Calls MockFoo(5, "hi").   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
The usage of `StrictMock` is similar, except that it makes all uninteresting calls failures:
``` using ::testing::StrictMock;
TEST(...) {   StrictMock<MockFoo> mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ...
// The test will fail if a method of mock_foo other than DoThis()   // is called. } ```
There are some caveats though (I don't like them just as much as the next guy, but sadly they are side effects of C++'s limitations):
1. `NiceMock<MockFoo>` and `StrictMock<MockFoo>` only work for mock methods defined using the `MOCK_METHOD*` family of macros **directly** in the `MockFoo` class. If a mock method is defined in a **base class** of `MockFoo`, the "nice" or "strict" modifier may not affect it, depending on the compiler. In particular, nesting `NiceMock` and `StrictMock` (e.g. `NiceMock<StrictMock<MockFoo> >`) is **not** supported.   1. The constructors of the base mock (`MockFoo`) cannot have arguments passed by non-const reference, which happens to be banned by the [Google C++ style guide](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml).   1. During the constructor or destructor of `MockFoo`, the mock object is _not_ nice or strict.  This may cause surprises if the constructor or destructor calls a mock method on `this` object. (This behavior, however, is consistent with C++'s general rule: if a constructor or destructor calls a virtual method of `this` object, that method is treated as non-virtual.  In other words, to the base class's constructor or destructor, `this` object behaves like an instance of the base class, not the derived class.  This rule is required for safety.  Otherwise a base constructor may use members of a derived class before they are initialized, or a base destructor may use members of a derived class after they have been destroyed.)
Finally, you should be **very cautious** when using this feature, as the decision you make applies to **all** future changes to the mock class. If an important change is made in the interface you are mocking (and thus in the mock class), it could break your tests (if you use `StrictMock`) or let bugs pass through without a warning (if you use `NiceMock`). Therefore, try to specify the mock's behavior using explicit `EXPECT_CALL` first, and only turn to `NiceMock` or `StrictMock` as the last resort.
Sometimes a method has a long list of arguments that is mostly uninteresting. For example,
``` class LogSink {  public:   ...   virtual void send(LogSeverity severity, const char* full_filename,                     const char* base_filename, int line,                     const struct tm* tm_time,                     const char* message, size_t message_len) = 0; }; ```
This method's argument list is lengthy and hard to work with (let's say that the `message` argument is not even 0-terminated). If we mock it as is, using the mock will be awkward. If, however, we try to simplify this interface, we'll need to fix all clients depending on it, which is often infeasible.
The trick is to re-dispatch the method in the mock class:
``` class ScopedMockLog : public LogSink {  public:   ...   virtual void send(LogSeverity severity, const char* full_filename,                     const char* base_filename, int line, const tm* tm_time,                     const char* message, size_t message_len) {     // We are only interested in the log severity, full file name, and     // log message.     Log(severity, full_filename, std::string(message, message_len));   }
// Implements the mock method:   //   //   void Log(LogSeverity severity,   //            const string& file_path,   //            const string& message);   MOCK_METHOD3(Log, void(LogSeverity severity, const string& file_path,                          const string& message)); }; ```
By defining a new mock method with a trimmed argument list, we make the mock class much more user-friendly.
Often you may find yourself using classes that don't implement interfaces. In order to test your code that uses such a class (let's call it `Concrete`), you may be tempted to make the methods of `Concrete` virtual and then mock it.
Try not to do that.
Making a non-virtual function virtual is a big decision. It creates an extension point where subclasses can tweak your class' behavior. This weakens your control on the class because now it's harder to maintain the class' invariants. You should make a function virtual only when there is a valid reason for a subclass to override it.
Mocking concrete classes directly is problematic as it creates a tight coupling between the class and the tests - any small change in the class may invalidate your tests and make test maintenance a pain.
To avoid such problems, many programmers have been practicing "coding to interfaces": instead of talking to the `Concrete` class, your code would define an interface and talk to it. Then you implement that interface as an adaptor on top of `Concrete`. In tests, you can easily mock that interface to observe how your code is doing.
This technique incurs some overhead:
* You pay the cost of virtual function calls (usually not a problem).   * There is more abstraction for the programmers to learn.
However, it can also bring significant benefits in addition to better testability:
* `Concrete`'s API may not fit your problem domain very well, as you may not be the only client it tries to serve. By designing your own interface, you have a chance to tailor it to your need - you may add higher-level functionalities, rename stuff, etc instead of just trimming the class. This allows you to write your code (user of the interface) in a more natural way, which means it will be more readable, more maintainable, and you'll be more productive.   * If `Concrete`'s implementation ever has to change, you don't have to rewrite everywhere it is used. Instead, you can absorb the change in your implementation of the interface, and your other code and tests will be insulated from this change.
Some people worry that if everyone is practicing this technique, they will end up writing lots of redundant code. This concern is totally understandable. However, there are two reasons why it may not be the case:
* Different projects may need to use `Concrete` in different ways, so the best interfaces for them will be different. Therefore, each of them will have its own domain-specific interface on top of `Concrete`, and they will not be the same code.   * If enough projects want to use the same interface, they can always share it, just like they have been sharing `Concrete`. You can check in the interface and the adaptor somewhere near `Concrete` (perhaps in a `contrib` sub-directory) and let many projects use it.
You need to weigh the pros and cons carefully for your particular problem, but I'd like to assure you that the Java community has been practicing this for a long time and it's a proven effective technique applicable in a wide variety of situations. :-)
Some times you have a non-trivial fake implementation of an interface. For example:
``` class Foo {  public:   virtual ~Foo() {}   virtual char DoThis(int n) = 0;   virtual void DoThat(const char* s, int* p) = 0; };
class FakeFoo : public Foo {  public:   virtual char DoThis(int n) {     return (n > 0) ? '+' :         (n < 0) ? '-' : '0';   }
virtual void DoThat(const char* s, int* p) {     *p = strlen(s);   } }; ```
Now you want to mock this interface such that you can set expectations on it. However, you also want to use `FakeFoo` for the default behavior, as duplicating it in the mock object is, well, a lot of work.
When you define the mock class using Google Mock, you can have it delegate its default action to a fake class you already have, using this pattern:
``` using ::testing::_; using ::testing::Invoke;
class MockFoo : public Foo {  public:   // Normal mock method definitions using Google Mock.   MOCK_METHOD1(DoThis, char(int n));   MOCK_METHOD2(DoThat, void(const char* s, int* p));
// Delegates the default actions of the methods to a FakeFoo object.   // This must be called *before* the custom ON_CALL() statements.   void DelegateToFake() {     ON_CALL(*this, DoThis(_))         .WillByDefault(Invoke(&fake_, &FakeFoo::DoThis));     ON_CALL(*this, DoThat(_, _))         .WillByDefault(Invoke(&fake_, &FakeFoo::DoThat));   }  private:   FakeFoo fake_;  // Keeps an instance of the fake in the mock. }; ```
With that, you can use `MockFoo` in your tests as usual. Just remember that if you don't explicitly set an action in an `ON_CALL()` or `EXPECT_CALL()`, the fake will be called upon to do it:
``` using ::testing::_;
TEST(AbcTest, Xyz) {   MockFoo foo;   foo.DelegateToFake(); // Enables the fake for delegation.
// Put your ON_CALL(foo, ...)s here, if any.
// No action specified, meaning to use the default action.   EXPECT_CALL(foo, DoThis(5));   EXPECT_CALL(foo, DoThat(_, _));
int n = 0;   EXPECT_EQ('+', foo.DoThis(5));  // FakeFoo::DoThis() is invoked.   foo.DoThat("Hi", &n);           // FakeFoo::DoThat() is invoked.   EXPECT_EQ(2, n); } ```
**Some tips:**
* If you want, you can still override the default action by providing your own `ON_CALL()` or using `.WillOnce()` / `.WillRepeatedly()` in `EXPECT_CALL()`.   * In `DelegateToFake()`, you only need to delegate the methods whose fake implementation you intend to use.   * The general technique discussed here works for overloaded methods, but you'll need to tell the compiler which version you mean. To disambiguate a mock function (the one you specify inside the parentheses of `ON_CALL()`), see the "Selecting Between Overloaded Functions" section on this page; to disambiguate a fake function (the one you place inside `Invoke()`), use a `static_cast` to specify the function's type.   * Having to mix a mock and a fake is often a sign of something gone wrong. Perhaps you haven't got used to the interaction-based way of testing yet. Or perhaps your interface is taking on too many roles and should be split up. Therefore, **don't abuse this**. We would only recommend to do it as an intermediate step when you are refactoring your code.
Regarding the tip on mixing a mock and a fake, here's an example on why it may be a bad sign: Suppose you have a class `System` for low-level system operations. In particular, it does file and I/O operations. And suppose you want to test how your code uses `System` to do I/O, and you just want the file operations to work normally. If you mock out the entire `System` class, you'll have to provide a fake implementation for the file operation part, which suggests that `System` is taking on too many roles.
Instead, you can define a `FileOps` interface and an `IOOps` interface and split `System`'s functionalities into the two. Then you can mock `IOOps` without mocking `FileOps`.
When using testing doubles (mocks, fakes, stubs, and etc), sometimes their behaviors will differ from those of the real objects. This difference could be either intentional (as in simulating an error such that you can test the error handling code) or unintentional. If your mocks have different behaviors than the real objects by mistake, you could end up with code that passes the tests but fails in production.
You can use the _delegating-to-real_ technique to ensure that your mock has the same behavior as the real object while retaining the ability to validate calls. This technique is very similar to the delegating-to-fake technique, the difference being that we use a real object instead of a fake. Here's an example:
``` using ::testing::_; using ::testing::AtLeast; using ::testing::Invoke;
class MockFoo : public Foo {  public:   MockFoo() {     // By default, all calls are delegated to the real object.     ON_CALL(*this, DoThis())         .WillByDefault(Invoke(&real_, &Foo::DoThis));     ON_CALL(*this, DoThat(_))         .WillByDefault(Invoke(&real_, &Foo::DoThat));     ...   }   MOCK_METHOD0(DoThis, ...);   MOCK_METHOD1(DoThat, ...);   ...  private:   Foo real_; }; ...
MockFoo mock;
EXPECT_CALL(mock, DoThis())       .Times(3);   EXPECT_CALL(mock, DoThat("Hi"))       .Times(AtLeast(1));   ... use mock in test ... ```
With this, Google Mock will verify that your code made the right calls (with the right arguments, in the right order, called the right number of times, etc), and a real object will answer the calls (so the behavior will be the same as in production). This gives you the best of both worlds.
Ideally, you should code to interfaces, whose methods are all pure virtual. In reality, sometimes you do need to mock a virtual method that is not pure (i.e, it already has an implementation). For example:
``` class Foo {  public:   virtual ~Foo();
virtual void Pure(int n) = 0;   virtual int Concrete(const char* str) { ... } };
class MockFoo : public Foo {  public:   // Mocking a pure method.   MOCK_METHOD1(Pure, void(int n));   // Mocking a concrete method.  Foo::Concrete() is shadowed.   MOCK_METHOD1(Concrete, int(const char* str)); }; ```
Sometimes you may want to call `Foo::Concrete()` instead of `MockFoo::Concrete()`. Perhaps you want to do it as part of a stub action, or perhaps your test doesn't need to mock `Concrete()` at all (but it would be oh-so painful to have to define a new mock class whenever you don't need to mock one of its methods).
The trick is to leave a back door in your mock class for accessing the real methods in the base class:
``` class MockFoo : public Foo {  public:   // Mocking a pure method.   MOCK_METHOD1(Pure, void(int n));   // Mocking a concrete method.  Foo::Concrete() is shadowed.   MOCK_METHOD1(Concrete, int(const char* str));
// Use this to call Concrete() defined in Foo.   int FooConcrete(const char* str) { return Foo::Concrete(str); } }; ```
Now, you can call `Foo::Concrete()` inside an action by:
``` using ::testing::_; using ::testing::Invoke; ...   EXPECT_CALL(foo, Concrete(_))       .WillOnce(Invoke(&foo, &MockFoo::FooConcrete)); ```
or tell the mock object that you don't want to mock `Concrete()`:
``` using ::testing::Invoke; ...   ON_CALL(foo, Concrete(_))       .WillByDefault(Invoke(&foo, &MockFoo::FooConcrete)); ```
(Why don't we just write `Invoke(&foo, &Foo::Concrete)`? If you do that, `MockFoo::Concrete()` will be called (and cause an infinite recursion) since `Foo::Concrete()` is virtual. That's just how C++ works.)
You can specify exactly which arguments a mock method is expecting:
``` using ::testing::Return; ...   EXPECT_CALL(foo, DoThis(5))       .WillOnce(Return('a'));   EXPECT_CALL(foo, DoThat("Hello", bar)); ```
You can use matchers to match arguments that have a certain property:
``` using ::testing::Ge; using ::testing::NotNull; using ::testing::Return; ...   EXPECT_CALL(foo, DoThis(Ge(5)))  // The argument must be >= 5.       .WillOnce(Return('a'));   EXPECT_CALL(foo, DoThat("Hello", NotNull()));   // The second argument must not be NULL. ```
A frequently used matcher is `_`, which matches anything:
``` using ::testing::_; using ::testing::NotNull; ...   EXPECT_CALL(foo, DoThat(_, NotNull())); ```
You can build complex matchers from existing ones using `AllOf()`, `AnyOf()`, and `Not()`:
``` using ::testing::AllOf; using ::testing::Gt; using ::testing::HasSubstr; using ::testing::Ne; using ::testing::Not; ...   // The argument must be > 5 and != 10.   EXPECT_CALL(foo, DoThis(AllOf(Gt(5),                                 Ne(10))));
// The first argument must not contain sub-string "blah".   EXPECT_CALL(foo, DoThat(Not(HasSubstr("blah")),                           NULL)); ```
Google Mock matchers are statically typed, meaning that the compiler can catch your mistake if you use a matcher of the wrong type (for example, if you use `Eq(5)` to match a `string` argument). Good for you!
Sometimes, however, you know what you're doing and want the compiler to give you some slack. One example is that you have a matcher for `long` and the argument you want to match is `int`. While the two types aren't exactly the same, there is nothing really wrong with using a `Matcher<long>` to match an `int` - after all, we can first convert the `int` argument to a `long` before giving it to the matcher.
To support this need, Google Mock gives you the `SafeMatcherCast<T>(m)` function. It casts a matcher `m` to type `Matcher<T>`. To ensure safety, Google Mock checks that (let `U` be the type `m` accepts):
1. Type `T` can be implicitly cast to type `U`;   1. When both `T` and `U` are built-in arithmetic types (`bool`, integers, and floating-point numbers), the conversion from `T` to `U` is not lossy (in other words, any value representable by `T` can also be represented by `U`); and   1. When `U` is a reference, `T` must also be a reference (as the underlying matcher may be interested in the address of the `U` value).
The code won't compile if any of these conditions isn't met.
Here's one example:
``` using ::testing::SafeMatcherCast;
// A base class and a child class. class Base { ... }; class Derived : public Base { ... };
class MockFoo : public Foo {  public:   MOCK_METHOD1(DoThis, void(Derived* derived)); }; ...
MockFoo foo;   // m is a Matcher<Base*> we got from somewhere.   EXPECT_CALL(foo, DoThis(SafeMatcherCast<Derived*>(m))); ```
If you find `SafeMatcherCast<T>(m)` too limiting, you can use a similar function `MatcherCast<T>(m)`. The difference is that `MatcherCast` works as long as you can `static_cast` type `T` to type `U`.
`MatcherCast` essentially lets you bypass C++'s type system (`static_cast` isn't always safe as it could throw away information, for example), so be careful not to misuse/abuse it.
If you expect an overloaded function to be called, the compiler may need some help on which overloaded version it is.
To disambiguate functions overloaded on the const-ness of this object, use the `Const()` argument wrapper.
``` using ::testing::ReturnRef;
class MockFoo : public Foo {   ...   MOCK_METHOD0(GetBar, Bar&());   MOCK_CONST_METHOD0(GetBar, const Bar&()); }; ...
MockFoo foo;   Bar bar1, bar2;   EXPECT_CALL(foo, GetBar())         // The non-const GetBar().       .WillOnce(ReturnRef(bar1));   EXPECT_CALL(Const(foo), GetBar())  // The const GetBar().       .WillOnce(ReturnRef(bar2)); ```
(`Const()` is defined by Google Mock and returns a `const` reference to its argument.)
To disambiguate overloaded functions with the same number of arguments but different argument types, you may need to specify the exact type of a matcher, either by wrapping your matcher in `Matcher<type>()`, or using a matcher whose type is fixed (`TypedEq<type>`, `An<type>()`, etc):
``` using ::testing::An; using ::testing::Lt; using ::testing::Matcher; using ::testing::TypedEq;
class MockPrinter : public Printer {  public:   MOCK_METHOD1(Print, void(int n));   MOCK_METHOD1(Print, void(char c)); };
TEST(PrinterTest, Print) {   MockPrinter printer;
EXPECT_CALL(printer, Print(An<int>()));            // void Print(int);   EXPECT_CALL(printer, Print(Matcher<int>(Lt(5))));  // void Print(int);   EXPECT_CALL(printer, Print(TypedEq<char>('a')));   // void Print(char);
printer.Print(3);   printer.Print(6);   printer.Print('a'); } ```
When a mock method is called, the _last_ matching expectation that's still active will be selected (think "newer overrides older"). So, you can make a method do different things depending on its argument values like this:
``` using ::testing::_; using ::testing::Lt; using ::testing::Return; ...   // The default case.   EXPECT_CALL(foo, DoThis(_))       .WillRepeatedly(Return('b'));
// The more specific case.   EXPECT_CALL(foo, DoThis(Lt(5)))       .WillRepeatedly(Return('a')); ```
Now, if `foo.DoThis()` is called with a value less than 5, `'a'` will be returned; otherwise `'b'` will be returned.
Sometimes it's not enough to match the arguments individually. For example, we may want to say that the first argument must be less than the second argument. The `With()` clause allows us to match all arguments of a mock function as a whole. For example,
``` using ::testing::_; using ::testing::Lt; using ::testing::Ne; ...   EXPECT_CALL(foo, InRange(Ne(0), _))       .With(Lt()); ```
says that the first argument of `InRange()` must not be 0, and must be less than the second argument.
The expression inside `With()` must be a matcher of type `Matcher<tr1::tuple<A1, ..., An> >`, where `A1`, ..., `An` are the types of the function arguments.
You can also write `AllArgs(m)` instead of `m` inside `.With()`. The two forms are equivalent, but `.With(AllArgs(Lt()))` is more readable than `.With(Lt())`.
You can use `Args<k1, ..., kn>(m)` to match the `n` selected arguments (as a tuple) against `m`. For example,
``` using ::testing::_; using ::testing::AllOf; using ::testing::Args; using ::testing::Lt; ...   EXPECT_CALL(foo, Blah(_, _, _))       .With(AllOf(Args<0, 1>(Lt()), Args<1, 2>(Lt()))); ```
says that `Blah()` will be called with arguments `x`, `y`, and `z` where `x < y < z`.
As a convenience and example, Google Mock provides some matchers for 2-tuples, including the `Lt()` matcher above. See the [CheatSheet](V1_6_CheatSheet.md) for the complete list.
Note that if you want to pass the arguments to a predicate of your own (e.g. `.With(Args<0, 1>(Truly(&MyPredicate)))`), that predicate MUST be written to take a `tr1::tuple` as its argument; Google Mock will pass the `n` selected arguments as _one_ single tuple to the predicate.
Have you noticed that a matcher is just a fancy predicate that also knows how to describe itself? Many existing algorithms take predicates as arguments (e.g. those defined in STL's `<algorithm>` header), and it would be a shame if Google Mock matchers are not allowed to participate.
Luckily, you can use a matcher where a unary predicate functor is expected by wrapping it inside the `Matches()` function. For example,
``` #include <algorithm> #include <vector>
std::vector<int> v; ... // How many elements in v are >= 10? const int count = count_if(v.begin(), v.end(), Matches(Ge(10))); ```
Since you can build complex matchers from simpler ones easily using Google Mock, this gives you a way to conveniently construct composite predicates (doing the same using STL's `<functional>` header is just painful). For example, here's a predicate that's satisfied by any number that is >= 0, <= 100, and != 50:
``` Matches(AllOf(Ge(0), Le(100), Ne(50))) ```
Since matchers are basically predicates that also know how to describe themselves, there is a way to take advantage of them in [Google Test](http://code.google.com/p/googletest/) assertions. It's called `ASSERT_THAT` and `EXPECT_THAT`:
```   ASSERT_THAT(value, matcher);  // Asserts that value matches matcher.   EXPECT_THAT(value, matcher);  // The non-fatal version. ```
For example, in a Google Test test you can write:
``` #include "gmock/gmock.h"
using ::testing::AllOf; using ::testing::Ge; using ::testing::Le; using ::testing::MatchesRegex; using ::testing::StartsWith; ...
EXPECT_THAT(Foo(), StartsWith("Hello"));   EXPECT_THAT(Bar(), MatchesRegex("Line \\d+"));   ASSERT_THAT(Baz(), AllOf(Ge(5), Le(10))); ```
which (as you can probably guess) executes `Foo()`, `Bar()`, and `Baz()`, and verifies that:
* `Foo()` returns a string that starts with `"Hello"`.   * `Bar()` returns a string that matches regular expression `"Line \\d+"`.   * `Baz()` returns a number in the range [5, 10].
The nice thing about these macros is that _they read like English_. They generate informative messages too. For example, if the first `EXPECT_THAT()` above fails, the message will be something like:
``` Value of: Foo()   Actual: "Hi, world!" Expected: starts with "Hello" ```
**Credit:** The idea of `(ASSERT|EXPECT)_THAT` was stolen from the [Hamcrest](http://code.google.com/p/hamcrest/) project, which adds `assertThat()` to JUnit.
Google Mock provides a built-in set of matchers. In case you find them lacking, you can use an arbitray unary predicate function or functor as a matcher - as long as the predicate accepts a value of the type you want. You do this by wrapping the predicate inside the `Truly()` function, for example:
``` using ::testing::Truly;
int IsEven(int n) { return (n % 2) == 0 ? 1 : 0; } ...
// Bar() must be called with an even number.   EXPECT_CALL(foo, Bar(Truly(IsEven))); ```
Note that the predicate function / functor doesn't have to return `bool`. It works as long as the return value can be used as the condition in statement `if (condition) ...`.
When you do an `EXPECT_CALL(mock_obj, Foo(bar))`, Google Mock saves away a copy of `bar`. When `Foo()` is called later, Google Mock compares the argument to `Foo()` with the saved copy of `bar`. This way, you don't need to worry about `bar` being modified or destroyed after the `EXPECT_CALL()` is executed. The same is true when you use matchers like `Eq(bar)`, `Le(bar)`, and so on.
But what if `bar` cannot be copied (i.e. has no copy constructor)? You could define your own matcher function and use it with `Truly()`, as the previous couple of recipes have shown. Or, you may be able to get away from it if you can guarantee that `bar` won't be changed after the `EXPECT_CALL()` is executed. Just tell Google Mock that it should save a reference to `bar`, instead of a copy of it. Here's how:
``` using ::testing::Eq; using ::testing::ByRef; using ::testing::Lt; ...   // Expects that Foo()'s argument == bar.   EXPECT_CALL(mock_obj, Foo(Eq(ByRef(bar))));
// Expects that Foo()'s argument < bar.   EXPECT_CALL(mock_obj, Foo(Lt(ByRef(bar)))); ```
Remember: if you do this, don't change `bar` after the `EXPECT_CALL()`, or the result is undefined.
Often a mock function takes a reference to object as an argument. When matching the argument, you may not want to compare the entire object against a fixed object, as that may be over-specification. Instead, you may need to validate a certain member variable or the result of a certain getter method of the object. You can do this with `Field()` and `Property()`. More specifically,
``` Field(&Foo::bar, m) ```
is a matcher that matches a `Foo` object whose `bar` member variable satisfies matcher `m`.
``` Property(&Foo::baz, m) ```
is a matcher that matches a `Foo` object whose `baz()` method returns a value that satisfies matcher `m`.
For example:
> | `Field(&Foo::number, Ge(3))` | Matches `x` where `x.number >= 3`. | |:-----------------------------|:-----------------------------------| > | `Property(&Foo::name, StartsWith("John "))` | Matches `x` where `x.name()` starts with `"John "`. |
Note that in `Property(&Foo::baz, ...)`, method `baz()` must take no argument and be declared as `const`.
BTW, `Field()` and `Property()` can also match plain pointers to objects. For instance,
``` Field(&Foo::number, Ge(3)) ```
matches a plain pointer `p` where `p->number >= 3`. If `p` is `NULL`, the match will always fail regardless of the inner matcher.
What if you want to validate more than one members at the same time? Remember that there is `AllOf()`.
C++ functions often take pointers as arguments. You can use matchers like `NULL`, `NotNull()`, and other comparison matchers to match a pointer, but what if you want to make sure the value _pointed to_ by the pointer, instead of the pointer itself, has a certain property? Well, you can use the `Pointee(m)` matcher.
`Pointee(m)` matches a pointer iff `m` matches the value the pointer points to. For example:
``` using ::testing::Ge; using ::testing::Pointee; ...   EXPECT_CALL(foo, Bar(Pointee(Ge(3)))); ```
expects `foo.Bar()` to be called with a pointer that points to a value greater than or equal to 3.
One nice thing about `Pointee()` is that it treats a `NULL` pointer as a match failure, so you can write `Pointee(m)` instead of
```   AllOf(NotNull(), Pointee(m)) ```
without worrying that a `NULL` pointer will crash your test.
Also, did we tell you that `Pointee()` works with both raw pointers **and** smart pointers (`linked_ptr`, `shared_ptr`, `scoped_ptr`, and etc)?
What if you have a pointer to pointer? You guessed it - you can use nested `Pointee()` to probe deeper inside the value. For example, `Pointee(Pointee(Lt(3)))` matches a pointer that points to a pointer that points to a number less than 3 (what a mouthful...).
Sometimes you want to specify that an object argument has a certain property, but there is no existing matcher that does this. If you want good error messages, you should define a matcher. If you want to do it quick and dirty, you could get away with writing an ordinary function.
Let's say you have a mock function that takes an object of type `Foo`, which has an `int bar()` method and an `int baz()` method, and you want to constrain that the argument's `bar()` value plus its `baz()` value is a given number. Here's how you can define a matcher to do it:
``` using ::testing::MatcherInterface; using ::testing::MatchResultListener;
class BarPlusBazEqMatcher : public MatcherInterface<const Foo&> {  public:   explicit BarPlusBazEqMatcher(int expected_sum)       : expected_sum_(expected_sum) {}
virtual bool MatchAndExplain(const Foo& foo,                                MatchResultListener* listener) const {     return (foo.bar() + foo.baz()) == expected_sum_;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "bar() + baz() equals " << expected_sum_;   }
virtual void DescribeNegationTo(::std::ostream* os) const {     *os << "bar() + baz() does not equal " << expected_sum_;   }  private:   const int expected_sum_; };
inline Matcher<const Foo&> BarPlusBazEq(int expected_sum) {   return MakeMatcher(new BarPlusBazEqMatcher(expected_sum)); }
...
EXPECT_CALL(..., DoThis(BarPlusBazEq(5)))...; ```
Sometimes an STL container (e.g. list, vector, map, ...) is passed to a mock function and you may want to validate it. Since most STL containers support the `==` operator, you can write `Eq(expected_container)` or simply `expected_container` to match a container exactly.
Sometimes, though, you may want to be more flexible (for example, the first element must be an exact match, but the second element can be any positive number, and so on). Also, containers used in tests often have a small number of elements, and having to define the expected container out-of-line is a bit of a hassle.
You can use the `ElementsAre()` matcher in such cases:
``` using ::testing::_; using ::testing::ElementsAre; using ::testing::Gt; ...
MOCK_METHOD1(Foo, void(const vector<int>& numbers)); ...
EXPECT_CALL(mock, Foo(ElementsAre(1, Gt(0), _, 5))); ```
The above matcher says that the container must have 4 elements, which must be 1, greater than 0, anything, and 5 respectively.
`ElementsAre()` is overloaded to take 0 to 10 arguments. If more are needed, you can place them in a C-style array and use `ElementsAreArray()` instead:
``` using ::testing::ElementsAreArray; ...
// ElementsAreArray accepts an array of element values.   const int expected_vector1[] = { 1, 5, 2, 4, ... };   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector1)));
// Or, an array of element matchers.   Matcher<int> expected_vector2 = { 1, Gt(2), _, 3, ... };   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector2))); ```
In case the array needs to be dynamically created (and therefore the array size cannot be inferred by the compiler), you can give `ElementsAreArray()` an additional argument to specify the array size:
``` using ::testing::ElementsAreArray; ...   int* const expected_vector3 = new int[count];   ... fill expected_vector3 with values ...   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector3, count))); ```
**Tips:**
* `ElementAre*()` works with _any_ container that implements the STL iterator concept (i.e. it has a `const_iterator` type and supports `begin()/end()`) and supports `size()`, not just the ones defined in STL. It will even work with container types yet to be written - as long as they follows the above pattern.   * You can use nested `ElementAre*()` to match nested (multi-dimensional) containers.   * If the container is passed by pointer instead of by reference, just write `Pointee(ElementsAre*(...))`.   * The order of elements _matters_ for `ElementsAre*()`. Therefore don't use it with containers whose element order is undefined (e.g. `hash_map`).
Under the hood, a Google Mock matcher object consists of a pointer to a ref-counted implementation object. Copying matchers is allowed and very efficient, as only the pointer is copied. When the last matcher that references the implementation object dies, the implementation object will be deleted.
Therefore, if you have some complex matcher that you want to use again and again, there is no need to build it everytime. Just assign it to a matcher variable and use that variable repeatedly! For example,
```   Matcher<int> in_range = AllOf(Gt(5), Le(10));   ... use in_range as a matcher in multiple EXPECT_CALLs ... ```
If you are not interested in how a mock method is called, just don't say anything about it. In this case, if the method is ever called, Google Mock will perform its default action to allow the test program to continue. If you are not happy with the default action taken by Google Mock, you can override it using `DefaultValue<T>::Set()` (described later in this document) or `ON_CALL()`.
Please note that once you expressed interest in a particular mock method (via `EXPECT_CALL()`), all invocations to it must match some expectation. If this function is called but the arguments don't match any `EXPECT_CALL()` statement, it will be an error.
If a mock method shouldn't be called at all, explicitly say so:
``` using ::testing::_; ...   EXPECT_CALL(foo, Bar(_))       .Times(0); ```
If some calls to the method are allowed, but the rest are not, just list all the expected calls:
``` using ::testing::AnyNumber; using ::testing::Gt; ...   EXPECT_CALL(foo, Bar(5));   EXPECT_CALL(foo, Bar(Gt(10)))       .Times(AnyNumber()); ```
A call to `foo.Bar()` that doesn't match any of the `EXPECT_CALL()` statements will be an error.
Although an `EXPECT_CALL()` statement defined earlier takes precedence when Google Mock tries to match a function call with an expectation, by default calls don't have to happen in the order `EXPECT_CALL()` statements are written. For example, if the arguments match the matchers in the third `EXPECT_CALL()`, but not those in the first two, then the third expectation will be used.
If you would rather have all calls occur in the order of the expectations, put the `EXPECT_CALL()` statements in a block where you define a variable of type `InSequence`:
```   using ::testing::_;   using ::testing::InSequence;
{     InSequence s;
EXPECT_CALL(foo, DoThis(5));     EXPECT_CALL(bar, DoThat(_))         .Times(2);     EXPECT_CALL(foo, DoThis(6));   } ```
In this example, we expect a call to `foo.DoThis(5)`, followed by two calls to `bar.DoThat()` where the argument can be anything, which are in turn followed by a call to `foo.DoThis(6)`. If a call occurred out-of-order, Google Mock will report an error.
Sometimes requiring everything to occur in a predetermined order can lead to brittle tests. For example, we may care about `A` occurring before both `B` and `C`, but aren't interested in the relative order of `B` and `C`. In this case, the test should reflect our real intent, instead of being overly constraining.
Google Mock allows you to impose an arbitrary DAG (directed acyclic graph) on the calls. One way to express the DAG is to use the [After](http://code.google.com/p/googlemock/wiki/V1_6_CheatSheet#The_After_Clause) clause of `EXPECT_CALL`.
Another way is via the `InSequence()` clause (not the same as the `InSequence` class), which we borrowed from jMock 2. It's less flexible than `After()`, but more convenient when you have long chains of sequential calls, as it doesn't require you to come up with different names for the expectations in the chains.  Here's how it works:
If we view `EXPECT_CALL()` statements as nodes in a graph, and add an edge from node A to node B wherever A must occur before B, we can get a DAG. We use the term "sequence" to mean a directed path in this DAG. Now, if we decompose the DAG into sequences, we just need to know which sequences each `EXPECT_CALL()` belongs to in order to be able to reconstruct the orginal DAG.
So, to specify the partial order on the expectations we need to do two things: first to define some `Sequence` objects, and then for each `EXPECT_CALL()` say which `Sequence` objects it is part of. Expectations in the same sequence must occur in the order they are written. For example,
```   using ::testing::Sequence;
Sequence s1, s2;
EXPECT_CALL(foo, A())       .InSequence(s1, s2);   EXPECT_CALL(bar, B())       .InSequence(s1);   EXPECT_CALL(bar, C())       .InSequence(s2);   EXPECT_CALL(foo, D())       .InSequence(s2); ```
specifies the following DAG (where `s1` is `A -> B`, and `s2` is `A -> C -> D`):
```        +---> B        |   A ---|        |        +---> C ---> D ```
This means that A must occur before B and C, and C must occur before D. There's no restriction about the order other than these.
When a mock method is called, Google Mock only consider expectations that are still active. An expectation is active when created, and becomes inactive (aka _retires_) when a call that has to occur later has occurred. For example, in
```   using ::testing::_;   using ::testing::Sequence;
Sequence s1, s2;
EXPECT_CALL(log, Log(WARNING, _, "File too large."))     // #1       .Times(AnyNumber())       .InSequence(s1, s2);   EXPECT_CALL(log, Log(WARNING, _, "Data set is empty."))  // #2       .InSequence(s1);   EXPECT_CALL(log, Log(WARNING, _, "User not found."))     // #3       .InSequence(s2); ```
as soon as either #2 or #3 is matched, #1 will retire. If a warning `"File too large."` is logged after this, it will be an error.
Note that an expectation doesn't retire automatically when it's saturated. For example,
``` using ::testing::_; ...   EXPECT_CALL(log, Log(WARNING, _, _));                  // #1   EXPECT_CALL(log, Log(WARNING, _, "File too large."));  // #2 ```
says that there will be exactly one warning with the message `"File too large."`. If the second warning contains this message too, #2 will match again and result in an upper-bound-violated error.
If this is not what you want, you can ask an expectation to retire as soon as it becomes saturated:
``` using ::testing::_; ...   EXPECT_CALL(log, Log(WARNING, _, _));                 // #1   EXPECT_CALL(log, Log(WARNING, _, "File too large."))  // #2       .RetiresOnSaturation(); ```
Here #2 can be used only once, so if you have two warnings with the message `"File too large."`, the first will match #2 and the second will match #1 - there will be no error.
If a mock function's return type is a reference, you need to use `ReturnRef()` instead of `Return()` to return a result:
``` using ::testing::ReturnRef;
class MockFoo : public Foo {  public:   MOCK_METHOD0(GetBar, Bar&()); }; ...
MockFoo foo;   Bar bar;   EXPECT_CALL(foo, GetBar())       .WillOnce(ReturnRef(bar)); ```
The `Return(x)` action saves a copy of `x` when the action is _created_, and always returns the same value whenever it's executed. Sometimes you may want to instead return the _live_ value of `x` (i.e. its value at the time when the action is _executed_.).
If the mock function's return type is a reference, you can do it using `ReturnRef(x)`, as shown in the previous recipe ("Returning References from Mock Methods"). However, Google Mock doesn't let you use `ReturnRef()` in a mock function whose return type is not a reference, as doing that usually indicates a user error. So, what shall you do?
You may be tempted to try `ByRef()`:
``` using testing::ByRef; using testing::Return;
class MockFoo : public Foo {  public:   MOCK_METHOD0(GetValue, int()); }; ...   int x = 0;   MockFoo foo;   EXPECT_CALL(foo, GetValue())       .WillRepeatedly(Return(ByRef(x)));   x = 42;   EXPECT_EQ(42, foo.GetValue()); ```
Unfortunately, it doesn't work here. The above code will fail with error:
``` Value of: foo.GetValue()   Actual: 0 Expected: 42 ```
The reason is that `Return(value)` converts `value` to the actual return type of the mock function at the time when the action is _created_, not when it is _executed_. (This behavior was chosen for the action to be safe when `value` is a proxy object that references some temporary objects.) As a result, `ByRef(x)` is converted to an `int` value (instead of a `const int&`) when the expectation is set, and `Return(ByRef(x))` will always return 0.
`ReturnPointee(pointer)` was provided to solve this problem specifically. It returns the value pointed to by `pointer` at the time the action is _executed_:
``` using testing::ReturnPointee; ...   int x = 0;   MockFoo foo;   EXPECT_CALL(foo, GetValue())       .WillRepeatedly(ReturnPointee(&x));  // Note the & here.   x = 42;   EXPECT_EQ(42, foo.GetValue());  // This will succeed now. ```
Want to do more than one thing when a function is called? That's fine. `DoAll()` allow you to do sequence of actions every time. Only the return value of the last action in the sequence will be used.
``` using ::testing::DoAll;
class MockFoo : public Foo {  public:   MOCK_METHOD1(Bar, bool(int n)); }; ...
EXPECT_CALL(foo, Bar(_))       .WillOnce(DoAll(action_1,                       action_2,                       ...                       action_n)); ```
Sometimes a method exhibits its effect not via returning a value but via side effects. For example, it may change some global state or modify an output argument. To mock side effects, in general you can define your own action by implementing `::testing::ActionInterface`.
If all you need to do is to change an output argument, the built-in `SetArgPointee()` action is convenient:
``` using ::testing::SetArgPointee;
class MockMutator : public Mutator {  public:   MOCK_METHOD2(Mutate, void(bool mutate, int* value));   ... }; ...
MockMutator mutator;   EXPECT_CALL(mutator, Mutate(true, _))       .WillOnce(SetArgPointee<1>(5)); ```
In this example, when `mutator.Mutate()` is called, we will assign 5 to the `int` variable pointed to by argument #1 (0-based).
`SetArgPointee()` conveniently makes an internal copy of the value you pass to it, removing the need to keep the value in scope and alive. The implication however is that the value must have a copy constructor and assignment operator.
If the mock method also needs to return a value as well, you can chain `SetArgPointee()` with `Return()` using `DoAll()`:
``` using ::testing::_; using ::testing::Return; using ::testing::SetArgPointee;
class MockMutator : public Mutator {  public:   ...   MOCK_METHOD1(MutateInt, bool(int* value)); }; ...
MockMutator mutator;   EXPECT_CALL(mutator, MutateInt(_))       .WillOnce(DoAll(SetArgPointee<0>(5),                       Return(true))); ```
If the output argument is an array, use the `SetArrayArgument<N>(first, last)` action instead. It copies the elements in source range `[first, last)` to the array pointed to by the `N`-th (0-based) argument:
``` using ::testing::NotNull; using ::testing::SetArrayArgument;
class MockArrayMutator : public ArrayMutator {  public:   MOCK_METHOD2(Mutate, void(int* values, int num_values));   ... }; ...
MockArrayMutator mutator;   int values[5] = { 1, 2, 3, 4, 5 };   EXPECT_CALL(mutator, Mutate(NotNull(), 5))       .WillOnce(SetArrayArgument<0>(values, values + 5)); ```
This also works when the argument is an output iterator:
``` using ::testing::_; using ::testing::SeArrayArgument;
class MockRolodex : public Rolodex {  public:   MOCK_METHOD1(GetNames, void(std::back_insert_iterator<vector<string> >));   ... }; ...
MockRolodex rolodex;   vector<string> names;   names.push_back("George");   names.push_back("John");   names.push_back("Thomas");   EXPECT_CALL(rolodex, GetNames(_))       .WillOnce(SetArrayArgument<0>(names.begin(), names.end())); ```
If you expect a call to change the behavior of a mock object, you can use `::testing::InSequence` to specify different behaviors before and after the call:
``` using ::testing::InSequence; using ::testing::Return;
...   {     InSequence seq;     EXPECT_CALL(my_mock, IsDirty())         .WillRepeatedly(Return(true));     EXPECT_CALL(my_mock, Flush());     EXPECT_CALL(my_mock, IsDirty())         .WillRepeatedly(Return(false));   }   my_mock.FlushIfDirty(); ```
This makes `my_mock.IsDirty()` return `true` before `my_mock.Flush()` is called and return `false` afterwards.
If the behavior change is more complex, you can store the effects in a variable and make a mock method get its return value from that variable:
``` using ::testing::_; using ::testing::SaveArg; using ::testing::Return;
ACTION_P(ReturnPointee, p) { return *p; } ...   int previous_value = 0;   EXPECT_CALL(my_mock, GetPrevValue())       .WillRepeatedly(ReturnPointee(&previous_value));   EXPECT_CALL(my_mock, UpdateValue(_))       .WillRepeatedly(SaveArg<0>(&previous_value));   my_mock.DoSomethingToUpdateValue(); ```
Here `my_mock.GetPrevValue()` will always return the argument of the last `UpdateValue()` call.
If a mock method's return type is a built-in C++ type or pointer, by default it will return 0 when invoked. You only need to specify an action if this default value doesn't work for you.
Sometimes, you may want to change this default value, or you may want to specify a default value for types Google Mock doesn't know about. You can do this using the `::testing::DefaultValue` class template:
``` class MockFoo : public Foo {  public:   MOCK_METHOD0(CalculateBar, Bar()); }; ...
Bar default_bar;   // Sets the default return value for type Bar.   DefaultValue<Bar>::Set(default_bar);
MockFoo foo;
// We don't need to specify an action here, as the default   // return value works for us.   EXPECT_CALL(foo, CalculateBar());
foo.CalculateBar();  // This should return default_bar.
// Unsets the default return value.   DefaultValue<Bar>::Clear(); ```
Please note that changing the default value for a type can make you tests hard to understand. We recommend you to use this feature judiciously. For example, you may want to make sure the `Set()` and `Clear()` calls are right next to the code that uses your mock.
You've learned how to change the default value of a given type. However, this may be too coarse for your purpose: perhaps you have two mock methods with the same return type and you want them to have different behaviors. The `ON_CALL()` macro allows you to customize your mock's behavior at the method level:
``` using ::testing::_; using ::testing::AnyNumber; using ::testing::Gt; using ::testing::Return; ...   ON_CALL(foo, Sign(_))       .WillByDefault(Return(-1));   ON_CALL(foo, Sign(0))       .WillByDefault(Return(0));   ON_CALL(foo, Sign(Gt(0)))       .WillByDefault(Return(1));
EXPECT_CALL(foo, Sign(_))       .Times(AnyNumber());
foo.Sign(5);   // This should return 1.   foo.Sign(-9);  // This should return -1.   foo.Sign(0);   // This should return 0. ```
As you may have guessed, when there are more than one `ON_CALL()` statements, the news order take precedence over the older ones. In other words, the **last** one that matches the function arguments will be used. This matching order allows you to set up the common behavior in a mock object's constructor or the test fixture's set-up phase and specialize the mock's behavior later.
If the built-in actions don't suit you, you can easily use an existing function, method, or functor as an action:
``` using ::testing::_; using ::testing::Invoke;
class MockFoo : public Foo {  public:   MOCK_METHOD2(Sum, int(int x, int y));   MOCK_METHOD1(ComplexJob, bool(int x)); };
int CalculateSum(int x, int y) { return x + y; }
class Helper {  public:   bool ComplexJob(int x); }; ...
MockFoo foo;   Helper helper;   EXPECT_CALL(foo, Sum(_, _))       .WillOnce(Invoke(CalculateSum));   EXPECT_CALL(foo, ComplexJob(_))       .WillOnce(Invoke(&helper, &Helper::ComplexJob));
foo.Sum(5, 6);       // Invokes CalculateSum(5, 6).   foo.ComplexJob(10);  // Invokes helper.ComplexJob(10); ```
The only requirement is that the type of the function, etc must be _compatible_ with the signature of the mock function, meaning that the latter's arguments can be implicitly converted to the corresponding arguments of the former, and the former's return type can be implicitly converted to that of the latter. So, you can invoke something whose type is _not_ exactly the same as the mock function, as long as it's safe to do so - nice, huh?
`Invoke()` is very useful for doing actions that are more complex. It passes the mock function's arguments to the function or functor being invoked such that the callee has the full context of the call to work with. If the invoked function is not interested in some or all of the arguments, it can simply ignore them.
Yet, a common pattern is that a test author wants to invoke a function without the arguments of the mock function. `Invoke()` allows her to do that using a wrapper function that throws away the arguments before invoking an underlining nullary function. Needless to say, this can be tedious and obscures the intent of the test.
`InvokeWithoutArgs()` solves this problem. It's like `Invoke()` except that it doesn't pass the mock function's arguments to the callee. Here's an example:
``` using ::testing::_; using ::testing::InvokeWithoutArgs;
class MockFoo : public Foo {  public:   MOCK_METHOD1(ComplexJob, bool(int n)); };
bool Job1() { ... } ...
MockFoo foo;   EXPECT_CALL(foo, ComplexJob(_))       .WillOnce(InvokeWithoutArgs(Job1));
foo.ComplexJob(10);  // Invokes Job1(). ```
Sometimes a mock function will receive a function pointer or a functor (in other words, a "callable") as an argument, e.g.
``` class MockFoo : public Foo {  public:   MOCK_METHOD2(DoThis, bool(int n, bool (*fp)(int))); }; ```
and you may want to invoke this callable argument:
``` using ::testing::_; ...   MockFoo foo;   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(...);   // Will execute (*fp)(5), where fp is the   // second argument DoThis() receives. ```
Arghh, you need to refer to a mock function argument but C++ has no lambda (yet), so you have to define your own action. :-( Or do you really?
Well, Google Mock has an action to solve _exactly_ this problem:
```   InvokeArgument<N>(arg_1, arg_2, ..., arg_m) ```
will invoke the `N`-th (0-based) argument the mock function receives, with `arg_1`, `arg_2`, ..., and `arg_m`. No matter if the argument is a function pointer or a functor, Google Mock handles them both.
With that, you could write:
``` using ::testing::_; using ::testing::InvokeArgument; ...   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(InvokeArgument<1>(5));   // Will execute (*fp)(5), where fp is the   // second argument DoThis() receives. ```
What if the callable takes an argument by reference? No problem - just wrap it inside `ByRef()`:
``` ...   MOCK_METHOD1(Bar, bool(bool (*fp)(int, const Helper&))); ... using ::testing::_; using ::testing::ByRef; using ::testing::InvokeArgument; ...
MockFoo foo;   Helper helper;   ...   EXPECT_CALL(foo, Bar(_))       .WillOnce(InvokeArgument<0>(5, ByRef(helper)));   // ByRef(helper) guarantees that a reference to helper, not a copy of it,   // will be passed to the callable. ```
What if the callable takes an argument by reference and we do **not** wrap the argument in `ByRef()`? Then `InvokeArgument()` will _make a copy_ of the argument, and pass a _reference to the copy_, instead of a reference to the original value, to the callable. This is especially handy when the argument is a temporary value:
``` ...   MOCK_METHOD1(DoThat, bool(bool (*f)(const double& x, const string& s))); ... using ::testing::_; using ::testing::InvokeArgument; ...
MockFoo foo;   ...   EXPECT_CALL(foo, DoThat(_))       .WillOnce(InvokeArgument<0>(5.0, string("Hi")));   // Will execute (*f)(5.0, string("Hi")), where f is the function pointer   // DoThat() receives.  Note that the values 5.0 and string("Hi") are   // temporary and dead once the EXPECT_CALL() statement finishes.  Yet   // it's fine to perform this action later, since a copy of the values   // are kept inside the InvokeArgument action. ```
Sometimes you have an action that returns _something_, but you need an action that returns `void` (perhaps you want to use it in a mock function that returns `void`, or perhaps it needs to be used in `DoAll()` and it's not the last in the list). `IgnoreResult()` lets you do that. For example:
``` using ::testing::_; using ::testing::Invoke; using ::testing::Return;
int Process(const MyData& data); string DoSomething();
class MockFoo : public Foo {  public:   MOCK_METHOD1(Abc, void(const MyData& data));   MOCK_METHOD0(Xyz, bool()); }; ...
MockFoo foo;   EXPECT_CALL(foo, Abc(_))   // .WillOnce(Invoke(Process));   // The above line won't compile as Process() returns int but Abc() needs   // to return void.       .WillOnce(IgnoreResult(Invoke(Process)));
EXPECT_CALL(foo, Xyz())       .WillOnce(DoAll(IgnoreResult(Invoke(DoSomething)),       // Ignores the string DoSomething() returns.                       Return(true))); ```
Note that you **cannot** use `IgnoreResult()` on an action that already returns `void`. Doing so will lead to ugly compiler errors.
Say you have a mock function `Foo()` that takes seven arguments, and you have a custom action that you want to invoke when `Foo()` is called. Trouble is, the custom action only wants three arguments:
``` using ::testing::_; using ::testing::Invoke; ...   MOCK_METHOD7(Foo, bool(bool visible, const string& name, int x, int y,                          const map<pair<int, int>, double>& weight,                          double min_weight, double max_wight)); ...
bool IsVisibleInQuadrant1(bool visible, int x, int y) {   return visible && x >= 0 && y >= 0; } ...
EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(Invoke(IsVisibleInQuadrant1));  // Uh, won't compile. :-( ```
To please the compiler God, you can to define an "adaptor" that has the same signature as `Foo()` and calls the custom action with the right arguments:
``` using ::testing::_; using ::testing::Invoke;
bool MyIsVisibleInQuadrant1(bool visible, const string& name, int x, int y,                             const map<pair<int, int>, double>& weight,                             double min_weight, double max_wight) {   return IsVisibleInQuadrant1(visible, x, y); } ...
EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(Invoke(MyIsVisibleInQuadrant1));  // Now it works. ```
But isn't this awkward?
Google Mock provides a generic _action adaptor_, so you can spend your time minding more important business than writing your own adaptors. Here's the syntax:
```   WithArgs<N1, N2, ..., Nk>(action) ```
creates an action that passes the arguments of the mock function at the given indices (0-based) to the inner `action` and performs it. Using `WithArgs`, our original example can be written as:
``` using ::testing::_; using ::testing::Invoke; using ::testing::WithArgs; ...   EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(WithArgs<0, 2, 3>(Invoke(IsVisibleInQuadrant1)));       // No need to define your own adaptor. ```
For better readability, Google Mock also gives you:
* `WithoutArgs(action)` when the inner `action` takes _no_ argument, and   * `WithArg<N>(action)` (no `s` after `Arg`) when the inner `action` takes _one_ argument.
As you may have realized, `InvokeWithoutArgs(...)` is just syntactic sugar for `WithoutArgs(Inovke(...))`.
Here are more tips:
* The inner action used in `WithArgs` and friends does not have to be `Invoke()` -- it can be anything.   * You can repeat an argument in the argument list if necessary, e.g. `WithArgs<2, 3, 3, 5>(...)`.   * You can change the order of the arguments, e.g. `WithArgs<3, 2, 1>(...)`.   * The types of the selected arguments do _not_ have to match the signature of the inner action exactly. It works as long as they can be implicitly converted to the corresponding arguments of the inner action. For example, if the 4-th argument of the mock function is an `int` and `my_action` takes a `double`, `WithArg<4>(my_action)` will work.
The selecting-an-action's-arguments recipe showed us one way to make a mock function and an action with incompatible argument lists fit together. The downside is that wrapping the action in `WithArgs<...>()` can get tedious for people writing the tests.
If you are defining a function, method, or functor to be used with `Invoke*()`, and you are not interested in some of its arguments, an alternative to `WithArgs` is to declare the uninteresting arguments as `Unused`. This makes the definition less cluttered and less fragile in case the types of the uninteresting arguments change. It could also increase the chance the action function can be reused. For example, given
```   MOCK_METHOD3(Foo, double(const string& label, double x, double y));   MOCK_METHOD3(Bar, double(int index, double x, double y)); ```
instead of
``` using ::testing::_; using ::testing::Invoke;
double DistanceToOriginWithLabel(const string& label, double x, double y) {   return sqrt(x*x + y*y); }
double DistanceToOriginWithIndex(int index, double x, double y) {   return sqrt(x*x + y*y); } ...
EXEPCT_CALL(mock, Foo("abc", _, _))       .WillOnce(Invoke(DistanceToOriginWithLabel));   EXEPCT_CALL(mock, Bar(5, _, _))       .WillOnce(Invoke(DistanceToOriginWithIndex)); ```
you could write
``` using ::testing::_; using ::testing::Invoke; using ::testing::Unused;
double DistanceToOrigin(Unused, double x, double y) {   return sqrt(x*x + y*y); } ...
EXEPCT_CALL(mock, Foo("abc", _, _))       .WillOnce(Invoke(DistanceToOrigin));   EXEPCT_CALL(mock, Bar(5, _, _))       .WillOnce(Invoke(DistanceToOrigin)); ```
Just like matchers, a Google Mock action object consists of a pointer to a ref-counted implementation object. Therefore copying actions is also allowed and very efficient. When the last action that references the implementation object dies, the implementation object will be deleted.
If you have some complex action that you want to use again and again, you may not have to build it from scratch everytime. If the action doesn't have an internal state (i.e. if it always does the same thing no matter how many times it has been called), you can assign it to an action variable and use that variable repeatedly. For example:
```   Action<bool(int*)> set_flag = DoAll(SetArgPointee<0>(5),                                       Return(true));   ... use set_flag in .WillOnce() and .WillRepeatedly() ... ```
However, if the action has its own state, you may be surprised if you share the action object. Suppose you have an action factory `IncrementCounter(init)` which creates an action that increments and returns a counter whose initial value is `init`, using two actions created from the same expression and using a shared action will exihibit different behaviors. Example:
```   EXPECT_CALL(foo, DoThis())       .WillRepeatedly(IncrementCounter(0));   EXPECT_CALL(foo, DoThat())       .WillRepeatedly(IncrementCounter(0));   foo.DoThis();  // Returns 1.   foo.DoThis();  // Returns 2.   foo.DoThat();  // Returns 1 - Blah() uses a different                  // counter than Bar()'s. ```
versus
```   Action<int()> increment = IncrementCounter(0);
EXPECT_CALL(foo, DoThis())       .WillRepeatedly(increment);   EXPECT_CALL(foo, DoThat())       .WillRepeatedly(increment);   foo.DoThis();  // Returns 1.   foo.DoThis();  // Returns 2.   foo.DoThat();  // Returns 3 - the counter is shared. ```
Believe it or not, the _vast majority_ of the time spent on compiling a mock class is in generating its constructor and destructor, as they perform non-trivial tasks (e.g. verification of the expectations). What's more, mock methods with different signatures have different types and thus their constructors/destructors need to be generated by the compiler separately. As a result, if you mock many different types of methods, compiling your mock class can get really slow.
If you are experiencing slow compilation, you can move the definition of your mock class' constructor and destructor out of the class body and into a `.cpp` file. This way, even if you `#include` your mock class in N files, the compiler only needs to generate its constructor and destructor once, resulting in a much faster compilation.
Let's illustrate the idea using an example. Here's the definition of a mock class before applying this recipe:
``` // File mock_foo.h. ... class MockFoo : public Foo {  public:   // Since we don't declare the constructor or the destructor,   // the compiler will generate them in every translation unit   // where this mock class is used.
MOCK_METHOD0(DoThis, int());   MOCK_METHOD1(DoThat, bool(const char* str));   ... more mock methods ... }; ```
After the change, it would look like:
``` // File mock_foo.h. ... class MockFoo : public Foo {  public:   // The constructor and destructor are declared, but not defined, here.   MockFoo();   virtual ~MockFoo();
MOCK_METHOD0(DoThis, int());   MOCK_METHOD1(DoThat, bool(const char* str));   ... more mock methods ... }; ``` and ``` // File mock_foo.cpp. #include "path/to/mock_foo.h"
// The definitions may appear trivial, but the functions actually do a // lot of things through the constructors/destructors of the member // variables used to implement the mock methods. MockFoo::MockFoo() {} MockFoo::~MockFoo() {} ```
When it's being destoyed, your friendly mock object will automatically verify that all expectations on it have been satisfied, and will generate [Google Test](http://code.google.com/p/googletest/) failures if not. This is convenient as it leaves you with one less thing to worry about. That is, unless you are not sure if your mock object will be destoyed.
How could it be that your mock object won't eventually be destroyed? Well, it might be created on the heap and owned by the code you are testing. Suppose there's a bug in that code and it doesn't delete the mock object properly - you could end up with a passing test when there's actually a bug.
Using a heap checker is a good idea and can alleviate the concern, but its implementation may not be 100% reliable. So, sometimes you do want to _force_ Google Mock to verify a mock object before it is (hopefully) destructed. You can do this with `Mock::VerifyAndClearExpectations(&mock_object)`:
``` TEST(MyServerTest, ProcessesRequest) {   using ::testing::Mock;
MockFoo* const foo = new MockFoo;   EXPECT_CALL(*foo, ...)...;   // ... other expectations ...
// server now owns foo.   MyServer server(foo);   server.ProcessRequest(...);
// In case that server's destructor will forget to delete foo,   // this will verify the expectations anyway.   Mock::VerifyAndClearExpectations(foo); }  // server is destroyed when it goes out of scope here. ```
**Tip:** The `Mock::VerifyAndClearExpectations()` function returns a `bool` to indicate whether the verification was successful (`true` for yes), so you can wrap that function call inside a `ASSERT_TRUE()` if there is no point going further when the verification has failed.
Sometimes you may want to "reset" a mock object at various check points in your test: at each check point, you verify that all existing expectations on the mock object have been satisfied, and then you set some new expectations on it as if it's newly created. This allows you to work with a mock object in "phases" whose sizes are each manageable.
One such scenario is that in your test's `SetUp()` function, you may want to put the object you are testing into a certain state, with the help from a mock object. Once in the desired state, you want to clear all expectations on the mock, such that in the `TEST_F` body you can set fresh expectations on it.
As you may have figured out, the `Mock::VerifyAndClearExpectations()` function we saw in the previous recipe can help you here. Or, if you are using `ON_CALL()` to set default actions on the mock object and want to clear the default actions as well, use `Mock::VerifyAndClear(&mock_object)` instead. This function does what `Mock::VerifyAndClearExpectations(&mock_object)` does and returns the same `bool`, **plus** it clears the `ON_CALL()` statements on `mock_object` too.
Another trick you can use to achieve the same effect is to put the expectations in sequences and insert calls to a dummy "check-point" function at specific places. Then you can verify that the mock function calls do happen at the right time. For example, if you are exercising code:
``` Foo(1); Foo(2); Foo(3); ```
and want to verify that `Foo(1)` and `Foo(3)` both invoke `mock.Bar("a")`, but `Foo(2)` doesn't invoke anything. You can write:
``` using ::testing::MockFunction;
TEST(FooTest, InvokesBarCorrectly) {   MyMock mock;   // Class MockFunction<F> has exactly one mock method.  It is named   // Call() and has type F.   MockFunction<void(string check_point_name)> check;   {     InSequence s;
EXPECT_CALL(mock, Bar("a"));     EXPECT_CALL(check, Call("1"));     EXPECT_CALL(check, Call("2"));     EXPECT_CALL(mock, Bar("a"));   }   Foo(1);   check.Call("1");   Foo(2);   check.Call("2");   Foo(3); } ```
The expectation spec says that the first `Bar("a")` must happen before check point "1", the second `Bar("a")` must happen after check point "2", and nothing should happen between the two check points. The explicit check points make it easy to tell which `Bar("a")` is called by which call to `Foo()`.
Sometimes you want to make sure a mock object is destructed at the right time, e.g. after `bar->A()` is called but before `bar->B()` is called. We already know that you can specify constraints on the order of mock function calls, so all we need to do is to mock the destructor of the mock function.
This sounds simple, except for one problem: a destructor is a special function with special syntax and special semantics, and the `MOCK_METHOD0` macro doesn't work for it:
```   MOCK_METHOD0(~MockFoo, void());  // Won't compile! ```
The good news is that you can use a simple pattern to achieve the same effect. First, add a mock function `Die()` to your mock class and call it in the destructor, like this:
``` class MockFoo : public Foo {   ...   // Add the following two lines to the mock class.   MOCK_METHOD0(Die, void());   virtual ~MockFoo() { Die(); } }; ```
(If the name `Die()` clashes with an existing symbol, choose another name.) Now, we have translated the problem of testing when a `MockFoo` object dies to testing when its `Die()` method is called:
```   MockFoo* foo = new MockFoo;   MockBar* bar = new MockBar;   ...   {     InSequence s;
// Expects *foo to die after bar->A() and before bar->B().     EXPECT_CALL(*bar, A());     EXPECT_CALL(*foo, Die());     EXPECT_CALL(*bar, B());   } ```
And that's that.
**IMPORTANT NOTE:** What we describe in this recipe is **ONLY** true on platforms where Google Mock is thread-safe. Currently these are only platforms that support the pthreads library (this includes Linux and Mac). To make it thread-safe on other platforms we only need to implement some synchronization operations in `"gtest/internal/gtest-port.h"`.
In a **unit** test, it's best if you could isolate and test a piece of code in a single-threaded context. That avoids race conditions and dead locks, and makes debugging your test much easier.
Yet many programs are multi-threaded, and sometimes to test something we need to pound on it from more than one thread. Google Mock works for this purpose too.
Remember the steps for using a mock:
1. Create a mock object `foo`.   1. Set its default actions and expectations using `ON_CALL()` and `EXPECT_CALL()`.   1. The code under test calls methods of `foo`.   1. Optionally, verify and reset the mock.   1. Destroy the mock yourself, or let the code under test destroy it. The destructor will automatically verify it.
If you follow the following simple rules, your mocks and threads can live happily togeter:
* Execute your _test code_ (as opposed to the code being tested) in _one_ thread. This makes your test easy to follow.   * Obviously, you can do step #1 without locking.   * When doing step #2 and #5, make sure no other thread is accessing `foo`. Obvious too, huh?   * #3 and #4 can be done either in one thread or in multiple threads - anyway you want. Google Mock takes care of the locking, so you don't have to do any - unless required by your test logic.
If you violate the rules (for example, if you set expectations on a mock while another thread is calling its methods), you get undefined behavior. That's not fun, so don't do it.
Google Mock guarantees that the action for a mock function is done in the same thread that called the mock function. For example, in
```   EXPECT_CALL(mock, Foo(1))       .WillOnce(action1);   EXPECT_CALL(mock, Foo(2))       .WillOnce(action2); ```
if `Foo(1)` is called in thread 1 and `Foo(2)` is called in thread 2, Google Mock will execute `action1` in thread 1 and `action2` in thread 2.
Google Mock does _not_ impose a sequence on actions performed in different threads (doing so may create deadlocks as the actions may need to cooperate). This means that the execution of `action1` and `action2` in the above example _may_ interleave. If this is a problem, you should add proper synchronization logic to `action1` and `action2` to make the test thread-safe.
Also, remember that `DefaultValue<T>` is a global resource that potentially affects _all_ living mock objects in your program. Naturally, you won't want to mess with it from multiple threads or when there still are mocks in action.
When Google Mock sees something that has the potential of being an error (e.g. a mock function with no expectation is called, a.k.a. an uninteresting call, which is allowed but perhaps you forgot to explicitly ban the call), it prints some warning messages, including the arguments of the function and the return value. Hopefully this will remind you to take a look and see if there is indeed a problem.
Sometimes you are confident that your tests are correct and may not appreciate such friendly messages. Some other times, you are debugging your tests or learning about the behavior of the code you are testing, and wish you could observe every mock call that happens (including argument values and the return value). Clearly, one size doesn't fit all.
You can control how much Google Mock tells you using the `--gmock_verbose=LEVEL` command-line flag, where `LEVEL` is a string with three possible values:
* `info`: Google Mock will print all informational messages, warnings, and errors (most verbose). At this setting, Google Mock will also log any calls to the `ON_CALL/EXPECT_CALL` macros.   * `warning`: Google Mock will print both warnings and errors (less verbose). This is the default.   * `error`: Google Mock will print errors only (least verbose).
Alternatively, you can adjust the value of that flag from within your tests like so:
```   ::testing::FLAGS_gmock_verbose = "error"; ```
Now, judiciously use the right flag to enable Google Mock serve you better!
If you build and run your tests in Emacs, the source file locations of Google Mock and [Google Test](http://code.google.com/p/googletest/) errors will be highlighted. Just press `<Enter>` on one of them and you'll be taken to the offending line. Or, you can just type `C-x `` to jump to the next error.
To make it even easier, you can add the following lines to your `~/.emacs` file:
``` (global-set-key "\M-m"   'compile)  ; m is for make (global-set-key [M-down] 'next-error) (global-set-key [M-up]   '(lambda () (interactive) (next-error -1))) ```
Then you can type `M-m` to start a build, or `M-up`/`M-down` to move back and forth between errors.
Google Mock's implementation consists of dozens of files (excluding its own tests).  Sometimes you may want them to be packaged up in fewer files instead, such that you can easily copy them to a new machine and start hacking there.  For this we provide an experimental Python script `fuse_gmock_files.py` in the `scripts/` directory (starting with release 1.2.0).  Assuming you have Python 2.4 or above installed on your machine, just go to that directory and run ``` python fuse_gmock_files.py OUTPUT_DIR ```
and you should see an `OUTPUT_DIR` directory being created with files `gtest/gtest.h`, `gmock/gmock.h`, and `gmock-gtest-all.cc` in it. These three files contain everything you need to use Google Mock (and Google Test).  Just copy them to anywhere you want and you are ready to write tests and use mocks.  You can use the [scrpts/test/Makefile](http://code.google.com/p/googlemock/source/browse/trunk/scripts/test/Makefile) file as an example on how to compile your tests against them.
The `MATCHER*` family of macros can be used to define custom matchers easily.  The syntax:
``` MATCHER(name, description_string_expression) { statements; } ```
will define a matcher with the given name that executes the statements, which must return a `bool` to indicate if the match succeeds.  Inside the statements, you can refer to the value being matched by `arg`, and refer to its type by `arg_type`.
The description string is a `string`-typed expression that documents what the matcher does, and is used to generate the failure message when the match fails.  It can (and should) reference the special `bool` variable `negation`, and should evaluate to the description of the matcher when `negation` is `false`, or that of the matcher's negation when `negation` is `true`.
For convenience, we allow the description string to be empty (`""`), in which case Google Mock will use the sequence of words in the matcher name as the description.
For example: ``` MATCHER(IsDivisibleBy7, "") { return (arg % 7) == 0; } ``` allows you to write ```   // Expects mock_foo.Bar(n) to be called where n is divisible by 7.   EXPECT_CALL(mock_foo, Bar(IsDivisibleBy7())); ``` or, ``` using ::testing::Not; ...   EXPECT_THAT(some_expression, IsDivisibleBy7());   EXPECT_THAT(some_other_expression, Not(IsDivisibleBy7())); ``` If the above assertions fail, they will print something like: ```   Value of: some_expression   Expected: is divisible by 7     Actual: 27 ...   Value of: some_other_expression   Expected: not (is divisible by 7)     Actual: 21 ``` where the descriptions `"is divisible by 7"` and `"not (is divisible by 7)"` are automatically calculated from the matcher name `IsDivisibleBy7`.
As you may have noticed, the auto-generated descriptions (especially those for the negation) may not be so great. You can always override them with a string expression of your own: ``` MATCHER(IsDivisibleBy7, std::string(negation ? "isn't" : "is") +                         " divisible by 7") {   return (arg % 7) == 0; } ```
Optionally, you can stream additional information to a hidden argument named `result_listener` to explain the match result. For example, a better definition of `IsDivisibleBy7` is: ``` MATCHER(IsDivisibleBy7, "") {   if ((arg % 7) == 0)     return true;
*result_listener << "the remainder is " << (arg % 7);   return false; } ```
With this definition, the above assertion will give a better message: ```   Value of: some_expression   Expected: is divisible by 7     Actual: 27 (the remainder is 6) ```
You should let `MatchAndExplain()` print _any additional information_ that can help a user understand the match result. Note that it should explain why the match succeeds in case of a success (unless it's obvious) - this is useful when the matcher is used inside `Not()`. There is no need to print the argument value itself, as Google Mock already prints it for you.
**Notes:**
1. The type of the value being matched (`arg_type`) is determined by the context in which you use the matcher and is supplied to you by the compiler, so you don't need to worry about declaring it (nor can you).  This allows the matcher to be polymorphic.  For example, `IsDivisibleBy7()` can be used to match any type where the value of `(arg % 7) == 0` can be implicitly converted to a `bool`.  In the `Bar(IsDivisibleBy7())` example above, if method `Bar()` takes an `int`, `arg_type` will be `int`; if it takes an `unsigned long`, `arg_type` will be `unsigned long`; and so on.   1. Google Mock doesn't guarantee when or how many times a matcher will be invoked. Therefore the matcher logic must be _purely functional_ (i.e. it cannot have any side effect, and the result must not depend on anything other than the value being matched and the matcher parameters). This requirement must be satisfied no matter how you define the matcher (e.g. using one of the methods described in the following recipes). In particular, a matcher can never call a mock function, as that will affect the state of the mock object and Google Mock.
Sometimes you'll want to define a matcher that has parameters.  For that you can use the macro: ``` MATCHER_P(name, param_name, description_string) { statements; } ``` where the description string can be either `""` or a string expression that references `negation` and `param_name`.
For example: ``` MATCHER_P(HasAbsoluteValue, value, "") { return abs(arg) == value; } ``` will allow you to write: ```   EXPECT_THAT(Blah("a"), HasAbsoluteValue(n)); ``` which may lead to this message (assuming `n` is 10): ```   Value of: Blah("a")   Expected: has absolute value 10     Actual: -9 ```
Note that both the matcher description and its parameter are printed, making the message human-friendly.
In the matcher definition body, you can write `foo_type` to reference the type of a parameter named `foo`.  For example, in the body of `MATCHER_P(HasAbsoluteValue, value)` above, you can write `value_type` to refer to the type of `value`.
Google Mock also provides `MATCHER_P2`, `MATCHER_P3`, ..., up to `MATCHER_P10` to support multi-parameter matchers: ``` MATCHER_Pk(name, param_1, ..., param_k, description_string) { statements; } ```
Please note that the custom description string is for a particular **instance** of the matcher, where the parameters have been bound to actual values.  Therefore usually you'll want the parameter values to be part of the description.  Google Mock lets you do that by referencing the matcher parameters in the description string expression.
For example, ```   using ::testing::PrintToString;   MATCHER_P2(InClosedRange, low, hi,              std::string(negation ? "isn't" : "is") + " in range [" +              PrintToString(low) + ", " + PrintToString(hi) + "]") {     return low <= arg && arg <= hi;   }   ...   EXPECT_THAT(3, InClosedRange(4, 6)); ``` would generate a failure that contains the message: ```   Expected: is in range [4, 6] ```
If you specify `""` as the description, the failure message will contain the sequence of words in the matcher name followed by the parameter values printed as a tuple.  For example, ```   MATCHER_P2(InClosedRange, low, hi, "") { ... }   ...   EXPECT_THAT(3, InClosedRange(4, 6)); ``` would generate a failure that contains the text: ```   Expected: in closed range (4, 6) ```
For the purpose of typing, you can view ``` MATCHER_Pk(Foo, p1, ..., pk, description_string) { ... } ``` as shorthand for ``` template <typename p1_type, ..., typename pk_type> FooMatcherPk<p1_type, ..., pk_type> Foo(p1_type p1, ..., pk_type pk) { ... } ```
When you write `Foo(v1, ..., vk)`, the compiler infers the types of the parameters `v1`, ..., and `vk` for you.  If you are not happy with the result of the type inference, you can specify the types by explicitly instantiating the template, as in `Foo<long, bool>(5, false)`. As said earlier, you don't get to (or need to) specify `arg_type` as that's determined by the context in which the matcher is used.
You can assign the result of expression `Foo(p1, ..., pk)` to a variable of type `FooMatcherPk<p1_type, ..., pk_type>`.  This can be useful when composing matchers.  Matchers that don't have a parameter or have only one parameter have special types: you can assign `Foo()` to a `FooMatcher`-typed variable, and assign `Foo(p)` to a `FooMatcherP<p_type>`-typed variable.
While you can instantiate a matcher template with reference types, passing the parameters by pointer usually makes your code more readable.  If, however, you still want to pass a parameter by reference, be aware that in the failure message generated by the matcher you will see the value of the referenced object but not its address.
You can overload matchers with different numbers of parameters: ``` MATCHER_P(Blah, a, description_string_1) { ... } MATCHER_P2(Blah, a, b, description_string_2) { ... } ```
While it's tempting to always use the `MATCHER*` macros when defining a new matcher, you should also consider implementing `MatcherInterface` or using `MakePolymorphicMatcher()` instead (see the recipes that follow), especially if you need to use the matcher a lot.  While these approaches require more work, they give you more control on the types of the value being matched and the matcher parameters, which in general leads to better compiler error messages that pay off in the long run.  They also allow overloading matchers based on parameter types (as opposed to just based on the number of parameters).
A matcher of argument type `T` implements `::testing::MatcherInterface<T>` and does two things: it tests whether a value of type `T` matches the matcher, and can describe what kind of values it matches. The latter ability is used for generating readable error messages when expectations are violated.
The interface looks like this:
``` class MatchResultListener {  public:   ...   // Streams x to the underlying ostream; does nothing if the ostream   // is NULL.   template <typename T>   MatchResultListener& operator<<(const T& x);
// Returns the underlying ostream.   ::std::ostream* stream(); };
template <typename T> class MatcherInterface {  public:   virtual ~MatcherInterface();
// Returns true iff the matcher matches x; also explains the match   // result to 'listener'.   virtual bool MatchAndExplain(T x, MatchResultListener* listener) const = 0;
// Describes this matcher to an ostream.   virtual void DescribeTo(::std::ostream* os) const = 0;
// Describes the negation of this matcher to an ostream.   virtual void DescribeNegationTo(::std::ostream* os) const; }; ```
If you need a custom matcher but `Truly()` is not a good option (for example, you may not be happy with the way `Truly(predicate)` describes itself, or you may want your matcher to be polymorphic as `Eq(value)` is), you can define a matcher to do whatever you want in two steps: first implement the matcher interface, and then define a factory function to create a matcher instance. The second step is not strictly needed but it makes the syntax of using the matcher nicer.
For example, you can define a matcher to test whether an `int` is divisible by 7 and then use it like this: ``` using ::testing::MakeMatcher; using ::testing::Matcher; using ::testing::MatcherInterface; using ::testing::MatchResultListener;
class DivisibleBy7Matcher : public MatcherInterface<int> {  public:   virtual bool MatchAndExplain(int n, MatchResultListener* listener) const {     return (n % 7) == 0;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "is divisible by 7";   }
virtual void DescribeNegationTo(::std::ostream* os) const {     *os << "is not divisible by 7";   } };
inline Matcher<int> DivisibleBy7() {   return MakeMatcher(new DivisibleBy7Matcher); } ...
EXPECT_CALL(foo, Bar(DivisibleBy7())); ```
You may improve the matcher message by streaming additional information to the `listener` argument in `MatchAndExplain()`:
``` class DivisibleBy7Matcher : public MatcherInterface<int> {  public:   virtual bool MatchAndExplain(int n,                                MatchResultListener* listener) const {     const int remainder = n % 7;     if (remainder != 0) {       *listener << "the remainder is " << remainder;     }     return remainder == 0;   }   ... }; ```
Then, `EXPECT_THAT(x, DivisibleBy7());` may general a message like this: ``` Value of: x Expected: is divisible by 7   Actual: 23 (the remainder is 2) ```
You've learned how to write your own matchers in the previous recipe. Just one problem: a matcher created using `MakeMatcher()` only works for one particular type of arguments. If you want a _polymorphic_ matcher that works with arguments of several types (for instance, `Eq(x)` can be used to match a `value` as long as `value` == `x` compiles -- `value` and `x` don't have to share the same type), you can learn the trick from `"gmock/gmock-matchers.h"` but it's a bit involved.
Fortunately, most of the time you can define a polymorphic matcher easily with the help of `MakePolymorphicMatcher()`. Here's how you can define `NotNull()` as an example:
``` using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; using ::testing::NotNull; using ::testing::PolymorphicMatcher;
class NotNullMatcher {  public:   // To implement a polymorphic matcher, first define a COPYABLE class   // that has three members MatchAndExplain(), DescribeTo(), and   // DescribeNegationTo(), like the following.
// In this example, we want to use NotNull() with any pointer, so   // MatchAndExplain() accepts a pointer of any type as its first argument.   // In general, you can define MatchAndExplain() as an ordinary method or   // a method template, or even overload it.   template <typename T>   bool MatchAndExplain(T* p,                        MatchResultListener* /* listener */) const {     return p != NULL;   }
// Describes the property of a value matching this matcher.   void DescribeTo(::std::ostream* os) const { *os << "is not NULL"; }
// Describes the property of a value NOT matching this matcher.   void DescribeNegationTo(::std::ostream* os) const { *os << "is NULL"; } };
// To construct a polymorphic matcher, pass an instance of the class // to MakePolymorphicMatcher().  Note the return type. inline PolymorphicMatcher<NotNullMatcher> NotNull() {   return MakePolymorphicMatcher(NotNullMatcher()); } ...
EXPECT_CALL(foo, Bar(NotNull()));  // The argument must be a non-NULL pointer. ```
**Note:** Your polymorphic matcher class does **not** need to inherit from `MatcherInterface` or any other class, and its methods do **not** need to be virtual.
Like in a monomorphic matcher, you may explain the match result by streaming additional information to the `listener` argument in `MatchAndExplain()`.
A cardinality is used in `Times()` to tell Google Mock how many times you expect a call to occur. It doesn't have to be exact. For example, you can say `AtLeast(5)` or `Between(2, 4)`.
If the built-in set of cardinalities doesn't suit you, you are free to define your own by implementing the following interface (in namespace `testing`):
``` class CardinalityInterface {  public:   virtual ~CardinalityInterface();
// Returns true iff call_count calls will satisfy this cardinality.   virtual bool IsSatisfiedByCallCount(int call_count) const = 0;
// Returns true iff call_count calls will saturate this cardinality.   virtual bool IsSaturatedByCallCount(int call_count) const = 0;
// Describes self to an ostream.   virtual void DescribeTo(::std::ostream* os) const = 0; }; ```
For example, to specify that a call must occur even number of times, you can write
``` using ::testing::Cardinality; using ::testing::CardinalityInterface; using ::testing::MakeCardinality;
class EvenNumberCardinality : public CardinalityInterface {  public:   virtual bool IsSatisfiedByCallCount(int call_count) const {     return (call_count % 2) == 0;   }
virtual bool IsSaturatedByCallCount(int call_count) const {     return false;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "called even number of times";   } };
Cardinality EvenNumber() {   return MakeCardinality(new EvenNumberCardinality); } ...
EXPECT_CALL(foo, Bar(3))       .Times(EvenNumber()); ```
If the built-in actions don't work for you, and you find it inconvenient to use `Invoke()`, you can use a macro from the `ACTION*` family to quickly define a new action that can be used in your code as if it's a built-in action.
By writing ``` ACTION(name) { statements; } ``` in a namespace scope (i.e. not inside a class or function), you will define an action with the given name that executes the statements. The value returned by `statements` will be used as the return value of the action.  Inside the statements, you can refer to the K-th (0-based) argument of the mock function as `argK`.  For example: ``` ACTION(IncrementArg1) { return ++(*arg1); } ``` allows you to write ``` ... WillOnce(IncrementArg1()); ```
Note that you don't need to specify the types of the mock function arguments.  Rest assured that your code is type-safe though: you'll get a compiler error if `*arg1` doesn't support the `++` operator, or if the type of `++(*arg1)` isn't compatible with the mock function's return type.
Another example: ``` ACTION(Foo) {   (*arg2)(5);   Blah();   *arg1 = 0;   return arg0; } ``` defines an action `Foo()` that invokes argument #2 (a function pointer) with 5, calls function `Blah()`, sets the value pointed to by argument #1 to 0, and returns argument #0.
For more convenience and flexibility, you can also use the following pre-defined symbols in the body of `ACTION`:
| `argK_type` | The type of the K-th (0-based) argument of the mock function | |:------------|:-------------------------------------------------------------| | `args`      | All arguments of the mock function as a tuple                | | `args_type` | The type of all arguments of the mock function as a tuple    | | `return_type` | The return type of the mock function                         | | `function_type` | The type of the mock function                                |
For example, when using an `ACTION` as a stub action for mock function: ``` int DoSomething(bool flag, int* ptr); ``` we have: | **Pre-defined Symbol** | **Is Bound To** | |:-----------------------|:----------------| | `arg0`                 | the value of `flag` | | `arg0_type`            | the type `bool` | | `arg1`                 | the value of `ptr` | | `arg1_type`            | the type `int*` | | `args`                 | the tuple `(flag, ptr)` | | `args_type`            | the type `std::tr1::tuple<bool, int*>` | | `return_type`          | the type `int`  | | `function_type`        | the type `int(bool, int*)` |
Sometimes you'll want to parameterize an action you define.  For that we have another macro ``` ACTION_P(name, param) { statements; } ```
For example, ``` ACTION_P(Add, n) { return arg0 + n; } ``` will allow you to write ``` // Returns argument #0 + 5. ... WillOnce(Add(5)); ```
For convenience, we use the term _arguments_ for the values used to invoke the mock function, and the term _parameters_ for the values used to instantiate an action.
Note that you don't need to provide the type of the parameter either. Suppose the parameter is named `param`, you can also use the Google-Mock-defined symbol `param_type` to refer to the type of the parameter as inferred by the compiler.  For example, in the body of `ACTION_P(Add, n)` above, you can write `n_type` for the type of `n`.
Google Mock also provides `ACTION_P2`, `ACTION_P3`, and etc to support multi-parameter actions.  For example, ``` ACTION_P2(ReturnDistanceTo, x, y) {   double dx = arg0 - x;   double dy = arg1 - y;   return sqrt(dx*dx + dy*dy); } ``` lets you write ``` ... WillOnce(ReturnDistanceTo(5.0, 26.5)); ```
You can view `ACTION` as a degenerated parameterized action where the number of parameters is 0.
You can also easily define actions overloaded on the number of parameters: ``` ACTION_P(Plus, a) { ... } ACTION_P2(Plus, a, b) { ... } ```
For maximum brevity and reusability, the `ACTION*` macros don't ask you to provide the types of the mock function arguments and the action parameters.  Instead, we let the compiler infer the types for us.
Sometimes, however, we may want to be more explicit about the types. There are several tricks to do that.  For example: ``` ACTION(Foo) {   // Makes sure arg0 can be converted to int.   int n = arg0;   ... use n instead of arg0 here ... }
ACTION_P(Bar, param) {   // Makes sure the type of arg1 is const char*.   ::testing::StaticAssertTypeEq<const char*, arg1_type>();
// Makes sure param can be converted to bool.   bool flag = param; } ``` where `StaticAssertTypeEq` is a compile-time assertion in Google Test that verifies two types are the same.
Sometimes you want to give an action explicit template parameters that cannot be inferred from its value parameters.  `ACTION_TEMPLATE()` supports that and can be viewed as an extension to `ACTION()` and `ACTION_P*()`.
The syntax: ``` ACTION_TEMPLATE(ActionName,                 HAS_m_TEMPLATE_PARAMS(kind1, name1, ..., kind_m, name_m),                 AND_n_VALUE_PARAMS(p1, ..., p_n)) { statements; } ```
defines an action template that takes _m_ explicit template parameters and _n_ value parameters, where _m_ is between 1 and 10, and _n_ is between 0 and 10.  `name_i` is the name of the i-th template parameter, and `kind_i` specifies whether it's a `typename`, an integral constant, or a template.  `p_i` is the name of the i-th value parameter.
Example: ``` // DuplicateArg<k, T>(output) converts the k-th argument of the mock // function to type T and copies it to *output. ACTION_TEMPLATE(DuplicateArg,                 // Note the comma between int and k:                 HAS_2_TEMPLATE_PARAMS(int, k, typename, T),                 AND_1_VALUE_PARAMS(output)) {   *output = T(std::tr1::get<k>(args)); } ```
To create an instance of an action template, write: ```   ActionName<t1, ..., t_m>(v1, ..., v_n) ``` where the `t`s are the template arguments and the `v`s are the value arguments.  The value argument types are inferred by the compiler.  For example: ``` using ::testing::_; ...   int n;   EXPECT_CALL(mock, Foo(_, _))       .WillOnce(DuplicateArg<1, unsigned char>(&n)); ```
If you want to explicitly specify the value argument types, you can provide additional template arguments: ```   ActionName<t1, ..., t_m, u1, ..., u_k>(v1, ..., v_n) ``` where `u_i` is the desired type of `v_i`.
`ACTION_TEMPLATE` and `ACTION`/`ACTION_P*` can be overloaded on the number of value parameters, but not on the number of template parameters.  Without the restriction, the meaning of the following is unclear:
```   OverloadedAction<int, bool>(x); ```
Are we using a single-template-parameter action where `bool` refers to the type of `x`, or a two-template-parameter action where the compiler is asked to infer the type of `x`?
If you are writing a function that returns an `ACTION` object, you'll need to know its type.  The type depends on the macro used to define the action and the parameter types.  The rule is relatively simple: | **Given Definition** | **Expression** | **Has Type** | |:---------------------|:---------------|:-------------| | `ACTION(Foo)`        | `Foo()`        | `FooAction`  | | `ACTION_TEMPLATE(Foo, HAS_m_TEMPLATE_PARAMS(...), AND_0_VALUE_PARAMS())` |	`Foo<t1, ..., t_m>()` | `FooAction<t1, ..., t_m>` | | `ACTION_P(Bar, param)` | `Bar(int_value)` | `BarActionP<int>` | | `ACTION_TEMPLATE(Bar, HAS_m_TEMPLATE_PARAMS(...), AND_1_VALUE_PARAMS(p1))` | `Bar<t1, ..., t_m>(int_value)` | `FooActionP<t1, ..., t_m, int>` | | `ACTION_P2(Baz, p1, p2)` | `Baz(bool_value, int_value)` | `BazActionP2<bool, int>` | | `ACTION_TEMPLATE(Baz, HAS_m_TEMPLATE_PARAMS(...), AND_2_VALUE_PARAMS(p1, p2))` | `Baz<t1, ..., t_m>(bool_value, int_value)` | `FooActionP2<t1, ..., t_m, bool, int>` | | ...                  | ...            | ...          |
Note that we have to pick different suffixes (`Action`, `ActionP`, `ActionP2`, and etc) for actions with different numbers of value parameters, or the action definitions cannot be overloaded on the number of them.
While the `ACTION*` macros are very convenient, sometimes they are inappropriate.  For example, despite the tricks shown in the previous recipes, they don't let you directly specify the types of the mock function arguments and the action parameters, which in general leads to unoptimized compiler error messages that can baffle unfamiliar users.  They also don't allow overloading actions based on parameter types without jumping through some hoops.
An alternative to the `ACTION*` macros is to implement `::testing::ActionInterface<F>`, where `F` is the type of the mock function in which the action will be used. For example:
``` template <typename F>class ActionInterface {  public:   virtual ~ActionInterface();
// Performs the action.  Result is the return type of function type   // F, and ArgumentTuple is the tuple of arguments of F.   //   // For example, if F is int(bool, const string&), then Result would   // be int, and ArgumentTuple would be tr1::tuple<bool, const string&>.   virtual Result Perform(const ArgumentTuple& args) = 0; };
using ::testing::_; using ::testing::Action; using ::testing::ActionInterface; using ::testing::MakeAction;
typedef int IncrementMethod(int*);
class IncrementArgumentAction : public ActionInterface<IncrementMethod> {  public:   virtual int Perform(const tr1::tuple<int*>& args) {     int* p = tr1::get<0>(args);  // Grabs the first argument.     return *p++;   } };
Action<IncrementMethod> IncrementArgument() {   return MakeAction(new IncrementArgumentAction); } ...
EXPECT_CALL(foo, Baz(_))       .WillOnce(IncrementArgument());
int n = 5;   foo.Baz(&n);  // Should return 5 and change n to 6. ```
The previous recipe showed you how to define your own action. This is all good, except that you need to know the type of the function in which the action will be used. Sometimes that can be a problem. For example, if you want to use the action in functions with _different_ types (e.g. like `Return()` and `SetArgPointee()`).
If an action can be used in several types of mock functions, we say it's _polymorphic_. The `MakePolymorphicAction()` function template makes it easy to define such an action:
``` namespace testing {
template <typename Impl> PolymorphicAction<Impl> MakePolymorphicAction(const Impl& impl);
}  // namespace testing ```
As an example, let's define an action that returns the second argument in the mock function's argument list. The first step is to define an implementation class:
``` class ReturnSecondArgumentAction {  public:   template <typename Result, typename ArgumentTuple>   Result Perform(const ArgumentTuple& args) const {     // To get the i-th (0-based) argument, use tr1::get<i>(args).     return tr1::get<1>(args);   } }; ```
This implementation class does _not_ need to inherit from any particular class. What matters is that it must have a `Perform()` method template. This method template takes the mock function's arguments as a tuple in a **single** argument, and returns the result of the action. It can be either `const` or not, but must be invokable with exactly one template argument, which is the result type. In other words, you must be able to call `Perform<R>(args)` where `R` is the mock function's return type and `args` is its arguments in a tuple.
Next, we use `MakePolymorphicAction()` to turn an instance of the implementation class into the polymorphic action we need. It will be convenient to have a wrapper for this:
``` using ::testing::MakePolymorphicAction; using ::testing::PolymorphicAction;
PolymorphicAction<ReturnSecondArgumentAction> ReturnSecondArgument() {   return MakePolymorphicAction(ReturnSecondArgumentAction()); } ```
Now, you can use this polymorphic action the same way you use the built-in ones:
``` using ::testing::_;
class MockFoo : public Foo {  public:   MOCK_METHOD2(DoThis, int(bool flag, int n));   MOCK_METHOD3(DoThat, string(int x, const char* str1, const char* str2)); }; ...
MockFoo foo;   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(ReturnSecondArgument());   EXPECT_CALL(foo, DoThat(_, _, _))       .WillOnce(ReturnSecondArgument());   ...   foo.DoThis(true, 5);         // Will return 5.   foo.DoThat(1, "Hi", "Bye");  // Will return "Hi". ```
When an uninteresting or unexpected call occurs, Google Mock prints the argument values and the stack trace to help you debug.  Assertion macros like `EXPECT_THAT` and `EXPECT_EQ` also print the values in question when the assertion fails.  Google Mock and Google Test do this using Google Test's user-extensible value printer.
This printer knows how to print built-in C++ types, native arrays, STL containers, and any type that supports the `<<` operator.  For other types, it prints the raw bytes in the value and hopes that you the user can figure it out. [Google Test's advanced guide](http://code.google.com/p/googletest/wiki/V1_6_AdvancedGuide#Teaching_Google_Test_How_to_Print_Your_Values) explains how to extend the printer to do a better job at printing your particular type than to dump the bytes.
This page lists all documentation wiki pages for Google Mock **1.6** - **if you use a released version of Google Mock, please read the documentation for that specific version instead.**
* [ForDummies](V1_6_ForDummies.md) -- start here if you are new to Google Mock.   * [CheatSheet](V1_6_CheatSheet.md) -- a quick reference.   * [CookBook](V1_6_CookBook.md) -- recipes for doing various tasks using Google Mock.   * [FrequentlyAskedQuestions](V1_6_FrequentlyAskedQuestions.md) -- check here before asking a question on the mailing list.
To contribute code to Google Mock, read:
* [DevGuide](DevGuide.md) -- read this _before_ writing your first patch.   * [Pump Manual](http://code.google.com/p/googletest/wiki/V1_6_PumpManual) -- how we generate some of Google Mock's source files.

(**Note:** If you get compiler errors that you don't understand, be sure to consult [Google Mock Doctor](http://code.google.com/p/googlemock/wiki/V1_6_FrequentlyAskedQuestions#How_am_I_supposed_to_make_sense_of_these_horrible_template_error).)
**Note:** It is easy to confuse the term _fake objects_ with mock objects. Fakes and mocks actually mean very different things in the Test-Driven Development (TDD) community:
* **Fake** objects have working implementations, but usually take some shortcut (perhaps to make the operations less expensive), which makes them not suitable for production. An in-memory file system would be an example of a fake.   * **Mocks** are objects pre-programmed with _expectations_, which form a specification of the calls they are expected to receive.
If all this seems too abstract for you, don't worry - the most important thing to remember is that a mock allows you to check the _interaction_ between itself and code that uses it. The difference between fakes and mocks will become much clearer once you start to use mocks.
**Google C++ Mocking Framework** (or **Google Mock** for short) is a library (sometimes we also call it a "framework" to make it sound cool) for creating mock classes and using them. It does to C++ what [jMock](http://www.jmock.org/) and [EasyMock](http://www.easymock.org/) do to Java.
Using Google Mock involves three basic steps:
1. Use some simple macros to describe the interface you want to mock, and they will expand to the implementation of your mock class;   1. Create some mock objects and specify its expectations and behavior using an intuitive syntax;   1. Exercise code that uses the mock objects. Google Mock will catch any violation of the expectations as soon as it arises.
* Someone has to implement the mocks. The job is usually tedious and error-prone. No wonder people go great distance to avoid it.   * The quality of those manually written mocks is a bit, uh, unpredictable. You may see some really polished ones, but you may also see some that were hacked up in a hurry and have all sorts of ad hoc restrictions.   * The knowledge you gained from using one mock doesn't transfer to the next.
In contrast, Java and Python programmers have some fine mock frameworks, which automate the creation of mocks. As a result, mocking is a proven effective technique and widely adopted practice in those communities. Having the right tool absolutely makes the difference.
Google Mock was built to help C++ programmers. It was inspired by [jMock](http://www.jmock.org/) and [EasyMock](http://www.easymock.org/), but designed with C++'s specifics in mind. It is your friend if any of the following problems is bothering you:
* You are stuck with a sub-optimal design and wish you had done more prototyping before it was too late, but prototyping in C++ is by no means "rapid".   * Your tests are slow as they depend on too many libraries or use expensive resources (e.g. a database).   * Your tests are brittle as some resources they use are unreliable (e.g. the network).   * You want to test how your code handles a failure (e.g. a file checksum error), but it's not easy to cause one.   * You need to make sure that your module interacts with other modules in the right way, but it's hard to observe the interaction; therefore you resort to observing the side effects at the end of the action, which is awkward at best.   * You want to "mock out" your dependencies, except that they don't have mock implementations yet; and, frankly, you aren't thrilled by some of those hand-written mocks.
We encourage you to use Google Mock as:
* a _design_ tool, for it lets you experiment with your interface design early and often. More iterations lead to better designs!   * a _testing_ tool to cut your tests' outbound dependencies and probe the interaction between your module and its collaborators.
``` class Turtle {   ...   virtual ~Turtle() {}   virtual void PenUp() = 0;   virtual void PenDown() = 0;   virtual void Forward(int distance) = 0;   virtual void Turn(int degrees) = 0;   virtual void GoTo(int x, int y) = 0;   virtual int GetX() const = 0;   virtual int GetY() const = 0; }; ```
(Note that the destructor of `Turtle` **must** be virtual, as is the case for **all** classes you intend to inherit from - otherwise the destructor of the derived class will not be called when you delete an object through a base pointer, and you'll get corrupted program states like memory leaks.)
You can control whether the turtle's movement will leave a trace using `PenUp()` and `PenDown()`, and control its movement using `Forward()`, `Turn()`, and `GoTo()`. Finally, `GetX()` and `GetY()` tell you the current position of the turtle.
Your program will normally use a real implementation of this interface. In tests, you can use a mock implementation instead. This allows you to easily check what drawing primitives your program is calling, with what arguments, and in which order. Tests written this way are much more robust (they won't break because your new machine does anti-aliasing differently), easier to read and maintain (the intent of a test is expressed in the code, not in some binary images), and run _much, much faster_.
1. Derive a class `MockTurtle` from `Turtle`.   1. Take a _virtual_ function of `Turtle` (while it's possible to [mock non-virtual methods using templates](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Mocking_Nonvirtual_Methods), it's much more involved). Count how many arguments it has.   1. In the `public:` section of the child class, write `MOCK_METHODn();` (or `MOCK_CONST_METHODn();` if you are mocking a `const` method), where `n` is the number of the arguments; if you counted wrong, shame on you, and a compiler error will tell you so.   1. Now comes the fun part: you take the function signature, cut-and-paste the _function name_ as the _first_ argument to the macro, and leave what's left as the _second_ argument (in case you're curious, this is the _type of the function_).   1. Repeat until all virtual functions you want to mock are done.
After the process, you should have something like:
``` #include "gmock/gmock.h"  // Brings in Google Mock. class MockTurtle : public Turtle {  public:   ...   MOCK_METHOD0(PenUp, void());   MOCK_METHOD0(PenDown, void());   MOCK_METHOD1(Forward, void(int distance));   MOCK_METHOD1(Turn, void(int degrees));   MOCK_METHOD2(GoTo, void(int x, int y));   MOCK_CONST_METHOD0(GetX, int());   MOCK_CONST_METHOD0(GetY, int()); }; ```
You don't need to define these mock methods somewhere else - the `MOCK_METHOD*` macros will generate the definitions for you. It's that simple! Once you get the hang of it, you can pump out mock classes faster than your source-control system can handle your check-ins.
**Tip:** If even this is too much work for you, you'll find the `gmock_gen.py` tool in Google Mock's `scripts/generator/` directory (courtesy of the [cppclean](http://code.google.com/p/cppclean/) project) useful.  This command-line tool requires that you have Python 2.4 installed.  You give it a C++ file and the name of an abstract class defined in it, and it will print the definition of the mock class for you.  Due to the complexity of the C++ language, this script may not always work, but it can be quite handy when it does.  For more details, read the [user documentation](http://code.google.com/p/googlemock/source/browse/trunk/scripts/generator/README).
So, the rule of thumb is: if you need to mock `Foo` and it's owned by others, define the mock class in `Foo`'s package (better, in a `testing` sub-package such that you can clearly separate production code and testing utilities), and put it in a `mock_foo.h`. Then everyone can reference `mock_foo.h` from their tests. If `Foo` ever changes, there is only one copy of `MockFoo` to change, and only tests that depend on the changed methods need to be fixed.
Another way to do it: you can introduce a thin layer `FooAdaptor` on top of `Foo` and code to this new interface. Since you own `FooAdaptor`, you can absorb changes in `Foo` much more easily. While this is more work initially, carefully choosing the adaptor interface can make your code easier to write and more readable (a net win in the long run), as you can choose `FooAdaptor` to fit your specific domain much better than `Foo` does.
1. Import the Google Mock names from the `testing` namespace such that you can use them unqualified (You only have to do it once per file. Remember that namespaces are a good idea and good for your health.).   1. Create some mock objects.   1. Specify your expectations on them (How many times will a method be called? With what arguments? What should it do? etc.).   1. Exercise some code that uses the mocks; optionally, check the result using Google Test assertions. If a mock method is called more than expected or with wrong arguments, you'll get an error immediately.   1. When a mock is destructed, Google Mock will automatically check whether all expectations on it have been satisfied.
Here's an example:
``` #include "path/to/mock-turtle.h" #include "gmock/gmock.h" #include "gtest/gtest.h" using ::testing::AtLeast;                     // #1
TEST(PainterTest, CanDrawSomething) {   MockTurtle turtle;                          // #2   EXPECT_CALL(turtle, PenDown())              // #3       .Times(AtLeast(1));
Painter painter(&turtle);                   // #4
EXPECT_TRUE(painter.DrawCircle(0, 0, 10)); }                                             // #5
int main(int argc, char** argv) {   // The following line must be executed to initialize Google Mock   // (and Google Test) before running the tests.   ::testing::InitGoogleMock(&argc, argv);   return RUN_ALL_TESTS(); } ```
As you might have guessed, this test checks that `PenDown()` is called at least once. If the `painter` object didn't call this method, your test will fail with a message like this:
``` path/to/my_test.cc:119: Failure Actual function call count doesn't match this expectation: Actually: never called; Expected: called at least once. ```
**Tip 1:** If you run the test from an Emacs buffer, you can hit `<Enter>` on the line number displayed in the error message to jump right to the failed expectation.
**Tip 2:** If your mock objects are never deleted, the final verification won't happen. Therefore it's a good idea to use a heap leak checker in your tests when you allocate mocks on the heap.
**Important note:** Google Mock requires expectations to be set **before** the mock functions are called, otherwise the behavior is **undefined**. In particular, you mustn't interleave `EXPECT_CALL()`s and calls to the mock functions.
This means `EXPECT_CALL()` should be read as expecting that a call will occur _in the future_, not that a call has occurred. Why does Google Mock work like that? Well, specifying the expectation beforehand allows Google Mock to report a violation as soon as it arises, when the context (stack trace, etc) is still available. This makes debugging much easier.
Admittedly, this test is contrived and doesn't do much. You can easily achieve the same effect without using Google Mock. However, as we shall reveal soon, Google Mock allows you to do _much more_ with the mocks.
This approach has a catch: it makes Google Mock throw an exception from a mock object's destructor sometimes.  With some compilers, this sometimes causes the test program to crash.  You'll still be able to notice that the test has failed, but it's not a graceful failure.
A better solution is to use Google Test's [event listener API](http://code.google.com/p/googletest/wiki/V1_6_AdvancedGuide#Extending_Google_Test_by_Handling_Test_Events) to report a test failure to your testing framework properly.  You'll need to implement the `OnTestPartResult()` method of the event listener interface, but it should be straightforward.
If this turns out to be too much work, we suggest that you stick with Google Test, which works with Google Mock seamlessly (in fact, it is technically part of Google Mock.).  If there is a reason that you cannot use Google Test, please let us know.
``` EXPECT_CALL(mock_object, method(matchers))     .Times(cardinality)     .WillOnce(action)     .WillRepeatedly(action); ```
The macro has two arguments: first the mock object, and then the method and its arguments. Note that the two are separated by a comma (`,`), not a period (`.`). (Why using a comma? The answer is that it was necessary for technical reasons.)
The macro can be followed by some optional _clauses_ that provide more information about the expectation. We'll discuss how each clause works in the coming sections.
This syntax is designed to make an expectation read like English. For example, you can probably guess that
``` using ::testing::Return;... EXPECT_CALL(turtle, GetX())     .Times(5)     .WillOnce(Return(100))     .WillOnce(Return(150))     .WillRepeatedly(Return(200)); ```
says that the `turtle` object's `GetX()` method will be called five times, it will return 100 the first time, 150 the second time, and then 200 every time. Some people like to call this style of syntax a Domain-Specific Language (DSL).
**Note:** Why do we use a macro to do this? It serves two purposes: first it makes expectations easily identifiable (either by `grep` or by a human reader), and second it allows Google Mock to include the source file location of a failed expectation in messages, making debugging easier.
``` // Expects the turtle to move forward by 100 units. EXPECT_CALL(turtle, Forward(100)); ```
Sometimes you may not want to be too specific (Remember that talk about tests being too rigid? Over specification leads to brittle tests and obscures the intent of tests. Therefore we encourage you to specify only what's necessary - no more, no less.). If you care to check that `Forward()` will be called but aren't interested in its actual argument, write `_` as the argument, which means "anything goes":
``` using ::testing::_; ... // Expects the turtle to move forward. EXPECT_CALL(turtle, Forward(_)); ```
`_` is an instance of what we call **matchers**. A matcher is like a predicate and can test whether an argument is what we'd expect. You can use a matcher inside `EXPECT_CALL()` wherever a function argument is expected.
A list of built-in matchers can be found in the [CheatSheet](V1_6_CheatSheet.md). For example, here's the `Ge` (greater than or equal) matcher:
``` using ::testing::Ge;... EXPECT_CALL(turtle, Forward(Ge(100))); ```
This checks that the turtle will be told to go forward by at least 100 units.
An interesting special case is when we say `Times(0)`. You may have guessed - it means that the function shouldn't be called with the given arguments at all, and Google Mock will report a Google Test failure whenever the function is (wrongfully) called.
We've seen `AtLeast(n)` as an example of fuzzy cardinalities earlier. For the list of built-in cardinalities you can use, see the [CheatSheet](V1_6_CheatSheet.md).
The `Times()` clause can be omitted. **If you omit `Times()`, Google Mock will infer the cardinality for you.** The rules are easy to remember:
* If **neither** `WillOnce()` **nor** `WillRepeatedly()` is in the `EXPECT_CALL()`, the inferred cardinality is `Times(1)`.   * If there are `n WillOnce()`'s but **no** `WillRepeatedly()`, where `n` >= 1, the cardinality is `Times(n)`.   * If there are `n WillOnce()`'s and **one** `WillRepeatedly()`, where `n` >= 0, the cardinality is `Times(AtLeast(n))`.
**Quick quiz:** what do you think will happen if a function is expected to be called twice but actually called four times?
First, if the return type of a mock function is a built-in type or a pointer, the function has a **default action** (a `void` function will just return, a `bool` function will return `false`, and other functions will return 0). If you don't say anything, this behavior will be used.
Second, if a mock function doesn't have a default action, or the default action doesn't suit you, you can specify the action to be taken each time the expectation matches using a series of `WillOnce()` clauses followed by an optional `WillRepeatedly()`. For example,
``` using ::testing::Return;... EXPECT_CALL(turtle, GetX())     .WillOnce(Return(100))     .WillOnce(Return(200))     .WillOnce(Return(300)); ```
This says that `turtle.GetX()` will be called _exactly three times_ (Google Mock inferred this from how many `WillOnce()` clauses we've written, since we didn't explicitly write `Times()`), and will return 100, 200, and 300 respectively.
``` using ::testing::Return;... EXPECT_CALL(turtle, GetY())     .WillOnce(Return(100))     .WillOnce(Return(200))     .WillRepeatedly(Return(300)); ```
says that `turtle.GetY()` will be called _at least twice_ (Google Mock knows this as we've written two `WillOnce()` clauses and a `WillRepeatedly()` while having no explicit `Times()`), will return 100 the first time, 200 the second time, and 300 from the third time on.
Of course, if you explicitly write a `Times()`, Google Mock will not try to infer the cardinality itself. What if the number you specified is larger than there are `WillOnce()` clauses? Well, after all `WillOnce()`s are used up, Google Mock will do the _default_ action for the function every time (unless, of course, you have a `WillRepeatedly()`.).
What can we do inside `WillOnce()` besides `Return()`? You can return a reference using `ReturnRef(variable)`, or invoke a pre-defined function, among [others](http://code.google.com/p/googlemock/wiki/V1_6_CheatSheet#Actions).
**Important note:** The `EXPECT_CALL()` statement evaluates the action clause only once, even though the action may be performed many times. Therefore you must be careful about side effects. The following may not do what you want:
``` int n = 100; EXPECT_CALL(turtle, GetX()) .Times(4) .WillRepeatedly(Return(n++)); ```
Instead of returning 100, 101, 102, ..., consecutively, this mock function will always return 100 as `n++` is only evaluated once. Similarly, `Return(new Foo)` will create a new `Foo` object when the `EXPECT_CALL()` is executed, and will return the same pointer every time. If you want the side effect to happen every time, you need to define a custom action, which we'll teach in the [CookBook](V1_6_CookBook.md).
Time for another quiz! What do you think the following means?
``` using ::testing::Return;... EXPECT_CALL(turtle, GetY()) .Times(4) .WillOnce(Return(100)); ```
Obviously `turtle.GetY()` is expected to be called four times. But if you think it will return 100 every time, think twice! Remember that one `WillOnce()` clause will be consumed each time the function is invoked and the default action will be taken afterwards. So the right answer is that `turtle.GetY()` will return 100 the first time, but **return 0 from the second time on**, as returning 0 is the default action for `int` functions.
By default, when a mock method is invoked, Google Mock will search the expectations in the **reverse order** they are defined, and stop when an active expectation that matches the arguments is found (you can think of it as "newer rules override older ones."). If the matching expectation cannot take any more calls, you will get an upper-bound-violated failure. Here's an example:
``` using ::testing::_;... EXPECT_CALL(turtle, Forward(_));  // #1 EXPECT_CALL(turtle, Forward(10))  // #2     .Times(2); ```
If `Forward(10)` is called three times in a row, the third time it will be an error, as the last matching expectation (#2) has been saturated. If, however, the third `Forward(10)` call is replaced by `Forward(20)`, then it would be OK, as now #1 will be the matching expectation.
**Side note:** Why does Google Mock search for a match in the _reverse_ order of the expectations? The reason is that this allows a user to set up the default expectations in a mock object's constructor or the test fixture's set-up phase and then customize the mock by writing more specific expectations in the test body. So, if you have two expectations on the same method, you want to put the one with more specific matchers **after** the other, or the more specific rule would be shadowed by the more general one that comes after it.
Sometimes, you may want all the expected calls to occur in a strict order. To say this in Google Mock is easy:
``` using ::testing::InSequence;... TEST(FooTest, DrawsLineSegment) {   ...   {     InSequence dummy;
EXPECT_CALL(turtle, PenDown());     EXPECT_CALL(turtle, Forward(100));     EXPECT_CALL(turtle, PenUp());   }   Foo(); } ```
By creating an object of type `InSequence`, all expectations in its scope are put into a _sequence_ and have to occur _sequentially_. Since we are just relying on the constructor and destructor of this object to do the actual work, its name is really irrelevant.
In this example, we test that `Foo()` calls the three expected functions in the order as written. If a call is made out-of-order, it will be an error.
(What if you care about the relative order of some of the calls, but not all of them? Can you specify an arbitrary partial order? The answer is ... yes! If you are impatient, the details can be found in the [CookBook](V1_6_CookBook.md).)
After you've come up with your answer, take a look at ours and compare notes (solve it yourself first - don't cheat!):
``` using ::testing::_;... EXPECT_CALL(turtle, GoTo(_, _))  // #1     .Times(AnyNumber()); EXPECT_CALL(turtle, GoTo(0, 0))  // #2     .Times(2); ```
Suppose `turtle.GoTo(0, 0)` is called three times. In the third time, Google Mock will see that the arguments match expectation #2 (remember that we always pick the last matching expectation). Now, since we said that there should be only two such calls, Google Mock will report an error immediately. This is basically what we've told you in the "Using Multiple Expectations" section above.
This example shows that **expectations in Google Mock are "sticky" by default**, in the sense that they remain active even after we have reached their invocation upper bounds. This is an important rule to remember, as it affects the meaning of the spec, and is **different** to how it's done in many other mocking frameworks (Why'd we do that? Because we think our rule makes the common cases easier to express and understand.).
Simple? Let's see if you've really understood it: what does the following code say?
``` using ::testing::Return; ... for (int i = n; i > 0; i--) {   EXPECT_CALL(turtle, GetX())       .WillOnce(Return(10*i)); } ```
If you think it says that `turtle.GetX()` will be called `n` times and will return 10, 20, 30, ..., consecutively, think twice! The problem is that, as we said, expectations are sticky. So, the second time `turtle.GetX()` is called, the last (latest) `EXPECT_CALL()` statement will match, and will immediately lead to an "upper bound exceeded" error - this piece of code is not very useful!
One correct way of saying that `turtle.GetX()` will return 10, 20, 30, ..., is to explicitly say that the expectations are _not_ sticky. In other words, they should _retire_ as soon as they are saturated:
``` using ::testing::Return; ... for (int i = n; i > 0; i--) {   EXPECT_CALL(turtle, GetX())     .WillOnce(Return(10*i))     .RetiresOnSaturation(); } ```
And, there's a better way to do it: in this case, we expect the calls to occur in a specific order, and we line up the actions to match the order. Since the order is important here, we should make it explicit using a sequence:
``` using ::testing::InSequence; using ::testing::Return; ... {   InSequence s;
for (int i = 1; i <= n; i++) {     EXPECT_CALL(turtle, GetX())         .WillOnce(Return(10*i))         .RetiresOnSaturation();   } } ```
By the way, the other situation where an expectation may _not_ be sticky is when it's in a sequence - as soon as another expectation that comes after it in the sequence has been used, it automatically retires (and will never be used to match any call).
In Google Mock, if you are not interested in a method, just don't say anything about it. If a call to this method occurs, you'll see a warning in the test output, but it won't be a failure.
Then, if you feel like increasing your mock quotient, you should move on to the [CookBook](V1_6_CookBook.md). You can learn many advanced features of Google Mock there -- and advance your level of enjoyment and testing bliss.

Please send your questions to the [googlemock](http://groups.google.com/group/googlemock) discussion group. If you need help with compiler errors, make sure you have tried [Google Mock Doctor](#How_am_I_supposed_to_make_sense_of_these_horrible_template_error.md) first.
In order for a method to be mocked, it must be _virtual_, unless you use the [high-perf dependency injection technique](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Mocking_Nonvirtual_Methods).
After version 1.4.0 of Google Mock was released, we had an idea on how to make it easier to write matchers that can generate informative messages efficiently.  We experimented with this idea and liked what we saw.  Therefore we decided to implement it.
Unfortunately, this means that if you have defined your own matchers by implementing `MatcherInterface` or using `MakePolymorphicMatcher()`, your definitions will no longer compile.  Matchers defined using the `MATCHER*` family of macros are not affected.
Sorry for the hassle if your matchers are affected.  We believe it's in everyone's long-term interest to make this change sooner than later.  Fortunately, it's usually not hard to migrate an existing matcher to the new API.  Here's what you need to do:
If you wrote your matcher like this: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MatcherInterface; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }   ... }; ```
you'll need to change it to: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MatcherInterface; using ::testing::MatchResultListener; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool MatchAndExplain(MyType value,                                MatchResultListener* listener) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }   ... }; ``` (i.e. rename `Matches()` to `MatchAndExplain()` and give it a second argument of type `MatchResultListener*`.)
If you were also using `ExplainMatchResultTo()` to improve the matcher message: ``` // Old matcher definition that doesn't work with the lastest // Google Mock. using ::testing::MatcherInterface; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }
virtual void ExplainMatchResultTo(MyType value,                                     ::std::ostream* os) const {     // Prints some helpful information to os to help     // a user understand why value matches (or doesn't match).     *os << "the Foo property is " << value.GetFoo();   }   ... }; ```
you should move the logic of `ExplainMatchResultTo()` into `MatchAndExplain()`, using the `MatchResultListener` argument where the `::std::ostream` was used: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MatcherInterface; using ::testing::MatchResultListener; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool MatchAndExplain(MyType value,                                MatchResultListener* listener) const {     // Returns true if value matches.     *listener << "the Foo property is " << value.GetFoo();     return value.GetFoo() > 5;   }   ... }; ```
If your matcher is defined using `MakePolymorphicMatcher()`: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MakePolymorphicMatcher; ... class MyGreatMatcher {  public:   ...   bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
you should rename the `Matches()` method to `MatchAndExplain()` and add a `MatchResultListener*` argument (the same as what you need to do for matchers defined by implementing `MatcherInterface`): ``` // New matcher definition that works with the latest Google Mock. using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; ... class MyGreatMatcher {  public:   ...   bool MatchAndExplain(MyType value,                        MatchResultListener* listener) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
If your polymorphic matcher uses `ExplainMatchResultTo()` for better failure messages: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MakePolymorphicMatcher; ... class MyGreatMatcher {  public:   ...   bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; void ExplainMatchResultTo(const MyGreatMatcher& matcher,                           MyType value,                           ::std::ostream* os) {   // Prints some helpful information to os to help   // a user understand why value matches (or doesn't match).   *os << "the Bar property is " << value.GetBar(); } ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
you'll need to move the logic inside `ExplainMatchResultTo()` to `MatchAndExplain()`: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; ... class MyGreatMatcher {  public:   ...   bool MatchAndExplain(MyType value,                        MatchResultListener* listener) const {     // Returns true if value matches.     *listener << "the Bar property is " << value.GetBar();     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
For more information, you can read these [two](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Writing_New_Monomorphic_Matchers) [recipes](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Writing_New_Polymorphic_Matchers) from the cookbook.  As always, you are welcome to post questions on `googlemock@googlegroups.com` if you need any help.
Google Mock works out of the box with Google Test.  However, it's easy to configure it to work with any testing framework of your choice. [Here](http://code.google.com/p/googlemock/wiki/V1_6_ForDummies#Using_Google_Mock_with_Any_Testing_Framework) is how.
If you are confused by the compiler errors gcc threw at you, try consulting the _Google Mock Doctor_ tool first.  What it does is to scan stdin for gcc error messages, and spit out diagnoses on the problems (we call them diseases) your code has.
To "install", run command: ``` alias gmd='<path to googlemock>/scripts/gmock_doctor.py' ```
To use it, do: ``` <your-favorite-build-command> <your-test> 2>&1 | gmd ```
For example: ``` make my_test 2>&1 | gmd ```
Or you can run `gmd` and copy-n-paste gcc's error messages to it.
You cannot mock a variadic function (i.e. a function taking ellipsis (`...`) arguments) directly in Google Mock.
The problem is that in general, there is _no way_ for a mock object to know how many arguments are passed to the variadic method, and what the arguments' types are.  Only the _author of the base class_ knows the protocol, and we cannot look into his head.
Therefore, to mock such a function, the _user_ must teach the mock object how to figure out the number of arguments and their types.  One way to do it is to provide overloaded versions of the function.
Ellipsis arguments are inherited from C and not really a C++ feature. They are unsafe to use and don't work with arguments that have constructors or destructors.  Therefore we recommend to avoid them in C++ as much as possible.
If you compile this using Microsoft Visual C++ 2005 SP1: ``` class Foo {   ...   virtual void Bar(const int i) = 0; };
class MockFoo : public Foo {   ...   MOCK_METHOD1(Bar, void(const int i)); }; ``` You may get the following warning: ``` warning C4301: 'MockFoo::Bar': overriding virtual function only differs from 'Foo::Bar' by const/volatile qualifier ```
This is a MSVC bug.  The same code compiles fine with gcc ,for example.  If you use Visual C++ 2008 SP1, you would get the warning: ``` warning C4373: 'MockFoo::Bar': virtual function overrides 'Foo::Bar', previous versions of the compiler did not override when parameters only differed by const/volatile qualifiers ```
In C++, if you _declare_ a function with a `const` parameter, the `const` modifier is _ignored_.  Therefore, the `Foo` base class above is equivalent to: ``` class Foo {   ...   virtual void Bar(int i) = 0;  // int or const int?  Makes no difference. }; ```
In fact, you can _declare_ Bar() with an `int` parameter, and _define_ it with a `const int` parameter.  The compiler will still match them up.
Since making a parameter `const` is meaningless in the method _declaration_, we recommend to remove it in both `Foo` and `MockFoo`. That should workaround the VC bug.
Note that we are talking about the _top-level_ `const` modifier here. If the function parameter is passed by pointer or reference, declaring the _pointee_ or _referee_ as `const` is still meaningful.  For example, the following two declarations are _not_ equivalent: ``` void Bar(int* p);        // Neither p nor *p is const. void Bar(const int* p);  // p is not const, but *p is. ```
We've noticed that when the `/clr` compiler flag is used, Visual C++ uses 5~6 times as much memory when compiling a mock class.  We suggest to avoid `/clr` when compiling native C++ mocks.
You might want to run your test with `--gmock_verbose=info`.  This flag lets Google Mock print a trace of every mock function call it receives.  By studying the trace, you'll gain insights on why the expectations you set are not met.
``` EXPECT_CALL(foo, Bar(_))     .Times(0); ```
When Google Mock detects a failure, it prints relevant information (the mock function arguments, the state of relevant expectations, and etc) to help the user debug.  If another failure is detected, Google Mock will do the same, including printing the state of relevant expectations.
Sometimes an expectation's state didn't change between two failures, and you'll see the same description of the state twice.  They are however _not_ redundant, as they refer to _different points in time_. The fact they are the same _is_ interesting information.
Does the class (hopefully a pure interface) you are mocking have a virtual destructor?
Whenever you derive from a base class, make sure its destructor is virtual.  Otherwise Bad Things will happen.  Consider the following code:
``` class Base {  public:   // Not virtual, but should be.   ~Base() { ... }   ... };
class Derived : public Base {  public:   ...  private:   std::string value_; };
...   Base* p = new Derived;   ...   delete p;  // Surprise! ~Base() will be called, but ~Derived() will not              // - value_ is leaked. ```
By changing `~Base()` to virtual, `~Derived()` will be correctly called when `delete p` is executed, and the heap checker will be happy.
When people complain about this, often they are referring to code like:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time.  However, I have to write the expectations in the // reverse order.  This sucks big time!!! EXPECT_CALL(foo, Bar())     .WillOnce(Return(2))     .RetiresOnSaturation(); EXPECT_CALL(foo, Bar())     .WillOnce(Return(1))     .RetiresOnSaturation(); ```
The problem is that they didn't pick the **best** way to express the test's intent.
By default, expectations don't have to be matched in _any_ particular order.  If you want them to match in a certain order, you need to be explicit.  This is Google Mock's (and jMock's) fundamental philosophy: it's easy to accidentally over-specify your tests, and we want to make it harder to do so.
There are two better ways to write the test spec.  You could either put the expectations in sequence:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time.  Using a sequence, we can write the expectations // in their natural order. {   InSequence s;   EXPECT_CALL(foo, Bar())       .WillOnce(Return(1))       .RetiresOnSaturation();   EXPECT_CALL(foo, Bar())       .WillOnce(Return(2))       .RetiresOnSaturation(); } ```
or you can put the sequence of actions in the same expectation:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time. EXPECT_CALL(foo, Bar())     .WillOnce(Return(1))     .WillOnce(Return(2))     .RetiresOnSaturation(); ```
Back to the original questions: why does Google Mock search the expectations (and `ON_CALL`s) from back to front?  Because this allows a user to set up a mock's behavior for the common case early (e.g. in the mock's constructor or the test fixture's set-up phase) and customize it with more specific rules later.  If Google Mock searches from front to back, this very useful pattern won't be possible.
When choosing between being neat and being safe, we lean toward the latter.  So the answer is that we think it's better to show the warning.
Often people write `ON_CALL`s in the mock object's constructor or `SetUp()`, as the default behavior rarely changes from test to test.  Then in the test body they set the expectations, which are often different for each test.  Having an `ON_CALL` in the set-up part of a test doesn't mean that the calls are expected.  If there's no `EXPECT_CALL` and the method is called, it's possibly an error.  If we quietly let the call go through without notifying the user, bugs may creep in unnoticed.
If, however, you are sure that the calls are OK, you can write
``` EXPECT_CALL(foo, Bar(_))     .WillRepeatedly(...); ```
instead of
``` ON_CALL(foo, Bar(_))     .WillByDefault(...); ```
This tells Google Mock that you do expect the calls and no warning should be printed.
Also, you can control the verbosity using the `--gmock_verbose` flag. If you find the output too noisy when debugging, just choose a less verbose level.
If you find yourself needing to perform some action that's not supported by Google Mock directly, remember that you can define your own actions using [MakeAction()](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Writing_New_Actions) or [MakePolymorphicAction()](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Writing_New_Polymorphic_Actions), or you can write a stub function and invoke it using [Invoke()](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Using_Functions_Methods_Functors).
What?!  I think it's beautiful. :-)
While which syntax looks more natural is a subjective matter to some extent, Google Mock's syntax was chosen for several practical advantages it has.
Try to mock a function that takes a map as an argument: ``` virtual int GetSize(const map<int, std::string>& m); ```
Using the proposed syntax, it would be: ``` MOCK_METHOD1(GetSize, int, const map<int, std::string>& m); ```
Guess what?  You'll get a compiler error as the compiler thinks that `const map<int, std::string>& m` are **two**, not one, arguments. To work around this you can use `typedef` to give the map type a name, but that gets in the way of your work.  Google Mock's syntax avoids this problem as the function's argument types are protected inside a pair of parentheses: ``` // This compiles fine. MOCK_METHOD1(GetSize, int(const map<int, std::string>& m)); ```
You still need a `typedef` if the return type contains an unprotected comma, but that's much rarer.
Other advantages include:   1. `MOCK_METHOD1(Foo, int, bool)` can leave a reader wonder whether the method returns `int` or `bool`, while there won't be such confusion using Google Mock's syntax.   1. The way Google Mock describes a function type is nothing new, although many people may not be familiar with it.  The same syntax was used in C, and the `function` library in `tr1` uses this syntax extensively.  Since `tr1` will become a part of the new version of STL, we feel very comfortable to be consistent with it.   1. The function type syntax is also used in other parts of Google Mock's API (e.g. the action interface) in order to make the implementation tractable. A user needs to learn it anyway in order to utilize Google Mock's more advanced features.  We'd as well stick to the same syntax in `MOCK_METHOD*`!
You can, but you need to make some changes.
In general, if you find yourself needing to mock a static function, it's a sign that your modules are too tightly coupled (and less flexible, less reusable, less testable, etc).  You are probably better off defining a small interface and call the function through that interface, which then can be easily mocked.  It's a bit of work initially, but usually pays for itself quickly.
This Google Testing Blog [post](http://googletesting.blogspot.com/2008/06/defeat-static-cling.html) says it excellently.  Check it out.
I know it's not a question, but you get an answer for free any way. :-)
With Google Mock, you can create mocks in C++ easily.  And people might be tempted to use them everywhere. Sometimes they work great, and sometimes you may find them, well, a pain to use. So, what's wrong in the latter case?
When you write a test without using mocks, you exercise the code and assert that it returns the correct value or that the system is in an expected state.  This is sometimes called "state-based testing".
Mocks are great for what some call "interaction-based" testing: instead of checking the system state at the very end, mock objects verify that they are invoked the right way and report an error as soon as it arises, giving you a handle on the precise context in which the error was triggered.  This is often more effective and economical to do than state-based testing.
If you are doing state-based testing and using a test double just to simulate the real object, you are probably better off using a fake. Using a mock in this case causes pain, as it's not a strong point for mocks to perform complex actions.  If you experience this and think that mocks suck, you are just not using the right tool for your problem. Or, you might be trying to solve the wrong problem. :-)
By all means, NO!  It's just an FYI.
What it means is that you have a mock function, you haven't set any expectations on it (by Google Mock's rule this means that you are not interested in calls to this function and therefore it can be called any number of times), and it is called.  That's OK - you didn't say it's not OK to call the function!
What if you actually meant to disallow this function to be called, but forgot to write `EXPECT_CALL(foo, Bar()).Times(0)`?  While one can argue that it's the user's fault, Google Mock tries to be nice and prints you a note.
So, when you see the message and believe that there shouldn't be any uninteresting calls, you should investigate what's going on.  To make your life easier, Google Mock prints the function name and arguments when an uninteresting call is encountered.
Either way is fine - you want to choose the one that's more convenient for your circumstance.
Usually, if your action is for a particular function type, defining it using `Invoke()` should be easier; if your action can be used in functions of different types (e.g. if you are defining `Return(value)`), `MakePolymorphicAction()` is easiest.  Sometimes you want precise control on what types of functions the action can be used in, and implementing `ActionInterface` is the way to go here. See the implementation of `Return()` in `include/gmock/gmock-actions.h` for an example.
You got this error as Google Mock has no idea what value it should return when the mock method is called.  `SetArgPointee()` says what the side effect is, but doesn't say what the return value should be.  You need `DoAll()` to chain a `SetArgPointee()` with a `Return()`.
See this [recipe](http://code.google.com/p/googlemock/wiki/V1_6_CookBook#Mocking_Side_Effects) for more details and an example.
If you cannot find the answer to your question in this FAQ, there are some other resources you can use:
1. read other [wiki pages](http://code.google.com/p/googlemock/w/list),   1. search the mailing list [archive](http://groups.google.com/group/googlemock/topics),   1. ask it on [googlemock@googlegroups.com](mailto:googlemock@googlegroups.com) and someone will answer it (to prevent spam, we require you to join the [discussion group](http://groups.google.com/group/googlemock) before you can post.).
Please note that creating an issue in the [issue tracker](http://code.google.com/p/googlemock/issues/list) is _not_ a good way to get your answer, as it is monitored infrequently by a very small number of people.
When asking a question, it's helpful to provide as much of the following information as possible (people cannot help you if there's not enough information in your question):
* the version (or the revision number if you check out from SVN directly) of Google Mock you use (Google Mock is under active development, so it's possible that your problem has been solved in a later version),   * your operating system,   * the name and version of your compiler,   * the complete command line flags you give to your compiler,   * the complete compiler error messages (if the question is about compilation),   * the _actual_ code (ideally, a minimal but complete program) that has the problem you encounter.

Given ``` class Foo {   ...   virtual ~Foo();   virtual int GetSize() const = 0;   virtual string Describe(const char* name) = 0;   virtual string Describe(int type) = 0;   virtual bool Process(Bar elem, int count) = 0; }; ``` (note that `~Foo()` **must** be virtual) we can define its mock as ``` #include "gmock/gmock.h"
class MockFoo : public Foo {   MOCK_CONST_METHOD0(GetSize, int());   MOCK_METHOD1(Describe, string(const char* name));   MOCK_METHOD1(Describe, string(int type));   MOCK_METHOD2(Process, bool(Bar elem, int count)); }; ```
To create a "nice" mock object which ignores all uninteresting calls, or a "strict" mock object, which treats them as failures: ``` NiceMock<MockFoo> nice_foo;     // The type is a subclass of MockFoo. StrictMock<MockFoo> strict_foo; // The type is a subclass of MockFoo. ```
To mock ``` template <typename Elem> class StackInterface {  public:   ...   virtual ~StackInterface();   virtual int GetSize() const = 0;   virtual void Push(const Elem& x) = 0; }; ``` (note that `~StackInterface()` **must** be virtual) just append `_T` to the `MOCK_*` macros: ``` template <typename Elem> class MockStack : public StackInterface<Elem> {  public:   ...   MOCK_CONST_METHOD0_T(GetSize, int());   MOCK_METHOD1_T(Push, void(const Elem& x)); }; ```
If your mock function doesn't use the default calling convention, you can specify it by appending `_WITH_CALLTYPE` to any of the macros described in the previous two sections and supplying the calling convention as the first argument to the macro. For example, ```   MOCK_METHOD_1_WITH_CALLTYPE(STDMETHODCALLTYPE, Foo, bool(int n));   MOCK_CONST_METHOD2_WITH_CALLTYPE(STDMETHODCALLTYPE, Bar, int(double x, double y)); ``` where `STDMETHODCALLTYPE` is defined by `<objbase.h>` on Windows.
The typical flow is:   1. Import the Google Mock names you need to use. All Google Mock names are in the `testing` namespace unless they are macros or otherwise noted.   1. Create the mock objects.   1. Optionally, set the default actions of the mock objects.   1. Set your expectations on the mock objects (How will they be called? What wil they do?).   1. Exercise code that uses the mock objects; if necessary, check the result using [Google Test](http://code.google.com/p/googletest/) assertions.   1. When a mock objects is destructed, Google Mock automatically verifies that all expectations on it have been satisfied.
Here is an example: ``` using ::testing::Return;                            // #1
TEST(BarTest, DoesThis) {   MockFoo foo;                                    // #2
ON_CALL(foo, GetSize())                         // #3       .WillByDefault(Return(1));   // ... other default actions ...
EXPECT_CALL(foo, Describe(5))                   // #4       .Times(3)       .WillRepeatedly(Return("Category 5"));   // ... other expectations ...
EXPECT_EQ("good", MyProductionFunction(&foo));  // #5 }                                                 // #6 ```
Google Mock has a **built-in default action** for any function that returns `void`, `bool`, a numeric value, or a pointer.
To customize the default action for functions with return type `T` globally: ``` using ::testing::DefaultValue;
DefaultValue<T>::Set(value);  // Sets the default value to be returned. // ... use the mocks ... DefaultValue<T>::Clear();     // Resets the default value. ```
To customize the default action for a particular method, use `ON_CALL()`: ``` ON_CALL(mock_object, method(matchers))     .With(multi_argument_matcher)  ?     .WillByDefault(action); ```
`EXPECT_CALL()` sets **expectations** on a mock method (How will it be called? What will it do?): ``` EXPECT_CALL(mock_object, method(matchers))     .With(multi_argument_matcher)  ?     .Times(cardinality)            ?     .InSequence(sequences)         *     .After(expectations)           *     .WillOnce(action)              *     .WillRepeatedly(action)        ?     .RetiresOnSaturation();        ? ```
If `Times()` is omitted, the cardinality is assumed to be:
* `Times(1)` when there is neither `WillOnce()` nor `WillRepeatedly()`;   * `Times(n)` when there are `n WillOnce()`s but no `WillRepeatedly()`, where `n` >= 1; or   * `Times(AtLeast(n))` when there are `n WillOnce()`s and a `WillRepeatedly()`, where `n` >= 0.
A method with no `EXPECT_CALL()` is free to be invoked _any number of times_, and the default action will be taken each time.
A **matcher** matches a _single_ argument.  You can use it inside `ON_CALL()` or `EXPECT_CALL()`, or use it to validate a value directly:
| `EXPECT_THAT(value, matcher)` | Asserts that `value` matches `matcher`. | |:------------------------------|:----------------------------------------| | `ASSERT_THAT(value, matcher)` | The same as `EXPECT_THAT(value, matcher)`, except that it generates a **fatal** failure. |
Built-in matchers (where `argument` is the function argument) are divided into several categories:
|`Eq(value)` or `value`|`argument == value`| |:---------------------|:------------------| |`Ge(value)`           |`argument >= value`| |`Gt(value)`           |`argument > value` | |`Le(value)`           |`argument <= value`| |`Lt(value)`           |`argument < value` | |`Ne(value)`           |`argument != value`| |`IsNull()`            |`argument` is a `NULL` pointer (raw or smart).| |`NotNull()`           |`argument` is a non-null pointer (raw or smart).| |`Ref(variable)`       |`argument` is a reference to `variable`.| |`TypedEq<type>(value)`|`argument` has type `type` and is equal to `value`. You may need to use this instead of `Eq(value)` when the mock function is overloaded.|
Except `Ref()`, these matchers make a _copy_ of `value` in case it's modified or destructed later. If the compiler complains that `value` doesn't have a public copy constructor, try wrap it in `ByRef()`, e.g. `Eq(ByRef(non_copyable_value))`. If you do that, make sure `non_copyable_value` is not changed afterwards, or the meaning of your matcher will be changed.
|`DoubleEq(a_double)`|`argument` is a `double` value approximately equal to `a_double`, treating two NaNs as unequal.| |:-------------------|:----------------------------------------------------------------------------------------------| |`FloatEq(a_float)`  |`argument` is a `float` value approximately equal to `a_float`, treating two NaNs as unequal.  | |`NanSensitiveDoubleEq(a_double)`|`argument` is a `double` value approximately equal to `a_double`, treating two NaNs as equal.  | |`NanSensitiveFloatEq(a_float)`|`argument` is a `float` value approximately equal to `a_float`, treating two NaNs as equal.    |
The above matchers use ULP-based comparison (the same as used in [Google Test](http://code.google.com/p/googletest/)). They automatically pick a reasonable error bound based on the absolute value of the expected value.  `DoubleEq()` and `FloatEq()` conform to the IEEE standard, which requires comparing two NaNs for equality to return false. The `NanSensitive*` version instead treats two NaNs as equal, which is often what a user wants.
|`DoubleNear(a_double, max_abs_error)`|`argument` is a `double` value close to `a_double` (absolute error <= `max_abs_error`), treating two NaNs as unequal.| |:------------------------------------|:--------------------------------------------------------------------------------------------------------------------| |`FloatNear(a_float, max_abs_error)`  |`argument` is a `float` value close to `a_float` (absolute error <= `max_abs_error`), treating two NaNs as unequal.  | |`NanSensitiveDoubleNear(a_double, max_abs_error)`|`argument` is a `double` value close to `a_double` (absolute error <= `max_abs_error`), treating two NaNs as equal.  | |`NanSensitiveFloatNear(a_float, max_abs_error)`|`argument` is a `float` value close to `a_float` (absolute error <= `max_abs_error`), treating two NaNs as equal.    |
The `argument` can be either a C string or a C++ string object:
|`ContainsRegex(string)`|`argument` matches the given regular expression.| |:----------------------|:-----------------------------------------------| |`EndsWith(suffix)`     |`argument` ends with string `suffix`.           | |`HasSubstr(string)`    |`argument` contains `string` as a sub-string.   | |`MatchesRegex(string)` |`argument` matches the given regular expression with the match starting at the first character and ending at the last character.| |`StartsWith(prefix)`   |`argument` starts with string `prefix`.         | |`StrCaseEq(string)`    |`argument` is equal to `string`, ignoring case. | |`StrCaseNe(string)`    |`argument` is not equal to `string`, ignoring case.| |`StrEq(string)`        |`argument` is equal to `string`.                | |`StrNe(string)`        |`argument` is not equal to `string`.            |
`ContainsRegex()` and `MatchesRegex()` use the regular expression syntax defined [here](http://code.google.com/p/googletest/wiki/AdvancedGuide#Regular_Expression_Syntax). `StrCaseEq()`, `StrCaseNe()`, `StrEq()`, and `StrNe()` work for wide strings as well.
Most STL-style containers support `==`, so you can use `Eq(expected_container)` or simply `expected_container` to match a container exactly.   If you want to write the elements in-line, match them more flexibly, or get more informative messages, you can use:
| `ContainerEq(container)` | The same as `Eq(container)` except that the failure message also includes which elements are in one container but not the other. | |:-------------------------|:---------------------------------------------------------------------------------------------------------------------------------| | `Contains(e)`            | `argument` contains an element that matches `e`, which can be either a value or a matcher.                                       | | `Each(e)`                | `argument` is a container where _every_ element matches `e`, which can be either a value or a matcher.                           | | `ElementsAre(e0, e1, ..., en)` | `argument` has `n + 1` elements, where the i-th element matches `ei`, which can be a value or a matcher. 0 to 10 arguments are allowed. | | `ElementsAreArray({ e0, e1, ..., en })`, `ElementsAreArray(array)`, or `ElementsAreArray(array, count)` | The same as `ElementsAre()` except that the expected element values/matchers come from an initializer list, vector, or C-style array. | | `IsEmpty()`              | `argument` is an empty container (`container.empty()`).                                                                          | | `Pointwise(m, container)` | `argument` contains the same number of elements as in `container`, and for all i, (the i-th element in `argument`, the i-th element in `container`) match `m`, which is a matcher on 2-tuples. E.g. `Pointwise(Le(), upper_bounds)` verifies that each element in `argument` doesn't exceed the corresponding element in `upper_bounds`. See more detail below. | | `SizeIs(m)`              | `argument` is a container whose size matches `m`. E.g. `SizeIs(2)` or `SizeIs(Lt(2))`.                                           | | `UnorderedElementsAre(e0, e1, ..., en)` | `argument` has `n + 1` elements, and under some permutation each element matches an `ei` (for a different `i`), which can be a value or a matcher. 0 to 10 arguments are allowed. | | `UnorderedElementsAreArray({ e0, e1, ..., en })`, `UnorderedElementsAreArray(array)`, or `UnorderedElementsAreArray(array, count)` | The same as `UnorderedElementsAre()` except that the expected element values/matchers come from an initializer list, vector, or C-style array. | | `WhenSorted(m)`          | When `argument` is sorted using the `<` operator, it matches container matcher `m`. E.g. `WhenSorted(UnorderedElementsAre(1, 2, 3))` verifies that `argument` contains elements `1`, `2`, and `3`, ignoring order. | | `WhenSortedBy(comparator, m)` | The same as `WhenSorted(m)`, except that the given comparator instead of `<` is used to sort `argument`. E.g. `WhenSortedBy(std::greater<int>(), ElementsAre(3, 2, 1))`. |
Notes:
* These matchers can also match:     1. a native array passed by reference (e.g. in `Foo(const int (&a)[5])`), and     1. an array passed as a pointer and a count (e.g. in `Bar(const T* buffer, int len)` -- see [Multi-argument Matchers](#Multiargument_Matchers.md)).   * The array being matched may be multi-dimensional (i.e. its elements can be arrays).   * `m` in `Pointwise(m, ...)` should be a matcher for `std::tr1::tuple<T, U>` where `T` and `U` are the element type of the actual container and the expected container, respectively. For example, to compare two `Foo` containers where `Foo` doesn't support `operator==` but has an `Equals()` method, one might write:
``` using ::std::tr1::get; MATCHER(FooEq, "") {   return get<0>(arg).Equals(get<1>(arg)); } ... EXPECT_THAT(actual_foos, Pointwise(FooEq(), expected_foos)); ```
|`Field(&class::field, m)`|`argument.field` (or `argument->field` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_.| |:------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------| |`Key(e)`                 |`argument.first` matches `e`, which can be either a value or a matcher. E.g. `Contains(Key(Le(5)))` can verify that a `map` contains a key `<= 5`.| |`Pair(m1, m2)`           |`argument` is an `std::pair` whose `first` field matches `m1` and `second` field matches `m2`.                                                | |`Property(&class::property, m)`|`argument.property()` (or `argument->property()` when `argument` is a plain pointer) matches matcher `m`, where `argument` is an object of type _class_.|
|`ResultOf(f, m)`|`f(argument)` matches matcher `m`, where `f` is a function or functor.| |:---------------|:---------------------------------------------------------------------|
|`Pointee(m)`|`argument` (either a smart pointer or a raw pointer) points to a value that matches matcher `m`.| |:-----------|:-----------------------------------------------------------------------------------------------|
Technically, all matchers match a _single_ value. A "multi-argument" matcher is just one that matches a _tuple_. The following matchers can be used to match a tuple `(x, y)`:
|`Eq()`|`x == y`| |:-----|:-------| |`Ge()`|`x >= y`| |`Gt()`|`x > y` | |`Le()`|`x <= y`| |`Lt()`|`x < y` | |`Ne()`|`x != y`|
You can use the following selectors to pick a subset of the arguments (or reorder them) to participate in the matching:
|`AllArgs(m)`|Equivalent to `m`. Useful as syntactic sugar in `.With(AllArgs(m))`.| |:-----------|:-------------------------------------------------------------------| |`Args<N1, N2, ..., Nk>(m)`|The tuple of the `k` selected (using 0-based indices) arguments matches `m`, e.g. `Args<1, 2>(Eq())`.|
You can make a matcher from one or more other matchers:
|`AllOf(m1, m2, ..., mn)`|`argument` matches all of the matchers `m1` to `mn`.| |:-----------------------|:---------------------------------------------------| |`AnyOf(m1, m2, ..., mn)`|`argument` matches at least one of the matchers `m1` to `mn`.| |`Not(m)`                |`argument` doesn't match matcher `m`.               |
|`MatcherCast<T>(m)`|casts matcher `m` to type `Matcher<T>`.| |:------------------|:--------------------------------------| |`SafeMatcherCast<T>(m)`| [safely casts](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Casting_Matchers) matcher `m` to type `Matcher<T>`. | |`Truly(predicate)` |`predicate(argument)` returns something considered by C++ to be true, where `predicate` is a function or functor.|
|`Matches(m)(value)`|evaluates to `true` if `value` matches `m`. You can use `Matches(m)` alone as a unary functor.| |:------------------|:---------------------------------------------------------------------------------------------| |`ExplainMatchResult(m, value, result_listener)`|evaluates to `true` if `value` matches `m`, explaining the result to `result_listener`.       | |`Value(value, m)`  |evaluates to `true` if `value` matches `m`.                                                   |
| `MATCHER(IsEven, "") { return (arg % 2) == 0; }` | Defines a matcher `IsEven()` to match an even number. | |:-------------------------------------------------|:------------------------------------------------------| | `MATCHER_P(IsDivisibleBy, n, "") { *result_listener << "where the remainder is " << (arg % n); return (arg % n) == 0; }` | Defines a macher `IsDivisibleBy(n)` to match a number divisible by `n`. | | `MATCHER_P2(IsBetween, a, b, std::string(negation ? "isn't" : "is") + " between " + PrintToString(a) + " and " + PrintToString(b)) { return a <= arg && arg <= b; }` | Defines a matcher `IsBetween(a, b)` to match a value in the range [`a`, `b`]. |
**Notes:**
1. The `MATCHER*` macros cannot be used inside a function or class.   1. The matcher body must be _purely functional_ (i.e. it cannot have any side effect, and the result must not depend on anything other than the value being matched and the matcher parameters).   1. You can use `PrintToString(x)` to convert a value `x` of any type to a string.
|`ASSERT_THAT(expression, m)`|Generates a [fatal failure](http://code.google.com/p/googletest/wiki/Primer#Assertions) if the value of `expression` doesn't match matcher `m`.| |:---------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------| |`EXPECT_THAT(expression, m)`|Generates a non-fatal failure if the value of `expression` doesn't match matcher `m`.                                                          |
**Actions** specify what a mock function should do when invoked.
|`Return()`|Return from a `void` mock function.| |:---------|:----------------------------------| |`Return(value)`|Return `value`. If the type of `value` is different to the mock function's return type, `value` is converted to the latter type <i>at the time the expectation is set</i>, not when the action is executed.| |`ReturnArg<N>()`|Return the `N`-th (0-based) argument.| |`ReturnNew<T>(a1, ..., ak)`|Return `new T(a1, ..., ak)`; a different object is created each time.| |`ReturnNull()`|Return a null pointer.             | |`ReturnPointee(ptr)`|Return the value pointed to by `ptr`.| |`ReturnRef(variable)`|Return a reference to `variable`.  | |`ReturnRefOfCopy(value)`|Return a reference to a copy of `value`; the copy lives as long as the action.|
|`Assign(&variable, value)`|Assign `value` to variable.| |:-------------------------|:--------------------------| | `DeleteArg<N>()`         | Delete the `N`-th (0-based) argument, which must be a pointer. | | `SaveArg<N>(pointer)`    | Save the `N`-th (0-based) argument to `*pointer`. | | `SaveArgPointee<N>(pointer)` | Save the value pointed to by the `N`-th (0-based) argument to `*pointer`. | | `SetArgReferee<N>(value)` |	Assign value to the variable referenced by the `N`-th (0-based) argument. | |`SetArgPointee<N>(value)` |Assign `value` to the variable pointed by the `N`-th (0-based) argument.| |`SetArgumentPointee<N>(value)`|Same as `SetArgPointee<N>(value)`. Deprecated. Will be removed in v1.7.0.| |`SetArrayArgument<N>(first, last)`|Copies the elements in source range [`first`, `last`) to the array pointed to by the `N`-th (0-based) argument, which can be either a pointer or an iterator. The action does not take ownership of the elements in the source range.| |`SetErrnoAndReturn(error, value)`|Set `errno` to `error` and return `value`.| |`Throw(exception)`        |Throws the given exception, which can be any copyable value. Available since v1.1.0.|
|`Invoke(f)`|Invoke `f` with the arguments passed to the mock function, where `f` can be a global/static function or a functor.| |:----------|:-----------------------------------------------------------------------------------------------------------------| |`Invoke(object_pointer, &class::method)`|Invoke the {method on the object with the arguments passed to the mock function.                                  | |`InvokeWithoutArgs(f)`|Invoke `f`, which can be a global/static function or a functor. `f` must take no arguments.                       | |`InvokeWithoutArgs(object_pointer, &class::method)`|Invoke the method on the object, which takes no arguments.                                                        | |`InvokeArgument<N>(arg1, arg2, ..., argk)`|Invoke the mock function's `N`-th (0-based) argument, which must be a function or a functor, with the `k` arguments.|
The return value of the invoked function is used as the return value of the action.
When defining a function or functor to be used with `Invoke*()`, you can declare any unused parameters as `Unused`: ```   double Distance(Unused, double x, double y) { return sqrt(x*x + y*y); }   ...   EXPECT_CALL(mock, Foo("Hi", _, _)).WillOnce(Invoke(Distance)); ```
In `InvokeArgument<N>(...)`, if an argument needs to be passed by reference, wrap it inside `ByRef()`. For example, ```   InvokeArgument<2>(5, string("Hi"), ByRef(foo)) ``` calls the mock function's #2 argument, passing to it `5` and `string("Hi")` by value, and `foo` by reference.
|`DoDefault()`|Do the default action (specified by `ON_CALL()` or the built-in one).| |:------------|:--------------------------------------------------------------------|
**Note:** due to technical reasons, `DoDefault()` cannot be used inside  a composite action - trying to do so will result in a run-time error.
|`DoAll(a1, a2, ..., an)`|Do all actions `a1` to `an` and return the result of `an` in each invocation. The first `n - 1` sub-actions must return void. | |:-----------------------|:-----------------------------------------------------------------------------------------------------------------------------| |`IgnoreResult(a)`       |Perform action `a` and ignore its result. `a` must not return void.                                                           | |`WithArg<N>(a)`         |Pass the `N`-th (0-based) argument of the mock function to action `a` and perform it.                                         | |`WithArgs<N1, N2, ..., Nk>(a)`|Pass the selected (0-based) arguments of the mock function to action `a` and perform it.                                      | |`WithoutArgs(a)`        |Perform action `a` without any arguments.                                                                                     |
| `ACTION(Sum) { return arg0 + arg1; }` | Defines an action `Sum()` to return the sum of the mock function's argument #0 and #1. | |:--------------------------------------|:---------------------------------------------------------------------------------------| | `ACTION_P(Plus, n) { return arg0 + n; }` | Defines an action `Plus(n)` to return the sum of the mock function's argument #0 and `n`. | | `ACTION_Pk(Foo, p1, ..., pk) { statements; }` | Defines a parameterized action `Foo(p1, ..., pk)` to execute the given `statements`.   |
The `ACTION*` macros cannot be used inside a function or class.
These are used in `Times()` to specify how many times a mock function will be called:
|`AnyNumber()`|The function can be called any number of times.| |:------------|:----------------------------------------------| |`AtLeast(n)` |The call is expected at least `n` times.       | |`AtMost(n)`  |The call is expected at most `n` times.        | |`Between(m, n)`|The call is expected between `m` and `n` (inclusive) times.| |`Exactly(n) or n`|The call is expected exactly `n` times. In particular, the call should never happen when `n` is 0.|
By default, the expectations can be matched in _any_ order.  If some or all expectations must be matched in a given order, there are two ways to specify it.  They can be used either independently or together.
``` using ::testing::Expectation; ... Expectation init_x = EXPECT_CALL(foo, InitX()); Expectation init_y = EXPECT_CALL(foo, InitY()); EXPECT_CALL(foo, Bar())     .After(init_x, init_y); ``` says that `Bar()` can be called only after both `InitX()` and `InitY()` have been called.
If you don't know how many pre-requisites an expectation has when you write it, you can use an `ExpectationSet` to collect them:
``` using ::testing::ExpectationSet; ... ExpectationSet all_inits; for (int i = 0; i < element_count; i++) {   all_inits += EXPECT_CALL(foo, InitElement(i)); } EXPECT_CALL(foo, Bar())     .After(all_inits); ``` says that `Bar()` can be called only after all elements have been initialized (but we don't care about which elements get initialized before the others).
Modifying an `ExpectationSet` after using it in an `.After()` doesn't affect the meaning of the `.After()`.
When you have a long chain of sequential expectations, it's easier to specify the order using **sequences**, which don't require you to given each expectation in the chain a different name.  <i>All expected<br> calls</i> in the same sequence must occur in the order they are specified.
``` using ::testing::Sequence; Sequence s1, s2; ... EXPECT_CALL(foo, Reset())     .InSequence(s1, s2)     .WillOnce(Return(true)); EXPECT_CALL(foo, GetSize())     .InSequence(s1)     .WillOnce(Return(1)); EXPECT_CALL(foo, Describe(A<const char*>()))     .InSequence(s2)     .WillOnce(Return("dummy")); ``` says that `Reset()` must be called before _both_ `GetSize()` _and_ `Describe()`, and the latter two can occur in any order.
To put many expectations in a sequence conveniently: ``` using ::testing::InSequence; {   InSequence dummy;
EXPECT_CALL(...)...;   EXPECT_CALL(...)...;   ...   EXPECT_CALL(...)...; } ``` says that all expected calls in the scope of `dummy` must occur in strict order. The name `dummy` is irrelevant.)
Google Mock will verify the expectations on a mock object when it is destructed, or you can do it earlier: ``` using ::testing::Mock; ... // Verifies and removes the expectations on mock_obj; // returns true iff successful. Mock::VerifyAndClearExpectations(&mock_obj); ... // Verifies and removes the expectations on mock_obj; // also removes the default actions set by ON_CALL(); // returns true iff successful. Mock::VerifyAndClear(&mock_obj); ```
You can also tell Google Mock that a mock object can be leaked and doesn't need to be verified: ``` Mock::AllowLeak(&mock_obj); ```
Google Mock defines a convenient mock class template ``` class MockFunction<R(A1, ..., An)> {  public:   MOCK_METHODn(Call, R(A1, ..., An)); }; ``` See this [recipe](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Using_Check_Points) for one application of it.
| `--gmock_catch_leaked_mocks=0` | Don't report leaked mock objects as failures. | |:-------------------------------|:----------------------------------------------| | `--gmock_verbose=LEVEL`        | Sets the default verbosity level (`info`, `warning`, or `error`) of Google Mock messages. |

You can find recipes for using Google Mock here. If you haven't yet, please read the [ForDummies](V1_7_ForDummies.md) document first to make sure you understand the basics.
**Note:** Google Mock lives in the `testing` name space. For readability, it is recommended to write `using ::testing::Foo;` once in your file before using the name `Foo` defined by Google Mock. We omit such `using` statements in this page for brevity, but you should do it in your own code.
You must always put a mock method definition (`MOCK_METHOD*`) in a `public:` section of the mock class, regardless of the method being mocked being `public`, `protected`, or `private` in the base class. This allows `ON_CALL` and `EXPECT_CALL` to reference the mock function from outside of the mock class.  (Yes, C++ allows a subclass to change the access level of a virtual function in the base class.)  Example:
``` class Foo {  public:   ...   virtual bool Transform(Gadget* g) = 0;
protected:   virtual void Resume();
private:   virtual int GetTimeOut(); };
class MockFoo : public Foo {  public:   ...   MOCK_METHOD1(Transform, bool(Gadget* g));
// The following must be in the public section, even though the   // methods are protected or private in the base class.   MOCK_METHOD0(Resume, void());   MOCK_METHOD0(GetTimeOut, int()); }; ```
You can mock overloaded functions as usual. No special attention is required:
``` class Foo {   ...
// Must be virtual as we'll inherit from Foo.   virtual ~Foo();
// Overloaded on the types and/or numbers of arguments.   virtual int Add(Element x);   virtual int Add(int times, Element x);
// Overloaded on the const-ness of this object.   virtual Bar& GetBar();   virtual const Bar& GetBar() const; };
class MockFoo : public Foo {   ...   MOCK_METHOD1(Add, int(Element x));   MOCK_METHOD2(Add, int(int times, Element x);
MOCK_METHOD0(GetBar, Bar&());   MOCK_CONST_METHOD0(GetBar, const Bar&()); }; ```
**Note:** if you don't mock all versions of the overloaded method, the compiler will give you a warning about some methods in the base class being hidden. To fix that, use `using` to bring them in scope:
``` class MockFoo : public Foo {   ...   using Foo::Add;   MOCK_METHOD1(Add, int(Element x));   // We don't want to mock int Add(int times, Element x);   ... }; ```
To mock a class template, append `_T` to the `MOCK_*` macros:
``` template <typename Elem> class StackInterface {   ...   // Must be virtual as we'll inherit from StackInterface.   virtual ~StackInterface();
virtual int GetSize() const = 0;   virtual void Push(const Elem& x) = 0; };
template <typename Elem> class MockStack : public StackInterface<Elem> {   ...   MOCK_CONST_METHOD0_T(GetSize, int());   MOCK_METHOD1_T(Push, void(const Elem& x)); }; ```
Google Mock can mock non-virtual functions to be used in what we call _hi-perf dependency injection_.
In this case, instead of sharing a common base class with the real class, your mock class will be _unrelated_ to the real class, but contain methods with the same signatures.  The syntax for mocking non-virtual methods is the _same_ as mocking virtual methods:
``` // A simple packet stream class.  None of its members is virtual. class ConcretePacketStream {  public:   void AppendPacket(Packet* new_packet);   const Packet* GetPacket(size_t packet_number) const;   size_t NumberOfPackets() const;   ... };
// A mock packet stream class.  It inherits from no other, but defines // GetPacket() and NumberOfPackets(). class MockPacketStream {  public:   MOCK_CONST_METHOD1(GetPacket, const Packet*(size_t packet_number));   MOCK_CONST_METHOD0(NumberOfPackets, size_t());   ... }; ```
Note that the mock class doesn't define `AppendPacket()`, unlike the real class. That's fine as long as the test doesn't need to call it.
Next, you need a way to say that you want to use `ConcretePacketStream` in production code, and use `MockPacketStream` in tests.  Since the functions are not virtual and the two classes are unrelated, you must specify your choice at _compile time_ (as opposed to run time).
One way to do it is to templatize your code that needs to use a packet stream.  More specifically, you will give your code a template type argument for the type of the packet stream.  In production, you will instantiate your template with `ConcretePacketStream` as the type argument.  In tests, you will instantiate the same template with `MockPacketStream`.  For example, you may write:
``` template <class PacketStream> void CreateConnection(PacketStream* stream) { ... }
template <class PacketStream> class PacketReader {  public:   void ReadPackets(PacketStream* stream, size_t packet_num); }; ```
Then you can use `CreateConnection<ConcretePacketStream>()` and `PacketReader<ConcretePacketStream>` in production code, and use `CreateConnection<MockPacketStream>()` and `PacketReader<MockPacketStream>` in tests.
```   MockPacketStream mock_stream;   EXPECT_CALL(mock_stream, ...)...;   .. set more expectations on mock_stream ...   PacketReader<MockPacketStream> reader(&mock_stream);   ... exercise reader ... ```
It's possible to use Google Mock to mock a free function (i.e. a C-style function or a static method).  You just need to rewrite your code to use an interface (abstract class).
Instead of calling a free function (say, `OpenFile`) directly, introduce an interface for it and have a concrete subclass that calls the free function:
``` class FileInterface {  public:   ...   virtual bool Open(const char* path, const char* mode) = 0; };
class File : public FileInterface {  public:   ...   virtual bool Open(const char* path, const char* mode) {     return OpenFile(path, mode);   } }; ```
Your code should talk to `FileInterface` to open a file.  Now it's easy to mock out the function.
This may seem much hassle, but in practice you often have multiple related functions that you can put in the same interface, so the per-function syntactic overhead will be much lower.
If you are concerned about the performance overhead incurred by virtual functions, and profiling confirms your concern, you can combine this with the recipe for [mocking non-virtual methods](#Mocking_Nonvirtual_Methods.md).
If a mock method has no `EXPECT_CALL` spec but is called, Google Mock will print a warning about the "uninteresting call". The rationale is:
* New methods may be added to an interface after a test is written. We shouldn't fail a test just because a method it doesn't know about is called.   * However, this may also mean there's a bug in the test, so Google Mock shouldn't be silent either. If the user believes these calls are harmless, he can add an `EXPECT_CALL()` to suppress the warning.
However, sometimes you may want to suppress all "uninteresting call" warnings, while sometimes you may want the opposite, i.e. to treat all of them as errors. Google Mock lets you make the decision on a per-mock-object basis.
Suppose your test uses a mock class `MockFoo`:
``` TEST(...) {   MockFoo mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
If a method of `mock_foo` other than `DoThis()` is called, it will be reported by Google Mock as a warning. However, if you rewrite your test to use `NiceMock<MockFoo>` instead, the warning will be gone, resulting in a cleaner test output:
``` using ::testing::NiceMock;
TEST(...) {   NiceMock<MockFoo> mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
`NiceMock<MockFoo>` is a subclass of `MockFoo`, so it can be used wherever `MockFoo` is accepted.
It also works if `MockFoo`'s constructor takes some arguments, as `NiceMock<MockFoo>` "inherits" `MockFoo`'s constructors:
``` using ::testing::NiceMock;
TEST(...) {   NiceMock<MockFoo> mock_foo(5, "hi");  // Calls MockFoo(5, "hi").   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ... } ```
The usage of `StrictMock` is similar, except that it makes all uninteresting calls failures:
``` using ::testing::StrictMock;
TEST(...) {   StrictMock<MockFoo> mock_foo;   EXPECT_CALL(mock_foo, DoThis());   ... code that uses mock_foo ...
// The test will fail if a method of mock_foo other than DoThis()   // is called. } ```
There are some caveats though (I don't like them just as much as the next guy, but sadly they are side effects of C++'s limitations):
1. `NiceMock<MockFoo>` and `StrictMock<MockFoo>` only work for mock methods defined using the `MOCK_METHOD*` family of macros **directly** in the `MockFoo` class. If a mock method is defined in a **base class** of `MockFoo`, the "nice" or "strict" modifier may not affect it, depending on the compiler. In particular, nesting `NiceMock` and `StrictMock` (e.g. `NiceMock<StrictMock<MockFoo> >`) is **not** supported.   1. The constructors of the base mock (`MockFoo`) cannot have arguments passed by non-const reference, which happens to be banned by the [Google C++ style guide](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml).   1. During the constructor or destructor of `MockFoo`, the mock object is _not_ nice or strict.  This may cause surprises if the constructor or destructor calls a mock method on `this` object. (This behavior, however, is consistent with C++'s general rule: if a constructor or destructor calls a virtual method of `this` object, that method is treated as non-virtual.  In other words, to the base class's constructor or destructor, `this` object behaves like an instance of the base class, not the derived class.  This rule is required for safety.  Otherwise a base constructor may use members of a derived class before they are initialized, or a base destructor may use members of a derived class after they have been destroyed.)
Finally, you should be **very cautious** about when to use naggy or strict mocks, as they tend to make tests more brittle and harder to maintain. When you refactor your code without changing its externally visible behavior, ideally you should't need to update any tests. If your code interacts with a naggy mock, however, you may start to get spammed with warnings as the result of your change. Worse, if your code interacts with a strict mock, your tests may start to fail and you'll be forced to fix them. Our general recommendation is to use nice mocks (not yet the default) most of the time, use naggy mocks (the current default) when developing or debugging tests, and use strict mocks only as the last resort.
Sometimes a method has a long list of arguments that is mostly uninteresting. For example,
``` class LogSink {  public:   ...   virtual void send(LogSeverity severity, const char* full_filename,                     const char* base_filename, int line,                     const struct tm* tm_time,                     const char* message, size_t message_len) = 0; }; ```
This method's argument list is lengthy and hard to work with (let's say that the `message` argument is not even 0-terminated). If we mock it as is, using the mock will be awkward. If, however, we try to simplify this interface, we'll need to fix all clients depending on it, which is often infeasible.
The trick is to re-dispatch the method in the mock class:
``` class ScopedMockLog : public LogSink {  public:   ...   virtual void send(LogSeverity severity, const char* full_filename,                     const char* base_filename, int line, const tm* tm_time,                     const char* message, size_t message_len) {     // We are only interested in the log severity, full file name, and     // log message.     Log(severity, full_filename, std::string(message, message_len));   }
// Implements the mock method:   //   //   void Log(LogSeverity severity,   //            const string& file_path,   //            const string& message);   MOCK_METHOD3(Log, void(LogSeverity severity, const string& file_path,                          const string& message)); }; ```
By defining a new mock method with a trimmed argument list, we make the mock class much more user-friendly.
Often you may find yourself using classes that don't implement interfaces. In order to test your code that uses such a class (let's call it `Concrete`), you may be tempted to make the methods of `Concrete` virtual and then mock it.
Try not to do that.
Making a non-virtual function virtual is a big decision. It creates an extension point where subclasses can tweak your class' behavior. This weakens your control on the class because now it's harder to maintain the class' invariants. You should make a function virtual only when there is a valid reason for a subclass to override it.
Mocking concrete classes directly is problematic as it creates a tight coupling between the class and the tests - any small change in the class may invalidate your tests and make test maintenance a pain.
To avoid such problems, many programmers have been practicing "coding to interfaces": instead of talking to the `Concrete` class, your code would define an interface and talk to it. Then you implement that interface as an adaptor on top of `Concrete`. In tests, you can easily mock that interface to observe how your code is doing.
This technique incurs some overhead:
* You pay the cost of virtual function calls (usually not a problem).   * There is more abstraction for the programmers to learn.
However, it can also bring significant benefits in addition to better testability:
* `Concrete`'s API may not fit your problem domain very well, as you may not be the only client it tries to serve. By designing your own interface, you have a chance to tailor it to your need - you may add higher-level functionalities, rename stuff, etc instead of just trimming the class. This allows you to write your code (user of the interface) in a more natural way, which means it will be more readable, more maintainable, and you'll be more productive.   * If `Concrete`'s implementation ever has to change, you don't have to rewrite everywhere it is used. Instead, you can absorb the change in your implementation of the interface, and your other code and tests will be insulated from this change.
Some people worry that if everyone is practicing this technique, they will end up writing lots of redundant code. This concern is totally understandable. However, there are two reasons why it may not be the case:
* Different projects may need to use `Concrete` in different ways, so the best interfaces for them will be different. Therefore, each of them will have its own domain-specific interface on top of `Concrete`, and they will not be the same code.   * If enough projects want to use the same interface, they can always share it, just like they have been sharing `Concrete`. You can check in the interface and the adaptor somewhere near `Concrete` (perhaps in a `contrib` sub-directory) and let many projects use it.
You need to weigh the pros and cons carefully for your particular problem, but I'd like to assure you that the Java community has been practicing this for a long time and it's a proven effective technique applicable in a wide variety of situations. :-)
Some times you have a non-trivial fake implementation of an interface. For example:
``` class Foo {  public:   virtual ~Foo() {}   virtual char DoThis(int n) = 0;   virtual void DoThat(const char* s, int* p) = 0; };
class FakeFoo : public Foo {  public:   virtual char DoThis(int n) {     return (n > 0) ? '+' :         (n < 0) ? '-' : '0';   }
virtual void DoThat(const char* s, int* p) {     *p = strlen(s);   } }; ```
Now you want to mock this interface such that you can set expectations on it. However, you also want to use `FakeFoo` for the default behavior, as duplicating it in the mock object is, well, a lot of work.
When you define the mock class using Google Mock, you can have it delegate its default action to a fake class you already have, using this pattern:
``` using ::testing::_; using ::testing::Invoke;
class MockFoo : public Foo {  public:   // Normal mock method definitions using Google Mock.   MOCK_METHOD1(DoThis, char(int n));   MOCK_METHOD2(DoThat, void(const char* s, int* p));
// Delegates the default actions of the methods to a FakeFoo object.   // This must be called *before* the custom ON_CALL() statements.   void DelegateToFake() {     ON_CALL(*this, DoThis(_))         .WillByDefault(Invoke(&fake_, &FakeFoo::DoThis));     ON_CALL(*this, DoThat(_, _))         .WillByDefault(Invoke(&fake_, &FakeFoo::DoThat));   }  private:   FakeFoo fake_;  // Keeps an instance of the fake in the mock. }; ```
With that, you can use `MockFoo` in your tests as usual. Just remember that if you don't explicitly set an action in an `ON_CALL()` or `EXPECT_CALL()`, the fake will be called upon to do it:
``` using ::testing::_;
TEST(AbcTest, Xyz) {   MockFoo foo;   foo.DelegateToFake(); // Enables the fake for delegation.
// Put your ON_CALL(foo, ...)s here, if any.
// No action specified, meaning to use the default action.   EXPECT_CALL(foo, DoThis(5));   EXPECT_CALL(foo, DoThat(_, _));
int n = 0;   EXPECT_EQ('+', foo.DoThis(5));  // FakeFoo::DoThis() is invoked.   foo.DoThat("Hi", &n);           // FakeFoo::DoThat() is invoked.   EXPECT_EQ(2, n); } ```
**Some tips:**
* If you want, you can still override the default action by providing your own `ON_CALL()` or using `.WillOnce()` / `.WillRepeatedly()` in `EXPECT_CALL()`.   * In `DelegateToFake()`, you only need to delegate the methods whose fake implementation you intend to use.   * The general technique discussed here works for overloaded methods, but you'll need to tell the compiler which version you mean. To disambiguate a mock function (the one you specify inside the parentheses of `ON_CALL()`), see the "Selecting Between Overloaded Functions" section on this page; to disambiguate a fake function (the one you place inside `Invoke()`), use a `static_cast` to specify the function's type. For instance, if class `Foo` has methods `char DoThis(int n)` and `bool DoThis(double x) const`, and you want to invoke the latter, you need to write `Invoke(&fake_, static_cast<bool (FakeFoo::*)(double) const>(&FakeFoo::DoThis))` instead of `Invoke(&fake_, &FakeFoo::DoThis)` (The strange-looking thing inside the angled brackets of `static_cast` is the type of a function pointer to the second `DoThis()` method.).   * Having to mix a mock and a fake is often a sign of something gone wrong. Perhaps you haven't got used to the interaction-based way of testing yet. Or perhaps your interface is taking on too many roles and should be split up. Therefore, **don't abuse this**. We would only recommend to do it as an intermediate step when you are refactoring your code.
Regarding the tip on mixing a mock and a fake, here's an example on why it may be a bad sign: Suppose you have a class `System` for low-level system operations. In particular, it does file and I/O operations. And suppose you want to test how your code uses `System` to do I/O, and you just want the file operations to work normally. If you mock out the entire `System` class, you'll have to provide a fake implementation for the file operation part, which suggests that `System` is taking on too many roles.
Instead, you can define a `FileOps` interface and an `IOOps` interface and split `System`'s functionalities into the two. Then you can mock `IOOps` without mocking `FileOps`.
When using testing doubles (mocks, fakes, stubs, and etc), sometimes their behaviors will differ from those of the real objects. This difference could be either intentional (as in simulating an error such that you can test the error handling code) or unintentional. If your mocks have different behaviors than the real objects by mistake, you could end up with code that passes the tests but fails in production.
You can use the _delegating-to-real_ technique to ensure that your mock has the same behavior as the real object while retaining the ability to validate calls. This technique is very similar to the delegating-to-fake technique, the difference being that we use a real object instead of a fake. Here's an example:
``` using ::testing::_; using ::testing::AtLeast; using ::testing::Invoke;
class MockFoo : public Foo {  public:   MockFoo() {     // By default, all calls are delegated to the real object.     ON_CALL(*this, DoThis())         .WillByDefault(Invoke(&real_, &Foo::DoThis));     ON_CALL(*this, DoThat(_))         .WillByDefault(Invoke(&real_, &Foo::DoThat));     ...   }   MOCK_METHOD0(DoThis, ...);   MOCK_METHOD1(DoThat, ...);   ...  private:   Foo real_; }; ...
MockFoo mock;
EXPECT_CALL(mock, DoThis())       .Times(3);   EXPECT_CALL(mock, DoThat("Hi"))       .Times(AtLeast(1));   ... use mock in test ... ```
With this, Google Mock will verify that your code made the right calls (with the right arguments, in the right order, called the right number of times, etc), and a real object will answer the calls (so the behavior will be the same as in production). This gives you the best of both worlds.
Ideally, you should code to interfaces, whose methods are all pure virtual. In reality, sometimes you do need to mock a virtual method that is not pure (i.e, it already has an implementation). For example:
``` class Foo {  public:   virtual ~Foo();
virtual void Pure(int n) = 0;   virtual int Concrete(const char* str) { ... } };
class MockFoo : public Foo {  public:   // Mocking a pure method.   MOCK_METHOD1(Pure, void(int n));   // Mocking a concrete method.  Foo::Concrete() is shadowed.   MOCK_METHOD1(Concrete, int(const char* str)); }; ```
Sometimes you may want to call `Foo::Concrete()` instead of `MockFoo::Concrete()`. Perhaps you want to do it as part of a stub action, or perhaps your test doesn't need to mock `Concrete()` at all (but it would be oh-so painful to have to define a new mock class whenever you don't need to mock one of its methods).
The trick is to leave a back door in your mock class for accessing the real methods in the base class:
``` class MockFoo : public Foo {  public:   // Mocking a pure method.   MOCK_METHOD1(Pure, void(int n));   // Mocking a concrete method.  Foo::Concrete() is shadowed.   MOCK_METHOD1(Concrete, int(const char* str));
// Use this to call Concrete() defined in Foo.   int FooConcrete(const char* str) { return Foo::Concrete(str); } }; ```
Now, you can call `Foo::Concrete()` inside an action by:
``` using ::testing::_; using ::testing::Invoke; ...   EXPECT_CALL(foo, Concrete(_))       .WillOnce(Invoke(&foo, &MockFoo::FooConcrete)); ```
or tell the mock object that you don't want to mock `Concrete()`:
``` using ::testing::Invoke; ...   ON_CALL(foo, Concrete(_))       .WillByDefault(Invoke(&foo, &MockFoo::FooConcrete)); ```
(Why don't we just write `Invoke(&foo, &Foo::Concrete)`? If you do that, `MockFoo::Concrete()` will be called (and cause an infinite recursion) since `Foo::Concrete()` is virtual. That's just how C++ works.)
You can specify exactly which arguments a mock method is expecting:
``` using ::testing::Return; ...   EXPECT_CALL(foo, DoThis(5))       .WillOnce(Return('a'));   EXPECT_CALL(foo, DoThat("Hello", bar)); ```
You can use matchers to match arguments that have a certain property:
``` using ::testing::Ge; using ::testing::NotNull; using ::testing::Return; ...   EXPECT_CALL(foo, DoThis(Ge(5)))  // The argument must be >= 5.       .WillOnce(Return('a'));   EXPECT_CALL(foo, DoThat("Hello", NotNull()));   // The second argument must not be NULL. ```
A frequently used matcher is `_`, which matches anything:
``` using ::testing::_; using ::testing::NotNull; ...   EXPECT_CALL(foo, DoThat(_, NotNull())); ```
You can build complex matchers from existing ones using `AllOf()`, `AnyOf()`, and `Not()`:
``` using ::testing::AllOf; using ::testing::Gt; using ::testing::HasSubstr; using ::testing::Ne; using ::testing::Not; ...   // The argument must be > 5 and != 10.   EXPECT_CALL(foo, DoThis(AllOf(Gt(5),                                 Ne(10))));
// The first argument must not contain sub-string "blah".   EXPECT_CALL(foo, DoThat(Not(HasSubstr("blah")),                           NULL)); ```
Google Mock matchers are statically typed, meaning that the compiler can catch your mistake if you use a matcher of the wrong type (for example, if you use `Eq(5)` to match a `string` argument). Good for you!
Sometimes, however, you know what you're doing and want the compiler to give you some slack. One example is that you have a matcher for `long` and the argument you want to match is `int`. While the two types aren't exactly the same, there is nothing really wrong with using a `Matcher<long>` to match an `int` - after all, we can first convert the `int` argument to a `long` before giving it to the matcher.
To support this need, Google Mock gives you the `SafeMatcherCast<T>(m)` function. It casts a matcher `m` to type `Matcher<T>`. To ensure safety, Google Mock checks that (let `U` be the type `m` accepts):
1. Type `T` can be implicitly cast to type `U`;   1. When both `T` and `U` are built-in arithmetic types (`bool`, integers, and floating-point numbers), the conversion from `T` to `U` is not lossy (in other words, any value representable by `T` can also be represented by `U`); and   1. When `U` is a reference, `T` must also be a reference (as the underlying matcher may be interested in the address of the `U` value).
The code won't compile if any of these conditions isn't met.
Here's one example:
``` using ::testing::SafeMatcherCast;
// A base class and a child class. class Base { ... }; class Derived : public Base { ... };
class MockFoo : public Foo {  public:   MOCK_METHOD1(DoThis, void(Derived* derived)); }; ...
MockFoo foo;   // m is a Matcher<Base*> we got from somewhere.   EXPECT_CALL(foo, DoThis(SafeMatcherCast<Derived*>(m))); ```
If you find `SafeMatcherCast<T>(m)` too limiting, you can use a similar function `MatcherCast<T>(m)`. The difference is that `MatcherCast` works as long as you can `static_cast` type `T` to type `U`.
`MatcherCast` essentially lets you bypass C++'s type system (`static_cast` isn't always safe as it could throw away information, for example), so be careful not to misuse/abuse it.
If you expect an overloaded function to be called, the compiler may need some help on which overloaded version it is.
To disambiguate functions overloaded on the const-ness of this object, use the `Const()` argument wrapper.
``` using ::testing::ReturnRef;
class MockFoo : public Foo {   ...   MOCK_METHOD0(GetBar, Bar&());   MOCK_CONST_METHOD0(GetBar, const Bar&()); }; ...
MockFoo foo;   Bar bar1, bar2;   EXPECT_CALL(foo, GetBar())         // The non-const GetBar().       .WillOnce(ReturnRef(bar1));   EXPECT_CALL(Const(foo), GetBar())  // The const GetBar().       .WillOnce(ReturnRef(bar2)); ```
(`Const()` is defined by Google Mock and returns a `const` reference to its argument.)
To disambiguate overloaded functions with the same number of arguments but different argument types, you may need to specify the exact type of a matcher, either by wrapping your matcher in `Matcher<type>()`, or using a matcher whose type is fixed (`TypedEq<type>`, `An<type>()`, etc):
``` using ::testing::An; using ::testing::Lt; using ::testing::Matcher; using ::testing::TypedEq;
class MockPrinter : public Printer {  public:   MOCK_METHOD1(Print, void(int n));   MOCK_METHOD1(Print, void(char c)); };
TEST(PrinterTest, Print) {   MockPrinter printer;
EXPECT_CALL(printer, Print(An<int>()));            // void Print(int);   EXPECT_CALL(printer, Print(Matcher<int>(Lt(5))));  // void Print(int);   EXPECT_CALL(printer, Print(TypedEq<char>('a')));   // void Print(char);
printer.Print(3);   printer.Print(6);   printer.Print('a'); } ```
When a mock method is called, the _last_ matching expectation that's still active will be selected (think "newer overrides older"). So, you can make a method do different things depending on its argument values like this:
``` using ::testing::_; using ::testing::Lt; using ::testing::Return; ...   // The default case.   EXPECT_CALL(foo, DoThis(_))       .WillRepeatedly(Return('b'));
// The more specific case.   EXPECT_CALL(foo, DoThis(Lt(5)))       .WillRepeatedly(Return('a')); ```
Now, if `foo.DoThis()` is called with a value less than 5, `'a'` will be returned; otherwise `'b'` will be returned.
Sometimes it's not enough to match the arguments individually. For example, we may want to say that the first argument must be less than the second argument. The `With()` clause allows us to match all arguments of a mock function as a whole. For example,
``` using ::testing::_; using ::testing::Lt; using ::testing::Ne; ...   EXPECT_CALL(foo, InRange(Ne(0), _))       .With(Lt()); ```
says that the first argument of `InRange()` must not be 0, and must be less than the second argument.
The expression inside `With()` must be a matcher of type `Matcher<tr1::tuple<A1, ..., An> >`, where `A1`, ..., `An` are the types of the function arguments.
You can also write `AllArgs(m)` instead of `m` inside `.With()`. The two forms are equivalent, but `.With(AllArgs(Lt()))` is more readable than `.With(Lt())`.
You can use `Args<k1, ..., kn>(m)` to match the `n` selected arguments (as a tuple) against `m`. For example,
``` using ::testing::_; using ::testing::AllOf; using ::testing::Args; using ::testing::Lt; ...   EXPECT_CALL(foo, Blah(_, _, _))       .With(AllOf(Args<0, 1>(Lt()), Args<1, 2>(Lt()))); ```
says that `Blah()` will be called with arguments `x`, `y`, and `z` where `x < y < z`.
As a convenience and example, Google Mock provides some matchers for 2-tuples, including the `Lt()` matcher above. See the [CheatSheet](V1_7_CheatSheet.md) for the complete list.
Note that if you want to pass the arguments to a predicate of your own (e.g. `.With(Args<0, 1>(Truly(&MyPredicate)))`), that predicate MUST be written to take a `tr1::tuple` as its argument; Google Mock will pass the `n` selected arguments as _one_ single tuple to the predicate.
Have you noticed that a matcher is just a fancy predicate that also knows how to describe itself? Many existing algorithms take predicates as arguments (e.g. those defined in STL's `<algorithm>` header), and it would be a shame if Google Mock matchers are not allowed to participate.
Luckily, you can use a matcher where a unary predicate functor is expected by wrapping it inside the `Matches()` function. For example,
``` #include <algorithm> #include <vector>
std::vector<int> v; ... // How many elements in v are >= 10? const int count = count_if(v.begin(), v.end(), Matches(Ge(10))); ```
Since you can build complex matchers from simpler ones easily using Google Mock, this gives you a way to conveniently construct composite predicates (doing the same using STL's `<functional>` header is just painful). For example, here's a predicate that's satisfied by any number that is >= 0, <= 100, and != 50:
``` Matches(AllOf(Ge(0), Le(100), Ne(50))) ```
Since matchers are basically predicates that also know how to describe themselves, there is a way to take advantage of them in [Google Test](http://code.google.com/p/googletest/) assertions. It's called `ASSERT_THAT` and `EXPECT_THAT`:
```   ASSERT_THAT(value, matcher);  // Asserts that value matches matcher.   EXPECT_THAT(value, matcher);  // The non-fatal version. ```
For example, in a Google Test test you can write:
``` #include "gmock/gmock.h"
using ::testing::AllOf; using ::testing::Ge; using ::testing::Le; using ::testing::MatchesRegex; using ::testing::StartsWith; ...
EXPECT_THAT(Foo(), StartsWith("Hello"));   EXPECT_THAT(Bar(), MatchesRegex("Line \\d+"));   ASSERT_THAT(Baz(), AllOf(Ge(5), Le(10))); ```
which (as you can probably guess) executes `Foo()`, `Bar()`, and `Baz()`, and verifies that:
* `Foo()` returns a string that starts with `"Hello"`.   * `Bar()` returns a string that matches regular expression `"Line \\d+"`.   * `Baz()` returns a number in the range [5, 10].
The nice thing about these macros is that _they read like English_. They generate informative messages too. For example, if the first `EXPECT_THAT()` above fails, the message will be something like:
``` Value of: Foo()   Actual: "Hi, world!" Expected: starts with "Hello" ```
**Credit:** The idea of `(ASSERT|EXPECT)_THAT` was stolen from the [Hamcrest](http://code.google.com/p/hamcrest/) project, which adds `assertThat()` to JUnit.
Google Mock provides a built-in set of matchers. In case you find them lacking, you can use an arbitray unary predicate function or functor as a matcher - as long as the predicate accepts a value of the type you want. You do this by wrapping the predicate inside the `Truly()` function, for example:
``` using ::testing::Truly;
int IsEven(int n) { return (n % 2) == 0 ? 1 : 0; } ...
// Bar() must be called with an even number.   EXPECT_CALL(foo, Bar(Truly(IsEven))); ```
Note that the predicate function / functor doesn't have to return `bool`. It works as long as the return value can be used as the condition in statement `if (condition) ...`.
When you do an `EXPECT_CALL(mock_obj, Foo(bar))`, Google Mock saves away a copy of `bar`. When `Foo()` is called later, Google Mock compares the argument to `Foo()` with the saved copy of `bar`. This way, you don't need to worry about `bar` being modified or destroyed after the `EXPECT_CALL()` is executed. The same is true when you use matchers like `Eq(bar)`, `Le(bar)`, and so on.
But what if `bar` cannot be copied (i.e. has no copy constructor)? You could define your own matcher function and use it with `Truly()`, as the previous couple of recipes have shown. Or, you may be able to get away from it if you can guarantee that `bar` won't be changed after the `EXPECT_CALL()` is executed. Just tell Google Mock that it should save a reference to `bar`, instead of a copy of it. Here's how:
``` using ::testing::Eq; using ::testing::ByRef; using ::testing::Lt; ...   // Expects that Foo()'s argument == bar.   EXPECT_CALL(mock_obj, Foo(Eq(ByRef(bar))));
// Expects that Foo()'s argument < bar.   EXPECT_CALL(mock_obj, Foo(Lt(ByRef(bar)))); ```
Remember: if you do this, don't change `bar` after the `EXPECT_CALL()`, or the result is undefined.
Often a mock function takes a reference to object as an argument. When matching the argument, you may not want to compare the entire object against a fixed object, as that may be over-specification. Instead, you may need to validate a certain member variable or the result of a certain getter method of the object. You can do this with `Field()` and `Property()`. More specifically,
``` Field(&Foo::bar, m) ```
is a matcher that matches a `Foo` object whose `bar` member variable satisfies matcher `m`.
``` Property(&Foo::baz, m) ```
is a matcher that matches a `Foo` object whose `baz()` method returns a value that satisfies matcher `m`.
For example:
> | `Field(&Foo::number, Ge(3))` | Matches `x` where `x.number >= 3`. | |:-----------------------------|:-----------------------------------| > | `Property(&Foo::name, StartsWith("John "))` | Matches `x` where `x.name()` starts with `"John "`. |
Note that in `Property(&Foo::baz, ...)`, method `baz()` must take no argument and be declared as `const`.
BTW, `Field()` and `Property()` can also match plain pointers to objects. For instance,
``` Field(&Foo::number, Ge(3)) ```
matches a plain pointer `p` where `p->number >= 3`. If `p` is `NULL`, the match will always fail regardless of the inner matcher.
What if you want to validate more than one members at the same time? Remember that there is `AllOf()`.
C++ functions often take pointers as arguments. You can use matchers like `IsNull()`, `NotNull()`, and other comparison matchers to match a pointer, but what if you want to make sure the value _pointed to_ by the pointer, instead of the pointer itself, has a certain property? Well, you can use the `Pointee(m)` matcher.
`Pointee(m)` matches a pointer iff `m` matches the value the pointer points to. For example:
``` using ::testing::Ge; using ::testing::Pointee; ...   EXPECT_CALL(foo, Bar(Pointee(Ge(3)))); ```
expects `foo.Bar()` to be called with a pointer that points to a value greater than or equal to 3.
One nice thing about `Pointee()` is that it treats a `NULL` pointer as a match failure, so you can write `Pointee(m)` instead of
```   AllOf(NotNull(), Pointee(m)) ```
without worrying that a `NULL` pointer will crash your test.
Also, did we tell you that `Pointee()` works with both raw pointers **and** smart pointers (`linked_ptr`, `shared_ptr`, `scoped_ptr`, and etc)?
What if you have a pointer to pointer? You guessed it - you can use nested `Pointee()` to probe deeper inside the value. For example, `Pointee(Pointee(Lt(3)))` matches a pointer that points to a pointer that points to a number less than 3 (what a mouthful...).
Sometimes you want to specify that an object argument has a certain property, but there is no existing matcher that does this. If you want good error messages, you should define a matcher. If you want to do it quick and dirty, you could get away with writing an ordinary function.
Let's say you have a mock function that takes an object of type `Foo`, which has an `int bar()` method and an `int baz()` method, and you want to constrain that the argument's `bar()` value plus its `baz()` value is a given number. Here's how you can define a matcher to do it:
``` using ::testing::MatcherInterface; using ::testing::MatchResultListener;
class BarPlusBazEqMatcher : public MatcherInterface<const Foo&> {  public:   explicit BarPlusBazEqMatcher(int expected_sum)       : expected_sum_(expected_sum) {}
virtual bool MatchAndExplain(const Foo& foo,                                MatchResultListener* listener) const {     return (foo.bar() + foo.baz()) == expected_sum_;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "bar() + baz() equals " << expected_sum_;   }
virtual void DescribeNegationTo(::std::ostream* os) const {     *os << "bar() + baz() does not equal " << expected_sum_;   }  private:   const int expected_sum_; };
inline Matcher<const Foo&> BarPlusBazEq(int expected_sum) {   return MakeMatcher(new BarPlusBazEqMatcher(expected_sum)); }
...
EXPECT_CALL(..., DoThis(BarPlusBazEq(5)))...; ```
Sometimes an STL container (e.g. list, vector, map, ...) is passed to a mock function and you may want to validate it. Since most STL containers support the `==` operator, you can write `Eq(expected_container)` or simply `expected_container` to match a container exactly.
Sometimes, though, you may want to be more flexible (for example, the first element must be an exact match, but the second element can be any positive number, and so on). Also, containers used in tests often have a small number of elements, and having to define the expected container out-of-line is a bit of a hassle.
You can use the `ElementsAre()` or `UnorderedElementsAre()` matcher in such cases:
``` using ::testing::_; using ::testing::ElementsAre; using ::testing::Gt; ...
MOCK_METHOD1(Foo, void(const vector<int>& numbers)); ...
EXPECT_CALL(mock, Foo(ElementsAre(1, Gt(0), _, 5))); ```
The above matcher says that the container must have 4 elements, which must be 1, greater than 0, anything, and 5 respectively.
If you instead write:
``` using ::testing::_; using ::testing::Gt; using ::testing::UnorderedElementsAre; ...
MOCK_METHOD1(Foo, void(const vector<int>& numbers)); ...
EXPECT_CALL(mock, Foo(UnorderedElementsAre(1, Gt(0), _, 5))); ```
It means that the container must have 4 elements, which under some permutation must be 1, greater than 0, anything, and 5 respectively.
`ElementsAre()` and `UnorderedElementsAre()` are overloaded to take 0 to 10 arguments. If more are needed, you can place them in a C-style array and use `ElementsAreArray()` or `UnorderedElementsAreArray()` instead:
``` using ::testing::ElementsAreArray; ...
// ElementsAreArray accepts an array of element values.   const int expected_vector1[] = { 1, 5, 2, 4, ... };   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector1)));
// Or, an array of element matchers.   Matcher<int> expected_vector2 = { 1, Gt(2), _, 3, ... };   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector2))); ```
In case the array needs to be dynamically created (and therefore the array size cannot be inferred by the compiler), you can give `ElementsAreArray()` an additional argument to specify the array size:
``` using ::testing::ElementsAreArray; ...   int* const expected_vector3 = new int[count];   ... fill expected_vector3 with values ...   EXPECT_CALL(mock, Foo(ElementsAreArray(expected_vector3, count))); ```
**Tips:**
* `ElementsAre*()` can be used to match _any_ container that implements the STL iterator pattern (i.e. it has a `const_iterator` type and supports `begin()/end()`), not just the ones defined in STL. It will even work with container types yet to be written - as long as they follows the above pattern.   * You can use nested `ElementsAre*()` to match nested (multi-dimensional) containers.   * If the container is passed by pointer instead of by reference, just write `Pointee(ElementsAre*(...))`.   * The order of elements _matters_ for `ElementsAre*()`. Therefore don't use it with containers whose element order is undefined (e.g. `hash_map`).
Under the hood, a Google Mock matcher object consists of a pointer to a ref-counted implementation object. Copying matchers is allowed and very efficient, as only the pointer is copied. When the last matcher that references the implementation object dies, the implementation object will be deleted.
Therefore, if you have some complex matcher that you want to use again and again, there is no need to build it everytime. Just assign it to a matcher variable and use that variable repeatedly! For example,
```   Matcher<int> in_range = AllOf(Gt(5), Le(10));   ... use in_range as a matcher in multiple EXPECT_CALLs ... ```
`ON_CALL` is likely the single most under-utilized construct in Google Mock.
There are basically two constructs for defining the behavior of a mock object: `ON_CALL` and `EXPECT_CALL`. The difference? `ON_CALL` defines what happens when a mock method is called, but _doesn't imply any expectation on the method being called._ `EXPECT_CALL` not only defines the behavior, but also sets an expectation that _the method will be called with the given arguments, for the given number of times_ (and _in the given order_ when you specify the order too).
Since `EXPECT_CALL` does more, isn't it better than `ON_CALL`? Not really. Every `EXPECT_CALL` adds a constraint on the behavior of the code under test. Having more constraints than necessary is _baaad_ - even worse than not having enough constraints.
This may be counter-intuitive. How could tests that verify more be worse than tests that verify less? Isn't verification the whole point of tests?
The answer, lies in _what_ a test should verify. **A good test verifies the contract of the code.** If a test over-specifies, it doesn't leave enough freedom to the implementation. As a result, changing the implementation without breaking the contract (e.g. refactoring and optimization), which should be perfectly fine to do, can break such tests. Then you have to spend time fixing them, only to see them broken again the next time the implementation is changed.
Keep in mind that one doesn't have to verify more than one property in one test. In fact, **it's a good style to verify only one thing in one test.** If you do that, a bug will likely break only one or two tests instead of dozens (which case would you rather debug?). If you are also in the habit of giving tests descriptive names that tell what they verify, you can often easily guess what's wrong just from the test log itself.
So use `ON_CALL` by default, and only use `EXPECT_CALL` when you actually intend to verify that the call is made. For example, you may have a bunch of `ON_CALL`s in your test fixture to set the common mock behavior shared by all tests in the same group, and write (scarcely) different `EXPECT_CALL`s in different `TEST_F`s to verify different aspects of the code's behavior. Compared with the style where each `TEST` has many `EXPECT_CALL`s, this leads to tests that are more resilient to implementational changes (and thus less likely to require maintenance) and makes the intent of the tests more obvious (so they are easier to maintain when you do need to maintain them).
If you are not interested in how a mock method is called, just don't say anything about it. In this case, if the method is ever called, Google Mock will perform its default action to allow the test program to continue. If you are not happy with the default action taken by Google Mock, you can override it using `DefaultValue<T>::Set()` (described later in this document) or `ON_CALL()`.
Please note that once you expressed interest in a particular mock method (via `EXPECT_CALL()`), all invocations to it must match some expectation. If this function is called but the arguments don't match any `EXPECT_CALL()` statement, it will be an error.
If a mock method shouldn't be called at all, explicitly say so:
``` using ::testing::_; ...   EXPECT_CALL(foo, Bar(_))       .Times(0); ```
If some calls to the method are allowed, but the rest are not, just list all the expected calls:
``` using ::testing::AnyNumber; using ::testing::Gt; ...   EXPECT_CALL(foo, Bar(5));   EXPECT_CALL(foo, Bar(Gt(10)))       .Times(AnyNumber()); ```
A call to `foo.Bar()` that doesn't match any of the `EXPECT_CALL()` statements will be an error.
Although an `EXPECT_CALL()` statement defined earlier takes precedence when Google Mock tries to match a function call with an expectation, by default calls don't have to happen in the order `EXPECT_CALL()` statements are written. For example, if the arguments match the matchers in the third `EXPECT_CALL()`, but not those in the first two, then the third expectation will be used.
If you would rather have all calls occur in the order of the expectations, put the `EXPECT_CALL()` statements in a block where you define a variable of type `InSequence`:
```   using ::testing::_;   using ::testing::InSequence;
{     InSequence s;
EXPECT_CALL(foo, DoThis(5));     EXPECT_CALL(bar, DoThat(_))         .Times(2);     EXPECT_CALL(foo, DoThis(6));   } ```
In this example, we expect a call to `foo.DoThis(5)`, followed by two calls to `bar.DoThat()` where the argument can be anything, which are in turn followed by a call to `foo.DoThis(6)`. If a call occurred out-of-order, Google Mock will report an error.
Sometimes requiring everything to occur in a predetermined order can lead to brittle tests. For example, we may care about `A` occurring before both `B` and `C`, but aren't interested in the relative order of `B` and `C`. In this case, the test should reflect our real intent, instead of being overly constraining.
Google Mock allows you to impose an arbitrary DAG (directed acyclic graph) on the calls. One way to express the DAG is to use the [After](http://code.google.com/p/googlemock/wiki/V1_7_CheatSheet#The_After_Clause) clause of `EXPECT_CALL`.
Another way is via the `InSequence()` clause (not the same as the `InSequence` class), which we borrowed from jMock 2. It's less flexible than `After()`, but more convenient when you have long chains of sequential calls, as it doesn't require you to come up with different names for the expectations in the chains.  Here's how it works:
If we view `EXPECT_CALL()` statements as nodes in a graph, and add an edge from node A to node B wherever A must occur before B, we can get a DAG. We use the term "sequence" to mean a directed path in this DAG. Now, if we decompose the DAG into sequences, we just need to know which sequences each `EXPECT_CALL()` belongs to in order to be able to reconstruct the orginal DAG.
So, to specify the partial order on the expectations we need to do two things: first to define some `Sequence` objects, and then for each `EXPECT_CALL()` say which `Sequence` objects it is part of. Expectations in the same sequence must occur in the order they are written. For example,
```   using ::testing::Sequence;
Sequence s1, s2;
EXPECT_CALL(foo, A())       .InSequence(s1, s2);   EXPECT_CALL(bar, B())       .InSequence(s1);   EXPECT_CALL(bar, C())       .InSequence(s2);   EXPECT_CALL(foo, D())       .InSequence(s2); ```
specifies the following DAG (where `s1` is `A -> B`, and `s2` is `A -> C -> D`):
```        +---> B        |   A ---|        |        +---> C ---> D ```
This means that A must occur before B and C, and C must occur before D. There's no restriction about the order other than these.
When a mock method is called, Google Mock only consider expectations that are still active. An expectation is active when created, and becomes inactive (aka _retires_) when a call that has to occur later has occurred. For example, in
```   using ::testing::_;   using ::testing::Sequence;
Sequence s1, s2;
EXPECT_CALL(log, Log(WARNING, _, "File too large."))     // #1       .Times(AnyNumber())       .InSequence(s1, s2);   EXPECT_CALL(log, Log(WARNING, _, "Data set is empty."))  // #2       .InSequence(s1);   EXPECT_CALL(log, Log(WARNING, _, "User not found."))     // #3       .InSequence(s2); ```
as soon as either #2 or #3 is matched, #1 will retire. If a warning `"File too large."` is logged after this, it will be an error.
Note that an expectation doesn't retire automatically when it's saturated. For example,
``` using ::testing::_; ...   EXPECT_CALL(log, Log(WARNING, _, _));                  // #1   EXPECT_CALL(log, Log(WARNING, _, "File too large."));  // #2 ```
says that there will be exactly one warning with the message `"File too large."`. If the second warning contains this message too, #2 will match again and result in an upper-bound-violated error.
If this is not what you want, you can ask an expectation to retire as soon as it becomes saturated:
``` using ::testing::_; ...   EXPECT_CALL(log, Log(WARNING, _, _));                 // #1   EXPECT_CALL(log, Log(WARNING, _, "File too large."))  // #2       .RetiresOnSaturation(); ```
Here #2 can be used only once, so if you have two warnings with the message `"File too large."`, the first will match #2 and the second will match #1 - there will be no error.
If a mock function's return type is a reference, you need to use `ReturnRef()` instead of `Return()` to return a result:
``` using ::testing::ReturnRef;
class MockFoo : public Foo {  public:   MOCK_METHOD0(GetBar, Bar&()); }; ...
MockFoo foo;   Bar bar;   EXPECT_CALL(foo, GetBar())       .WillOnce(ReturnRef(bar)); ```
The `Return(x)` action saves a copy of `x` when the action is _created_, and always returns the same value whenever it's executed. Sometimes you may want to instead return the _live_ value of `x` (i.e. its value at the time when the action is _executed_.).
If the mock function's return type is a reference, you can do it using `ReturnRef(x)`, as shown in the previous recipe ("Returning References from Mock Methods"). However, Google Mock doesn't let you use `ReturnRef()` in a mock function whose return type is not a reference, as doing that usually indicates a user error. So, what shall you do?
You may be tempted to try `ByRef()`:
``` using testing::ByRef; using testing::Return;
class MockFoo : public Foo {  public:   MOCK_METHOD0(GetValue, int()); }; ...   int x = 0;   MockFoo foo;   EXPECT_CALL(foo, GetValue())       .WillRepeatedly(Return(ByRef(x)));   x = 42;   EXPECT_EQ(42, foo.GetValue()); ```
Unfortunately, it doesn't work here. The above code will fail with error:
``` Value of: foo.GetValue()   Actual: 0 Expected: 42 ```
The reason is that `Return(value)` converts `value` to the actual return type of the mock function at the time when the action is _created_, not when it is _executed_. (This behavior was chosen for the action to be safe when `value` is a proxy object that references some temporary objects.) As a result, `ByRef(x)` is converted to an `int` value (instead of a `const int&`) when the expectation is set, and `Return(ByRef(x))` will always return 0.
`ReturnPointee(pointer)` was provided to solve this problem specifically. It returns the value pointed to by `pointer` at the time the action is _executed_:
``` using testing::ReturnPointee; ...   int x = 0;   MockFoo foo;   EXPECT_CALL(foo, GetValue())       .WillRepeatedly(ReturnPointee(&x));  // Note the & here.   x = 42;   EXPECT_EQ(42, foo.GetValue());  // This will succeed now. ```
Want to do more than one thing when a function is called? That's fine. `DoAll()` allow you to do sequence of actions every time. Only the return value of the last action in the sequence will be used.
``` using ::testing::DoAll;
class MockFoo : public Foo {  public:   MOCK_METHOD1(Bar, bool(int n)); }; ...
EXPECT_CALL(foo, Bar(_))       .WillOnce(DoAll(action_1,                       action_2,                       ...                       action_n)); ```
Sometimes a method exhibits its effect not via returning a value but via side effects. For example, it may change some global state or modify an output argument. To mock side effects, in general you can define your own action by implementing `::testing::ActionInterface`.
If all you need to do is to change an output argument, the built-in `SetArgPointee()` action is convenient:
``` using ::testing::SetArgPointee;
class MockMutator : public Mutator {  public:   MOCK_METHOD2(Mutate, void(bool mutate, int* value));   ... }; ...
MockMutator mutator;   EXPECT_CALL(mutator, Mutate(true, _))       .WillOnce(SetArgPointee<1>(5)); ```
In this example, when `mutator.Mutate()` is called, we will assign 5 to the `int` variable pointed to by argument #1 (0-based).
`SetArgPointee()` conveniently makes an internal copy of the value you pass to it, removing the need to keep the value in scope and alive. The implication however is that the value must have a copy constructor and assignment operator.
If the mock method also needs to return a value as well, you can chain `SetArgPointee()` with `Return()` using `DoAll()`:
``` using ::testing::_; using ::testing::Return; using ::testing::SetArgPointee;
class MockMutator : public Mutator {  public:   ...   MOCK_METHOD1(MutateInt, bool(int* value)); }; ...
MockMutator mutator;   EXPECT_CALL(mutator, MutateInt(_))       .WillOnce(DoAll(SetArgPointee<0>(5),                       Return(true))); ```
If the output argument is an array, use the `SetArrayArgument<N>(first, last)` action instead. It copies the elements in source range `[first, last)` to the array pointed to by the `N`-th (0-based) argument:
``` using ::testing::NotNull; using ::testing::SetArrayArgument;
class MockArrayMutator : public ArrayMutator {  public:   MOCK_METHOD2(Mutate, void(int* values, int num_values));   ... }; ...
MockArrayMutator mutator;   int values[5] = { 1, 2, 3, 4, 5 };   EXPECT_CALL(mutator, Mutate(NotNull(), 5))       .WillOnce(SetArrayArgument<0>(values, values + 5)); ```
This also works when the argument is an output iterator:
``` using ::testing::_; using ::testing::SeArrayArgument;
class MockRolodex : public Rolodex {  public:   MOCK_METHOD1(GetNames, void(std::back_insert_iterator<vector<string> >));   ... }; ...
MockRolodex rolodex;   vector<string> names;   names.push_back("George");   names.push_back("John");   names.push_back("Thomas");   EXPECT_CALL(rolodex, GetNames(_))       .WillOnce(SetArrayArgument<0>(names.begin(), names.end())); ```
If you expect a call to change the behavior of a mock object, you can use `::testing::InSequence` to specify different behaviors before and after the call:
``` using ::testing::InSequence; using ::testing::Return;
...   {     InSequence seq;     EXPECT_CALL(my_mock, IsDirty())         .WillRepeatedly(Return(true));     EXPECT_CALL(my_mock, Flush());     EXPECT_CALL(my_mock, IsDirty())         .WillRepeatedly(Return(false));   }   my_mock.FlushIfDirty(); ```
This makes `my_mock.IsDirty()` return `true` before `my_mock.Flush()` is called and return `false` afterwards.
If the behavior change is more complex, you can store the effects in a variable and make a mock method get its return value from that variable:
``` using ::testing::_; using ::testing::SaveArg; using ::testing::Return;
ACTION_P(ReturnPointee, p) { return *p; } ...   int previous_value = 0;   EXPECT_CALL(my_mock, GetPrevValue())       .WillRepeatedly(ReturnPointee(&previous_value));   EXPECT_CALL(my_mock, UpdateValue(_))       .WillRepeatedly(SaveArg<0>(&previous_value));   my_mock.DoSomethingToUpdateValue(); ```
Here `my_mock.GetPrevValue()` will always return the argument of the last `UpdateValue()` call.
If a mock method's return type is a built-in C++ type or pointer, by default it will return 0 when invoked. You only need to specify an action if this default value doesn't work for you.
Sometimes, you may want to change this default value, or you may want to specify a default value for types Google Mock doesn't know about. You can do this using the `::testing::DefaultValue` class template:
``` class MockFoo : public Foo {  public:   MOCK_METHOD0(CalculateBar, Bar()); }; ...
Bar default_bar;   // Sets the default return value for type Bar.   DefaultValue<Bar>::Set(default_bar);
MockFoo foo;
// We don't need to specify an action here, as the default   // return value works for us.   EXPECT_CALL(foo, CalculateBar());
foo.CalculateBar();  // This should return default_bar.
// Unsets the default return value.   DefaultValue<Bar>::Clear(); ```
Please note that changing the default value for a type can make you tests hard to understand. We recommend you to use this feature judiciously. For example, you may want to make sure the `Set()` and `Clear()` calls are right next to the code that uses your mock.
You've learned how to change the default value of a given type. However, this may be too coarse for your purpose: perhaps you have two mock methods with the same return type and you want them to have different behaviors. The `ON_CALL()` macro allows you to customize your mock's behavior at the method level:
``` using ::testing::_; using ::testing::AnyNumber; using ::testing::Gt; using ::testing::Return; ...   ON_CALL(foo, Sign(_))       .WillByDefault(Return(-1));   ON_CALL(foo, Sign(0))       .WillByDefault(Return(0));   ON_CALL(foo, Sign(Gt(0)))       .WillByDefault(Return(1));
EXPECT_CALL(foo, Sign(_))       .Times(AnyNumber());
foo.Sign(5);   // This should return 1.   foo.Sign(-9);  // This should return -1.   foo.Sign(0);   // This should return 0. ```
As you may have guessed, when there are more than one `ON_CALL()` statements, the news order take precedence over the older ones. In other words, the **last** one that matches the function arguments will be used. This matching order allows you to set up the common behavior in a mock object's constructor or the test fixture's set-up phase and specialize the mock's behavior later.
If the built-in actions don't suit you, you can easily use an existing function, method, or functor as an action:
``` using ::testing::_; using ::testing::Invoke;
class MockFoo : public Foo {  public:   MOCK_METHOD2(Sum, int(int x, int y));   MOCK_METHOD1(ComplexJob, bool(int x)); };
int CalculateSum(int x, int y) { return x + y; }
class Helper {  public:   bool ComplexJob(int x); }; ...
MockFoo foo;   Helper helper;   EXPECT_CALL(foo, Sum(_, _))       .WillOnce(Invoke(CalculateSum));   EXPECT_CALL(foo, ComplexJob(_))       .WillOnce(Invoke(&helper, &Helper::ComplexJob));
foo.Sum(5, 6);       // Invokes CalculateSum(5, 6).   foo.ComplexJob(10);  // Invokes helper.ComplexJob(10); ```
The only requirement is that the type of the function, etc must be _compatible_ with the signature of the mock function, meaning that the latter's arguments can be implicitly converted to the corresponding arguments of the former, and the former's return type can be implicitly converted to that of the latter. So, you can invoke something whose type is _not_ exactly the same as the mock function, as long as it's safe to do so - nice, huh?
`Invoke()` is very useful for doing actions that are more complex. It passes the mock function's arguments to the function or functor being invoked such that the callee has the full context of the call to work with. If the invoked function is not interested in some or all of the arguments, it can simply ignore them.
Yet, a common pattern is that a test author wants to invoke a function without the arguments of the mock function. `Invoke()` allows her to do that using a wrapper function that throws away the arguments before invoking an underlining nullary function. Needless to say, this can be tedious and obscures the intent of the test.
`InvokeWithoutArgs()` solves this problem. It's like `Invoke()` except that it doesn't pass the mock function's arguments to the callee. Here's an example:
``` using ::testing::_; using ::testing::InvokeWithoutArgs;
class MockFoo : public Foo {  public:   MOCK_METHOD1(ComplexJob, bool(int n)); };
bool Job1() { ... } ...
MockFoo foo;   EXPECT_CALL(foo, ComplexJob(_))       .WillOnce(InvokeWithoutArgs(Job1));
foo.ComplexJob(10);  // Invokes Job1(). ```
Sometimes a mock function will receive a function pointer or a functor (in other words, a "callable") as an argument, e.g.
``` class MockFoo : public Foo {  public:   MOCK_METHOD2(DoThis, bool(int n, bool (*fp)(int))); }; ```
and you may want to invoke this callable argument:
``` using ::testing::_; ...   MockFoo foo;   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(...);   // Will execute (*fp)(5), where fp is the   // second argument DoThis() receives. ```
Arghh, you need to refer to a mock function argument but C++ has no lambda (yet), so you have to define your own action. :-( Or do you really?
Well, Google Mock has an action to solve _exactly_ this problem:
```   InvokeArgument<N>(arg_1, arg_2, ..., arg_m) ```
will invoke the `N`-th (0-based) argument the mock function receives, with `arg_1`, `arg_2`, ..., and `arg_m`. No matter if the argument is a function pointer or a functor, Google Mock handles them both.
With that, you could write:
``` using ::testing::_; using ::testing::InvokeArgument; ...   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(InvokeArgument<1>(5));   // Will execute (*fp)(5), where fp is the   // second argument DoThis() receives. ```
What if the callable takes an argument by reference? No problem - just wrap it inside `ByRef()`:
``` ...   MOCK_METHOD1(Bar, bool(bool (*fp)(int, const Helper&))); ... using ::testing::_; using ::testing::ByRef; using ::testing::InvokeArgument; ...
MockFoo foo;   Helper helper;   ...   EXPECT_CALL(foo, Bar(_))       .WillOnce(InvokeArgument<0>(5, ByRef(helper)));   // ByRef(helper) guarantees that a reference to helper, not a copy of it,   // will be passed to the callable. ```
What if the callable takes an argument by reference and we do **not** wrap the argument in `ByRef()`? Then `InvokeArgument()` will _make a copy_ of the argument, and pass a _reference to the copy_, instead of a reference to the original value, to the callable. This is especially handy when the argument is a temporary value:
``` ...   MOCK_METHOD1(DoThat, bool(bool (*f)(const double& x, const string& s))); ... using ::testing::_; using ::testing::InvokeArgument; ...
MockFoo foo;   ...   EXPECT_CALL(foo, DoThat(_))       .WillOnce(InvokeArgument<0>(5.0, string("Hi")));   // Will execute (*f)(5.0, string("Hi")), where f is the function pointer   // DoThat() receives.  Note that the values 5.0 and string("Hi") are   // temporary and dead once the EXPECT_CALL() statement finishes.  Yet   // it's fine to perform this action later, since a copy of the values   // are kept inside the InvokeArgument action. ```
Sometimes you have an action that returns _something_, but you need an action that returns `void` (perhaps you want to use it in a mock function that returns `void`, or perhaps it needs to be used in `DoAll()` and it's not the last in the list). `IgnoreResult()` lets you do that. For example:
``` using ::testing::_; using ::testing::Invoke; using ::testing::Return;
int Process(const MyData& data); string DoSomething();
class MockFoo : public Foo {  public:   MOCK_METHOD1(Abc, void(const MyData& data));   MOCK_METHOD0(Xyz, bool()); }; ...
MockFoo foo;   EXPECT_CALL(foo, Abc(_))   // .WillOnce(Invoke(Process));   // The above line won't compile as Process() returns int but Abc() needs   // to return void.       .WillOnce(IgnoreResult(Invoke(Process)));
EXPECT_CALL(foo, Xyz())       .WillOnce(DoAll(IgnoreResult(Invoke(DoSomething)),       // Ignores the string DoSomething() returns.                       Return(true))); ```
Note that you **cannot** use `IgnoreResult()` on an action that already returns `void`. Doing so will lead to ugly compiler errors.
Say you have a mock function `Foo()` that takes seven arguments, and you have a custom action that you want to invoke when `Foo()` is called. Trouble is, the custom action only wants three arguments:
``` using ::testing::_; using ::testing::Invoke; ...   MOCK_METHOD7(Foo, bool(bool visible, const string& name, int x, int y,                          const map<pair<int, int>, double>& weight,                          double min_weight, double max_wight)); ...
bool IsVisibleInQuadrant1(bool visible, int x, int y) {   return visible && x >= 0 && y >= 0; } ...
EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(Invoke(IsVisibleInQuadrant1));  // Uh, won't compile. :-( ```
To please the compiler God, you can to define an "adaptor" that has the same signature as `Foo()` and calls the custom action with the right arguments:
``` using ::testing::_; using ::testing::Invoke;
bool MyIsVisibleInQuadrant1(bool visible, const string& name, int x, int y,                             const map<pair<int, int>, double>& weight,                             double min_weight, double max_wight) {   return IsVisibleInQuadrant1(visible, x, y); } ...
EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(Invoke(MyIsVisibleInQuadrant1));  // Now it works. ```
But isn't this awkward?
Google Mock provides a generic _action adaptor_, so you can spend your time minding more important business than writing your own adaptors. Here's the syntax:
```   WithArgs<N1, N2, ..., Nk>(action) ```
creates an action that passes the arguments of the mock function at the given indices (0-based) to the inner `action` and performs it. Using `WithArgs`, our original example can be written as:
``` using ::testing::_; using ::testing::Invoke; using ::testing::WithArgs; ...   EXPECT_CALL(mock, Foo(_, _, _, _, _, _, _))       .WillOnce(WithArgs<0, 2, 3>(Invoke(IsVisibleInQuadrant1)));       // No need to define your own adaptor. ```
For better readability, Google Mock also gives you:
* `WithoutArgs(action)` when the inner `action` takes _no_ argument, and   * `WithArg<N>(action)` (no `s` after `Arg`) when the inner `action` takes _one_ argument.
As you may have realized, `InvokeWithoutArgs(...)` is just syntactic sugar for `WithoutArgs(Inovke(...))`.
Here are more tips:
* The inner action used in `WithArgs` and friends does not have to be `Invoke()` -- it can be anything.   * You can repeat an argument in the argument list if necessary, e.g. `WithArgs<2, 3, 3, 5>(...)`.   * You can change the order of the arguments, e.g. `WithArgs<3, 2, 1>(...)`.   * The types of the selected arguments do _not_ have to match the signature of the inner action exactly. It works as long as they can be implicitly converted to the corresponding arguments of the inner action. For example, if the 4-th argument of the mock function is an `int` and `my_action` takes a `double`, `WithArg<4>(my_action)` will work.
The selecting-an-action's-arguments recipe showed us one way to make a mock function and an action with incompatible argument lists fit together. The downside is that wrapping the action in `WithArgs<...>()` can get tedious for people writing the tests.
If you are defining a function, method, or functor to be used with `Invoke*()`, and you are not interested in some of its arguments, an alternative to `WithArgs` is to declare the uninteresting arguments as `Unused`. This makes the definition less cluttered and less fragile in case the types of the uninteresting arguments change. It could also increase the chance the action function can be reused. For example, given
```   MOCK_METHOD3(Foo, double(const string& label, double x, double y));   MOCK_METHOD3(Bar, double(int index, double x, double y)); ```
instead of
``` using ::testing::_; using ::testing::Invoke;
double DistanceToOriginWithLabel(const string& label, double x, double y) {   return sqrt(x*x + y*y); }
double DistanceToOriginWithIndex(int index, double x, double y) {   return sqrt(x*x + y*y); } ...
EXEPCT_CALL(mock, Foo("abc", _, _))       .WillOnce(Invoke(DistanceToOriginWithLabel));   EXEPCT_CALL(mock, Bar(5, _, _))       .WillOnce(Invoke(DistanceToOriginWithIndex)); ```
you could write
``` using ::testing::_; using ::testing::Invoke; using ::testing::Unused;
double DistanceToOrigin(Unused, double x, double y) {   return sqrt(x*x + y*y); } ...
EXEPCT_CALL(mock, Foo("abc", _, _))       .WillOnce(Invoke(DistanceToOrigin));   EXEPCT_CALL(mock, Bar(5, _, _))       .WillOnce(Invoke(DistanceToOrigin)); ```
Just like matchers, a Google Mock action object consists of a pointer to a ref-counted implementation object. Therefore copying actions is also allowed and very efficient. When the last action that references the implementation object dies, the implementation object will be deleted.
If you have some complex action that you want to use again and again, you may not have to build it from scratch everytime. If the action doesn't have an internal state (i.e. if it always does the same thing no matter how many times it has been called), you can assign it to an action variable and use that variable repeatedly. For example:
```   Action<bool(int*)> set_flag = DoAll(SetArgPointee<0>(5),                                       Return(true));   ... use set_flag in .WillOnce() and .WillRepeatedly() ... ```
However, if the action has its own state, you may be surprised if you share the action object. Suppose you have an action factory `IncrementCounter(init)` which creates an action that increments and returns a counter whose initial value is `init`, using two actions created from the same expression and using a shared action will exihibit different behaviors. Example:
```   EXPECT_CALL(foo, DoThis())       .WillRepeatedly(IncrementCounter(0));   EXPECT_CALL(foo, DoThat())       .WillRepeatedly(IncrementCounter(0));   foo.DoThis();  // Returns 1.   foo.DoThis();  // Returns 2.   foo.DoThat();  // Returns 1 - Blah() uses a different                  // counter than Bar()'s. ```
versus
```   Action<int()> increment = IncrementCounter(0);
EXPECT_CALL(foo, DoThis())       .WillRepeatedly(increment);   EXPECT_CALL(foo, DoThat())       .WillRepeatedly(increment);   foo.DoThis();  // Returns 1.   foo.DoThis();  // Returns 2.   foo.DoThat();  // Returns 3 - the counter is shared. ```
Believe it or not, the _vast majority_ of the time spent on compiling a mock class is in generating its constructor and destructor, as they perform non-trivial tasks (e.g. verification of the expectations). What's more, mock methods with different signatures have different types and thus their constructors/destructors need to be generated by the compiler separately. As a result, if you mock many different types of methods, compiling your mock class can get really slow.
If you are experiencing slow compilation, you can move the definition of your mock class' constructor and destructor out of the class body and into a `.cpp` file. This way, even if you `#include` your mock class in N files, the compiler only needs to generate its constructor and destructor once, resulting in a much faster compilation.
Let's illustrate the idea using an example. Here's the definition of a mock class before applying this recipe:
``` // File mock_foo.h. ... class MockFoo : public Foo {  public:   // Since we don't declare the constructor or the destructor,   // the compiler will generate them in every translation unit   // where this mock class is used.
MOCK_METHOD0(DoThis, int());   MOCK_METHOD1(DoThat, bool(const char* str));   ... more mock methods ... }; ```
After the change, it would look like:
``` // File mock_foo.h. ... class MockFoo : public Foo {  public:   // The constructor and destructor are declared, but not defined, here.   MockFoo();   virtual ~MockFoo();
MOCK_METHOD0(DoThis, int());   MOCK_METHOD1(DoThat, bool(const char* str));   ... more mock methods ... }; ``` and ``` // File mock_foo.cpp. #include "path/to/mock_foo.h"
// The definitions may appear trivial, but the functions actually do a // lot of things through the constructors/destructors of the member // variables used to implement the mock methods. MockFoo::MockFoo() {} MockFoo::~MockFoo() {} ```
When it's being destoyed, your friendly mock object will automatically verify that all expectations on it have been satisfied, and will generate [Google Test](http://code.google.com/p/googletest/) failures if not. This is convenient as it leaves you with one less thing to worry about. That is, unless you are not sure if your mock object will be destoyed.
How could it be that your mock object won't eventually be destroyed? Well, it might be created on the heap and owned by the code you are testing. Suppose there's a bug in that code and it doesn't delete the mock object properly - you could end up with a passing test when there's actually a bug.
Using a heap checker is a good idea and can alleviate the concern, but its implementation may not be 100% reliable. So, sometimes you do want to _force_ Google Mock to verify a mock object before it is (hopefully) destructed. You can do this with `Mock::VerifyAndClearExpectations(&mock_object)`:
``` TEST(MyServerTest, ProcessesRequest) {   using ::testing::Mock;
MockFoo* const foo = new MockFoo;   EXPECT_CALL(*foo, ...)...;   // ... other expectations ...
// server now owns foo.   MyServer server(foo);   server.ProcessRequest(...);
// In case that server's destructor will forget to delete foo,   // this will verify the expectations anyway.   Mock::VerifyAndClearExpectations(foo); }  // server is destroyed when it goes out of scope here. ```
**Tip:** The `Mock::VerifyAndClearExpectations()` function returns a `bool` to indicate whether the verification was successful (`true` for yes), so you can wrap that function call inside a `ASSERT_TRUE()` if there is no point going further when the verification has failed.
Sometimes you may want to "reset" a mock object at various check points in your test: at each check point, you verify that all existing expectations on the mock object have been satisfied, and then you set some new expectations on it as if it's newly created. This allows you to work with a mock object in "phases" whose sizes are each manageable.
One such scenario is that in your test's `SetUp()` function, you may want to put the object you are testing into a certain state, with the help from a mock object. Once in the desired state, you want to clear all expectations on the mock, such that in the `TEST_F` body you can set fresh expectations on it.
As you may have figured out, the `Mock::VerifyAndClearExpectations()` function we saw in the previous recipe can help you here. Or, if you are using `ON_CALL()` to set default actions on the mock object and want to clear the default actions as well, use `Mock::VerifyAndClear(&mock_object)` instead. This function does what `Mock::VerifyAndClearExpectations(&mock_object)` does and returns the same `bool`, **plus** it clears the `ON_CALL()` statements on `mock_object` too.
Another trick you can use to achieve the same effect is to put the expectations in sequences and insert calls to a dummy "check-point" function at specific places. Then you can verify that the mock function calls do happen at the right time. For example, if you are exercising code:
``` Foo(1); Foo(2); Foo(3); ```
and want to verify that `Foo(1)` and `Foo(3)` both invoke `mock.Bar("a")`, but `Foo(2)` doesn't invoke anything. You can write:
``` using ::testing::MockFunction;
TEST(FooTest, InvokesBarCorrectly) {   MyMock mock;   // Class MockFunction<F> has exactly one mock method.  It is named   // Call() and has type F.   MockFunction<void(string check_point_name)> check;   {     InSequence s;
EXPECT_CALL(mock, Bar("a"));     EXPECT_CALL(check, Call("1"));     EXPECT_CALL(check, Call("2"));     EXPECT_CALL(mock, Bar("a"));   }   Foo(1);   check.Call("1");   Foo(2);   check.Call("2");   Foo(3); } ```
The expectation spec says that the first `Bar("a")` must happen before check point "1", the second `Bar("a")` must happen after check point "2", and nothing should happen between the two check points. The explicit check points make it easy to tell which `Bar("a")` is called by which call to `Foo()`.
Sometimes you want to make sure a mock object is destructed at the right time, e.g. after `bar->A()` is called but before `bar->B()` is called. We already know that you can specify constraints on the order of mock function calls, so all we need to do is to mock the destructor of the mock function.
This sounds simple, except for one problem: a destructor is a special function with special syntax and special semantics, and the `MOCK_METHOD0` macro doesn't work for it:
```   MOCK_METHOD0(~MockFoo, void());  // Won't compile! ```
The good news is that you can use a simple pattern to achieve the same effect. First, add a mock function `Die()` to your mock class and call it in the destructor, like this:
``` class MockFoo : public Foo {   ...   // Add the following two lines to the mock class.   MOCK_METHOD0(Die, void());   virtual ~MockFoo() { Die(); } }; ```
(If the name `Die()` clashes with an existing symbol, choose another name.) Now, we have translated the problem of testing when a `MockFoo` object dies to testing when its `Die()` method is called:
```   MockFoo* foo = new MockFoo;   MockBar* bar = new MockBar;   ...   {     InSequence s;
// Expects *foo to die after bar->A() and before bar->B().     EXPECT_CALL(*bar, A());     EXPECT_CALL(*foo, Die());     EXPECT_CALL(*bar, B());   } ```
And that's that.
**IMPORTANT NOTE:** What we describe in this recipe is **ONLY** true on platforms where Google Mock is thread-safe. Currently these are only platforms that support the pthreads library (this includes Linux and Mac). To make it thread-safe on other platforms we only need to implement some synchronization operations in `"gtest/internal/gtest-port.h"`.
In a **unit** test, it's best if you could isolate and test a piece of code in a single-threaded context. That avoids race conditions and dead locks, and makes debugging your test much easier.
Yet many programs are multi-threaded, and sometimes to test something we need to pound on it from more than one thread. Google Mock works for this purpose too.
Remember the steps for using a mock:
1. Create a mock object `foo`.   1. Set its default actions and expectations using `ON_CALL()` and `EXPECT_CALL()`.   1. The code under test calls methods of `foo`.   1. Optionally, verify and reset the mock.   1. Destroy the mock yourself, or let the code under test destroy it. The destructor will automatically verify it.
If you follow the following simple rules, your mocks and threads can live happily togeter:
* Execute your _test code_ (as opposed to the code being tested) in _one_ thread. This makes your test easy to follow.   * Obviously, you can do step #1 without locking.   * When doing step #2 and #5, make sure no other thread is accessing `foo`. Obvious too, huh?   * #3 and #4 can be done either in one thread or in multiple threads - anyway you want. Google Mock takes care of the locking, so you don't have to do any - unless required by your test logic.
If you violate the rules (for example, if you set expectations on a mock while another thread is calling its methods), you get undefined behavior. That's not fun, so don't do it.
Google Mock guarantees that the action for a mock function is done in the same thread that called the mock function. For example, in
```   EXPECT_CALL(mock, Foo(1))       .WillOnce(action1);   EXPECT_CALL(mock, Foo(2))       .WillOnce(action2); ```
if `Foo(1)` is called in thread 1 and `Foo(2)` is called in thread 2, Google Mock will execute `action1` in thread 1 and `action2` in thread 2.
Google Mock does _not_ impose a sequence on actions performed in different threads (doing so may create deadlocks as the actions may need to cooperate). This means that the execution of `action1` and `action2` in the above example _may_ interleave. If this is a problem, you should add proper synchronization logic to `action1` and `action2` to make the test thread-safe.
Also, remember that `DefaultValue<T>` is a global resource that potentially affects _all_ living mock objects in your program. Naturally, you won't want to mess with it from multiple threads or when there still are mocks in action.
When Google Mock sees something that has the potential of being an error (e.g. a mock function with no expectation is called, a.k.a. an uninteresting call, which is allowed but perhaps you forgot to explicitly ban the call), it prints some warning messages, including the arguments of the function and the return value. Hopefully this will remind you to take a look and see if there is indeed a problem.
Sometimes you are confident that your tests are correct and may not appreciate such friendly messages. Some other times, you are debugging your tests or learning about the behavior of the code you are testing, and wish you could observe every mock call that happens (including argument values and the return value). Clearly, one size doesn't fit all.
You can control how much Google Mock tells you using the `--gmock_verbose=LEVEL` command-line flag, where `LEVEL` is a string with three possible values:
* `info`: Google Mock will print all informational messages, warnings, and errors (most verbose). At this setting, Google Mock will also log any calls to the `ON_CALL/EXPECT_CALL` macros.   * `warning`: Google Mock will print both warnings and errors (less verbose). This is the default.   * `error`: Google Mock will print errors only (least verbose).
Alternatively, you can adjust the value of that flag from within your tests like so:
```   ::testing::FLAGS_gmock_verbose = "error"; ```
Now, judiciously use the right flag to enable Google Mock serve you better!
You have a test using Google Mock. It fails: Google Mock tells you that some expectations aren't satisfied. However, you aren't sure why: Is there a typo somewhere in the matchers? Did you mess up the order of the `EXPECT_CALL`s? Or is the code under test doing something wrong?  How can you find out the cause?
Won't it be nice if you have X-ray vision and can actually see the trace of all `EXPECT_CALL`s and mock method calls as they are made? For each call, would you like to see its actual argument values and which `EXPECT_CALL` Google Mock thinks it matches?
You can unlock this power by running your test with the `--gmock_verbose=info` flag. For example, given the test program:
``` using testing::_; using testing::HasSubstr; using testing::Return;
class MockFoo {  public:   MOCK_METHOD2(F, void(const string& x, const string& y)); };
TEST(Foo, Bar) {   MockFoo mock;   EXPECT_CALL(mock, F(_, _)).WillRepeatedly(Return());   EXPECT_CALL(mock, F("a", "b"));   EXPECT_CALL(mock, F("c", HasSubstr("d")));
mock.F("a", "good");   mock.F("a", "b"); } ```
if you run it with `--gmock_verbose=info`, you will see this output:
``` [ RUN      ] Foo.Bar
foo_test.cc:14: EXPECT_CALL(mock, F(_, _)) invoked foo_test.cc:15: EXPECT_CALL(mock, F("a", "b")) invoked foo_test.cc:16: EXPECT_CALL(mock, F("c", HasSubstr("d"))) invoked foo_test.cc:14: Mock function call matches EXPECT_CALL(mock, F(_, _))...     Function call: F(@0x7fff7c8dad40"a", @0x7fff7c8dad10"good") foo_test.cc:15: Mock function call matches EXPECT_CALL(mock, F("a", "b"))...     Function call: F(@0x7fff7c8dada0"a", @0x7fff7c8dad70"b") foo_test.cc:16: Failure Actual function call count doesn't match EXPECT_CALL(mock, F("c", HasSubstr("d")))...          Expected: to be called once            Actual: never called - unsatisfied and active [  FAILED  ] Foo.Bar ```
Suppose the bug is that the `"c"` in the third `EXPECT_CALL` is a typo and should actually be `"a"`. With the above message, you should see that the actual `F("a", "good")` call is matched by the first `EXPECT_CALL`, not the third as you thought. From that it should be obvious that the third `EXPECT_CALL` is written wrong. Case solved.
If you build and run your tests in Emacs, the source file locations of Google Mock and [Google Test](http://code.google.com/p/googletest/) errors will be highlighted. Just press `<Enter>` on one of them and you'll be taken to the offending line. Or, you can just type `C-x `` to jump to the next error.
To make it even easier, you can add the following lines to your `~/.emacs` file:
``` (global-set-key "\M-m"   'compile)  ; m is for make (global-set-key [M-down] 'next-error) (global-set-key [M-up]   '(lambda () (interactive) (next-error -1))) ```
Then you can type `M-m` to start a build, or `M-up`/`M-down` to move back and forth between errors.
Google Mock's implementation consists of dozens of files (excluding its own tests).  Sometimes you may want them to be packaged up in fewer files instead, such that you can easily copy them to a new machine and start hacking there.  For this we provide an experimental Python script `fuse_gmock_files.py` in the `scripts/` directory (starting with release 1.2.0).  Assuming you have Python 2.4 or above installed on your machine, just go to that directory and run ``` python fuse_gmock_files.py OUTPUT_DIR ```
and you should see an `OUTPUT_DIR` directory being created with files `gtest/gtest.h`, `gmock/gmock.h`, and `gmock-gtest-all.cc` in it. These three files contain everything you need to use Google Mock (and Google Test).  Just copy them to anywhere you want and you are ready to write tests and use mocks.  You can use the [scrpts/test/Makefile](http://code.google.com/p/googlemock/source/browse/trunk/scripts/test/Makefile) file as an example on how to compile your tests against them.
The `MATCHER*` family of macros can be used to define custom matchers easily.  The syntax:
``` MATCHER(name, description_string_expression) { statements; } ```
will define a matcher with the given name that executes the statements, which must return a `bool` to indicate if the match succeeds.  Inside the statements, you can refer to the value being matched by `arg`, and refer to its type by `arg_type`.
The description string is a `string`-typed expression that documents what the matcher does, and is used to generate the failure message when the match fails.  It can (and should) reference the special `bool` variable `negation`, and should evaluate to the description of the matcher when `negation` is `false`, or that of the matcher's negation when `negation` is `true`.
For convenience, we allow the description string to be empty (`""`), in which case Google Mock will use the sequence of words in the matcher name as the description.
For example: ``` MATCHER(IsDivisibleBy7, "") { return (arg % 7) == 0; } ``` allows you to write ```   // Expects mock_foo.Bar(n) to be called where n is divisible by 7.   EXPECT_CALL(mock_foo, Bar(IsDivisibleBy7())); ``` or, ``` using ::testing::Not; ...   EXPECT_THAT(some_expression, IsDivisibleBy7());   EXPECT_THAT(some_other_expression, Not(IsDivisibleBy7())); ``` If the above assertions fail, they will print something like: ```   Value of: some_expression   Expected: is divisible by 7     Actual: 27 ...   Value of: some_other_expression   Expected: not (is divisible by 7)     Actual: 21 ``` where the descriptions `"is divisible by 7"` and `"not (is divisible by 7)"` are automatically calculated from the matcher name `IsDivisibleBy7`.
As you may have noticed, the auto-generated descriptions (especially those for the negation) may not be so great. You can always override them with a string expression of your own: ``` MATCHER(IsDivisibleBy7, std::string(negation ? "isn't" : "is") +                         " divisible by 7") {   return (arg % 7) == 0; } ```
Optionally, you can stream additional information to a hidden argument named `result_listener` to explain the match result. For example, a better definition of `IsDivisibleBy7` is: ``` MATCHER(IsDivisibleBy7, "") {   if ((arg % 7) == 0)     return true;
*result_listener << "the remainder is " << (arg % 7);   return false; } ```
With this definition, the above assertion will give a better message: ```   Value of: some_expression   Expected: is divisible by 7     Actual: 27 (the remainder is 6) ```
You should let `MatchAndExplain()` print _any additional information_ that can help a user understand the match result. Note that it should explain why the match succeeds in case of a success (unless it's obvious) - this is useful when the matcher is used inside `Not()`. There is no need to print the argument value itself, as Google Mock already prints it for you.
**Notes:**
1. The type of the value being matched (`arg_type`) is determined by the context in which you use the matcher and is supplied to you by the compiler, so you don't need to worry about declaring it (nor can you).  This allows the matcher to be polymorphic.  For example, `IsDivisibleBy7()` can be used to match any type where the value of `(arg % 7) == 0` can be implicitly converted to a `bool`.  In the `Bar(IsDivisibleBy7())` example above, if method `Bar()` takes an `int`, `arg_type` will be `int`; if it takes an `unsigned long`, `arg_type` will be `unsigned long`; and so on.   1. Google Mock doesn't guarantee when or how many times a matcher will be invoked. Therefore the matcher logic must be _purely functional_ (i.e. it cannot have any side effect, and the result must not depend on anything other than the value being matched and the matcher parameters). This requirement must be satisfied no matter how you define the matcher (e.g. using one of the methods described in the following recipes). In particular, a matcher can never call a mock function, as that will affect the state of the mock object and Google Mock.
Sometimes you'll want to define a matcher that has parameters.  For that you can use the macro: ``` MATCHER_P(name, param_name, description_string) { statements; } ``` where the description string can be either `""` or a string expression that references `negation` and `param_name`.
For example: ``` MATCHER_P(HasAbsoluteValue, value, "") { return abs(arg) == value; } ``` will allow you to write: ```   EXPECT_THAT(Blah("a"), HasAbsoluteValue(n)); ``` which may lead to this message (assuming `n` is 10): ```   Value of: Blah("a")   Expected: has absolute value 10     Actual: -9 ```
Note that both the matcher description and its parameter are printed, making the message human-friendly.
In the matcher definition body, you can write `foo_type` to reference the type of a parameter named `foo`.  For example, in the body of `MATCHER_P(HasAbsoluteValue, value)` above, you can write `value_type` to refer to the type of `value`.
Google Mock also provides `MATCHER_P2`, `MATCHER_P3`, ..., up to `MATCHER_P10` to support multi-parameter matchers: ``` MATCHER_Pk(name, param_1, ..., param_k, description_string) { statements; } ```
Please note that the custom description string is for a particular **instance** of the matcher, where the parameters have been bound to actual values.  Therefore usually you'll want the parameter values to be part of the description.  Google Mock lets you do that by referencing the matcher parameters in the description string expression.
For example, ```   using ::testing::PrintToString;   MATCHER_P2(InClosedRange, low, hi,              std::string(negation ? "isn't" : "is") + " in range [" +              PrintToString(low) + ", " + PrintToString(hi) + "]") {     return low <= arg && arg <= hi;   }   ...   EXPECT_THAT(3, InClosedRange(4, 6)); ``` would generate a failure that contains the message: ```   Expected: is in range [4, 6] ```
If you specify `""` as the description, the failure message will contain the sequence of words in the matcher name followed by the parameter values printed as a tuple.  For example, ```   MATCHER_P2(InClosedRange, low, hi, "") { ... }   ...   EXPECT_THAT(3, InClosedRange(4, 6)); ``` would generate a failure that contains the text: ```   Expected: in closed range (4, 6) ```
For the purpose of typing, you can view ``` MATCHER_Pk(Foo, p1, ..., pk, description_string) { ... } ``` as shorthand for ``` template <typename p1_type, ..., typename pk_type> FooMatcherPk<p1_type, ..., pk_type> Foo(p1_type p1, ..., pk_type pk) { ... } ```
When you write `Foo(v1, ..., vk)`, the compiler infers the types of the parameters `v1`, ..., and `vk` for you.  If you are not happy with the result of the type inference, you can specify the types by explicitly instantiating the template, as in `Foo<long, bool>(5, false)`. As said earlier, you don't get to (or need to) specify `arg_type` as that's determined by the context in which the matcher is used.
You can assign the result of expression `Foo(p1, ..., pk)` to a variable of type `FooMatcherPk<p1_type, ..., pk_type>`.  This can be useful when composing matchers.  Matchers that don't have a parameter or have only one parameter have special types: you can assign `Foo()` to a `FooMatcher`-typed variable, and assign `Foo(p)` to a `FooMatcherP<p_type>`-typed variable.
While you can instantiate a matcher template with reference types, passing the parameters by pointer usually makes your code more readable.  If, however, you still want to pass a parameter by reference, be aware that in the failure message generated by the matcher you will see the value of the referenced object but not its address.
You can overload matchers with different numbers of parameters: ``` MATCHER_P(Blah, a, description_string_1) { ... } MATCHER_P2(Blah, a, b, description_string_2) { ... } ```
While it's tempting to always use the `MATCHER*` macros when defining a new matcher, you should also consider implementing `MatcherInterface` or using `MakePolymorphicMatcher()` instead (see the recipes that follow), especially if you need to use the matcher a lot.  While these approaches require more work, they give you more control on the types of the value being matched and the matcher parameters, which in general leads to better compiler error messages that pay off in the long run.  They also allow overloading matchers based on parameter types (as opposed to just based on the number of parameters).
A matcher of argument type `T` implements `::testing::MatcherInterface<T>` and does two things: it tests whether a value of type `T` matches the matcher, and can describe what kind of values it matches. The latter ability is used for generating readable error messages when expectations are violated.
The interface looks like this:
``` class MatchResultListener {  public:   ...   // Streams x to the underlying ostream; does nothing if the ostream   // is NULL.   template <typename T>   MatchResultListener& operator<<(const T& x);
// Returns the underlying ostream.   ::std::ostream* stream(); };
template <typename T> class MatcherInterface {  public:   virtual ~MatcherInterface();
// Returns true iff the matcher matches x; also explains the match   // result to 'listener'.   virtual bool MatchAndExplain(T x, MatchResultListener* listener) const = 0;
// Describes this matcher to an ostream.   virtual void DescribeTo(::std::ostream* os) const = 0;
// Describes the negation of this matcher to an ostream.   virtual void DescribeNegationTo(::std::ostream* os) const; }; ```
If you need a custom matcher but `Truly()` is not a good option (for example, you may not be happy with the way `Truly(predicate)` describes itself, or you may want your matcher to be polymorphic as `Eq(value)` is), you can define a matcher to do whatever you want in two steps: first implement the matcher interface, and then define a factory function to create a matcher instance. The second step is not strictly needed but it makes the syntax of using the matcher nicer.
For example, you can define a matcher to test whether an `int` is divisible by 7 and then use it like this: ``` using ::testing::MakeMatcher; using ::testing::Matcher; using ::testing::MatcherInterface; using ::testing::MatchResultListener;
class DivisibleBy7Matcher : public MatcherInterface<int> {  public:   virtual bool MatchAndExplain(int n, MatchResultListener* listener) const {     return (n % 7) == 0;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "is divisible by 7";   }
virtual void DescribeNegationTo(::std::ostream* os) const {     *os << "is not divisible by 7";   } };
inline Matcher<int> DivisibleBy7() {   return MakeMatcher(new DivisibleBy7Matcher); } ...
EXPECT_CALL(foo, Bar(DivisibleBy7())); ```
You may improve the matcher message by streaming additional information to the `listener` argument in `MatchAndExplain()`:
``` class DivisibleBy7Matcher : public MatcherInterface<int> {  public:   virtual bool MatchAndExplain(int n,                                MatchResultListener* listener) const {     const int remainder = n % 7;     if (remainder != 0) {       *listener << "the remainder is " << remainder;     }     return remainder == 0;   }   ... }; ```
Then, `EXPECT_THAT(x, DivisibleBy7());` may general a message like this: ``` Value of: x Expected: is divisible by 7   Actual: 23 (the remainder is 2) ```
You've learned how to write your own matchers in the previous recipe. Just one problem: a matcher created using `MakeMatcher()` only works for one particular type of arguments. If you want a _polymorphic_ matcher that works with arguments of several types (for instance, `Eq(x)` can be used to match a `value` as long as `value` == `x` compiles -- `value` and `x` don't have to share the same type), you can learn the trick from `"gmock/gmock-matchers.h"` but it's a bit involved.
Fortunately, most of the time you can define a polymorphic matcher easily with the help of `MakePolymorphicMatcher()`. Here's how you can define `NotNull()` as an example:
``` using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; using ::testing::NotNull; using ::testing::PolymorphicMatcher;
class NotNullMatcher {  public:   // To implement a polymorphic matcher, first define a COPYABLE class   // that has three members MatchAndExplain(), DescribeTo(), and   // DescribeNegationTo(), like the following.
// In this example, we want to use NotNull() with any pointer, so   // MatchAndExplain() accepts a pointer of any type as its first argument.   // In general, you can define MatchAndExplain() as an ordinary method or   // a method template, or even overload it.   template <typename T>   bool MatchAndExplain(T* p,                        MatchResultListener* /* listener */) const {     return p != NULL;   }
// Describes the property of a value matching this matcher.   void DescribeTo(::std::ostream* os) const { *os << "is not NULL"; }
// Describes the property of a value NOT matching this matcher.   void DescribeNegationTo(::std::ostream* os) const { *os << "is NULL"; } };
// To construct a polymorphic matcher, pass an instance of the class // to MakePolymorphicMatcher().  Note the return type. inline PolymorphicMatcher<NotNullMatcher> NotNull() {   return MakePolymorphicMatcher(NotNullMatcher()); } ...
EXPECT_CALL(foo, Bar(NotNull()));  // The argument must be a non-NULL pointer. ```
**Note:** Your polymorphic matcher class does **not** need to inherit from `MatcherInterface` or any other class, and its methods do **not** need to be virtual.
Like in a monomorphic matcher, you may explain the match result by streaming additional information to the `listener` argument in `MatchAndExplain()`.
A cardinality is used in `Times()` to tell Google Mock how many times you expect a call to occur. It doesn't have to be exact. For example, you can say `AtLeast(5)` or `Between(2, 4)`.
If the built-in set of cardinalities doesn't suit you, you are free to define your own by implementing the following interface (in namespace `testing`):
``` class CardinalityInterface {  public:   virtual ~CardinalityInterface();
// Returns true iff call_count calls will satisfy this cardinality.   virtual bool IsSatisfiedByCallCount(int call_count) const = 0;
// Returns true iff call_count calls will saturate this cardinality.   virtual bool IsSaturatedByCallCount(int call_count) const = 0;
// Describes self to an ostream.   virtual void DescribeTo(::std::ostream* os) const = 0; }; ```
For example, to specify that a call must occur even number of times, you can write
``` using ::testing::Cardinality; using ::testing::CardinalityInterface; using ::testing::MakeCardinality;
class EvenNumberCardinality : public CardinalityInterface {  public:   virtual bool IsSatisfiedByCallCount(int call_count) const {     return (call_count % 2) == 0;   }
virtual bool IsSaturatedByCallCount(int call_count) const {     return false;   }
virtual void DescribeTo(::std::ostream* os) const {     *os << "called even number of times";   } };
Cardinality EvenNumber() {   return MakeCardinality(new EvenNumberCardinality); } ...
EXPECT_CALL(foo, Bar(3))       .Times(EvenNumber()); ```
If the built-in actions don't work for you, and you find it inconvenient to use `Invoke()`, you can use a macro from the `ACTION*` family to quickly define a new action that can be used in your code as if it's a built-in action.
By writing ``` ACTION(name) { statements; } ``` in a namespace scope (i.e. not inside a class or function), you will define an action with the given name that executes the statements. The value returned by `statements` will be used as the return value of the action.  Inside the statements, you can refer to the K-th (0-based) argument of the mock function as `argK`.  For example: ``` ACTION(IncrementArg1) { return ++(*arg1); } ``` allows you to write ``` ... WillOnce(IncrementArg1()); ```
Note that you don't need to specify the types of the mock function arguments.  Rest assured that your code is type-safe though: you'll get a compiler error if `*arg1` doesn't support the `++` operator, or if the type of `++(*arg1)` isn't compatible with the mock function's return type.
Another example: ``` ACTION(Foo) {   (*arg2)(5);   Blah();   *arg1 = 0;   return arg0; } ``` defines an action `Foo()` that invokes argument #2 (a function pointer) with 5, calls function `Blah()`, sets the value pointed to by argument #1 to 0, and returns argument #0.
For more convenience and flexibility, you can also use the following pre-defined symbols in the body of `ACTION`:
| `argK_type` | The type of the K-th (0-based) argument of the mock function | |:------------|:-------------------------------------------------------------| | `args`      | All arguments of the mock function as a tuple                | | `args_type` | The type of all arguments of the mock function as a tuple    | | `return_type` | The return type of the mock function                         | | `function_type` | The type of the mock function                                |
For example, when using an `ACTION` as a stub action for mock function: ``` int DoSomething(bool flag, int* ptr); ``` we have: | **Pre-defined Symbol** | **Is Bound To** | |:-----------------------|:----------------| | `arg0`                 | the value of `flag` | | `arg0_type`            | the type `bool` | | `arg1`                 | the value of `ptr` | | `arg1_type`            | the type `int*` | | `args`                 | the tuple `(flag, ptr)` | | `args_type`            | the type `std::tr1::tuple<bool, int*>` | | `return_type`          | the type `int`  | | `function_type`        | the type `int(bool, int*)` |
Sometimes you'll want to parameterize an action you define.  For that we have another macro ``` ACTION_P(name, param) { statements; } ```
For example, ``` ACTION_P(Add, n) { return arg0 + n; } ``` will allow you to write ``` // Returns argument #0 + 5. ... WillOnce(Add(5)); ```
For convenience, we use the term _arguments_ for the values used to invoke the mock function, and the term _parameters_ for the values used to instantiate an action.
Note that you don't need to provide the type of the parameter either. Suppose the parameter is named `param`, you can also use the Google-Mock-defined symbol `param_type` to refer to the type of the parameter as inferred by the compiler.  For example, in the body of `ACTION_P(Add, n)` above, you can write `n_type` for the type of `n`.
Google Mock also provides `ACTION_P2`, `ACTION_P3`, and etc to support multi-parameter actions.  For example, ``` ACTION_P2(ReturnDistanceTo, x, y) {   double dx = arg0 - x;   double dy = arg1 - y;   return sqrt(dx*dx + dy*dy); } ``` lets you write ``` ... WillOnce(ReturnDistanceTo(5.0, 26.5)); ```
You can view `ACTION` as a degenerated parameterized action where the number of parameters is 0.
You can also easily define actions overloaded on the number of parameters: ``` ACTION_P(Plus, a) { ... } ACTION_P2(Plus, a, b) { ... } ```
For maximum brevity and reusability, the `ACTION*` macros don't ask you to provide the types of the mock function arguments and the action parameters.  Instead, we let the compiler infer the types for us.
Sometimes, however, we may want to be more explicit about the types. There are several tricks to do that.  For example: ``` ACTION(Foo) {   // Makes sure arg0 can be converted to int.   int n = arg0;   ... use n instead of arg0 here ... }
ACTION_P(Bar, param) {   // Makes sure the type of arg1 is const char*.   ::testing::StaticAssertTypeEq<const char*, arg1_type>();
// Makes sure param can be converted to bool.   bool flag = param; } ``` where `StaticAssertTypeEq` is a compile-time assertion in Google Test that verifies two types are the same.
Sometimes you want to give an action explicit template parameters that cannot be inferred from its value parameters.  `ACTION_TEMPLATE()` supports that and can be viewed as an extension to `ACTION()` and `ACTION_P*()`.
The syntax: ``` ACTION_TEMPLATE(ActionName,                 HAS_m_TEMPLATE_PARAMS(kind1, name1, ..., kind_m, name_m),                 AND_n_VALUE_PARAMS(p1, ..., p_n)) { statements; } ```
defines an action template that takes _m_ explicit template parameters and _n_ value parameters, where _m_ is between 1 and 10, and _n_ is between 0 and 10.  `name_i` is the name of the i-th template parameter, and `kind_i` specifies whether it's a `typename`, an integral constant, or a template.  `p_i` is the name of the i-th value parameter.
Example: ``` // DuplicateArg<k, T>(output) converts the k-th argument of the mock // function to type T and copies it to *output. ACTION_TEMPLATE(DuplicateArg,                 // Note the comma between int and k:                 HAS_2_TEMPLATE_PARAMS(int, k, typename, T),                 AND_1_VALUE_PARAMS(output)) {   *output = T(std::tr1::get<k>(args)); } ```
To create an instance of an action template, write: ```   ActionName<t1, ..., t_m>(v1, ..., v_n) ``` where the `t`s are the template arguments and the `v`s are the value arguments.  The value argument types are inferred by the compiler.  For example: ``` using ::testing::_; ...   int n;   EXPECT_CALL(mock, Foo(_, _))       .WillOnce(DuplicateArg<1, unsigned char>(&n)); ```
If you want to explicitly specify the value argument types, you can provide additional template arguments: ```   ActionName<t1, ..., t_m, u1, ..., u_k>(v1, ..., v_n) ``` where `u_i` is the desired type of `v_i`.
`ACTION_TEMPLATE` and `ACTION`/`ACTION_P*` can be overloaded on the number of value parameters, but not on the number of template parameters.  Without the restriction, the meaning of the following is unclear:
```   OverloadedAction<int, bool>(x); ```
Are we using a single-template-parameter action where `bool` refers to the type of `x`, or a two-template-parameter action where the compiler is asked to infer the type of `x`?
If you are writing a function that returns an `ACTION` object, you'll need to know its type.  The type depends on the macro used to define the action and the parameter types.  The rule is relatively simple: | **Given Definition** | **Expression** | **Has Type** | |:---------------------|:---------------|:-------------| | `ACTION(Foo)`        | `Foo()`        | `FooAction`  | | `ACTION_TEMPLATE(Foo, HAS_m_TEMPLATE_PARAMS(...), AND_0_VALUE_PARAMS())` |	`Foo<t1, ..., t_m>()` | `FooAction<t1, ..., t_m>` | | `ACTION_P(Bar, param)` | `Bar(int_value)` | `BarActionP<int>` | | `ACTION_TEMPLATE(Bar, HAS_m_TEMPLATE_PARAMS(...), AND_1_VALUE_PARAMS(p1))` | `Bar<t1, ..., t_m>(int_value)` | `FooActionP<t1, ..., t_m, int>` | | `ACTION_P2(Baz, p1, p2)` | `Baz(bool_value, int_value)` | `BazActionP2<bool, int>` | | `ACTION_TEMPLATE(Baz, HAS_m_TEMPLATE_PARAMS(...), AND_2_VALUE_PARAMS(p1, p2))` | `Baz<t1, ..., t_m>(bool_value, int_value)` | `FooActionP2<t1, ..., t_m, bool, int>` | | ...                  | ...            | ...          |
Note that we have to pick different suffixes (`Action`, `ActionP`, `ActionP2`, and etc) for actions with different numbers of value parameters, or the action definitions cannot be overloaded on the number of them.
While the `ACTION*` macros are very convenient, sometimes they are inappropriate.  For example, despite the tricks shown in the previous recipes, they don't let you directly specify the types of the mock function arguments and the action parameters, which in general leads to unoptimized compiler error messages that can baffle unfamiliar users.  They also don't allow overloading actions based on parameter types without jumping through some hoops.
An alternative to the `ACTION*` macros is to implement `::testing::ActionInterface<F>`, where `F` is the type of the mock function in which the action will be used. For example:
``` template <typename F>class ActionInterface {  public:   virtual ~ActionInterface();
// Performs the action.  Result is the return type of function type   // F, and ArgumentTuple is the tuple of arguments of F.   //   // For example, if F is int(bool, const string&), then Result would   // be int, and ArgumentTuple would be tr1::tuple<bool, const string&>.   virtual Result Perform(const ArgumentTuple& args) = 0; };
using ::testing::_; using ::testing::Action; using ::testing::ActionInterface; using ::testing::MakeAction;
typedef int IncrementMethod(int*);
class IncrementArgumentAction : public ActionInterface<IncrementMethod> {  public:   virtual int Perform(const tr1::tuple<int*>& args) {     int* p = tr1::get<0>(args);  // Grabs the first argument.     return *p++;   } };
Action<IncrementMethod> IncrementArgument() {   return MakeAction(new IncrementArgumentAction); } ...
EXPECT_CALL(foo, Baz(_))       .WillOnce(IncrementArgument());
int n = 5;   foo.Baz(&n);  // Should return 5 and change n to 6. ```
The previous recipe showed you how to define your own action. This is all good, except that you need to know the type of the function in which the action will be used. Sometimes that can be a problem. For example, if you want to use the action in functions with _different_ types (e.g. like `Return()` and `SetArgPointee()`).
If an action can be used in several types of mock functions, we say it's _polymorphic_. The `MakePolymorphicAction()` function template makes it easy to define such an action:
``` namespace testing {
template <typename Impl> PolymorphicAction<Impl> MakePolymorphicAction(const Impl& impl);
}  // namespace testing ```
As an example, let's define an action that returns the second argument in the mock function's argument list. The first step is to define an implementation class:
``` class ReturnSecondArgumentAction {  public:   template <typename Result, typename ArgumentTuple>   Result Perform(const ArgumentTuple& args) const {     // To get the i-th (0-based) argument, use tr1::get<i>(args).     return tr1::get<1>(args);   } }; ```
This implementation class does _not_ need to inherit from any particular class. What matters is that it must have a `Perform()` method template. This method template takes the mock function's arguments as a tuple in a **single** argument, and returns the result of the action. It can be either `const` or not, but must be invokable with exactly one template argument, which is the result type. In other words, you must be able to call `Perform<R>(args)` where `R` is the mock function's return type and `args` is its arguments in a tuple.
Next, we use `MakePolymorphicAction()` to turn an instance of the implementation class into the polymorphic action we need. It will be convenient to have a wrapper for this:
``` using ::testing::MakePolymorphicAction; using ::testing::PolymorphicAction;
PolymorphicAction<ReturnSecondArgumentAction> ReturnSecondArgument() {   return MakePolymorphicAction(ReturnSecondArgumentAction()); } ```
Now, you can use this polymorphic action the same way you use the built-in ones:
``` using ::testing::_;
class MockFoo : public Foo {  public:   MOCK_METHOD2(DoThis, int(bool flag, int n));   MOCK_METHOD3(DoThat, string(int x, const char* str1, const char* str2)); }; ...
MockFoo foo;   EXPECT_CALL(foo, DoThis(_, _))       .WillOnce(ReturnSecondArgument());   EXPECT_CALL(foo, DoThat(_, _, _))       .WillOnce(ReturnSecondArgument());   ...   foo.DoThis(true, 5);         // Will return 5.   foo.DoThat(1, "Hi", "Bye");  // Will return "Hi". ```
When an uninteresting or unexpected call occurs, Google Mock prints the argument values and the stack trace to help you debug.  Assertion macros like `EXPECT_THAT` and `EXPECT_EQ` also print the values in question when the assertion fails.  Google Mock and Google Test do this using Google Test's user-extensible value printer.
This printer knows how to print built-in C++ types, native arrays, STL containers, and any type that supports the `<<` operator.  For other types, it prints the raw bytes in the value and hopes that you the user can figure it out. [Google Test's advanced guide](http://code.google.com/p/googletest/wiki/AdvancedGuide#Teaching_Google_Test_How_to_Print_Your_Values) explains how to extend the printer to do a better job at printing your particular type than to dump the bytes.
This page lists all documentation wiki pages for Google Mock **(the SVN trunk version)** - **if you use a released version of Google Mock, please read the documentation for that specific version instead.**
* [ForDummies](V1_7_ForDummies.md) -- start here if you are new to Google Mock.   * [CheatSheet](V1_7_CheatSheet.md) -- a quick reference.   * [CookBook](V1_7_CookBook.md) -- recipes for doing various tasks using Google Mock.   * [FrequentlyAskedQuestions](V1_7_FrequentlyAskedQuestions.md) -- check here before asking a question on the mailing list.
To contribute code to Google Mock, read:
* [DevGuide](DevGuide.md) -- read this _before_ writing your first patch.   * [Pump Manual](http://code.google.com/p/googletest/wiki/PumpManual) -- how we generate some of Google Mock's source files.

(**Note:** If you get compiler errors that you don't understand, be sure to consult [Google Mock Doctor](http://code.google.com/p/googlemock/wiki/V1_7_FrequentlyAskedQuestions#How_am_I_supposed_to_make_sense_of_these_horrible_template_error).)
**Note:** It is easy to confuse the term _fake objects_ with mock objects. Fakes and mocks actually mean very different things in the Test-Driven Development (TDD) community:
* **Fake** objects have working implementations, but usually take some shortcut (perhaps to make the operations less expensive), which makes them not suitable for production. An in-memory file system would be an example of a fake.   * **Mocks** are objects pre-programmed with _expectations_, which form a specification of the calls they are expected to receive.
If all this seems too abstract for you, don't worry - the most important thing to remember is that a mock allows you to check the _interaction_ between itself and code that uses it. The difference between fakes and mocks will become much clearer once you start to use mocks.
**Google C++ Mocking Framework** (or **Google Mock** for short) is a library (sometimes we also call it a "framework" to make it sound cool) for creating mock classes and using them. It does to C++ what [jMock](http://www.jmock.org/) and [EasyMock](http://www.easymock.org/) do to Java.
Using Google Mock involves three basic steps:
1. Use some simple macros to describe the interface you want to mock, and they will expand to the implementation of your mock class;   1. Create some mock objects and specify its expectations and behavior using an intuitive syntax;   1. Exercise code that uses the mock objects. Google Mock will catch any violation of the expectations as soon as it arises.
* Someone has to implement the mocks. The job is usually tedious and error-prone. No wonder people go great distance to avoid it.   * The quality of those manually written mocks is a bit, uh, unpredictable. You may see some really polished ones, but you may also see some that were hacked up in a hurry and have all sorts of ad hoc restrictions.   * The knowledge you gained from using one mock doesn't transfer to the next.
In contrast, Java and Python programmers have some fine mock frameworks, which automate the creation of mocks. As a result, mocking is a proven effective technique and widely adopted practice in those communities. Having the right tool absolutely makes the difference.
Google Mock was built to help C++ programmers. It was inspired by [jMock](http://www.jmock.org/) and [EasyMock](http://www.easymock.org/), but designed with C++'s specifics in mind. It is your friend if any of the following problems is bothering you:
* You are stuck with a sub-optimal design and wish you had done more prototyping before it was too late, but prototyping in C++ is by no means "rapid".   * Your tests are slow as they depend on too many libraries or use expensive resources (e.g. a database).   * Your tests are brittle as some resources they use are unreliable (e.g. the network).   * You want to test how your code handles a failure (e.g. a file checksum error), but it's not easy to cause one.   * You need to make sure that your module interacts with other modules in the right way, but it's hard to observe the interaction; therefore you resort to observing the side effects at the end of the action, which is awkward at best.   * You want to "mock out" your dependencies, except that they don't have mock implementations yet; and, frankly, you aren't thrilled by some of those hand-written mocks.
We encourage you to use Google Mock as:
* a _design_ tool, for it lets you experiment with your interface design early and often. More iterations lead to better designs!   * a _testing_ tool to cut your tests' outbound dependencies and probe the interaction between your module and its collaborators.
``` class Turtle {   ...   virtual ~Turtle() {}   virtual void PenUp() = 0;   virtual void PenDown() = 0;   virtual void Forward(int distance) = 0;   virtual void Turn(int degrees) = 0;   virtual void GoTo(int x, int y) = 0;   virtual int GetX() const = 0;   virtual int GetY() const = 0; }; ```
(Note that the destructor of `Turtle` **must** be virtual, as is the case for **all** classes you intend to inherit from - otherwise the destructor of the derived class will not be called when you delete an object through a base pointer, and you'll get corrupted program states like memory leaks.)
You can control whether the turtle's movement will leave a trace using `PenUp()` and `PenDown()`, and control its movement using `Forward()`, `Turn()`, and `GoTo()`. Finally, `GetX()` and `GetY()` tell you the current position of the turtle.
Your program will normally use a real implementation of this interface. In tests, you can use a mock implementation instead. This allows you to easily check what drawing primitives your program is calling, with what arguments, and in which order. Tests written this way are much more robust (they won't break because your new machine does anti-aliasing differently), easier to read and maintain (the intent of a test is expressed in the code, not in some binary images), and run _much, much faster_.
1. Derive a class `MockTurtle` from `Turtle`.   1. Take a _virtual_ function of `Turtle` (while it's possible to [mock non-virtual methods using templates](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Mocking_Nonvirtual_Methods), it's much more involved). Count how many arguments it has.   1. In the `public:` section of the child class, write `MOCK_METHODn();` (or `MOCK_CONST_METHODn();` if you are mocking a `const` method), where `n` is the number of the arguments; if you counted wrong, shame on you, and a compiler error will tell you so.   1. Now comes the fun part: you take the function signature, cut-and-paste the _function name_ as the _first_ argument to the macro, and leave what's left as the _second_ argument (in case you're curious, this is the _type of the function_).   1. Repeat until all virtual functions you want to mock are done.
After the process, you should have something like:
``` #include "gmock/gmock.h"  // Brings in Google Mock. class MockTurtle : public Turtle {  public:   ...   MOCK_METHOD0(PenUp, void());   MOCK_METHOD0(PenDown, void());   MOCK_METHOD1(Forward, void(int distance));   MOCK_METHOD1(Turn, void(int degrees));   MOCK_METHOD2(GoTo, void(int x, int y));   MOCK_CONST_METHOD0(GetX, int());   MOCK_CONST_METHOD0(GetY, int()); }; ```
You don't need to define these mock methods somewhere else - the `MOCK_METHOD*` macros will generate the definitions for you. It's that simple! Once you get the hang of it, you can pump out mock classes faster than your source-control system can handle your check-ins.
**Tip:** If even this is too much work for you, you'll find the `gmock_gen.py` tool in Google Mock's `scripts/generator/` directory (courtesy of the [cppclean](http://code.google.com/p/cppclean/) project) useful.  This command-line tool requires that you have Python 2.4 installed.  You give it a C++ file and the name of an abstract class defined in it, and it will print the definition of the mock class for you.  Due to the complexity of the C++ language, this script may not always work, but it can be quite handy when it does.  For more details, read the [user documentation](http://code.google.com/p/googlemock/source/browse/trunk/scripts/generator/README).
So, the rule of thumb is: if you need to mock `Foo` and it's owned by others, define the mock class in `Foo`'s package (better, in a `testing` sub-package such that you can clearly separate production code and testing utilities), and put it in a `mock_foo.h`. Then everyone can reference `mock_foo.h` from their tests. If `Foo` ever changes, there is only one copy of `MockFoo` to change, and only tests that depend on the changed methods need to be fixed.
Another way to do it: you can introduce a thin layer `FooAdaptor` on top of `Foo` and code to this new interface. Since you own `FooAdaptor`, you can absorb changes in `Foo` much more easily. While this is more work initially, carefully choosing the adaptor interface can make your code easier to write and more readable (a net win in the long run), as you can choose `FooAdaptor` to fit your specific domain much better than `Foo` does.
1. Import the Google Mock names from the `testing` namespace such that you can use them unqualified (You only have to do it once per file. Remember that namespaces are a good idea and good for your health.).   1. Create some mock objects.   1. Specify your expectations on them (How many times will a method be called? With what arguments? What should it do? etc.).   1. Exercise some code that uses the mocks; optionally, check the result using Google Test assertions. If a mock method is called more than expected or with wrong arguments, you'll get an error immediately.   1. When a mock is destructed, Google Mock will automatically check whether all expectations on it have been satisfied.
Here's an example:
``` #include "path/to/mock-turtle.h" #include "gmock/gmock.h" #include "gtest/gtest.h" using ::testing::AtLeast;                     // #1
TEST(PainterTest, CanDrawSomething) {   MockTurtle turtle;                          // #2   EXPECT_CALL(turtle, PenDown())              // #3       .Times(AtLeast(1));
Painter painter(&turtle);                   // #4
EXPECT_TRUE(painter.DrawCircle(0, 0, 10)); }                                             // #5
int main(int argc, char** argv) {   // The following line must be executed to initialize Google Mock   // (and Google Test) before running the tests.   ::testing::InitGoogleMock(&argc, argv);   return RUN_ALL_TESTS(); } ```
As you might have guessed, this test checks that `PenDown()` is called at least once. If the `painter` object didn't call this method, your test will fail with a message like this:
``` path/to/my_test.cc:119: Failure Actual function call count doesn't match this expectation: Actually: never called; Expected: called at least once. ```
**Tip 1:** If you run the test from an Emacs buffer, you can hit `<Enter>` on the line number displayed in the error message to jump right to the failed expectation.
**Tip 2:** If your mock objects are never deleted, the final verification won't happen. Therefore it's a good idea to use a heap leak checker in your tests when you allocate mocks on the heap.
**Important note:** Google Mock requires expectations to be set **before** the mock functions are called, otherwise the behavior is **undefined**. In particular, you mustn't interleave `EXPECT_CALL()`s and calls to the mock functions.
This means `EXPECT_CALL()` should be read as expecting that a call will occur _in the future_, not that a call has occurred. Why does Google Mock work like that? Well, specifying the expectation beforehand allows Google Mock to report a violation as soon as it arises, when the context (stack trace, etc) is still available. This makes debugging much easier.
Admittedly, this test is contrived and doesn't do much. You can easily achieve the same effect without using Google Mock. However, as we shall reveal soon, Google Mock allows you to do _much more_ with the mocks.
This approach has a catch: it makes Google Mock throw an exception from a mock object's destructor sometimes.  With some compilers, this sometimes causes the test program to crash.  You'll still be able to notice that the test has failed, but it's not a graceful failure.
A better solution is to use Google Test's [event listener API](http://code.google.com/p/googletest/wiki/AdvancedGuide#Extending_Google_Test_by_Handling_Test_Events) to report a test failure to your testing framework properly.  You'll need to implement the `OnTestPartResult()` method of the event listener interface, but it should be straightforward.
If this turns out to be too much work, we suggest that you stick with Google Test, which works with Google Mock seamlessly (in fact, it is technically part of Google Mock.).  If there is a reason that you cannot use Google Test, please let us know.
``` EXPECT_CALL(mock_object, method(matchers))     .Times(cardinality)     .WillOnce(action)     .WillRepeatedly(action); ```
The macro has two arguments: first the mock object, and then the method and its arguments. Note that the two are separated by a comma (`,`), not a period (`.`). (Why using a comma? The answer is that it was necessary for technical reasons.)
The macro can be followed by some optional _clauses_ that provide more information about the expectation. We'll discuss how each clause works in the coming sections.
This syntax is designed to make an expectation read like English. For example, you can probably guess that
``` using ::testing::Return;... EXPECT_CALL(turtle, GetX())     .Times(5)     .WillOnce(Return(100))     .WillOnce(Return(150))     .WillRepeatedly(Return(200)); ```
says that the `turtle` object's `GetX()` method will be called five times, it will return 100 the first time, 150 the second time, and then 200 every time. Some people like to call this style of syntax a Domain-Specific Language (DSL).
**Note:** Why do we use a macro to do this? It serves two purposes: first it makes expectations easily identifiable (either by `grep` or by a human reader), and second it allows Google Mock to include the source file location of a failed expectation in messages, making debugging easier.
``` // Expects the turtle to move forward by 100 units. EXPECT_CALL(turtle, Forward(100)); ```
Sometimes you may not want to be too specific (Remember that talk about tests being too rigid? Over specification leads to brittle tests and obscures the intent of tests. Therefore we encourage you to specify only what's necessary - no more, no less.). If you care to check that `Forward()` will be called but aren't interested in its actual argument, write `_` as the argument, which means "anything goes":
``` using ::testing::_; ... // Expects the turtle to move forward. EXPECT_CALL(turtle, Forward(_)); ```
`_` is an instance of what we call **matchers**. A matcher is like a predicate and can test whether an argument is what we'd expect. You can use a matcher inside `EXPECT_CALL()` wherever a function argument is expected.
A list of built-in matchers can be found in the [CheatSheet](V1_7_CheatSheet.md). For example, here's the `Ge` (greater than or equal) matcher:
``` using ::testing::Ge;... EXPECT_CALL(turtle, Forward(Ge(100))); ```
This checks that the turtle will be told to go forward by at least 100 units.
An interesting special case is when we say `Times(0)`. You may have guessed - it means that the function shouldn't be called with the given arguments at all, and Google Mock will report a Google Test failure whenever the function is (wrongfully) called.
We've seen `AtLeast(n)` as an example of fuzzy cardinalities earlier. For the list of built-in cardinalities you can use, see the [CheatSheet](V1_7_CheatSheet.md).
The `Times()` clause can be omitted. **If you omit `Times()`, Google Mock will infer the cardinality for you.** The rules are easy to remember:
* If **neither** `WillOnce()` **nor** `WillRepeatedly()` is in the `EXPECT_CALL()`, the inferred cardinality is `Times(1)`.   * If there are `n WillOnce()`'s but **no** `WillRepeatedly()`, where `n` >= 1, the cardinality is `Times(n)`.   * If there are `n WillOnce()`'s and **one** `WillRepeatedly()`, where `n` >= 0, the cardinality is `Times(AtLeast(n))`.
**Quick quiz:** what do you think will happen if a function is expected to be called twice but actually called four times?
First, if the return type of a mock function is a built-in type or a pointer, the function has a **default action** (a `void` function will just return, a `bool` function will return `false`, and other functions will return 0). If you don't say anything, this behavior will be used.
Second, if a mock function doesn't have a default action, or the default action doesn't suit you, you can specify the action to be taken each time the expectation matches using a series of `WillOnce()` clauses followed by an optional `WillRepeatedly()`. For example,
``` using ::testing::Return;... EXPECT_CALL(turtle, GetX())     .WillOnce(Return(100))     .WillOnce(Return(200))     .WillOnce(Return(300)); ```
This says that `turtle.GetX()` will be called _exactly three times_ (Google Mock inferred this from how many `WillOnce()` clauses we've written, since we didn't explicitly write `Times()`), and will return 100, 200, and 300 respectively.
``` using ::testing::Return;... EXPECT_CALL(turtle, GetY())     .WillOnce(Return(100))     .WillOnce(Return(200))     .WillRepeatedly(Return(300)); ```
says that `turtle.GetY()` will be called _at least twice_ (Google Mock knows this as we've written two `WillOnce()` clauses and a `WillRepeatedly()` while having no explicit `Times()`), will return 100 the first time, 200 the second time, and 300 from the third time on.
Of course, if you explicitly write a `Times()`, Google Mock will not try to infer the cardinality itself. What if the number you specified is larger than there are `WillOnce()` clauses? Well, after all `WillOnce()`s are used up, Google Mock will do the _default_ action for the function every time (unless, of course, you have a `WillRepeatedly()`.).
What can we do inside `WillOnce()` besides `Return()`? You can return a reference using `ReturnRef(variable)`, or invoke a pre-defined function, among [others](http://code.google.com/p/googlemock/wiki/V1_7_CheatSheet#Actions).
**Important note:** The `EXPECT_CALL()` statement evaluates the action clause only once, even though the action may be performed many times. Therefore you must be careful about side effects. The following may not do what you want:
``` int n = 100; EXPECT_CALL(turtle, GetX()) .Times(4) .WillRepeatedly(Return(n++)); ```
Instead of returning 100, 101, 102, ..., consecutively, this mock function will always return 100 as `n++` is only evaluated once. Similarly, `Return(new Foo)` will create a new `Foo` object when the `EXPECT_CALL()` is executed, and will return the same pointer every time. If you want the side effect to happen every time, you need to define a custom action, which we'll teach in the [CookBook](V1_7_CookBook.md).
Time for another quiz! What do you think the following means?
``` using ::testing::Return;... EXPECT_CALL(turtle, GetY()) .Times(4) .WillOnce(Return(100)); ```
Obviously `turtle.GetY()` is expected to be called four times. But if you think it will return 100 every time, think twice! Remember that one `WillOnce()` clause will be consumed each time the function is invoked and the default action will be taken afterwards. So the right answer is that `turtle.GetY()` will return 100 the first time, but **return 0 from the second time on**, as returning 0 is the default action for `int` functions.
By default, when a mock method is invoked, Google Mock will search the expectations in the **reverse order** they are defined, and stop when an active expectation that matches the arguments is found (you can think of it as "newer rules override older ones."). If the matching expectation cannot take any more calls, you will get an upper-bound-violated failure. Here's an example:
``` using ::testing::_;... EXPECT_CALL(turtle, Forward(_));  // #1 EXPECT_CALL(turtle, Forward(10))  // #2     .Times(2); ```
If `Forward(10)` is called three times in a row, the third time it will be an error, as the last matching expectation (#2) has been saturated. If, however, the third `Forward(10)` call is replaced by `Forward(20)`, then it would be OK, as now #1 will be the matching expectation.
**Side note:** Why does Google Mock search for a match in the _reverse_ order of the expectations? The reason is that this allows a user to set up the default expectations in a mock object's constructor or the test fixture's set-up phase and then customize the mock by writing more specific expectations in the test body. So, if you have two expectations on the same method, you want to put the one with more specific matchers **after** the other, or the more specific rule would be shadowed by the more general one that comes after it.
Sometimes, you may want all the expected calls to occur in a strict order. To say this in Google Mock is easy:
``` using ::testing::InSequence;... TEST(FooTest, DrawsLineSegment) {   ...   {     InSequence dummy;
EXPECT_CALL(turtle, PenDown());     EXPECT_CALL(turtle, Forward(100));     EXPECT_CALL(turtle, PenUp());   }   Foo(); } ```
By creating an object of type `InSequence`, all expectations in its scope are put into a _sequence_ and have to occur _sequentially_. Since we are just relying on the constructor and destructor of this object to do the actual work, its name is really irrelevant.
In this example, we test that `Foo()` calls the three expected functions in the order as written. If a call is made out-of-order, it will be an error.
(What if you care about the relative order of some of the calls, but not all of them? Can you specify an arbitrary partial order? The answer is ... yes! If you are impatient, the details can be found in the [CookBook](V1_7_CookBook#Expecting_Partially_Ordered_Calls.md).)
After you've come up with your answer, take a look at ours and compare notes (solve it yourself first - don't cheat!):
``` using ::testing::_;... EXPECT_CALL(turtle, GoTo(_, _))  // #1     .Times(AnyNumber()); EXPECT_CALL(turtle, GoTo(0, 0))  // #2     .Times(2); ```
Suppose `turtle.GoTo(0, 0)` is called three times. In the third time, Google Mock will see that the arguments match expectation #2 (remember that we always pick the last matching expectation). Now, since we said that there should be only two such calls, Google Mock will report an error immediately. This is basically what we've told you in the "Using Multiple Expectations" section above.
This example shows that **expectations in Google Mock are "sticky" by default**, in the sense that they remain active even after we have reached their invocation upper bounds. This is an important rule to remember, as it affects the meaning of the spec, and is **different** to how it's done in many other mocking frameworks (Why'd we do that? Because we think our rule makes the common cases easier to express and understand.).
Simple? Let's see if you've really understood it: what does the following code say?
``` using ::testing::Return; ... for (int i = n; i > 0; i--) {   EXPECT_CALL(turtle, GetX())       .WillOnce(Return(10*i)); } ```
If you think it says that `turtle.GetX()` will be called `n` times and will return 10, 20, 30, ..., consecutively, think twice! The problem is that, as we said, expectations are sticky. So, the second time `turtle.GetX()` is called, the last (latest) `EXPECT_CALL()` statement will match, and will immediately lead to an "upper bound exceeded" error - this piece of code is not very useful!
One correct way of saying that `turtle.GetX()` will return 10, 20, 30, ..., is to explicitly say that the expectations are _not_ sticky. In other words, they should _retire_ as soon as they are saturated:
``` using ::testing::Return; ... for (int i = n; i > 0; i--) {   EXPECT_CALL(turtle, GetX())     .WillOnce(Return(10*i))     .RetiresOnSaturation(); } ```
And, there's a better way to do it: in this case, we expect the calls to occur in a specific order, and we line up the actions to match the order. Since the order is important here, we should make it explicit using a sequence:
``` using ::testing::InSequence; using ::testing::Return; ... {   InSequence s;
for (int i = 1; i <= n; i++) {     EXPECT_CALL(turtle, GetX())         .WillOnce(Return(10*i))         .RetiresOnSaturation();   } } ```
By the way, the other situation where an expectation may _not_ be sticky is when it's in a sequence - as soon as another expectation that comes after it in the sequence has been used, it automatically retires (and will never be used to match any call).
In Google Mock, if you are not interested in a method, just don't say anything about it. If a call to this method occurs, you'll see a warning in the test output, but it won't be a failure.
Then, if you feel like increasing your mock quotient, you should move on to the [CookBook](V1_7_CookBook.md). You can learn many advanced features of Google Mock there -- and advance your level of enjoyment and testing bliss.

Please send your questions to the [googlemock](http://groups.google.com/group/googlemock) discussion group. If you need help with compiler errors, make sure you have tried [Google Mock Doctor](#How_am_I_supposed_to_make_sense_of_these_horrible_template_error.md) first.
In order for a method to be mocked, it must be _virtual_, unless you use the [high-perf dependency injection technique](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Mocking_Nonvirtual_Methods).
After version 1.4.0 of Google Mock was released, we had an idea on how to make it easier to write matchers that can generate informative messages efficiently.  We experimented with this idea and liked what we saw.  Therefore we decided to implement it.
Unfortunately, this means that if you have defined your own matchers by implementing `MatcherInterface` or using `MakePolymorphicMatcher()`, your definitions will no longer compile.  Matchers defined using the `MATCHER*` family of macros are not affected.
Sorry for the hassle if your matchers are affected.  We believe it's in everyone's long-term interest to make this change sooner than later.  Fortunately, it's usually not hard to migrate an existing matcher to the new API.  Here's what you need to do:
If you wrote your matcher like this: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MatcherInterface; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }   ... }; ```
you'll need to change it to: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MatcherInterface; using ::testing::MatchResultListener; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool MatchAndExplain(MyType value,                                MatchResultListener* listener) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }   ... }; ``` (i.e. rename `Matches()` to `MatchAndExplain()` and give it a second argument of type `MatchResultListener*`.)
If you were also using `ExplainMatchResultTo()` to improve the matcher message: ``` // Old matcher definition that doesn't work with the lastest // Google Mock. using ::testing::MatcherInterface; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetFoo() > 5;   }
virtual void ExplainMatchResultTo(MyType value,                                     ::std::ostream* os) const {     // Prints some helpful information to os to help     // a user understand why value matches (or doesn't match).     *os << "the Foo property is " << value.GetFoo();   }   ... }; ```
you should move the logic of `ExplainMatchResultTo()` into `MatchAndExplain()`, using the `MatchResultListener` argument where the `::std::ostream` was used: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MatcherInterface; using ::testing::MatchResultListener; ... class MyWonderfulMatcher : public MatcherInterface<MyType> {  public:   ...   virtual bool MatchAndExplain(MyType value,                                MatchResultListener* listener) const {     // Returns true if value matches.     *listener << "the Foo property is " << value.GetFoo();     return value.GetFoo() > 5;   }   ... }; ```
If your matcher is defined using `MakePolymorphicMatcher()`: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MakePolymorphicMatcher; ... class MyGreatMatcher {  public:   ...   bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
you should rename the `Matches()` method to `MatchAndExplain()` and add a `MatchResultListener*` argument (the same as what you need to do for matchers defined by implementing `MatcherInterface`): ``` // New matcher definition that works with the latest Google Mock. using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; ... class MyGreatMatcher {  public:   ...   bool MatchAndExplain(MyType value,                        MatchResultListener* listener) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
If your polymorphic matcher uses `ExplainMatchResultTo()` for better failure messages: ``` // Old matcher definition that doesn't work with the latest // Google Mock. using ::testing::MakePolymorphicMatcher; ... class MyGreatMatcher {  public:   ...   bool Matches(MyType value) const {     // Returns true if value matches.     return value.GetBar() < 42;   }   ... }; void ExplainMatchResultTo(const MyGreatMatcher& matcher,                           MyType value,                           ::std::ostream* os) {   // Prints some helpful information to os to help   // a user understand why value matches (or doesn't match).   *os << "the Bar property is " << value.GetBar(); } ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
you'll need to move the logic inside `ExplainMatchResultTo()` to `MatchAndExplain()`: ``` // New matcher definition that works with the latest Google Mock. using ::testing::MakePolymorphicMatcher; using ::testing::MatchResultListener; ... class MyGreatMatcher {  public:   ...   bool MatchAndExplain(MyType value,                        MatchResultListener* listener) const {     // Returns true if value matches.     *listener << "the Bar property is " << value.GetBar();     return value.GetBar() < 42;   }   ... }; ... MakePolymorphicMatcher(MyGreatMatcher()) ... ```
For more information, you can read these [two](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Writing_New_Monomorphic_Matchers) [recipes](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Writing_New_Polymorphic_Matchers) from the cookbook.  As always, you are welcome to post questions on `googlemock@googlegroups.com` if you need any help.
Google Mock works out of the box with Google Test.  However, it's easy to configure it to work with any testing framework of your choice. [Here](http://code.google.com/p/googlemock/wiki/V1_7_ForDummies#Using_Google_Mock_with_Any_Testing_Framework) is how.
If you are confused by the compiler errors gcc threw at you, try consulting the _Google Mock Doctor_ tool first.  What it does is to scan stdin for gcc error messages, and spit out diagnoses on the problems (we call them diseases) your code has.
To "install", run command: ``` alias gmd='<path to googlemock>/scripts/gmock_doctor.py' ```
To use it, do: ``` <your-favorite-build-command> <your-test> 2>&1 | gmd ```
For example: ``` make my_test 2>&1 | gmd ```
Or you can run `gmd` and copy-n-paste gcc's error messages to it.
You cannot mock a variadic function (i.e. a function taking ellipsis (`...`) arguments) directly in Google Mock.
The problem is that in general, there is _no way_ for a mock object to know how many arguments are passed to the variadic method, and what the arguments' types are.  Only the _author of the base class_ knows the protocol, and we cannot look into his head.
Therefore, to mock such a function, the _user_ must teach the mock object how to figure out the number of arguments and their types.  One way to do it is to provide overloaded versions of the function.
Ellipsis arguments are inherited from C and not really a C++ feature. They are unsafe to use and don't work with arguments that have constructors or destructors.  Therefore we recommend to avoid them in C++ as much as possible.
If you compile this using Microsoft Visual C++ 2005 SP1: ``` class Foo {   ...   virtual void Bar(const int i) = 0; };
class MockFoo : public Foo {   ...   MOCK_METHOD1(Bar, void(const int i)); }; ``` You may get the following warning: ``` warning C4301: 'MockFoo::Bar': overriding virtual function only differs from 'Foo::Bar' by const/volatile qualifier ```
This is a MSVC bug.  The same code compiles fine with gcc ,for example.  If you use Visual C++ 2008 SP1, you would get the warning: ``` warning C4373: 'MockFoo::Bar': virtual function overrides 'Foo::Bar', previous versions of the compiler did not override when parameters only differed by const/volatile qualifiers ```
In C++, if you _declare_ a function with a `const` parameter, the `const` modifier is _ignored_.  Therefore, the `Foo` base class above is equivalent to: ``` class Foo {   ...   virtual void Bar(int i) = 0;  // int or const int?  Makes no difference. }; ```
In fact, you can _declare_ Bar() with an `int` parameter, and _define_ it with a `const int` parameter.  The compiler will still match them up.
Since making a parameter `const` is meaningless in the method _declaration_, we recommend to remove it in both `Foo` and `MockFoo`. That should workaround the VC bug.
Note that we are talking about the _top-level_ `const` modifier here. If the function parameter is passed by pointer or reference, declaring the _pointee_ or _referee_ as `const` is still meaningful.  For example, the following two declarations are _not_ equivalent: ``` void Bar(int* p);        // Neither p nor *p is const. void Bar(const int* p);  // p is not const, but *p is. ```
We've noticed that when the `/clr` compiler flag is used, Visual C++ uses 5~6 times as much memory when compiling a mock class.  We suggest to avoid `/clr` when compiling native C++ mocks.
You might want to run your test with `--gmock_verbose=info`.  This flag lets Google Mock print a trace of every mock function call it receives.  By studying the trace, you'll gain insights on why the expectations you set are not met.
``` EXPECT_CALL(foo, Bar(_))     .Times(0); ```
When Google Mock detects a failure, it prints relevant information (the mock function arguments, the state of relevant expectations, and etc) to help the user debug.  If another failure is detected, Google Mock will do the same, including printing the state of relevant expectations.
Sometimes an expectation's state didn't change between two failures, and you'll see the same description of the state twice.  They are however _not_ redundant, as they refer to _different points in time_. The fact they are the same _is_ interesting information.
Does the class (hopefully a pure interface) you are mocking have a virtual destructor?
Whenever you derive from a base class, make sure its destructor is virtual.  Otherwise Bad Things will happen.  Consider the following code:
``` class Base {  public:   // Not virtual, but should be.   ~Base() { ... }   ... };
class Derived : public Base {  public:   ...  private:   std::string value_; };
...   Base* p = new Derived;   ...   delete p;  // Surprise! ~Base() will be called, but ~Derived() will not              // - value_ is leaked. ```
By changing `~Base()` to virtual, `~Derived()` will be correctly called when `delete p` is executed, and the heap checker will be happy.
When people complain about this, often they are referring to code like:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time.  However, I have to write the expectations in the // reverse order.  This sucks big time!!! EXPECT_CALL(foo, Bar())     .WillOnce(Return(2))     .RetiresOnSaturation(); EXPECT_CALL(foo, Bar())     .WillOnce(Return(1))     .RetiresOnSaturation(); ```
The problem is that they didn't pick the **best** way to express the test's intent.
By default, expectations don't have to be matched in _any_ particular order.  If you want them to match in a certain order, you need to be explicit.  This is Google Mock's (and jMock's) fundamental philosophy: it's easy to accidentally over-specify your tests, and we want to make it harder to do so.
There are two better ways to write the test spec.  You could either put the expectations in sequence:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time.  Using a sequence, we can write the expectations // in their natural order. {   InSequence s;   EXPECT_CALL(foo, Bar())       .WillOnce(Return(1))       .RetiresOnSaturation();   EXPECT_CALL(foo, Bar())       .WillOnce(Return(2))       .RetiresOnSaturation(); } ```
or you can put the sequence of actions in the same expectation:
``` // foo.Bar() should be called twice, return 1 the first time, and return // 2 the second time. EXPECT_CALL(foo, Bar())     .WillOnce(Return(1))     .WillOnce(Return(2))     .RetiresOnSaturation(); ```
Back to the original questions: why does Google Mock search the expectations (and `ON_CALL`s) from back to front?  Because this allows a user to set up a mock's behavior for the common case early (e.g. in the mock's constructor or the test fixture's set-up phase) and customize it with more specific rules later.  If Google Mock searches from front to back, this very useful pattern won't be possible.
When choosing between being neat and being safe, we lean toward the latter.  So the answer is that we think it's better to show the warning.
Often people write `ON_CALL`s in the mock object's constructor or `SetUp()`, as the default behavior rarely changes from test to test.  Then in the test body they set the expectations, which are often different for each test.  Having an `ON_CALL` in the set-up part of a test doesn't mean that the calls are expected.  If there's no `EXPECT_CALL` and the method is called, it's possibly an error.  If we quietly let the call go through without notifying the user, bugs may creep in unnoticed.
If, however, you are sure that the calls are OK, you can write
``` EXPECT_CALL(foo, Bar(_))     .WillRepeatedly(...); ```
instead of
``` ON_CALL(foo, Bar(_))     .WillByDefault(...); ```
This tells Google Mock that you do expect the calls and no warning should be printed.
Also, you can control the verbosity using the `--gmock_verbose` flag. If you find the output too noisy when debugging, just choose a less verbose level.
If you find yourself needing to perform some action that's not supported by Google Mock directly, remember that you can define your own actions using [MakeAction()](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Writing_New_Actions) or [MakePolymorphicAction()](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Writing_New_Polymorphic_Actions), or you can write a stub function and invoke it using [Invoke()](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Using_Functions_Methods_Functors).
What?!  I think it's beautiful. :-)
While which syntax looks more natural is a subjective matter to some extent, Google Mock's syntax was chosen for several practical advantages it has.
Try to mock a function that takes a map as an argument: ``` virtual int GetSize(const map<int, std::string>& m); ```
Using the proposed syntax, it would be: ``` MOCK_METHOD1(GetSize, int, const map<int, std::string>& m); ```
Guess what?  You'll get a compiler error as the compiler thinks that `const map<int, std::string>& m` are **two**, not one, arguments. To work around this you can use `typedef` to give the map type a name, but that gets in the way of your work.  Google Mock's syntax avoids this problem as the function's argument types are protected inside a pair of parentheses: ``` // This compiles fine. MOCK_METHOD1(GetSize, int(const map<int, std::string>& m)); ```
You still need a `typedef` if the return type contains an unprotected comma, but that's much rarer.
Other advantages include:   1. `MOCK_METHOD1(Foo, int, bool)` can leave a reader wonder whether the method returns `int` or `bool`, while there won't be such confusion using Google Mock's syntax.   1. The way Google Mock describes a function type is nothing new, although many people may not be familiar with it.  The same syntax was used in C, and the `function` library in `tr1` uses this syntax extensively.  Since `tr1` will become a part of the new version of STL, we feel very comfortable to be consistent with it.   1. The function type syntax is also used in other parts of Google Mock's API (e.g. the action interface) in order to make the implementation tractable. A user needs to learn it anyway in order to utilize Google Mock's more advanced features.  We'd as well stick to the same syntax in `MOCK_METHOD*`!
You can, but you need to make some changes.
In general, if you find yourself needing to mock a static function, it's a sign that your modules are too tightly coupled (and less flexible, less reusable, less testable, etc).  You are probably better off defining a small interface and call the function through that interface, which then can be easily mocked.  It's a bit of work initially, but usually pays for itself quickly.
This Google Testing Blog [post](http://googletesting.blogspot.com/2008/06/defeat-static-cling.html) says it excellently.  Check it out.
I know it's not a question, but you get an answer for free any way. :-)
With Google Mock, you can create mocks in C++ easily.  And people might be tempted to use them everywhere. Sometimes they work great, and sometimes you may find them, well, a pain to use. So, what's wrong in the latter case?
When you write a test without using mocks, you exercise the code and assert that it returns the correct value or that the system is in an expected state.  This is sometimes called "state-based testing".
Mocks are great for what some call "interaction-based" testing: instead of checking the system state at the very end, mock objects verify that they are invoked the right way and report an error as soon as it arises, giving you a handle on the precise context in which the error was triggered.  This is often more effective and economical to do than state-based testing.
If you are doing state-based testing and using a test double just to simulate the real object, you are probably better off using a fake. Using a mock in this case causes pain, as it's not a strong point for mocks to perform complex actions.  If you experience this and think that mocks suck, you are just not using the right tool for your problem. Or, you might be trying to solve the wrong problem. :-)
By all means, NO!  It's just an FYI.
What it means is that you have a mock function, you haven't set any expectations on it (by Google Mock's rule this means that you are not interested in calls to this function and therefore it can be called any number of times), and it is called.  That's OK - you didn't say it's not OK to call the function!
What if you actually meant to disallow this function to be called, but forgot to write `EXPECT_CALL(foo, Bar()).Times(0)`?  While one can argue that it's the user's fault, Google Mock tries to be nice and prints you a note.
So, when you see the message and believe that there shouldn't be any uninteresting calls, you should investigate what's going on.  To make your life easier, Google Mock prints the function name and arguments when an uninteresting call is encountered.
Either way is fine - you want to choose the one that's more convenient for your circumstance.
Usually, if your action is for a particular function type, defining it using `Invoke()` should be easier; if your action can be used in functions of different types (e.g. if you are defining `Return(value)`), `MakePolymorphicAction()` is easiest.  Sometimes you want precise control on what types of functions the action can be used in, and implementing `ActionInterface` is the way to go here. See the implementation of `Return()` in `include/gmock/gmock-actions.h` for an example.
You got this error as Google Mock has no idea what value it should return when the mock method is called.  `SetArgPointee()` says what the side effect is, but doesn't say what the return value should be.  You need `DoAll()` to chain a `SetArgPointee()` with a `Return()`.
See this [recipe](http://code.google.com/p/googlemock/wiki/V1_7_CookBook#Mocking_Side_Effects) for more details and an example.
If you cannot find the answer to your question in this FAQ, there are some other resources you can use:
1. read other [wiki pages](http://code.google.com/p/googlemock/w/list),   1. search the mailing list [archive](http://groups.google.com/group/googlemock/topics),   1. ask it on [googlemock@googlegroups.com](mailto:googlemock@googlegroups.com) and someone will answer it (to prevent spam, we require you to join the [discussion group](http://groups.google.com/group/googlemock) before you can post.).
Please note that creating an issue in the [issue tracker](http://code.google.com/p/googlemock/issues/list) is _not_ a good way to get your answer, as it is monitored infrequently by a very small number of people.
When asking a question, it's helpful to provide as much of the following information as possible (people cannot help you if there's not enough information in your question):
* the version (or the revision number if you check out from SVN directly) of Google Mock you use (Google Mock is under active development, so it's possible that your problem has been solved in a later version),   * your operating system,   * the name and version of your compiler,   * the complete command line flags you give to your compiler,   * the complete compiler error messages (if the question is about compilation),   * the _actual_ code (ideally, a minimal but complete program) that has the problem you encounter.
To build Google Test and your tests that use it, you need to tell your build system where to find its headers and source files.  The exact way to do it depends on which build system you use, and is usually straightforward.
Suppose you put Google Test in directory `${GTEST_DIR}`.  To build it, create a library build target (or a project as called by Visual Studio and Xcode) to compile
${GTEST_DIR}/src/gtest-all.cc
with `${GTEST_DIR}/include` in the system header search path and `${GTEST_DIR}` in the normal header search path.  Assuming a Linux-like system and gcc, something like the following will do:
g++ -isystem ${GTEST_DIR}/include -I${GTEST_DIR} \         -pthread -c ${GTEST_DIR}/src/gtest-all.cc     ar -rv libgtest.a gtest-all.o
(We need `-pthread` as Google Test uses threads.)
Next, you should compile your test source file with `${GTEST_DIR}/include` in the system header search path, and link it with gtest and any other necessary libraries:
g++ -isystem ${GTEST_DIR}/include -pthread path/to/your_test.cc libgtest.a \         -o your_test
As an example, the make/ directory contains a Makefile that you can use to build Google Test on systems where GNU make is available (e.g. Linux, Mac OS X, and Cygwin).  It doesn't try to build Google Test's own tests.  Instead, it just builds the Google Test library and a sample test.  You can use it as a starting point for your own build script.
If the default settings are correct for your environment, the following commands should succeed:
cd ${GTEST_DIR}/make     make     ./sample1_unittest
If you see errors, try to tweak the contents of `make/Makefile` to make them go away.  There are instructions in `make/Makefile` on how to do it.
Google Test comes with a CMake build script ( [CMakeLists.txt](CMakeLists.txt)) that can be used on a wide range of platforms ("C" stands for cross-platform.). If you don't have CMake installed already, you can download it for free from <http://www.cmake.org/>.
CMake works by generating native makefiles or build projects that can be used in the compiler environment of your choice.  The typical workflow starts with:
mkdir mybuild       # Create a directory to hold the build output.     cd mybuild     cmake ${GTEST_DIR}  # Generate native build scripts.
If you want to build Google Test's samples, you should replace the last command with
cmake -Dgtest_build_samples=ON ${GTEST_DIR}
If you are on a \*nix system, you should now see a Makefile in the current directory.  Just type 'make' to build gtest.
If you use Windows and have Visual Studio installed, a `gtest.sln` file and several `.vcproj` files will be created.  You can then build them using Visual Studio.
On Mac OS X with Xcode installed, a `.xcodeproj` file will be generated.
Before settling on CMake, we have been providing hand-maintained build projects/scripts for Visual Studio, Xcode, and Autotools.  While we continue to provide them for convenience, they are not actively maintained any more.  We highly recommend that you follow the instructions in the previous two sections to integrate Google Test with your existing build system.
If you still need to use the legacy build scripts, here's how:
The msvc\ folder contains two solutions with Visual C++ projects. Open the `gtest.sln` or `gtest-md.sln` file using Visual Studio, and you are ready to build Google Test the same way you build any Visual Studio project.  Files that have names ending with -md use DLL versions of Microsoft runtime libraries (the /MD or the /MDd compiler option).  Files without that suffix use static versions of the runtime libraries (the /MT or the /MTd option).  Please note that one must use the same option to compile both gtest and the test code.  If you use Visual Studio 2005 or above, we recommend the -md version as /MD is the default for new projects in these versions of Visual Studio.
On Mac OS X, open the `gtest.xcodeproj` in the `xcode/` folder using Xcode.  Build the "gtest" target.  The universal binary framework will end up in your selected build directory (selected in the Xcode "Preferences..." -> "Building" pane and defaults to xcode/build). Alternatively, at the command line, enter:
xcodebuild
This will build the "Release" configuration of gtest.framework in your default build location.  See the "xcodebuild" man page for more information about building different configurations and building in different locations.
If you wish to use the Google Test Xcode project with Xcode 4.x and above, you need to either:
* update the SDK configuration options in xcode/Config/General.xconfig.    Comment options `SDKROOT`, `MACOS_DEPLOYMENT_TARGET`, and `GCC_VERSION`. If    you choose this route you lose the ability to target earlier versions    of MacOS X.  * Install an SDK for an earlier version. This doesn't appear to be    supported by Apple, but has been reported to work    (http://stackoverflow.com/questions/5378518).
Google Test can be used in diverse environments.  The default configuration may not work (or may not work well) out of the box in some environments.  However, you can easily tweak Google Test by defining control macros on the compiler command line.  Generally, these macros are named like `GTEST_XYZ` and you define them to either 1 or 0 to enable or disable a certain feature.
We list the most frequently used macros below.  For a complete list, see file [include/gtest/internal/gtest-port.h](include/gtest/internal/gtest-port.h).
Some Google Test features require the C++ Technical Report 1 (TR1) tuple library, which is not yet available with all compilers.  The good news is that Google Test implements a subset of TR1 tuple that's enough for its own need, and will automatically use this when the compiler doesn't provide TR1 tuple.
Usually you don't need to care about which tuple library Google Test uses.  However, if your project already uses TR1 tuple, you need to tell Google Test to use the same TR1 tuple library the rest of your project uses, or the two tuple implementations will clash.  To do that, add
-DGTEST_USE_OWN_TR1_TUPLE=0
to the compiler flags while compiling Google Test and your tests.  If you want to force Google Test to use its own tuple library, just add
-DGTEST_USE_OWN_TR1_TUPLE=1
to the compiler flags instead.
If you don't want Google Test to use tuple at all, add
-DGTEST_HAS_TR1_TUPLE=0
and all features using tuple will be disabled.
Google Test is thread-safe where the pthread library is available. After `#include "gtest/gtest.h"`, you can check the `GTEST_IS_THREADSAFE` macro to see whether this is the case (yes if the macro is `#defined` to 1, no if it's undefined.).
If Google Test doesn't correctly detect whether pthread is available in your environment, you can force it with
-DGTEST_HAS_PTHREAD=1
or
-DGTEST_HAS_PTHREAD=0
When Google Test uses pthread, you may need to add flags to your compiler and/or linker to select the pthread library, or you'll get link errors.  If you use the CMake script or the deprecated Autotools script, this is taken care of for you.  If you use your own build script, you'll need to read your compiler and linker's manual to figure out what flags to add.
Google Test is compact, so most users can build and link it as a static library for the simplicity.  You can choose to use Google Test as a shared library (known as a DLL on Windows) if you prefer.
To compile *gtest* as a shared library, add
-DGTEST_CREATE_SHARED_LIBRARY=1
to the compiler flags.  You'll also need to tell the linker to produce a shared library instead - consult your linker's manual for how to do it.
To compile your *tests* that use the gtest shared library, add
-DGTEST_LINKED_AS_SHARED_LIBRARY=1
to the compiler flags.
Note: while the above steps aren't technically necessary today when using some compilers (e.g. GCC), they may become necessary in the future, if we decide to improve the speed of loading the library (see <http://gcc.gnu.org/wiki/Visibility> for details).  Therefore you are recommended to always add the above flags when using Google Test as a shared library.  Otherwise a future release of Google Test may break your build script.
In C++, macros don't obey namespaces.  Therefore two libraries that both define a macro of the same name will clash if you `#include` both definitions.  In case a Google Test macro clashes with another library, you can force Google Test to rename its macro to avoid the conflict.
Specifically, if both Google Test and some other code define macro FOO, you can add
-DGTEST_DONT_DEFINE_FOO=1
to the compiler flags to tell Google Test to change the macro's name from `FOO` to `GTEST_FOO`.  Currently `FOO` can be `FAIL`, `SUCCEED`, or `TEST`.  For example, with `-DGTEST_DONT_DEFINE_TEST=1`, you'll need to write
GTEST_TEST(SomeTest, DoesThis) { ... }
instead of
TEST(SomeTest, DoesThis) { ... }
in order to define a test.
This section discusses how to make your own changes to Google Test.
To make sure your changes work as intended and don't break existing functionality, you'll want to compile and run Google Test's own tests. For that you can use CMake:
mkdir mybuild     cd mybuild     cmake -Dgtest_build_tests=ON ${GTEST_DIR}
Make sure you have Python installed, as some of Google Test's tests are written in Python.  If the cmake command complains about not being able to find Python (`Could NOT find PythonInterp (missing: PYTHON_EXECUTABLE)`), try telling it explicitly where your Python executable can be found:
cmake -DPYTHON_EXECUTABLE=path/to/python -Dgtest_build_tests=ON ${GTEST_DIR}
Next, you can build Google Test and all of its own tests.  On \*nix, this is usually done by 'make'.  To run the tests, do
make test
All tests should pass.
Normally you don't need to worry about regenerating the source files, unless you need to modify them.  In that case, you should modify the corresponding .pump files instead and run the pump.py Python script to regenerate them.  You can find pump.py in the [scripts/](scripts/) directory. Read the [Pump manual](docs/PumpManual.md) for how to use it.

Now that you have read [Primer](Primer.md) and learned how to write tests using Google Test, it's time to learn some new tricks. This document will show you more assertions as well as how to construct complex failure messages, propagate fatal failures, reuse and speed up your test fixtures, and use various flags with your tests.
This section covers some less frequently used, but still significant, assertions.
These three assertions do not actually test a value or expression. Instead, they generate a success or failure directly. Like the macros that actually perform a test, you may stream a custom failure message into the them.
| `SUCCEED();` | |:-------------|
Generates a success. This does NOT make the overall test succeed. A test is considered successful only if none of its assertions fail during its execution.
Note: `SUCCEED()` is purely documentary and currently doesn't generate any user-visible output. However, we may add `SUCCEED()` messages to Google Test's output in the future.
| `FAIL();`  | `ADD_FAILURE();` | `ADD_FAILURE_AT("`_file\_path_`", `_line\_number_`);` | |:-----------|:-----------------|:------------------------------------------------------|
`FAIL()` generates a fatal failure, while `ADD_FAILURE()` and `ADD_FAILURE_AT()` generate a nonfatal failure. These are useful when control flow, rather than a Boolean expression, deteremines the test's success or failure. For example, you might want to write something like:
``` switch(expression) {   case 1: ... some checks ...   case 2: ... some other checks   ...   default: FAIL() << "We shouldn't get here."; } ```
Note: you can only use `FAIL()` in functions that return `void`. See the [Assertion Placement section](#assertion-placement) for more information.
_Availability_: Linux, Windows, Mac.
These are for verifying that a piece of code throws (or does not throw) an exception of the given type:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_THROW(`_statement_, _exception\_type_`);`  | `EXPECT_THROW(`_statement_, _exception\_type_`);`  | _statement_ throws an exception of the given type  | | `ASSERT_ANY_THROW(`_statement_`);`                | `EXPECT_ANY_THROW(`_statement_`);`                | _statement_ throws an exception of any type        | | `ASSERT_NO_THROW(`_statement_`);`                 | `EXPECT_NO_THROW(`_statement_`);`                 | _statement_ doesn't throw any exception            |
Examples:
``` ASSERT_THROW(Foo(5), bar_exception);
EXPECT_NO_THROW({   int n = 5;   Bar(&n); }); ```
_Availability_: Linux, Windows, Mac; since version 1.1.0.
Even though Google Test has a rich set of assertions, they can never be complete, as it's impossible (nor a good idea) to anticipate all the scenarios a user might run into. Therefore, sometimes a user has to use `EXPECT_TRUE()` to check a complex expression, for lack of a better macro. This has the problem of not showing you the values of the parts of the expression, making it hard to understand what went wrong. As a workaround, some users choose to construct the failure message by themselves, streaming it into `EXPECT_TRUE()`. However, this is awkward especially when the expression has side-effects or is expensive to evaluate.
Google Test gives you three different options to solve this problem:
If you already have a function or a functor that returns `bool` (or a type that can be implicitly converted to `bool`), you can use it in a _predicate assertion_ to get the function arguments printed for free:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_PRED1(`_pred1, val1_`);`       | `EXPECT_PRED1(`_pred1, val1_`);` | _pred1(val1)_ returns true | | `ASSERT_PRED2(`_pred2, val1, val2_`);` | `EXPECT_PRED2(`_pred2, val1, val2_`);` |  _pred2(val1, val2)_ returns true | |  ...                | ...                    | ...          |
In the above, _predn_ is an _n_-ary predicate function or functor, where _val1_, _val2_, ..., and _valn_ are its arguments. The assertion succeeds if the predicate returns `true` when applied to the given arguments, and fails otherwise. When the assertion fails, it prints the value of each argument. In either case, the arguments are evaluated exactly once.
Here's an example. Given
``` // Returns true iff m and n have no common divisors except 1. bool MutuallyPrime(int m, int n) { ... } const int a = 3; const int b = 4; const int c = 10; ```
the assertion `EXPECT_PRED2(MutuallyPrime, a, b);` will succeed, while the assertion `EXPECT_PRED2(MutuallyPrime, b, c);` will fail with the message
<pre> !MutuallyPrime(b, c) is false, where<br> b is 4<br> c is 10<br> </pre>
**Notes:**
1. If you see a compiler error "no matching function to call" when using `ASSERT_PRED*` or `EXPECT_PRED*`, please see [this FAQ](FAQ.md#the-compiler-complains-no-matching-function-to-call-when-i-use-assert_predn-how-do-i-fix-it) for how to resolve it.   1. Currently we only provide predicate assertions of arity <= 5. If you need a higher-arity assertion, let us know.
_Availability_: Linux, Windows, Mac
While `EXPECT_PRED*()` and friends are handy for a quick job, the syntax is not satisfactory: you have to use different macros for different arities, and it feels more like Lisp than C++.  The `::testing::AssertionResult` class solves this problem.
An `AssertionResult` object represents the result of an assertion (whether it's a success or a failure, and an associated message).  You can create an `AssertionResult` using one of these factory functions:
``` namespace testing {
// Returns an AssertionResult object to indicate that an assertion has // succeeded. AssertionResult AssertionSuccess();
// Returns an AssertionResult object to indicate that an assertion has // failed. AssertionResult AssertionFailure();
} ```
You can then use the `<<` operator to stream messages to the `AssertionResult` object.
To provide more readable messages in Boolean assertions (e.g. `EXPECT_TRUE()`), write a predicate function that returns `AssertionResult` instead of `bool`. For example, if you define `IsEven()` as:
``` ::testing::AssertionResult IsEven(int n) {   if ((n % 2) == 0)     return ::testing::AssertionSuccess();   else     return ::testing::AssertionFailure() << n << " is odd"; } ```
instead of:
``` bool IsEven(int n) {   return (n % 2) == 0; } ```
the failed assertion `EXPECT_TRUE(IsEven(Fib(4)))` will print:
<pre> Value of: IsEven(Fib(4))<br> Actual: false (*3 is odd*)<br> Expected: true<br> </pre>
instead of a more opaque
<pre> Value of: IsEven(Fib(4))<br> Actual: false<br> Expected: true<br> </pre>
If you want informative messages in `EXPECT_FALSE` and `ASSERT_FALSE` as well, and are fine with making the predicate slower in the success case, you can supply a success message:
``` ::testing::AssertionResult IsEven(int n) {   if ((n % 2) == 0)     return ::testing::AssertionSuccess() << n << " is even";   else     return ::testing::AssertionFailure() << n << " is odd"; } ```
Then the statement `EXPECT_FALSE(IsEven(Fib(6)))` will print
<pre> Value of: IsEven(Fib(6))<br> Actual: true (8 is even)<br> Expected: false<br> </pre>
_Availability_: Linux, Windows, Mac; since version 1.4.1.
If you find the default message generated by `(ASSERT|EXPECT)_PRED*` and `(ASSERT|EXPECT)_(TRUE|FALSE)` unsatisfactory, or some arguments to your predicate do not support streaming to `ostream`, you can instead use the following _predicate-formatter assertions_ to _fully_ customize how the message is formatted:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_PRED_FORMAT1(`_pred\_format1, val1_`);`        | `EXPECT_PRED_FORMAT1(`_pred\_format1, val1_`);` | _pred\_format1(val1)_ is successful | | `ASSERT_PRED_FORMAT2(`_pred\_format2, val1, val2_`);` | `EXPECT_PRED_FORMAT2(`_pred\_format2, val1, val2_`);` | _pred\_format2(val1, val2)_ is successful | | `...`               | `...`                  | `...`        |
The difference between this and the previous two groups of macros is that instead of a predicate, `(ASSERT|EXPECT)_PRED_FORMAT*` take a _predicate-formatter_ (_pred\_formatn_), which is a function or functor with the signature:
`::testing::AssertionResult PredicateFormattern(const char* `_expr1_`, const char* `_expr2_`, ... const char* `_exprn_`, T1 `_val1_`, T2 `_val2_`, ... Tn `_valn_`);`
where _val1_, _val2_, ..., and _valn_ are the values of the predicate arguments, and _expr1_, _expr2_, ..., and _exprn_ are the corresponding expressions as they appear in the source code. The types `T1`, `T2`, ..., and `Tn` can be either value types or reference types. For example, if an argument has type `Foo`, you can declare it as either `Foo` or `const Foo&`, whichever is appropriate.
A predicate-formatter returns a `::testing::AssertionResult` object to indicate whether the assertion has succeeded or not. The only way to create such an object is to call one of these factory functions:
As an example, let's improve the failure message in the previous example, which uses `EXPECT_PRED2()`:
``` // Returns the smallest prime common divisor of m and n, // or 1 when m and n are mutually prime. int SmallestPrimeCommonDivisor(int m, int n) { ... }
// A predicate-formatter for asserting that two integers are mutually prime. ::testing::AssertionResult AssertMutuallyPrime(const char* m_expr,                                                const char* n_expr,                                                int m,                                                int n) {   if (MutuallyPrime(m, n))     return ::testing::AssertionSuccess();
return ::testing::AssertionFailure()       << m_expr << " and " << n_expr << " (" << m << " and " << n       << ") are not mutually prime, " << "as they have a common divisor "       << SmallestPrimeCommonDivisor(m, n); } ```
With this predicate-formatter, we can use
``` EXPECT_PRED_FORMAT2(AssertMutuallyPrime, b, c); ```
to generate the message
<pre> b and c (4 and 10) are not mutually prime, as they have a common divisor 2.<br> </pre>
As you may have realized, many of the assertions we introduced earlier are special cases of `(EXPECT|ASSERT)_PRED_FORMAT*`. In fact, most of them are indeed defined using `(EXPECT|ASSERT)_PRED_FORMAT*`.
_Availability_: Linux, Windows, Mac.
Comparing floating-point numbers is tricky. Due to round-off errors, it is very unlikely that two floating-points will match exactly. Therefore, `ASSERT_EQ` 's naive comparison usually doesn't work. And since floating-points can have a wide value range, no single fixed error bound works. It's better to compare by a fixed relative error bound, except for values close to 0 due to the loss of precision there.
In general, for floating-point comparison to make sense, the user needs to carefully choose the error bound. If they don't want or care to, comparing in terms of Units in the Last Place (ULPs) is a good default, and Google Test provides assertions to do this. Full details about ULPs are quite long; if you want to learn more, see [this article on float comparison](http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm).
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_FLOAT_EQ(`_val1, val2_`);`  | `EXPECT_FLOAT_EQ(`_val1, val2_`);` | the two `float` values are almost equal | | `ASSERT_DOUBLE_EQ(`_val1, val2_`);` | `EXPECT_DOUBLE_EQ(`_val1, val2_`);` | the two `double` values are almost equal |
By "almost equal", we mean the two values are within 4 ULP's from each other.
The following assertions allow you to choose the acceptable error bound:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_NEAR(`_val1, val2, abs\_error_`);` | `EXPECT_NEAR`_(val1, val2, abs\_error_`);` | the difference between _val1_ and _val2_ doesn't exceed the given absolute error |
_Availability_: Linux, Windows, Mac.
Some floating-point operations are useful, but not that often used. In order to avoid an explosion of new macros, we provide them as predicate-format functions that can be used in predicate assertion macros (e.g. `EXPECT_PRED_FORMAT2`, etc).
``` EXPECT_PRED_FORMAT2(::testing::FloatLE, val1, val2); EXPECT_PRED_FORMAT2(::testing::DoubleLE, val1, val2); ```
Verifies that _val1_ is less than, or almost equal to, _val2_. You can replace `EXPECT_PRED_FORMAT2` in the above table with `ASSERT_PRED_FORMAT2`.
_Availability_: Linux, Windows, Mac.
These assertions test for `HRESULT` success or failure.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_HRESULT_SUCCEEDED(`_expression_`);` | `EXPECT_HRESULT_SUCCEEDED(`_expression_`);` | _expression_ is a success `HRESULT` | | `ASSERT_HRESULT_FAILED(`_expression_`);`    | `EXPECT_HRESULT_FAILED(`_expression_`);`    | _expression_ is a failure `HRESULT` |
The generated output contains the human-readable error message associated with the `HRESULT` code returned by _expression_.
You might use them like this:
``` CComPtr shell; ASSERT_HRESULT_SUCCEEDED(shell.CoCreateInstance(L"Shell.Application")); CComVariant empty; ASSERT_HRESULT_SUCCEEDED(shell->ShellExecute(CComBSTR(url), empty, empty, empty, empty)); ```
_Availability_: Windows.
You can call the function ``` ::testing::StaticAssertTypeEq<T1, T2>(); ``` to assert that types `T1` and `T2` are the same.  The function does nothing if the assertion is satisfied.  If the types are different, the function call will fail to compile, and the compiler error message will likely (depending on the compiler) show you the actual values of `T1` and `T2`.  This is mainly useful inside template code.
_Caveat:_ When used inside a member function of a class template or a function template, `StaticAssertTypeEq<T1, T2>()` is effective _only if_ the function is instantiated.  For example, given: ``` template <typename T> class Foo {  public:   void Bar() { ::testing::StaticAssertTypeEq<int, T>(); } }; ``` the code: ``` void Test1() { Foo<bool> foo; } ``` will _not_ generate a compiler error, as `Foo<bool>::Bar()` is never actually instantiated.  Instead, you need: ``` void Test2() { Foo<bool> foo; foo.Bar(); } ``` to cause a compiler error.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
You can use assertions in any C++ function. In particular, it doesn't have to be a method of the test fixture class. The one constraint is that assertions that generate a fatal failure (`FAIL*` and `ASSERT_*`) can only be used in void-returning functions. This is a consequence of Google Test not using exceptions. By placing it in a non-void function you'll get a confusing compile error like `"error: void value not ignored as it ought to be"`.
If you need to use assertions in a function that returns non-void, one option is to make the function return the value in an out parameter instead. For example, you can rewrite `T2 Foo(T1 x)` to `void Foo(T1 x, T2* result)`. You need to make sure that `*result` contains some sensible value even when the function returns prematurely. As the function now returns `void`, you can use any assertion inside of it.
If changing the function's type is not an option, you should just use assertions that generate non-fatal failures, such as `ADD_FAILURE*` and `EXPECT_*`.
_Note_: Constructors and destructors are not considered void-returning functions, according to the C++ language specification, and so you may not use fatal assertions in them. You'll get a compilation error if you try. A simple workaround is to transfer the entire body of the constructor or destructor to a private void-returning method. However, you should be aware that a fatal assertion failure in a constructor does not terminate the current test, as your intuition might suggest; it merely returns from the constructor early, possibly leaving your object in a partially-constructed state. Likewise, a fatal assertion failure in a destructor may leave your object in a partially-destructed state. Use assertions carefully in these situations!
When a test assertion such as `EXPECT_EQ` fails, Google Test prints the argument values to help you debug.  It does this using a user-extensible value printer.
This printer knows how to print built-in C++ types, native arrays, STL containers, and any type that supports the `<<` operator.  For other types, it prints the raw bytes in the value and hopes that you the user can figure it out.
As mentioned earlier, the printer is _extensible_.  That means you can teach it to do a better job at printing your particular type than to dump the bytes.  To do that, define `<<` for your type:
``` #include <iostream>
namespace foo {
class Bar { ... };  // We want Google Test to be able to print instances of this.
// It's important that the << operator is defined in the SAME // namespace that defines Bar.  C++'s look-up rules rely on that. ::std::ostream& operator<<(::std::ostream& os, const Bar& bar) {   return os << bar.DebugString();  // whatever needed to print bar to os }
}  // namespace foo ```
Sometimes, this might not be an option: your team may consider it bad style to have a `<<` operator for `Bar`, or `Bar` may already have a `<<` operator that doesn't do what you want (and you cannot change it).  If so, you can instead define a `PrintTo()` function like this:
``` #include <iostream>
namespace foo {
class Bar { ... };
// It's important that PrintTo() is defined in the SAME // namespace that defines Bar.  C++'s look-up rules rely on that. void PrintTo(const Bar& bar, ::std::ostream* os) {   *os << bar.DebugString();  // whatever needed to print bar to os }
}  // namespace foo ```
If you have defined both `<<` and `PrintTo()`, the latter will be used when Google Test is concerned.  This allows you to customize how the value appears in Google Test's output without affecting code that relies on the behavior of its `<<` operator.
If you want to print a value `x` using Google Test's value printer yourself, just call `::testing::PrintToString(`_x_`)`, which returns an `std::string`:
``` vector<pair<Bar, int> > bar_ints = GetBarIntVector();
EXPECT_TRUE(IsCorrectBarIntVector(bar_ints))     << "bar_ints = " << ::testing::PrintToString(bar_ints); ```
In many applications, there are assertions that can cause application failure if a condition is not met. These sanity checks, which ensure that the program is in a known good state, are there to fail at the earliest possible time after some program state is corrupted. If the assertion checks the wrong condition, then the program may proceed in an erroneous state, which could lead to memory corruption, security holes, or worse. Hence it is vitally important to test that such assertion statements work as expected.
Since these precondition checks cause the processes to die, we call such tests _death tests_. More generally, any test that checks that a program terminates (except by throwing an exception) in an expected fashion is also a death test.
Note that if a piece of code throws an exception, we don't consider it "death" for the purpose of death tests, as the caller of the code could catch the exception and avoid the crash. If you want to verify exceptions thrown by your code, see [Exception Assertions](#exception-assertions).
If you want to test `EXPECT_*()/ASSERT_*()` failures in your test code, see [Catching Failures](#catching-failures).
Google Test has the following macros to support death tests:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_DEATH(`_statement, regex_`);` | `EXPECT_DEATH(`_statement, regex_`);` | _statement_ crashes with the given error | | `ASSERT_DEATH_IF_SUPPORTED(`_statement, regex_`);` | `EXPECT_DEATH_IF_SUPPORTED(`_statement, regex_`);` | if death tests are supported, verifies that _statement_ crashes with the given error; otherwise verifies nothing | | `ASSERT_EXIT(`_statement, predicate, regex_`);` | `EXPECT_EXIT(`_statement, predicate, regex_`);` |_statement_ exits with the given error and its exit code matches _predicate_ |
where _statement_ is a statement that is expected to cause the process to die, _predicate_ is a function or function object that evaluates an integer exit status, and _regex_ is a regular expression that the stderr output of _statement_ is expected to match. Note that _statement_ can be _any valid statement_ (including _compound statement_) and doesn't have to be an expression.
As usual, the `ASSERT` variants abort the current test function, while the `EXPECT` variants do not.
**Note:** We use the word "crash" here to mean that the process terminates with a _non-zero_ exit status code.  There are two possibilities: either the process has called `exit()` or `_exit()` with a non-zero value, or it may be killed by a signal.
This means that if _statement_ terminates the process with a 0 exit code, it is _not_ considered a crash by `EXPECT_DEATH`.  Use `EXPECT_EXIT` instead if this is the case, or if you want to restrict the exit code more precisely.
A predicate here must accept an `int` and return a `bool`. The death test succeeds only if the predicate returns `true`. Google Test defines a few predicates that handle the most common cases:
``` ::testing::ExitedWithCode(exit_code) ```
This expression is `true` if the program exited normally with the given exit code.
``` ::testing::KilledBySignal(signal_number)  // Not available on Windows. ```
This expression is `true` if the program was killed by the given signal.
The `*_DEATH` macros are convenient wrappers for `*_EXIT` that use a predicate that verifies the process' exit code is non-zero.
Note that a death test only cares about three things:
1. does _statement_ abort or exit the process?   1. (in the case of `ASSERT_EXIT` and `EXPECT_EXIT`) does the exit status satisfy _predicate_?  Or (in the case of `ASSERT_DEATH` and `EXPECT_DEATH`) is the exit status non-zero?  And   1. does the stderr output match _regex_?
In particular, if _statement_ generates an `ASSERT_*` or `EXPECT_*` failure, it will **not** cause the death test to fail, as Google Test assertions don't abort the process.
To write a death test, simply use one of the above macros inside your test function. For example,
``` TEST(MyDeathTest, Foo) {   // This death test uses a compound statement.   ASSERT_DEATH({ int n = 5; Foo(&n); }, "Error on line .* of Foo()"); } TEST(MyDeathTest, NormalExit) {   EXPECT_EXIT(NormalExit(), ::testing::ExitedWithCode(0), "Success"); } TEST(MyDeathTest, KillMyself) {   EXPECT_EXIT(KillMyself(), ::testing::KilledBySignal(SIGKILL), "Sending myself unblockable signal"); } ```
verifies that:
* calling `Foo(5)` causes the process to die with the given error message,   * calling `NormalExit()` causes the process to print `"Success"` to stderr and exit with exit code 0, and   * calling `KillMyself()` kills the process with signal `SIGKILL`.
The test function body may contain other assertions and statements as well, if necessary.
_Important:_ We strongly recommend you to follow the convention of naming your test case (not test) `*DeathTest` when it contains a death test, as demonstrated in the above example. The `Death Tests And Threads` section below explains why.
If a test fixture class is shared by normal tests and death tests, you can use typedef to introduce an alias for the fixture class and avoid duplicating its code: ``` class FooTest : public ::testing::Test { ... };
typedef FooTest FooDeathTest;
TEST_F(FooTest, DoesThis) {   // normal test }
TEST_F(FooDeathTest, DoesThat) {   // death test } ```
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Cygwin, and Mac (the latter three are supported since v1.3.0).  `(ASSERT|EXPECT)_DEATH_IF_SUPPORTED` are new in v1.4.0.
On POSIX systems (e.g. Linux, Cygwin, and Mac), Google Test uses the [POSIX extended regular expression](http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html#tag_09_04) syntax in death tests. To learn about this syntax, you may want to read this [Wikipedia entry](http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions).
On Windows, Google Test uses its own simple regular expression implementation. It lacks many features you can find in POSIX extended regular expressions.  For example, we don't support union (`"x|y"`), grouping (`"(xy)"`), brackets (`"[xy]"`), and repetition count (`"x{5,7}"`), among others. Below is what we do support (Letter `A` denotes a literal character, period (`.`), or a single `\\` escape sequence; `x` and `y` denote regular expressions.):
| `c` | matches any literal character `c` | |:----|:----------------------------------| | `\\d` | matches any decimal digit         | | `\\D` | matches any character that's not a decimal digit | | `\\f` | matches `\f`                      | | `\\n` | matches `\n`                      | | `\\r` | matches `\r`                      | | `\\s` | matches any ASCII whitespace, including `\n` | | `\\S` | matches any character that's not a whitespace | | `\\t` | matches `\t`                      | | `\\v` | matches `\v`                      | | `\\w` | matches any letter, `_`, or decimal digit | | `\\W` | matches any character that `\\w` doesn't match | | `\\c` | matches any literal character `c`, which must be a punctuation | | `\\.` | matches the `.` character         | | `.` | matches any single character except `\n` | | `A?` | matches 0 or 1 occurrences of `A` | | `A*` | matches 0 or many occurrences of `A` | | `A+` | matches 1 or many occurrences of `A` | | `^` | matches the beginning of a string (not that of each line) | | `$` | matches the end of a string (not that of each line) | | `xy` | matches `x` followed by `y`       |
To help you determine which capability is available on your system, Google Test defines macro `GTEST_USES_POSIX_RE=1` when it uses POSIX extended regular expressions, or `GTEST_USES_SIMPLE_RE=1` when it uses the simple version.  If you want your death tests to work in both cases, you can either `#if` on these macros or use the more limited syntax only.
Under the hood, `ASSERT_EXIT()` spawns a new process and executes the death test statement in that process. The details of of how precisely that happens depend on the platform and the variable `::testing::GTEST_FLAG(death_test_style)` (which is initialized from the command-line flag `--gtest_death_test_style`).
* On POSIX systems, `fork()` (or `clone()` on Linux) is used to spawn the child, after which:     * If the variable's value is `"fast"`, the death test statement is immediately executed.     * If the variable's value is `"threadsafe"`, the child process re-executes the unit test binary just as it was originally invoked, but with some extra flags to cause just the single death test under consideration to be run.   * On Windows, the child is spawned using the `CreateProcess()` API, and re-executes the binary to cause just the single death test under consideration to be run - much like the `threadsafe` mode on POSIX.
Other values for the variable are illegal and will cause the death test to fail. Currently, the flag's default value is `"fast"`. However, we reserve the right to change it in the future. Therefore, your tests should not depend on this.
In either case, the parent process waits for the child process to complete, and checks that
1. the child's exit status satisfies the predicate, and   1. the child's stderr matches the regular expression.
If the death test statement runs to completion without dying, the child process will nonetheless terminate, and the assertion fails.
The reason for the two death test styles has to do with thread safety. Due to well-known problems with forking in the presence of threads, death tests should be run in a single-threaded context. Sometimes, however, it isn't feasible to arrange that kind of environment. For example, statically-initialized modules may start threads before main is ever reached. Once threads have been created, it may be difficult or impossible to clean them up.
Google Test has three features intended to raise awareness of threading issues.
1. A warning is emitted if multiple threads are running when a death test is encountered.   1. Test cases with a name ending in "DeathTest" are run before all other tests.   1. It uses `clone()` instead of `fork()` to spawn the child process on Linux (`clone()` is not available on Cygwin and Mac), as `fork()` is more likely to cause the child to hang when the parent process has multiple threads.
It's perfectly fine to create threads inside a death test statement; they are executed in a separate process and cannot affect the parent.
The "threadsafe" death test style was introduced in order to help mitigate the risks of testing in a possibly multithreaded environment. It trades increased test execution time (potentially dramatically so) for improved thread safety. We suggest using the faster, default "fast" style unless your test has specific problems with it.
You can choose a particular style of death tests by setting the flag programmatically:
``` ::testing::FLAGS_gtest_death_test_style = "threadsafe"; ```
You can do this in `main()` to set the style for all death tests in the binary, or in individual tests. Recall that flags are saved before running each test and restored afterwards, so you need not do that yourself. For example:
``` TEST(MyDeathTest, TestOne) {   ::testing::FLAGS_gtest_death_test_style = "threadsafe";   // This test is run in the "threadsafe" style:   ASSERT_DEATH(ThisShouldDie(), ""); }
TEST(MyDeathTest, TestTwo) {   // This test is run in the "fast" style:   ASSERT_DEATH(ThisShouldDie(), ""); }
int main(int argc, char** argv) {   ::testing::InitGoogleTest(&argc, argv);   ::testing::FLAGS_gtest_death_test_style = "fast";   return RUN_ALL_TESTS(); } ```
The _statement_ argument of `ASSERT_EXIT()` can be any valid C++ statement. If it leaves the current function via a `return` statement or by throwing an exception, the death test is considered to have failed.  Some Google Test macros may return from the current function (e.g. `ASSERT_TRUE()`), so be sure to avoid them in _statement_.
Since _statement_ runs in the child process, any in-memory side effect (e.g. modifying a variable, releasing memory, etc) it causes will _not_ be observable in the parent process. In particular, if you release memory in a death test, your program will fail the heap check as the parent process will never see the memory reclaimed. To solve this problem, you can
1. try not to free memory in a death test;   1. free the memory again in the parent process; or   1. do not use the heap checker in your program.
Due to an implementation detail, you cannot place multiple death test assertions on the same line; otherwise, compilation will fail with an unobvious error message.
Despite the improved thread safety afforded by the "threadsafe" style of death test, thread problems such as deadlock are still possible in the presence of handlers registered with `pthread_atfork(3)`.
If a test sub-routine is called from several places, when an assertion inside it fails, it can be hard to tell which invocation of the sub-routine the failure is from.  You can alleviate this problem using extra logging or custom failure messages, but that usually clutters up your tests. A better solution is to use the `SCOPED_TRACE` macro:
| `SCOPED_TRACE(`_message_`);` | |:-----------------------------|
where _message_ can be anything streamable to `std::ostream`. This macro will cause the current file name, line number, and the given message to be added in every failure message. The effect will be undone when the control leaves the current lexical scope.
For example,
``` 10: void Sub1(int n) { 11:   EXPECT_EQ(1, Bar(n)); 12:   EXPECT_EQ(2, Bar(n + 1)); 13: } 14: 15: TEST(FooTest, Bar) { 16:   { 17:     SCOPED_TRACE("A");  // This trace point will be included in 18:                         // every failure in this scope. 19:     Sub1(1); 20:   } 21:   // Now it won't. 22:   Sub1(9); 23: } ```
could result in messages like these:
``` path/to/foo_test.cc:11: Failure Value of: Bar(n) Expected: 1   Actual: 2    Trace: path/to/foo_test.cc:17: A
path/to/foo_test.cc:12: Failure Value of: Bar(n + 1) Expected: 2   Actual: 3 ```
Without the trace, it would've been difficult to know which invocation of `Sub1()` the two failures come from respectively. (You could add an extra message to each assertion in `Sub1()` to indicate the value of `n`, but that's tedious.)
Some tips on using `SCOPED_TRACE`:
1. With a suitable message, it's often enough to use `SCOPED_TRACE` at the beginning of a sub-routine, instead of at each call site.   1. When calling sub-routines inside a loop, make the loop iterator part of the message in `SCOPED_TRACE` such that you can know which iteration the failure is from.   1. Sometimes the line number of the trace point is enough for identifying the particular invocation of a sub-routine. In this case, you don't have to choose a unique message for `SCOPED_TRACE`. You can simply use `""`.   1. You can use `SCOPED_TRACE` in an inner scope when there is one in the outer scope. In this case, all active trace points will be included in the failure messages, in reverse order they are encountered.   1. The trace dump is clickable in Emacs' compilation buffer - hit return on a line number and you'll be taken to that line in the source file!
_Availability:_ Linux, Windows, Mac.
A common pitfall when using `ASSERT_*` and `FAIL*` is not understanding that when they fail they only abort the _current function_, not the entire test. For example, the following test will segfault: ``` void Subroutine() {   // Generates a fatal failure and aborts the current function.   ASSERT_EQ(1, 2);   // The following won't be executed.   ... }
TEST(FooTest, Bar) {   Subroutine();   // The intended behavior is for the fatal failure   // in Subroutine() to abort the entire test.   // The actual behavior: the function goes on after Subroutine() returns.   int* p = NULL;   *p = 3; // Segfault! } ```
Since we don't use exceptions, it is technically impossible to implement the intended behavior here.  To alleviate this, Google Test provides two solutions.  You could use either the `(ASSERT|EXPECT)_NO_FATAL_FAILURE` assertions or the `HasFatalFailure()` function.  They are described in the following two subsections.
As shown above, if your test calls a subroutine that has an `ASSERT_*` failure in it, the test will continue after the subroutine returns. This may not be what you want.
Often people want fatal failures to propagate like exceptions.  For that Google Test offers the following macros:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_NO_FATAL_FAILURE(`_statement_`);` | `EXPECT_NO_FATAL_FAILURE(`_statement_`);` | _statement_ doesn't generate any new fatal failures in the current thread. |
Only failures in the thread that executes the assertion are checked to determine the result of this type of assertions.  If _statement_ creates new threads, failures in these threads are ignored.
Examples:
``` ASSERT_NO_FATAL_FAILURE(Foo());
int i; EXPECT_NO_FATAL_FAILURE({   i = Bar(); }); ```
_Availability:_ Linux, Windows, Mac. Assertions from multiple threads are currently not supported.
`HasFatalFailure()` in the `::testing::Test` class returns `true` if an assertion in the current test has suffered a fatal failure. This allows functions to catch fatal failures in a sub-routine and return early.
``` class Test {  public:   ...   static bool HasFatalFailure(); }; ```
The typical usage, which basically simulates the behavior of a thrown exception, is:
``` TEST(FooTest, Bar) {   Subroutine();   // Aborts if Subroutine() had a fatal failure.   if (HasFatalFailure())     return;   // The following won't be executed.   ... } ```
If `HasFatalFailure()` is used outside of `TEST()` , `TEST_F()` , or a test fixture, you must add the `::testing::Test::` prefix, as in:
``` if (::testing::Test::HasFatalFailure())   return; ```
Similarly, `HasNonfatalFailure()` returns `true` if the current test has at least one non-fatal failure, and `HasFailure()` returns `true` if the current test has at least one failure of either kind.
_Availability:_ Linux, Windows, Mac.  `HasNonfatalFailure()` and `HasFailure()` are available since version 1.4.0.
In your test code, you can call `RecordProperty("key", value)` to log additional information, where `value` can be either a string or an `int`. The _last_ value recorded for a key will be emitted to the XML output if you specify one. For example, the test
``` TEST_F(WidgetUsageTest, MinAndMaxWidgets) {   RecordProperty("MaximumWidgets", ComputeMaxUsage());   RecordProperty("MinimumWidgets", ComputeMinUsage()); } ```
will output XML like this:
``` ...   <testcase name="MinAndMaxWidgets" status="run" time="6" classname="WidgetUsageTest"             MaximumWidgets="12"             MinimumWidgets="9" /> ... ```
_Note_:   * `RecordProperty()` is a static member of the `Test` class. Therefore it needs to be prefixed with `::testing::Test::` if used outside of the `TEST` body and the test fixture class.   * `key` must be a valid XML attribute name, and cannot conflict with the ones already used by Google Test (`name`, `status`, `time`, `classname`, `type_param`, and `value_param`).   * Calling `RecordProperty()` outside of the lifespan of a test is allowed. If it's called outside of a test but between a test case's `SetUpTestCase()` and `TearDownTestCase()` methods, it will be attributed to the XML element for the test case. If it's called outside of all test cases (e.g. in a test environment), it will be attributed to the top-level XML element.
_Availability_: Linux, Windows, Mac.

Google Test creates a new test fixture object for each test in order to make tests independent and easier to debug. However, sometimes tests use resources that are expensive to set up, making the one-copy-per-test model prohibitively expensive.
If the tests don't change the resource, there's no harm in them sharing a single resource copy. So, in addition to per-test set-up/tear-down, Google Test also supports per-test-case set-up/tear-down. To use it:
1. In your test fixture class (say `FooTest` ), define as `static` some member variables to hold the shared resources.   1. In the same test fixture class, define a `static void SetUpTestCase()` function (remember not to spell it as **`SetupTestCase`** with a small `u`!) to set up the shared resources and a `static void TearDownTestCase()` function to tear them down.
That's it! Google Test automatically calls `SetUpTestCase()` before running the _first test_ in the `FooTest` test case (i.e. before creating the first `FooTest` object), and calls `TearDownTestCase()` after running the _last test_ in it (i.e. after deleting the last `FooTest` object). In between, the tests can use the shared resources.
Remember that the test order is undefined, so your code can't depend on a test preceding or following another. Also, the tests must either not modify the state of any shared resource, or, if they do modify the state, they must restore the state to its original value before passing control to the next test.
Here's an example of per-test-case set-up and tear-down: ``` class FooTest : public ::testing::Test {  protected:   // Per-test-case set-up.   // Called before the first test in this test case.   // Can be omitted if not needed.   static void SetUpTestCase() {     shared_resource_ = new ...;   }
// Per-test-case tear-down.   // Called after the last test in this test case.   // Can be omitted if not needed.   static void TearDownTestCase() {     delete shared_resource_;     shared_resource_ = NULL;   }
// You can define per-test set-up and tear-down logic as usual.   virtual void SetUp() { ... }   virtual void TearDown() { ... }
// Some expensive resource shared by all tests.   static T* shared_resource_; };
T* FooTest::shared_resource_ = NULL;
TEST_F(FooTest, Test1) {   ... you can refer to shared_resource here ... } TEST_F(FooTest, Test2) {   ... you can refer to shared_resource here ... } ```
_Availability:_ Linux, Windows, Mac.
Just as you can do set-up and tear-down at the test level and the test case level, you can also do it at the test program level. Here's how.
First, you subclass the `::testing::Environment` class to define a test environment, which knows how to set-up and tear-down:
``` class Environment {  public:   virtual ~Environment() {}   // Override this to define how to set up the environment.   virtual void SetUp() {}   // Override this to define how to tear down the environment.   virtual void TearDown() {} }; ```
Then, you register an instance of your environment class with Google Test by calling the `::testing::AddGlobalTestEnvironment()` function:
``` Environment* AddGlobalTestEnvironment(Environment* env); ```
Now, when `RUN_ALL_TESTS()` is called, it first calls the `SetUp()` method of the environment object, then runs the tests if there was no fatal failures, and finally calls `TearDown()` of the environment object.
It's OK to register multiple environment objects. In this case, their `SetUp()` will be called in the order they are registered, and their `TearDown()` will be called in the reverse order.
Note that Google Test takes ownership of the registered environment objects. Therefore **do not delete them** by yourself.
You should call `AddGlobalTestEnvironment()` before `RUN_ALL_TESTS()` is called, probably in `main()`. If you use `gtest_main`, you need to      call this before `main()` starts for it to take effect. One way to do this is to define a global variable like this:
``` ::testing::Environment* const foo_env = ::testing::AddGlobalTestEnvironment(new FooEnvironment); ```
However, we strongly recommend you to write your own `main()` and call `AddGlobalTestEnvironment()` there, as relying on initialization of global variables makes the code harder to read and may cause problems when you register multiple environments from different translation units and the environments have dependencies among them (remember that the compiler doesn't guarantee the order in which global variables from different translation units are initialized).
_Availability:_ Linux, Windows, Mac.
_Value-parameterized tests_ allow you to test your code with different parameters without writing multiple copies of the same test.
Suppose you write a test for your code and then realize that your code is affected by a presence of a Boolean command line flag.
``` TEST(MyCodeTest, TestFoo) {   // A code to test foo(). } ```
Usually people factor their test code into a function with a Boolean parameter in such situations. The function sets the flag, then executes the testing code.
``` void TestFooHelper(bool flag_value) {   flag = flag_value;   // A code to test foo(). }
TEST(MyCodeTest, TestFoo) {   TestFooHelper(false);   TestFooHelper(true); } ```
But this setup has serious drawbacks. First, when a test assertion fails in your tests, it becomes unclear what value of the parameter caused it to fail. You can stream a clarifying message into your `EXPECT`/`ASSERT` statements, but it you'll have to do it with all of them. Second, you have to add one such helper function per test. What if you have ten tests? Twenty? A hundred?
Value-parameterized tests will let you write your test only once and then easily instantiate and run it with an arbitrary number of parameter values.
Here are some other situations when value-parameterized tests come handy:
* You want to test different implementations of an OO interface.   * You want to test your code over various inputs (a.k.a. data-driven testing). This feature is easy to abuse, so please exercise your good sense when doing it!
To write value-parameterized tests, first you should define a fixture class.  It must be derived from both `::testing::Test` and `::testing::WithParamInterface<T>` (the latter is a pure interface), where `T` is the type of your parameter values.  For convenience, you can just derive the fixture class from `::testing::TestWithParam<T>`, which itself is derived from both `::testing::Test` and `::testing::WithParamInterface<T>`. `T` can be any copyable type. If it's a raw pointer, you are responsible for managing the lifespan of the pointed values.
``` class FooTest : public ::testing::TestWithParam<const char*> {   // You can implement all the usual fixture class members here.   // To access the test parameter, call GetParam() from class   // TestWithParam<T>. };
// Or, when you want to add parameters to a pre-existing fixture class: class BaseTest : public ::testing::Test {   ... }; class BarTest : public BaseTest,                 public ::testing::WithParamInterface<const char*> {   ... }; ```
Then, use the `TEST_P` macro to define as many test patterns using this fixture as you want.  The `_P` suffix is for "parameterized" or "pattern", whichever you prefer to think.
``` TEST_P(FooTest, DoesBlah) {   // Inside a test, access the test parameter with the GetParam() method   // of the TestWithParam<T> class:   EXPECT_TRUE(foo.Blah(GetParam()));   ... }
TEST_P(FooTest, HasBlahBlah) {   ... } ```
Finally, you can use `INSTANTIATE_TEST_CASE_P` to instantiate the test case with any set of parameters you want. Google Test defines a number of functions for generating test parameters. They return what we call (surprise!) _parameter generators_. Here is a summary of them, which are all in the `testing` namespace:
| `Range(begin, end[, step])` | Yields values `{begin, begin+step, begin+step+step, ...}`. The values do not include `end`. `step` defaults to 1. | |:----------------------------|:------------------------------------------------------------------------------------------------------------------| | `Values(v1, v2, ..., vN)`   | Yields values `{v1, v2, ..., vN}`.                                                                                | | `ValuesIn(container)` and `ValuesIn(begin, end)` | Yields values from a C-style array, an STL-style container, or an iterator range `[begin, end)`. `container`, `begin`, and `end` can be expressions whose values are determined at run time.  | | `Bool()`                    | Yields sequence `{false, true}`.                                                                                  | | `Combine(g1, g2, ..., gN)`  | Yields all combinations (the Cartesian product for the math savvy) of the values generated by the `N` generators. This is only available if your system provides the `<tr1/tuple>` header. If you are sure your system does, and Google Test disagrees, you can override it by defining `GTEST_HAS_TR1_TUPLE=1`. See comments in [include/gtest/internal/gtest-port.h](../include/gtest/internal/gtest-port.h) for more information. |
For more details, see the comments at the definitions of these functions in the [source code](../include/gtest/gtest-param-test.h).
The following statement will instantiate tests from the `FooTest` test case each with parameter values `"meeny"`, `"miny"`, and `"moe"`.
``` INSTANTIATE_TEST_CASE_P(InstantiationName,                         FooTest,                         ::testing::Values("meeny", "miny", "moe")); ```
To distinguish different instances of the pattern (yes, you can instantiate it more than once), the first argument to `INSTANTIATE_TEST_CASE_P` is a prefix that will be added to the actual test case name. Remember to pick unique prefixes for different instantiations. The tests from the instantiation above will have these names:
* `InstantiationName/FooTest.DoesBlah/0` for `"meeny"`   * `InstantiationName/FooTest.DoesBlah/1` for `"miny"`   * `InstantiationName/FooTest.DoesBlah/2` for `"moe"`   * `InstantiationName/FooTest.HasBlahBlah/0` for `"meeny"`   * `InstantiationName/FooTest.HasBlahBlah/1` for `"miny"`   * `InstantiationName/FooTest.HasBlahBlah/2` for `"moe"`
You can use these names in [--gtest\_filter](#running-a-subset-of-the-tests).
This statement will instantiate all tests from `FooTest` again, each with parameter values `"cat"` and `"dog"`:
``` const char* pets[] = {"cat", "dog"}; INSTANTIATE_TEST_CASE_P(AnotherInstantiationName, FooTest,                         ::testing::ValuesIn(pets)); ```
The tests from the instantiation above will have these names:
* `AnotherInstantiationName/FooTest.DoesBlah/0` for `"cat"`   * `AnotherInstantiationName/FooTest.DoesBlah/1` for `"dog"`   * `AnotherInstantiationName/FooTest.HasBlahBlah/0` for `"cat"`   * `AnotherInstantiationName/FooTest.HasBlahBlah/1` for `"dog"`
Please note that `INSTANTIATE_TEST_CASE_P` will instantiate _all_ tests in the given test case, whether their definitions come before or _after_ the `INSTANTIATE_TEST_CASE_P` statement.
You can see [these](../samples/sample7_unittest.cc) [files](../samples/sample8_unittest.cc) for more examples.
_Availability_: Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.2.0.
In the above, we define and instantiate `FooTest` in the same source file. Sometimes you may want to define value-parameterized tests in a library and let other people instantiate them later. This pattern is known as <i>abstract tests</i>. As an example of its application, when you are designing an interface you can write a standard suite of abstract tests (perhaps using a factory function as the test parameter) that all implementations of the interface are expected to pass. When someone implements the interface, he can instantiate your suite to get all the interface-conformance tests for free.
To define abstract tests, you should organize your code like this:
1. Put the definition of the parameterized test fixture class (e.g. `FooTest`) in a header file, say `foo_param_test.h`. Think of this as _declaring_ your abstract tests.   1. Put the `TEST_P` definitions in `foo_param_test.cc`, which includes `foo_param_test.h`. Think of this as _implementing_ your abstract tests.
Once they are defined, you can instantiate them by including `foo_param_test.h`, invoking `INSTANTIATE_TEST_CASE_P()`, and linking with `foo_param_test.cc`. You can instantiate the same abstract test case multiple times, possibly in different source files.
Suppose you have multiple implementations of the same interface and want to make sure that all of them satisfy some common requirements. Or, you may have defined several types that are supposed to conform to the same "concept" and you want to verify it.  In both cases, you want the same test logic repeated for different types.
While you can write one `TEST` or `TEST_F` for each type you want to test (and you may even factor the test logic into a function template that you invoke from the `TEST`), it's tedious and doesn't scale: if you want _m_ tests over _n_ types, you'll end up writing _m\*n_ `TEST`s.
_Typed tests_ allow you to repeat the same test logic over a list of types.  You only need to write the test logic once, although you must know the type list when writing typed tests.  Here's how you do it:
First, define a fixture class template.  It should be parameterized by a type.  Remember to derive it from `::testing::Test`:
``` template <typename T> class FooTest : public ::testing::Test {  public:   ...   typedef std::list<T> List;   static T shared_;   T value_; }; ```
Next, associate a list of types with the test case, which will be repeated for each type in the list:
``` typedef ::testing::Types<char, int, unsigned int> MyTypes; TYPED_TEST_CASE(FooTest, MyTypes); ```
The `typedef` is necessary for the `TYPED_TEST_CASE` macro to parse correctly.  Otherwise the compiler will think that each comma in the type list introduces a new macro argument.
Then, use `TYPED_TEST()` instead of `TEST_F()` to define a typed test for this test case.  You can repeat this as many times as you want:
``` TYPED_TEST(FooTest, DoesBlah) {   // Inside a test, refer to the special name TypeParam to get the type   // parameter.  Since we are inside a derived class template, C++ requires   // us to visit the members of FooTest via 'this'.   TypeParam n = this->value_;
// To visit static members of the fixture, add the 'TestFixture::'   // prefix.   n += TestFixture::shared_;
// To refer to typedefs in the fixture, add the 'typename TestFixture::'   // prefix.  The 'typename' is required to satisfy the compiler.   typename TestFixture::List values;   values.push_back(n);   ... }
TYPED_TEST(FooTest, HasPropertyA) { ... } ```
You can see `samples/sample6_unittest.cc` for a complete example.
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.1.0.
_Type-parameterized tests_ are like typed tests, except that they don't require you to know the list of types ahead of time.  Instead, you can define the test logic first and instantiate it with different type lists later.  You can even instantiate it more than once in the same program.
If you are designing an interface or concept, you can define a suite of type-parameterized tests to verify properties that any valid implementation of the interface/concept should have.  Then, the author of each implementation can just instantiate the test suite with his type to verify that it conforms to the requirements, without having to write similar tests repeatedly.  Here's an example:
First, define a fixture class template, as we did with typed tests:
``` template <typename T> class FooTest : public ::testing::Test {   ... }; ```
Next, declare that you will define a type-parameterized test case:
``` TYPED_TEST_CASE_P(FooTest); ```
The `_P` suffix is for "parameterized" or "pattern", whichever you prefer to think.
Then, use `TYPED_TEST_P()` to define a type-parameterized test.  You can repeat this as many times as you want:
``` TYPED_TEST_P(FooTest, DoesBlah) {   // Inside a test, refer to TypeParam to get the type parameter.   TypeParam n = 0;   ... }
TYPED_TEST_P(FooTest, HasPropertyA) { ... } ```
Now the tricky part: you need to register all test patterns using the `REGISTER_TYPED_TEST_CASE_P` macro before you can instantiate them. The first argument of the macro is the test case name; the rest are the names of the tests in this test case:
``` REGISTER_TYPED_TEST_CASE_P(FooTest,                            DoesBlah, HasPropertyA); ```
Finally, you are free to instantiate the pattern with the types you want.  If you put the above code in a header file, you can `#include` it in multiple C++ source files and instantiate it multiple times.
``` typedef ::testing::Types<char, int, unsigned int> MyTypes; INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, MyTypes); ```
To distinguish different instances of the pattern, the first argument to the `INSTANTIATE_TYPED_TEST_CASE_P` macro is a prefix that will be added to the actual test case name.  Remember to pick unique prefixes for different instances.
In the special case where the type list contains only one type, you can write that type directly without `::testing::Types<...>`, like this:
``` INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, int); ```
You can see `samples/sample6_unittest.cc` for a complete example.
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.1.0.
If you change your software's internal implementation, your tests should not break as long as the change is not observable by users. Therefore, per the _black-box testing principle_, most of the time you should test your code through its public interfaces.
If you still find yourself needing to test internal implementation code, consider if there's a better design that wouldn't require you to do so. If you absolutely have to test non-public interface code though, you can. There are two cases to consider:
* Static functions (_not_ the same as static member functions!) or unnamed namespaces, and   * Private or protected class members
Both static functions and definitions/declarations in an unnamed namespace are only visible within the same translation unit. To test them, you can `#include` the entire `.cc` file being tested in your `*_test.cc` file. (`#include`ing `.cc` files is not a good way to reuse code - you should not do this in production code!)
However, a better approach is to move the private code into the `foo::internal` namespace, where `foo` is the namespace your project normally uses, and put the private declarations in a `*-internal.h` file. Your production `.cc` files and your tests are allowed to include this internal header, but your clients are not. This way, you can fully test your internal implementation without leaking it to your clients.
Private class members are only accessible from within the class or by friends. To access a class' private members, you can declare your test fixture as a friend to the class and define accessors in your fixture. Tests using the fixture can then access the private members of your production class via the accessors in the fixture. Note that even though your fixture is a friend to your production class, your tests are not automatically friends to it, as they are technically defined in sub-classes of the fixture.
Another way to test private members is to refactor them into an implementation class, which is then declared in a `*-internal.h` file. Your clients aren't allowed to include this header but your tests can. Such is called the Pimpl (Private Implementation) idiom.
Or, you can declare an individual test as a friend of your class by adding this line in the class body:
``` FRIEND_TEST(TestCaseName, TestName); ```
For example, ``` // foo.h #include "gtest/gtest_prod.h"
// Defines FRIEND_TEST. class Foo {   ...  private:   FRIEND_TEST(FooTest, BarReturnsZeroOnNull);   int Bar(void* x); };
// foo_test.cc ... TEST(FooTest, BarReturnsZeroOnNull) {   Foo foo;   EXPECT_EQ(0, foo.Bar(NULL));   // Uses Foo's private member Bar(). } ```
Pay special attention when your class is defined in a namespace, as you should define your test fixtures and tests in the same namespace if you want them to be friends of your class. For example, if the code to be tested looks like:
``` namespace my_namespace {
class Foo {   friend class FooTest;   FRIEND_TEST(FooTest, Bar);   FRIEND_TEST(FooTest, Baz);   ...   definition of the class Foo   ... };
}  // namespace my_namespace ```
Your test code should be something like:
``` namespace my_namespace { class FooTest : public ::testing::Test {  protected:   ... };
TEST_F(FooTest, Bar) { ... } TEST_F(FooTest, Baz) { ... }
}  // namespace my_namespace ```
If you are building a testing utility on top of Google Test, you'll want to test your utility.  What framework would you use to test it? Google Test, of course.
The challenge is to verify that your testing utility reports failures correctly.  In frameworks that report a failure by throwing an exception, you could catch the exception and assert on it.  But Google Test doesn't use exceptions, so how do we test that a piece of code generates an expected failure?
`"gtest/gtest-spi.h"` contains some constructs to do this.  After  `#include`ing this header, you can use
| `EXPECT_FATAL_FAILURE(`_statement, substring_`);` | |:--------------------------------------------------|
to assert that _statement_ generates a fatal (e.g. `ASSERT_*`) failure whose message contains the given _substring_, or use
| `EXPECT_NONFATAL_FAILURE(`_statement, substring_`);` | |:-----------------------------------------------------|
if you are expecting a non-fatal (e.g. `EXPECT_*`) failure.
For technical reasons, there are some caveats:
1. You cannot stream a failure message to either macro.   1. _statement_ in `EXPECT_FATAL_FAILURE()` cannot reference local non-static variables or non-static members of `this` object.   1. _statement_ in `EXPECT_FATAL_FAILURE()` cannot return a value.
_Note:_ Google Test is designed with threads in mind. Once the synchronization primitives in `"gtest/internal/gtest-port.h"` have been implemented, Google Test will become thread-safe, meaning that you can then use assertions in multiple threads concurrently. Before that, however, Google Test only supports single-threaded usage. Once thread-safe, `EXPECT_FATAL_FAILURE()` and `EXPECT_NONFATAL_FAILURE()` will capture failures in the current thread only. If _statement_ creates new threads, failures in these threads will be ignored. If you want to capture failures from all threads instead, you should use the following macros:
| `EXPECT_FATAL_FAILURE_ON_ALL_THREADS(`_statement, substring_`);` | |:-----------------------------------------------------------------| | `EXPECT_NONFATAL_FAILURE_ON_ALL_THREADS(`_statement, substring_`);` |
Sometimes a function may need to know the name of the currently running test. For example, you may be using the `SetUp()` method of your test fixture to set the golden file name based on which test is running. The `::testing::TestInfo` class has this information:
``` namespace testing {
class TestInfo {  public:   // Returns the test case name and the test name, respectively.   //   // Do NOT delete or free the return value - it's managed by the   // TestInfo class.   const char* test_case_name() const;   const char* name() const; };
}  // namespace testing ```
> To obtain a `TestInfo` object for the currently running test, call `current_test_info()` on the `UnitTest` singleton object:
``` // Gets information about the currently running test. // Do NOT delete the returned object - it's managed by the UnitTest class. const ::testing::TestInfo* const test_info =   ::testing::UnitTest::GetInstance()->current_test_info(); printf("We are in test %s of test case %s.\n",        test_info->name(), test_info->test_case_name()); ```
`current_test_info()` returns a null pointer if no test is running. In particular, you cannot find the test case name in `TestCaseSetUp()`, `TestCaseTearDown()` (where you know the test case name implicitly), or functions called from them.
_Availability:_ Linux, Windows, Mac.
Google Test provides an <b>event listener API</b> to let you receive notifications about the progress of a test program and test failures. The events you can listen to include the start and end of the test program, a test case, or a test method, among others. You may use this API to augment or replace the standard console output, replace the XML output, or provide a completely different form of output, such as a GUI or a database. You can also use test events as checkpoints to implement a resource leak checker, for example.
_Availability:_ Linux, Windows, Mac; since v1.4.0.
To define a event listener, you subclass either [testing::TestEventListener](../include/gtest/gtest.h#L991) or [testing::EmptyTestEventListener](../include/gtest/gtest.h#L1044). The former is an (abstract) interface, where <i>each pure virtual method<br> can be overridden to handle a test event</i> (For example, when a test starts, the `OnTestStart()` method will be called.). The latter provides an empty implementation of all methods in the interface, such that a subclass only needs to override the methods it cares about.
When an event is fired, its context is passed to the handler function as an argument. The following argument types are used:   * [UnitTest](../include/gtest/gtest.h#L1151) reflects the state of the entire test program,   * [TestCase](../include/gtest/gtest.h#L778) has information about a test case, which can contain one or more tests,   * [TestInfo](../include/gtest/gtest.h#L644) contains the state of a test, and   * [TestPartResult](../include/gtest/gtest-test-part.h#L47) represents the result of a test assertion.
An event handler function can examine the argument it receives to find out interesting information about the event and the test program's state.  Here's an example:
```   class MinimalistPrinter : public ::testing::EmptyTestEventListener {     // Called before a test starts.     virtual void OnTestStart(const ::testing::TestInfo& test_info) {       printf("*** Test %s.%s starting.\n",              test_info.test_case_name(), test_info.name());     }
// Called after a failed assertion or a SUCCEED() invocation.     virtual void OnTestPartResult(         const ::testing::TestPartResult& test_part_result) {       printf("%s in %s:%d\n%s\n",              test_part_result.failed() ? "*** Failure" : "Success",              test_part_result.file_name(),              test_part_result.line_number(),              test_part_result.summary());     }
// Called after a test ends.     virtual void OnTestEnd(const ::testing::TestInfo& test_info) {       printf("*** Test %s.%s ending.\n",              test_info.test_case_name(), test_info.name());     }   }; ```
To use the event listener you have defined, add an instance of it to the Google Test event listener list (represented by class [TestEventListeners](../include/gtest/gtest.h#L1064) - note the "s" at the end of the name) in your `main()` function, before calling `RUN_ALL_TESTS()`: ``` int main(int argc, char** argv) {   ::testing::InitGoogleTest(&argc, argv);   // Gets hold of the event listener list.   ::testing::TestEventListeners& listeners =       ::testing::UnitTest::GetInstance()->listeners();   // Adds a listener to the end.  Google Test takes the ownership.   listeners.Append(new MinimalistPrinter);   return RUN_ALL_TESTS(); } ```
There's only one problem: the default test result printer is still in effect, so its output will mingle with the output from your minimalist printer. To suppress the default printer, just release it from the event listener list and delete it. You can do so by adding one line: ```   ...   delete listeners.Release(listeners.default_result_printer());   listeners.Append(new MinimalistPrinter);   return RUN_ALL_TESTS(); ```
Now, sit back and enjoy a completely different output from your tests. For more details, you can read this [sample](../samples/sample9_unittest.cc).
You may append more than one listener to the list. When an `On*Start()` or `OnTestPartResult()` event is fired, the listeners will receive it in the order they appear in the list (since new listeners are added to the end of the list, the default text printer and the default XML generator will receive the event first). An `On*End()` event will be received by the listeners in the _reverse_ order. This allows output by listeners added later to be framed by output from listeners added earlier.
You may use failure-raising macros (`EXPECT_*()`, `ASSERT_*()`, `FAIL()`, etc) when processing an event. There are some restrictions:
1. You cannot generate any failure in `OnTestPartResult()` (otherwise it will cause `OnTestPartResult()` to be called recursively).   1. A listener that handles `OnTestPartResult()` is not allowed to generate any failure.
When you add listeners to the listener list, you should put listeners that handle `OnTestPartResult()` _before_ listeners that can generate failures. This ensures that failures generated by the latter are attributed to the right test by the former.
We have a sample of failure-raising listener [here](../samples/sample10_unittest.cc).
Google Test test programs are ordinary executables. Once built, you can run them directly and affect their behavior via the following environment variables and/or command line flags. For the flags to work, your programs must call `::testing::InitGoogleTest()` before calling `RUN_ALL_TESTS()`.
To see a list of supported flags and their usage, please run your test program with the `--help` flag.  You can also use `-h`, `-?`, or `/?` for short.  This feature is added in version 1.3.0.
If an option is specified both by an environment variable and by a flag, the latter takes precedence.  Most of the options can also be set/read in code: to access the value of command line flag `--gtest_foo`, write `::testing::GTEST_FLAG(foo)`.  A common pattern is to set the value of a flag before calling `::testing::InitGoogleTest()` to change the default value of the flag: ``` int main(int argc, char** argv) {   // Disables elapsed time by default.   ::testing::GTEST_FLAG(print_time) = false;
// This allows the user to override the flag on the command line.   ::testing::InitGoogleTest(&argc, argv);
return RUN_ALL_TESTS(); } ```
This section shows various options for choosing which tests to run.
Sometimes it is necessary to list the available tests in a program before running them so that a filter may be applied if needed. Including the flag `--gtest_list_tests` overrides all other flags and lists tests in the following format: ``` TestCase1.   TestName1   TestName2 TestCase2.   TestName ```
None of the tests listed are actually run if the flag is provided. There is no corresponding environment variable for this flag.
_Availability:_ Linux, Windows, Mac.
By default, a Google Test program runs all tests the user has defined. Sometimes, you want to run only a subset of the tests (e.g. for debugging or quickly verifying a change). If you set the `GTEST_FILTER` environment variable or the `--gtest_filter` flag to a filter string, Google Test will only run the tests whose full names (in the form of `TestCaseName.TestName`) match the filter.
The format of a filter is a '`:`'-separated list of wildcard patterns (called the positive patterns) optionally followed by a '`-`' and another '`:`'-separated pattern list (called the negative patterns). A test matches the filter if and only if it matches any of the positive patterns but does not match any of the negative patterns.
A pattern may contain `'*'` (matches any string) or `'?'` (matches any single character). For convenience, the filter `'*-NegativePatterns'` can be also written as `'-NegativePatterns'`.
For example:
* `./foo_test` Has no flag, and thus runs all its tests.   * `./foo_test --gtest_filter=*` Also runs everything, due to the single match-everything `*` value.   * `./foo_test --gtest_filter=FooTest.*` Runs everything in test case `FooTest`.   * `./foo_test --gtest_filter=*Null*:*Constructor*` Runs any test whose full name contains either `"Null"` or `"Constructor"`.   * `./foo_test --gtest_filter=-*DeathTest.*` Runs all non-death tests.   * `./foo_test --gtest_filter=FooTest.*-FooTest.Bar` Runs everything in test case `FooTest` except `FooTest.Bar`.
_Availability:_ Linux, Windows, Mac.
If you have a broken test that you cannot fix right away, you can add the `DISABLED_` prefix to its name. This will exclude it from execution. This is better than commenting out the code or using `#if 0`, as disabled tests are still compiled (and thus won't rot).
If you need to disable all tests in a test case, you can either add `DISABLED_` to the front of the name of each test, or alternatively add it to the front of the test case name.
For example, the following tests won't be run by Google Test, even though they will still be compiled:
``` // Tests that Foo does Abc. TEST(FooTest, DISABLED_DoesAbc) { ... }
class DISABLED_BarTest : public ::testing::Test { ... };
// Tests that Bar does Xyz. TEST_F(DISABLED_BarTest, DoesXyz) { ... } ```
_Note:_ This feature should only be used for temporary pain-relief. You still have to fix the disabled tests at a later date. As a reminder, Google Test will print a banner warning you if a test program contains any disabled tests.
_Tip:_ You can easily count the number of disabled tests you have using `grep`. This number can be used as a metric for improving your test quality.
_Availability:_ Linux, Windows, Mac.
To include [disabled tests](#temporarily-disabling-tests) in test execution, just invoke the test program with the `--gtest_also_run_disabled_tests` flag or set the `GTEST_ALSO_RUN_DISABLED_TESTS` environment variable to a value other than `0`.  You can combine this with the [--gtest\_filter](#running-a-subset-of-the-tests) flag to further select which disabled tests to run.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
Once in a while you'll run into a test whose result is hit-or-miss. Perhaps it will fail only 1% of the time, making it rather hard to reproduce the bug under a debugger. This can be a major source of frustration.
The `--gtest_repeat` flag allows you to repeat all (or selected) test methods in a program many times. Hopefully, a flaky test will eventually fail and give you a chance to debug. Here's how to use it:
| `$ foo_test --gtest_repeat=1000` | Repeat foo\_test 1000 times and don't stop at failures. | |:---------------------------------|:--------------------------------------------------------| | `$ foo_test --gtest_repeat=-1`   | A negative count means repeating forever.               | | `$ foo_test --gtest_repeat=1000 --gtest_break_on_failure` | Repeat foo\_test 1000 times, stopping at the first failure. This is especially useful when running under a debugger: when the testfails, it will drop into the debugger and you can then inspect variables and stacks. | | `$ foo_test --gtest_repeat=1000 --gtest_filter=FooBar` | Repeat the tests whose name matches the filter 1000 times. |
If your test program contains global set-up/tear-down code registered using `AddGlobalTestEnvironment()`, it will be repeated in each iteration as well, as the flakiness may be in it. You can also specify the repeat count by setting the `GTEST_REPEAT` environment variable.
_Availability:_ Linux, Windows, Mac.
You can specify the `--gtest_shuffle` flag (or set the `GTEST_SHUFFLE` environment variable to `1`) to run the tests in a program in a random order. This helps to reveal bad dependencies between tests.
By default, Google Test uses a random seed calculated from the current time. Therefore you'll get a different order every time. The console output includes the random seed value, such that you can reproduce an order-related test failure later. To specify the random seed explicitly, use the `--gtest_random_seed=SEED` flag (or set the `GTEST_RANDOM_SEED` environment variable), where `SEED` is an integer between 0 and 99999. The seed value 0 is special: it tells Google Test to do the default behavior of calculating the seed from the current time.
If you combine this with `--gtest_repeat=N`, Google Test will pick a different random seed and re-shuffle the tests in each iteration.
_Availability:_ Linux, Windows, Mac; since v1.4.0.
This section teaches how to tweak the way test results are reported.
Google Test can use colors in its terminal output to make it easier to spot the separation between tests, and whether tests passed.
You can set the GTEST\_COLOR environment variable or set the `--gtest_color` command line flag to `yes`, `no`, or `auto` (the default) to enable colors, disable colors, or let Google Test decide. When the value is `auto`, Google Test will use colors if and only if the output goes to a terminal and (on non-Windows platforms) the `TERM` environment variable is set to `xterm` or `xterm-color`.
_Availability:_ Linux, Windows, Mac.
By default, Google Test prints the time it takes to run each test.  To suppress that, run the test program with the `--gtest_print_time=0` command line flag.  Setting the `GTEST_PRINT_TIME` environment variable to `0` has the same effect.
_Availability:_ Linux, Windows, Mac.  (In Google Test 1.3.0 and lower, the default behavior is that the elapsed time is **not** printed.)
Google Test can emit a detailed XML report to a file in addition to its normal textual output. The report contains the duration of each test, and thus can help you identify slow tests.
To generate the XML report, set the `GTEST_OUTPUT` environment variable or the `--gtest_output` flag to the string `"xml:_path_to_output_file_"`, which will create the file at the given location. You can also just use the string `"xml"`, in which case the output can be found in the `test_detail.xml` file in the current directory.
If you specify a directory (for example, `"xml:output/directory/"` on Linux or `"xml:output\directory\"` on Windows), Google Test will create the XML file in that directory, named after the test executable (e.g. `foo_test.xml` for test program `foo_test` or `foo_test.exe`). If the file already exists (perhaps left over from a previous run), Google Test will pick a different name (e.g. `foo_test_1.xml`) to avoid overwriting it.
The report uses the format described here.  It is based on the `junitreport` Ant task and can be parsed by popular continuous build systems like [Hudson](https://hudson.dev.java.net/). Since that format was originally intended for Java, a little interpretation is required to make it apply to Google Test tests, as shown here:
``` <testsuites name="AllTests" ...>   <testsuite name="test_case_name" ...>     <testcase name="test_name" ...>       <failure message="..."/>       <failure message="..."/>       <failure message="..."/>     </testcase>   </testsuite> </testsuites> ```
* The root `<testsuites>` element corresponds to the entire test program.   * `<testsuite>` elements correspond to Google Test test cases.   * `<testcase>` elements correspond to Google Test test functions.
For instance, the following program
``` TEST(MathTest, Addition) { ... } TEST(MathTest, Subtraction) { ... } TEST(LogicTest, NonContradiction) { ... } ```
could generate this report:
``` <?xml version="1.0" encoding="UTF-8"?> <testsuites tests="3" failures="1" errors="0" time="35" name="AllTests">   <testsuite name="MathTest" tests="2" failures="1" errors="0" time="15">     <testcase name="Addition" status="run" time="7" classname="">       <failure message="Value of: add(1, 1)&#x0A; Actual: 3&#x0A;Expected: 2" type=""/>       <failure message="Value of: add(1, -1)&#x0A; Actual: 1&#x0A;Expected: 0" type=""/>     </testcase>     <testcase name="Subtraction" status="run" time="5" classname="">     </testcase>   </testsuite>   <testsuite name="LogicTest" tests="1" failures="0" errors="0" time="5">     <testcase name="NonContradiction" status="run" time="5" classname="">     </testcase>   </testsuite> </testsuites> ```
Things to note:
* The `tests` attribute of a `<testsuites>` or `<testsuite>` element tells how many test functions the Google Test program or test case contains, while the `failures` attribute tells how many of them failed.   * The `time` attribute expresses the duration of the test, test case, or entire test program in milliseconds.   * Each `<failure>` element corresponds to a single failed Google Test assertion.   * Some JUnit concepts don't apply to Google Test, yet we have to conform to the DTD. Therefore you'll see some dummy elements and attributes in the report. You can safely ignore these parts.
_Availability:_ Linux, Windows, Mac.
When running test programs under a debugger, it's very convenient if the debugger can catch an assertion failure and automatically drop into interactive mode. Google Test's _break-on-failure_ mode supports this behavior.
To enable it, set the `GTEST_BREAK_ON_FAILURE` environment variable to a value other than `0` . Alternatively, you can use the `--gtest_break_on_failure` command line flag.
_Availability:_ Linux, Windows, Mac.
Google Test can be used either with or without exceptions enabled.  If a test throws a C++ exception or (on Windows) a structured exception (SEH), by default Google Test catches it, reports it as a test failure, and continues with the next test method.  This maximizes the coverage of a test run.  Also, on Windows an uncaught exception will cause a pop-up window, so catching the exceptions allows you to run the tests automatically.
When debugging the test failures, however, you may instead want the exceptions to be handled by the debugger, such that you can examine the call stack when an exception is thrown.  To achieve that, set the `GTEST_CATCH_EXCEPTIONS` environment variable to `0`, or use the `--gtest_catch_exceptions=0` flag when running the tests.
**Availability**: Linux, Windows, Mac.
If you work on a project that has already been using another testing framework and is not ready to completely switch to Google Test yet, you can get much of Google Test's benefit by using its assertions in your existing tests.  Just change your `main()` function to look like:
``` #include "gtest/gtest.h"
int main(int argc, char** argv) {   ::testing::GTEST_FLAG(throw_on_failure) = true;   // Important: Google Test must be initialized.   ::testing::InitGoogleTest(&argc, argv);
... whatever your existing testing framework requires ... } ```
With that, you can use Google Test assertions in addition to the native assertions your testing framework provides, for example:
``` void TestFooDoesBar() {   Foo foo;   EXPECT_LE(foo.Bar(1), 100);     // A Google Test assertion.   CPPUNIT_ASSERT(foo.IsEmpty());  // A native assertion. } ```
If a Google Test assertion fails, it will print an error message and throw an exception, which will be treated as a failure by your host testing framework.  If you compile your code with exceptions disabled, a failed Google Test assertion will instead exit your program with a non-zero code, which will also signal a test failure to your test runner.
If you don't write `::testing::GTEST_FLAG(throw_on_failure) = true;` in your `main()`, you can alternatively enable this feature by specifying the `--gtest_throw_on_failure` flag on the command-line or setting the `GTEST_THROW_ON_FAILURE` environment variable to a non-zero value.
Death tests are _not_ supported when other test framework is used to organize tests.
_Availability:_ Linux, Windows, Mac; since v1.3.0.
If you have more than one machine you can use to run a test program, you might want to run the test functions in parallel and get the result faster.  We call this technique _sharding_, where each machine is called a _shard_.
Google Test is compatible with test sharding.  To take advantage of this feature, your test runner (not part of Google Test) needs to do the following:
1. Allocate a number of machines (shards) to run the tests.   1. On each shard, set the `GTEST_TOTAL_SHARDS` environment variable to the total number of shards.  It must be the same for all shards.   1. On each shard, set the `GTEST_SHARD_INDEX` environment variable to the index of the shard.  Different shards must be assigned different indices, which must be in the range `[0, GTEST_TOTAL_SHARDS - 1]`.   1. Run the same test program on all shards.  When Google Test sees the above two environment variables, it will select a subset of the test functions to run.  Across all shards, each test function in the program will be run exactly once.   1. Wait for all shards to finish, then collect and report the results.
Your project may have tests that were written without Google Test and thus don't understand this protocol.  In order for your test runner to figure out which test supports sharding, it can set the environment variable `GTEST_SHARD_STATUS_FILE` to a non-existent file path.  If a test program supports sharding, it will create this file to acknowledge the fact (the actual contents of the file are not important at this time; although we may stick some useful information in it in the future.); otherwise it will not create it.
Here's an example to make it clear.  Suppose you have a test program `foo_test` that contains the following 5 test functions: ``` TEST(A, V) TEST(A, W) TEST(B, X) TEST(B, Y) TEST(B, Z) ``` and you have 3 machines at your disposal.  To run the test functions in parallel, you would set `GTEST_TOTAL_SHARDS` to 3 on all machines, and set `GTEST_SHARD_INDEX` to 0, 1, and 2 on the machines respectively. Then you would run the same `foo_test` on each machine.
Google Test reserves the right to change how the work is distributed across the shards, but here's one possible scenario:
* Machine #0 runs `A.V` and `B.X`.   * Machine #1 runs `A.W` and `B.Y`.   * Machine #2 runs `B.Z`.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
Google Test's implementation consists of ~30 files (excluding its own tests).  Sometimes you may want them to be packaged up in two files (a `.h` and a `.cc`) instead, such that you can easily copy them to a new machine and start hacking there.  For this we provide an experimental Python script `fuse_gtest_files.py` in the `scripts/` directory (since release 1.3.0). Assuming you have Python 2.4 or above installed on your machine, just go to that directory and run ``` python fuse_gtest_files.py OUTPUT_DIR ```
and you should see an `OUTPUT_DIR` directory being created with files `gtest/gtest.h` and `gtest/gtest-all.cc` in it.  These files contain everything you need to use Google Test.  Just copy them to anywhere you want and you are ready to write tests.  You can use the [scripts/test/Makefile](../scripts/test/Makefile) file as an example on how to compile your tests against them.
Congratulations! You've now learned more advanced Google Test tools and are ready to tackle more complex testing tasks. If you want to dive even deeper, you can read the [Frequently-Asked Questions](FAQ.md).

If you are interested in understanding the internals of Google Test, building from source, or contributing ideas or modifications to the project, then this document is for you.
First, let's give you some background of the project.
All Google Test source and pre-built packages are provided under the [New BSD License](http://www.opensource.org/licenses/bsd-license.php).
The Google Test community exists primarily through the [discussion group](http://groups.google.com/group/googletestframework) and the GitHub repository. You are definitely encouraged to contribute to the discussion and you can also help us to keep the effectiveness of the group high by following and promoting the guidelines listed here.
Showing courtesy and respect to others is a vital part of the Google culture, and we strongly encourage everyone participating in Google Test development to join us in accepting nothing less. Of course, being courteous is not the same as failing to constructively disagree with each other, but it does mean that we should be respectful of each other when enumerating the 42 technical reasons that a particular proposal may not be the best choice. There's never a reason to be antagonistic or dismissive toward anyone who is sincerely trying to contribute to a discussion.
Sure, C++ testing is serious business and all that, but it's also a lot of fun. Let's keep it that way. Let's strive to be one of the friendliest communities in all of open source.
As always, discuss Google Test in the official GoogleTest discussion group. You don't have to actually submit code in order to sign up. Your participation itself is a valuable contribution.
If you want to get your hands dirty with the code inside Google Test, this is the section for you.
Once you check out the code, you can find instructions on how to compile it in the [README](../README.md) file.
A testing framework is of no good if itself is not thoroughly tested. Tests should be written for any new code, and changes should be verified to not break existing tests before they are submitted for review. To perform the tests, follow the instructions in [README](../README.md) and verify that there are no failures.
We are excited that Google Test is now open source, and hope to get great patches from the community. Before you fire up your favorite IDE and begin hammering away at that new feature, though, please take the time to read this section and understand the process. While it seems rigorous, we want to keep a high standard of quality in the code base.
You must sign a Contributor License Agreement (CLA) before we can accept any code.  The CLA protects you and us.
* If you are an individual writing original source code and you're sure you own the intellectual property, then you'll need to sign an [individual CLA](http://code.google.com/legal/individual-cla-v1.0.html).   * If you work for a company that wants to allow you to contribute your work to Google Test, then you'll need to sign a [corporate CLA](http://code.google.com/legal/corporate-cla-v1.0.html).
Follow either of the two links above to access the appropriate CLA and instructions for how to sign and return it.
To keep the source consistent, readable, diffable and easy to merge, we use a fairly rigid coding style, as defined by the [google-styleguide](http://code.google.com/p/google-styleguide/) project.  All patches will be expected to conform to the style outlined [here](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml).
Some of Google Test's source files are generated by the Pump tool (a Python script).  If you need to update such files, please modify the source (`foo.h.pump`) and re-generate the C++ file using Pump.  You can read the PumpManual for details.
Please do submit code. Here's what you need to do:
1. A submission should be a set of changes that addresses one issue in the [issue tracker](https://github.com/google/googletest/issues). Please don't mix more than one logical change per submittal, because it makes the history hard to follow. If you want to make a change that doesn't have a corresponding issue in the issue tracker, please create one.   1. Also, coordinate with team members that are listed on the issue in question. This ensures that work isn't being duplicated and communicating your plan early also generally leads to better patches.   1. Ensure that your code adheres to the [Google Test source code style](#Coding_Style.md).   1. Ensure that there are unit tests for your code.   1. Sign a Contributor License Agreement.   1. Create a Pull Request in the usual way.
The current members of the Google Test engineering team are the only committers at present. In the great tradition of eating one's own dogfood, we will be requiring each new Google Test engineering team member to earn the right to become a committer by following the procedures in this document, writing consistently great code, and demonstrating repeatedly that he or she truly gets the zen of Google Test.
We follow a typical release process:
1. A release branch named `release-X.Y` is created.   1. Bugs are fixed and features are added in trunk; those individual patches are merged into the release branch until it's stable.   1. An individual point release (the `Z` in `X.Y.Z`) is made by creating a tag from the branch.   1. Repeat steps 2 and 3 throughout one release cycle (as determined by features or time).   1. Go back to step 1 to create another release branch and so on.
---
This page is based on the [Making GWT Better](http://code.google.com/webtoolkit/makinggwtbetter.html) guide from the [Google Web Toolkit](http://code.google.com/webtoolkit/) project.  Except as otherwise [noted](http://code.google.com/policies.html#restrictions), the content of this page is licensed under the [Creative Commons Attribution 2.5 License](http://creativecommons.org/licenses/by/2.5/).
This page lists all documentation wiki pages for Google Test **(the SVN trunk version)** -- **if you use a released version of Google Test, please read the documentation for that specific version instead.**
* [Primer](Primer.md) -- start here if you are new to Google Test.   * [Samples](Samples.md) -- learn from examples.   * [AdvancedGuide](AdvancedGuide.md) -- learn more about Google Test.   * [XcodeGuide](XcodeGuide.md) -- how to use Google Test in Xcode on Mac.   * [Frequently-Asked Questions](FAQ.md) -- check here before asking a question on the mailing list.
To contribute code to Google Test, read:
* [DevGuide](DevGuide.md) -- read this _before_ writing your first patch.   * [PumpManual](PumpManual.md) -- how we generate some of Google Test's source files.

If you cannot find the answer to your question here, and you have read [Primer](Primer.md) and [AdvancedGuide](AdvancedGuide.md), send it to googletestframework@googlegroups.com.
First, let us say clearly that we don't want to get into the debate of which C++ testing framework is **the best**.  There exist many fine frameworks for writing C++ tests, and we have tremendous respect for the developers and users of them.  We don't think there is (or will be) a single best framework - you have to pick the right tool for the particular task you are tackling.
We created Google Test because we couldn't find the right combination of features and conveniences in an existing framework to satisfy _our_ needs.  The following is a list of things that _we_ like about Google Test.  We don't claim them to be unique to Google Test - rather, the combination of them makes Google Test the choice for us.  We hope this list can help you decide whether it is for you too.
* Google Test is designed to be portable: it doesn't require exceptions or RTTI; it works around various bugs in various compilers and environments; etc.  As a result, it works on Linux, Mac OS X, Windows and several embedded operating systems.   * Nonfatal assertions (`EXPECT_*`) have proven to be great time savers, as they allow a test to report multiple failures in a single edit-compile-test cycle.   * It's easy to write assertions that generate informative messages: you just use the stream syntax to append any additional information, e.g. `ASSERT_EQ(5, Foo(i)) << " where i = " << i;`.  It doesn't require a new set of macros or special functions.   * Google Test automatically detects your tests and doesn't require you to enumerate them in order to run them.   * Death tests are pretty handy for ensuring that your asserts in production code are triggered by the right conditions.   * `SCOPED_TRACE` helps you understand the context of an assertion failure when it comes from inside a sub-routine or loop.   * You can decide which tests to run using name patterns.  This saves time when you want to quickly reproduce a test failure.   * Google Test can generate XML test result reports that can be parsed by popular continuous build system like Hudson.   * Simple things are easy in Google Test, while hard things are possible: in addition to advanced features like [global test environments](AdvancedGuide.md#global-set-up-and-tear-down) and tests parameterized by [values](AdvancedGuide.md#value-parameterized-tests) or [types](docs/AdvancedGuide.md#typed-tests), Google Test supports various ways for the user to extend the framework -- if Google Test doesn't do something out of the box, chances are that a user can implement the feature using Google Test's public API, without changing Google Test itself.  In particular, you can:     * expand your testing vocabulary by defining [custom predicates](AdvancedGuide.md#predicate-assertions-for-better-error-messages),     * teach Google Test how to [print your types](AdvancedGuide.md#teaching-google-test-how-to-print-your-values),     * define your own testing macros or utilities and verify them using Google Test's [Service Provider Interface](AdvancedGuide.md#catching-failures), and     * reflect on the test cases or change the test output format by intercepting the [test events](AdvancedGuide.md#extending-google-test-by-handling-test-events).
We strive to minimize compiler warnings Google Test generates.  Before releasing a new version, we test to make sure that it doesn't generate warnings when compiled using its CMake script on Windows, Linux, and Mac OS.
Unfortunately, this doesn't mean you are guaranteed to see no warnings when compiling Google Test in your environment:
* You may be using a different compiler as we use, or a different version of the same compiler.  We cannot possibly test for all compilers.   * You may be compiling on a different platform as we do.   * Your project may be using different compiler flags as we do.
It is not always possible to make Google Test warning-free for everyone.  Or, it may not be desirable if the warning is rarely enabled and fixing the violations makes the code more complex.
If you see warnings when compiling Google Test, we suggest that you use the `-isystem` flag (assuming your are using GCC) to mark Google Test headers as system headers.  That'll suppress warnings from Google Test headers.
Underscore (`_`) is special, as C++ reserves the following to be used by the compiler and the standard library:
1. any identifier that starts with an `_` followed by an upper-case letter, and   1. any identifier that containers two consecutive underscores (i.e. `__`) _anywhere_ in its name.
User code is _prohibited_ from using such identifiers.
Now let's look at what this means for `TEST` and `TEST_F`.
Currently `TEST(TestCaseName, TestName)` generates a class named `TestCaseName_TestName_Test`.  What happens if `TestCaseName` or `TestName` contains `_`?
1. If `TestCaseName` starts with an `_` followed by an upper-case letter (say, `_Foo`), we end up with `_Foo_TestName_Test`, which is reserved and thus invalid.   1. If `TestCaseName` ends with an `_` (say, `Foo_`), we get `Foo__TestName_Test`, which is invalid.   1. If `TestName` starts with an `_` (say, `_Bar`), we get `TestCaseName__Bar_Test`, which is invalid.   1. If `TestName` ends with an `_` (say, `Bar_`), we get `TestCaseName_Bar__Test`, which is invalid.
So clearly `TestCaseName` and `TestName` cannot start or end with `_` (Actually, `TestCaseName` can start with `_` -- as long as the `_` isn't followed by an upper-case letter.  But that's getting complicated.  So for simplicity we just say that it cannot start with `_`.).
It may seem fine for `TestCaseName` and `TestName` to contain `_` in the middle.  However, consider this: ``` cpp TEST(Time, Flies_Like_An_Arrow) { ... } TEST(Time_Flies, Like_An_Arrow) { ... } ```
Now, the two `TEST`s will both generate the same class (`Time_Files_Like_An_Arrow_Test`).  That's not good.
So for simplicity, we just ask the users to avoid `_` in `TestCaseName` and `TestName`.  The rule is more constraining than necessary, but it's simple and easy to remember.  It also gives Google Test some wiggle room in case its implementation needs to change in the future.
If you violate the rule, there may not be immediately consequences, but your test may (just may) break with a new compiler (or a new version of the compiler you are using) or with a new version of Google Test.  Therefore it's best to follow the rule.
In the early days, we said that you could install compiled Google Test libraries on `*`nix systems using `make install`. Then every user of your machine can write tests without recompiling Google Test.
This seemed like a good idea, but it has a got-cha: every user needs to compile his tests using the _same_ compiler flags used to compile the installed Google Test libraries; otherwise he may run into undefined behaviors (i.e. the tests can behave strangely and may even crash for no obvious reasons).
Why?  Because C++ has this thing called the One-Definition Rule: if two C++ source files contain different definitions of the same class/function/variable, and you link them together, you violate the rule.  The linker may or may not catch the error (in many cases it's not required by the C++ standard to catch the violation).  If it doesn't, you get strange run-time behaviors that are unexpected and hard to debug.
If you compile Google Test and your test code using different compiler flags, they may see different definitions of the same class/function/variable (e.g. due to the use of `#if` in Google Test). Therefore, for your sanity, we recommend to avoid installing pre-compiled Google Test libraries.  Instead, each project should compile Google Test itself such that it can be sure that the same flags are used for both Google Test and the tests.
(Answered by Trevor Robinson)
Load the supplied Visual Studio solution file, either `msvc\gtest-md.sln` or `msvc\gtest.sln`. Go through the migration wizard to migrate the solution and project files to Visual Studio 2008. Select `Configuration Manager...` from the `Build` menu. Select `<New...>` from the `Active solution platform` dropdown.  Select `x64` from the new platform dropdown, leave `Copy settings from` set to `Win32` and `Create new project platforms` checked, then click `OK`. You now have `Win32` and `x64` platform configurations, selectable from the `Standard` toolbar, which allow you to toggle between building 32-bit or 64-bit binaries (or both at once using Batch Build).
In order to prevent build output files from overwriting one another, you'll need to change the `Intermediate Directory` settings for the newly created platform configuration across all the projects. To do this, multi-select (e.g. using shift-click) all projects (but not the solution) in the `Solution Explorer`. Right-click one of them and select `Properties`. In the left pane, select `Configuration Properties`, and from the `Configuration` dropdown, select `All Configurations`. Make sure the selected platform is `x64`. For the `Intermediate Directory` setting, change the value from `$(PlatformName)\$(ConfigurationName)` to `$(OutDir)\$(ProjectName)`. Click `OK` and then build the solution. When the build is complete, the 64-bit binaries will be in the `msvc\x64\Debug` directory.
We haven't tested this ourselves, but Per Abrahamsen reported that he was able to compile and install Google Test successfully when using MinGW from Cygwin.  You'll need to configure it with:
`PATH/TO/configure CC="gcc -mno-cygwin" CXX="g++ -mno-cygwin"`
You should be able to replace the `-mno-cygwin` option with direct links to the real MinGW binaries, but we haven't tried that.
Caveats:
* There are many warnings when compiling.   * `make check` will produce some errors as not all tests for Google Test itself are compatible with MinGW.
We also have reports on successful cross compilation of Google Test MinGW binaries on Linux using [these instructions](http://wiki.wxwidgets.org/Cross-Compiling_Under_Linux#Cross-compiling_under_Linux_for_MS_Windows) on the WxWidgets site.
Please contact `googletestframework@googlegroups.com` if you are interested in improving the support for MinGW.
Due to some peculiarity of C++, it requires some non-trivial template meta programming tricks to support using `NULL` as an argument of the `EXPECT_XX()` and `ASSERT_XX()` macros. Therefore we only do it where it's most needed (otherwise we make the implementation of Google Test harder to maintain and more error-prone than necessary).
The `EXPECT_EQ()` macro takes the _expected_ value as its first argument and the _actual_ value as the second. It's reasonable that someone wants to write `EXPECT_EQ(NULL, some_expression)`, and this indeed was requested several times. Therefore we implemented it.
The need for `EXPECT_NE(NULL, ptr)` isn't nearly as strong. When the assertion fails, you already know that `ptr` must be `NULL`, so it doesn't add any information to print ptr in this case. That means `EXPECT_TRUE(ptr != NULL)` works just as well.
If we were to support `EXPECT_NE(NULL, ptr)`, for consistency we'll have to support `EXPECT_NE(ptr, NULL)` as well, as unlike `EXPECT_EQ`, we don't have a convention on the order of the two arguments for `EXPECT_NE`. This means using the template meta programming tricks twice in the implementation, making it even harder to understand and maintain. We believe the benefit doesn't justify the cost.
Finally, with the growth of Google Mock's [matcher](../../googlemock/docs/CookBook.md#using-matchers-in-google-test-assertions) library, we are encouraging people to use the unified `EXPECT_THAT(value, matcher)` syntax more often in tests. One significant advantage of the matcher approach is that matchers can be easily combined to form new matchers, while the `EXPECT_NE`, etc, macros cannot be easily combined. Therefore we want to invest more in the matchers than in the `EXPECT_XX()` macros.
Test runners tend to be tightly coupled with the build/test environment, and Google Test doesn't try to solve the problem of running tests in parallel.  Instead, we tried to make Google Test work nicely with test runners.  For example, Google Test's XML report contains the time spent on each test, and its `gtest_list_tests` and `gtest_filter` flags can be used for splitting the execution of test methods into multiple processes.  These functionalities can help the test runner run the tests in parallel.
It's difficult to write thread-safe code.  Most tests are not written with thread-safety in mind, and thus may not work correctly in a multi-threaded setting.
If you think about it, it's already hard to make your code work when you know what other threads are doing.  It's much harder, and sometimes even impossible, to make your code work when you don't know what other threads are doing (remember that test methods can be added, deleted, or modified after your test was written).  If you want to run the tests in parallel, you'd better run them in different processes.
Our original motivation was to be able to use Google Test in projects that disable exceptions.  Later we realized some additional benefits of this approach:
1. Throwing in a destructor is undefined behavior in C++.  Not using exceptions means Google Test's assertions are safe to use in destructors.   1. The `EXPECT_*` family of macros will continue even after a failure, allowing multiple failures in a `TEST` to be reported in a single run. This is a popular feature, as in C++ the edit-compile-test cycle is usually quite long and being able to fixing more than one thing at a time is a blessing.   1. If assertions are implemented using exceptions, a test may falsely ignore a failure if it's caught by user code: ``` cpp try { ... ASSERT_TRUE(...) ... } catch (...) { ... } ``` The above code will pass even if the `ASSERT_TRUE` throws.  While it's unlikely for someone to write this in a test, it's possible to run into this pattern when you write assertions in callbacks that are called by the code under test.
The downside of not using exceptions is that `ASSERT_*` (implemented using `return`) will only abort the current function, not the current `TEST`.
Unfortunately, C++'s macro system doesn't allow us to use the same macro for both cases.  One possibility is to provide only one macro for tests with fixtures, and require the user to define an empty fixture sometimes:
``` cpp class FooTest : public ::testing::Test {};
TEST_F(FooTest, DoesThis) { ... } ``` or ``` cpp typedef ::testing::Test FooTest;
TEST_F(FooTest, DoesThat) { ... } ```
Yet, many people think this is one line too many. :-) Our goal was to make it really easy to write tests, so we tried to make simple tests trivial to create.  That means using a separate macro for such tests.
We think neither approach is ideal, yet either of them is reasonable. In the end, it probably doesn't matter much either way.
We like to use structs only when representing passive data.  This distinction between structs and classes is good for documenting the intent of the code's author.  Since test fixtures have logic like `SetUp()` and `TearDown()`, they are better defined as classes.
Our goal was to make death tests as convenient for a user as C++ possibly allows.  In particular:
* The runner-style requires to split the information into two pieces: the definition of the death test itself, and the specification for the runner on how to run the death test and what to expect.  The death test would be written in C++, while the runner spec may or may not be.  A user needs to carefully keep the two in sync. `ASSERT_DEATH(statement, expected_message)` specifies all necessary information in one place, in one language, without boilerplate code. It is very declarative.   * `ASSERT_DEATH` has a similar syntax and error-reporting semantics as other Google Test assertions, and thus is easy to learn.   * `ASSERT_DEATH` can be mixed with other assertions and other logic at your will.  You are not limited to one death test per test method. For example, you can write something like: ``` cpp     if (FooCondition()) {       ASSERT_DEATH(Bar(), "blah");     } else {       ASSERT_EQ(5, Bar());     } ``` If you prefer one death test per test method, you can write your tests in that style too, but we don't want to impose that on the users.  The fewer artificial limitations the better.   * `ASSERT_DEATH` can reference local variables in the current function, and you can decide how many death tests you want based on run-time information.  For example, ``` cpp     const int count = GetCount();  // Only known at run time.     for (int i = 1; i <= count; i++) {       ASSERT_DEATH({         double* buffer = new double[i];         ... initializes buffer ...         Foo(buffer, i)       }, "blah blah");     } ``` The runner-based approach tends to be more static and less flexible, or requires more user effort to get this kind of flexibility.
Another interesting thing about `ASSERT_DEATH` is that it calls `fork()` to create a child process to run the death test.  This is lightening fast, as `fork()` uses copy-on-write pages and incurs almost zero overhead, and the child process starts from the user-supplied statement directly, skipping all global and local initialization and any code leading to the given statement.  If you launch the child process from scratch, it can take seconds just to load everything and start running if the test links to many libraries dynamically.
Death tests (`EXPECT_DEATH`, etc) are executed in a sub-process s.t. the expected crash won't kill the test program (i.e. the parent process). As a result, any in-memory side effects they incur are observable in their respective sub-processes, but not in the parent process. You can think of them as running in a parallel universe, more or less.
If your class has a static data member:
``` cpp // foo.h class Foo {   ...   static const int kBar = 100; }; ```
You also need to define it _outside_ of the class body in `foo.cc`:
``` cpp const int Foo::kBar;  // No initializer here. ```
Otherwise your code is **invalid C++**, and may break in unexpected ways. In particular, using it in Google Test comparison assertions (`EXPECT_EQ`, etc) will generate an "undefined reference" linker error.
Google Test doesn't yet have good support for this kind of tests, or data-driven tests in general. We hope to be able to make improvements in this area soon.
Yes.
Each test fixture has a corresponding and same named test case. This means only one test case can use a particular fixture. Sometimes, however, multiple test cases may want to use the same or slightly different fixtures. For example, you may want to make sure that all of a GUI library's test cases don't leak important system resources like fonts and brushes.
In Google Test, you share a fixture among test cases by putting the shared logic in a base test fixture, then deriving from that base a separate fixture for each test case that wants to use this common logic. You then use `TEST_F()` to write tests using each derived fixture.
Typically, your code looks like this:
``` cpp // Defines a base test fixture. class BaseTest : public ::testing::Test {   protected:    ... };
// Derives a fixture FooTest from BaseTest. class FooTest : public BaseTest {   protected:     virtual void SetUp() {       BaseTest::SetUp();  // Sets up the base fixture first.       ... additional set-up work ...     }     virtual void TearDown() {       ... clean-up work for FooTest ...       BaseTest::TearDown();  // Remember to tear down the base fixture                              // after cleaning up FooTest!     }     ... functions and variables for FooTest ... };
// Tests that use the fixture FooTest. TEST_F(FooTest, Bar) { ... } TEST_F(FooTest, Baz) { ... }
... additional fixtures derived from BaseTest ... ```
If necessary, you can continue to derive test fixtures from a derived fixture. Google Test has no limit on how deep the hierarchy can be.
For a complete example using derived test fixtures, see [sample5](../samples/sample5_unittest.cc).
You're probably using an `ASSERT_*()` in a function that doesn't return `void`. `ASSERT_*()` can only be used in `void` functions.
In Google Test, death tests are run in a child process and the way they work is delicate. To write death tests you really need to understand how they work. Please make sure you have read this.
In particular, death tests don't like having multiple threads in the parent process. So the first thing you can try is to eliminate creating threads outside of `EXPECT_DEATH()`.
Sometimes this is impossible as some library you must use may be creating threads before `main()` is even reached. In this case, you can try to minimize the chance of conflicts by either moving as many activities as possible inside `EXPECT_DEATH()` (in the extreme case, you want to move everything inside), or leaving as few things as possible in it. Also, you can try to set the death test style to `"threadsafe"`, which is safer but slower, and see if it helps.
If you go with thread-safe death tests, remember that they rerun the test program from the beginning in the child process. Therefore make sure your program can run side-by-side with itself and is deterministic.
In the end, this boils down to good concurrent programming. You have to make sure that there is no race conditions or dead locks in your program. No silver bullet - sorry!
The first thing to remember is that Google Test does not reuse the same test fixture object across multiple tests. For each `TEST_F`, Google Test will create a fresh test fixture object, _immediately_ call `SetUp()`, run the test body, call `TearDown()`, and then _immediately_ delete the test fixture object.
When you need to write per-test set-up and tear-down logic, you have the choice between using the test fixture constructor/destructor or `SetUp()/TearDown()`. The former is usually preferred, as it has the following benefits:
* By initializing a member variable in the constructor, we have the option to make it `const`, which helps prevent accidental changes to its value and makes the tests more obviously correct.   * In case we need to subclass the test fixture class, the subclass' constructor is guaranteed to call the base class' constructor first, and the subclass' destructor is guaranteed to call the base class' destructor afterward. With `SetUp()/TearDown()`, a subclass may make the mistake of forgetting to call the base class' `SetUp()/TearDown()` or call them at the wrong moment.
You may still want to use `SetUp()/TearDown()` in the following rare cases:   * If the tear-down operation could throw an exception, you must use `TearDown()` as opposed to the destructor, as throwing in a destructor leads to undefined behavior and usually will kill your program right away. Note that many standard libraries (like STL) may throw when exceptions are enabled in the compiler. Therefore you should prefer `TearDown()` if you want to write portable tests that work with or without exceptions.   * The assertion macros throw an exception when flag `--gtest_throw_on_failure` is specified. Therefore, you shouldn't use Google Test assertions in a destructor if you plan to run your tests with this flag.   * In a constructor or destructor, you cannot make a virtual function call on this object. (You can call a method declared as virtual, but it will be statically bound.) Therefore, if you need to call a method that will be overriden in a derived class, you have to use `SetUp()/TearDown()`.
If the predicate function you use in `ASSERT_PRED*` or `EXPECT_PRED*` is overloaded or a template, the compiler will have trouble figuring out which overloaded version it should use. `ASSERT_PRED_FORMAT*` and `EXPECT_PRED_FORMAT*` don't have this problem.
If you see this error, you might want to switch to `(ASSERT|EXPECT)_PRED_FORMAT*`, which will also give you a better failure message. If, however, that is not an option, you can resolve the problem by explicitly telling the compiler which version to pick.
For example, suppose you have
``` cpp bool IsPositive(int n) {   return n > 0; } bool IsPositive(double x) {   return x > 0; } ```
you will get a compiler error if you write
``` cpp EXPECT_PRED1(IsPositive, 5); ```
However, this will work:
``` cpp EXPECT_PRED1(*static_cast<bool (*)(int)>*(IsPositive), 5); ```
(The stuff inside the angled brackets for the `static_cast` operator is the type of the function pointer for the `int`-version of `IsPositive()`.)
As another example, when you have a template function
``` cpp template <typename T> bool IsNegative(T x) {   return x < 0; } ```
you can use it in a predicate assertion like this:
``` cpp ASSERT_PRED1(IsNegative*<int>*, -5); ```
Things are more interesting if your template has more than one parameters. The following won't compile:
``` cpp ASSERT_PRED2(*GreaterThan<int, int>*, 5, 0); ```
as the C++ pre-processor thinks you are giving `ASSERT_PRED2` 4 arguments, which is one more than expected. The workaround is to wrap the predicate function in parentheses:
``` cpp ASSERT_PRED2(*(GreaterThan<int, int>)*, 5, 0); ```
Some people had been ignoring the return value of `RUN_ALL_TESTS()`. That is, instead of
``` cpp return RUN_ALL_TESTS(); ```
they write
``` cpp RUN_ALL_TESTS(); ```
This is wrong and dangerous. A test runner needs to see the return value of `RUN_ALL_TESTS()` in order to determine if a test has passed. If your `main()` function ignores it, your test will be considered successful even if it has a Google Test assertion failure. Very bad.
To help the users avoid this dangerous bug, the implementation of `RUN_ALL_TESTS()` causes gcc to raise this warning, when the return value is ignored. If you see this warning, the fix is simple: just make sure its value is used as the return value of `main()`.
Due to a peculiarity of C++, in order to support the syntax for streaming messages to an `ASSERT_*`, e.g.
``` cpp ASSERT_EQ(1, Foo()) << "blah blah" << foo; ```
we had to give up using `ASSERT*` and `FAIL*` (but not `EXPECT*` and `ADD_FAILURE*`) in constructors and destructors. The workaround is to move the content of your constructor/destructor to a private void member function, or switch to `EXPECT_*()` if that works. This section in the user's guide explains it.
C++ is case-sensitive. It should be spelled as `SetUp()`.  Did you spell it as `Setup()`?
Similarly, sometimes people spell `SetUpTestCase()` as `SetupTestCase()` and wonder why it's never called.
Google Test's failure message format is understood by Emacs and many other IDEs, like acme and XCode. If a Google Test message is in a compilation buffer in Emacs, then it's clickable. You can now hit `enter` on a message to jump to the corresponding source code, or use `C-x `` to jump to the next failure.
You don't have to. Instead of
``` cpp class FooTest : public BaseTest {};
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
class BarTest : public BaseTest {};
TEST_F(BarTest, Abc) { ... } TEST_F(BarTest, Def) { ... } ```
you can simply `typedef` the test fixtures: ``` cpp typedef BaseTest FooTest;
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
typedef BaseTest BarTest;
TEST_F(BarTest, Abc) { ... } TEST_F(BarTest, Def) { ... } ```
The Google Test output is meant to be a concise and human-friendly report. If your test generates textual output itself, it will mix with the Google Test output, making it hard to read. However, there is an easy solution to this problem.
Since most log messages go to stderr, we decided to let Google Test output go to stdout. This way, you can easily separate the two using redirection. For example: ``` ./my_test > googletest_output.txt ```
There are several good reasons:   1. It's likely your test needs to change the states of its global variables. This makes it difficult to keep side effects from escaping one test and contaminating others, making debugging difficult. By using fixtures, each test has a fresh set of variables that's different (but with the same names). Thus, tests are kept independent of each other.   1. Global variables pollute the global namespace.   1. Test fixtures can be reused via subclassing, which cannot be done easily with global variables. This is useful if many test cases have something in common.
You should try to write testable code, which means classes should be easily tested from their public interface. One way to achieve this is the Pimpl idiom: you move all private members of a class into a helper class, and make all members of the helper class public.
You have several other options that don't require using `FRIEND_TEST`:   * Write the tests as members of the fixture class: ``` cpp class Foo {   friend class FooTest;   ... };
class FooTest : public ::testing::Test {  protected:   ...   void Test1() {...} // This accesses private members of class Foo.   void Test2() {...} // So does this one. };
TEST_F(FooTest, Test1) {   Test1(); }
TEST_F(FooTest, Test2) {   Test2(); } ```   * In the fixture class, write accessors for the tested class' private members, then use the accessors in your tests: ``` cpp class Foo {   friend class FooTest;   ... };
class FooTest : public ::testing::Test {  protected:   ...   T1 get_private_member1(Foo* obj) {     return obj->private_member1_;   } };
TEST_F(FooTest, Test1) {   ...   get_private_member1(x)   ... } ```   * If the methods are declared **protected**, you can change their access level in a test-only subclass: ``` cpp class YourClass {   ...  protected: // protected access for testability.   int DoSomethingReturningInt();   ... };
// in the your_class_test.cc file: class TestableYourClass : public YourClass {   ...  public: using YourClass::DoSomethingReturningInt; // changes access rights   ... };
TEST_F(YourClassTest, DoSomethingTest) {   TestableYourClass obj;   assertEquals(expected_value, obj.DoSomethingReturningInt()); } ```
We find private static methods clutter the header file.  They are implementation details and ideally should be kept out of a .h. So often I make them free functions instead.
Instead of: ``` cpp // foo.h class Foo {   ...  private:   static bool Func(int n); };
// foo.cc bool Foo::Func(int n) { ... }
// foo_test.cc EXPECT_TRUE(Foo::Func(12345)); ```
You probably should better write: ``` cpp // foo.h class Foo {   ... };
// foo.cc namespace internal {   bool Func(int n) { ... } }
// foo_test.cc namespace internal {   bool Func(int n); }
EXPECT_TRUE(internal::Func(12345)); ```
No. You can use a feature called [value-parameterized tests](AdvancedGuide.md#Value_Parameterized_Tests) which lets you repeat your tests with different parameters, without defining it more than once.
To test a `foo.cc` file, you need to compile and link it into your unit test program. However, when the file contains a definition for the `main()` function, it will clash with the `main()` of your unit test, and will result in a build error.
The right solution is to split it into three files:   1. `foo.h` which contains the declarations,   1. `foo.cc` which contains the definitions except `main()`, and   1. `foo_main.cc` which contains nothing but the definition of `main()`.
Then `foo.cc` can be easily tested.
If you are adding tests to an existing file and don't want an intrusive change like this, there is a hack: just include the entire `foo.cc` file in your unit test. For example: ``` cpp // File foo_unittest.cc
// The headers section ...
// Renames main() in foo.cc to make room for the unit test main() #define main FooMain
#include "a/b/foo.cc"
// The tests start here. ... ```
However, please remember this is a hack and should only be used as the last resort.
`ASSERT_DEATH(_statement_, _regex_)` (or any death assertion macro) can be used wherever `_statement_` is valid. So basically `_statement_` can be any C++ statement that makes sense in the current context. In particular, it can reference global and/or local variables, and can be:   * a simple function call (often the case),   * a complex expression, or   * a compound statement.
Some examples are shown here:
``` cpp // A death test can be a simple function call. TEST(MyDeathTest, FunctionCall) {   ASSERT_DEATH(Xyz(5), "Xyz failed"); }
// Or a complex expression that references variables and functions. TEST(MyDeathTest, ComplexExpression) {   const bool c = Condition();   ASSERT_DEATH((c ? Func1(0) : object2.Method("test")),                "(Func1|Method) failed"); }
// Death assertions can be used any where in a function. In // particular, they can be inside a loop. TEST(MyDeathTest, InsideLoop) {   // Verifies that Foo(0), Foo(1), ..., and Foo(4) all die.   for (int i = 0; i < 5; i++) {     EXPECT_DEATH_M(Foo(i), "Foo has \\d+ errors",                    ::testing::Message() << "where i is " << i);   } }
// A death assertion can contain a compound statement. TEST(MyDeathTest, CompoundStatement) {   // Verifies that at lease one of Bar(0), Bar(1), ..., and   // Bar(4) dies.   ASSERT_DEATH({     for (int i = 0; i < 5; i++) {       Bar(i);     }   },   "Bar has \\d+ errors");} ```
`googletest_unittest.cc` contains more examples if you are interested.
On POSIX systems, Google Test uses the POSIX Extended regular expression syntax (http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions). On Windows, it uses a limited variant of regular expression syntax. For more details, see the [regular expression syntax](AdvancedGuide.md#Regular_Expression_Syntax).
Google Test needs to be able to create objects of your test fixture class, so it must have a default constructor. Normally the compiler will define one for you. However, there are cases where you have to define your own:   * If you explicitly declare a non-default constructor for class `Foo`, then you need to define a default constructor, even if it would be empty.   * If `Foo` has a const non-static data member, then you have to define the default constructor _and_ initialize the const member in the initializer list of the constructor. (Early versions of `gcc` doesn't force you to initialize the const member. It's a bug that has been fixed in `gcc 4`.)
With the Linux pthread library, there is no turning back once you cross the line from single thread to multiple threads. The first time you create a thread, a manager thread is created in addition, so you get 3, not 2, threads. Later when the thread you create joins the main thread, the thread count decrements by 1, but the manager thread will never be killed, so you still have 2 threads, which means you cannot safely run a death test.
The new NPTL thread library doesn't suffer from this problem, as it doesn't create a manager thread. However, if you don't control which machine your test runs on, you shouldn't depend on this.
Google Test does not interleave tests from different test cases. That is, it runs all tests in one test case first, and then runs all tests in the next test case, and so on. Google Test does this because it needs to set up a test case before the first test in it is run, and tear it down afterwords. Splitting up the test case would require multiple set-up and tear-down processes, which is inefficient and makes the semantics unclean.
If we were to determine the order of tests based on test name instead of test case name, then we would have a problem with the following situation:
``` cpp TEST_F(FooTest, AbcDeathTest) { ... } TEST_F(FooTest, Uvw) { ... }
TEST_F(BarTest, DefDeathTest) { ... } TEST_F(BarTest, Xyz) { ... } ```
Since `FooTest.AbcDeathTest` needs to run before `BarTest.Xyz`, and we don't interleave tests from different test cases, we need to run all tests in the `FooTest` case before running any test in the `BarTest` case. This contradicts with the requirement to run `BarTest.DefDeathTest` before `FooTest.Uvw`.
You don't have to, but if you like, you may split up the test case into `FooTest` and `FooDeathTest`, where the names make it clear that they are related:
``` cpp class FooTest : public ::testing::Test { ... };
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
typedef FooTest FooDeathTest;
TEST_F(FooDeathTest, Uvw) { ... EXPECT_DEATH(...) ... } TEST_F(FooDeathTest, Xyz) { ... ASSERT_DEATH(...) ... } ```
If you use a user-defined type `FooType` in an assertion, you must make sure there is an `std::ostream& operator<<(std::ostream&, const FooType&)` function defined such that we can print a value of `FooType`.
In addition, if `FooType` is declared in a name space, the `<<` operator also needs to be defined in the _same_ name space.
Since the statically initialized Google Test singleton requires allocations on the heap, the Visual C++ memory leak detector will report memory leaks at the end of the program run. The easiest way to avoid this is to use the `_CrtMemCheckpoint` and `_CrtMemDumpAllObjectsSince` calls to not report any statically initialized heap objects. See MSDN for more details and additional heap check/debug routines.
You may get a number of the following linker error or warnings if you attempt to link your test project with the Google Test library when your project and the are not built using the same compiler settings.
* LNK2005: symbol already defined in object   * LNK4217: locally defined symbol 'symbol' imported in function 'function'   * LNK4049: locally defined symbol 'symbol' imported
The Google Test project (gtest.vcproj) has the Runtime Library option set to /MT (use multi-threaded static libraries, /MTd for debug). If your project uses something else, for example /MD (use multi-threaded DLLs, /MDd for debug), you need to change the setting in the Google Test project to match your project's.
To update this setting open the project properties in the Visual Studio IDE then select the branch Configuration Properties | C/C++ | Code Generation and change the option "Runtime Library".  You may also try using gtest-md.vcproj instead of gtest.vcproj.
`export CC=cc CXX=CC CXXFLAGS='-library=stlport4'`
If you write code that sniffs whether it's running in a test and does different things accordingly, you are leaking test-only logic into production code and there is no easy way to ensure that the test-only code paths aren't run by mistake in production.  Such cleverness also leads to [Heisenbugs](http://en.wikipedia.org/wiki/Unusual_software_bug#Heisenbug). Therefore we strongly advise against the practice, and Google Test doesn't provide a way to do it.
In general, the recommended way to cause the code to behave differently under test is [dependency injection](http://jamesshore.com/Blog/Dependency-Injection-Demystified.html). You can inject different functionality from the test and from the production code.  Since your production code doesn't link in the for-test logic at all, there is no danger in accidentally running it.
However, if you _really_, _really_, _really_ have no choice, and if you follow the rule of ending your test program names with `_test`, you can use the _horrible_ hack of sniffing your executable name (`argv[0]` in `main()`) to know whether the code is under test.
In C++, macros don't obey namespaces.  Therefore two libraries that both define a macro of the same name will clash if you `#include` both definitions.  In case a Google Test macro clashes with another library, you can force Google Test to rename its macro to avoid the conflict.
Specifically, if both Google Test and some other code define macro `FOO`, you can add ```   -DGTEST_DONT_DEFINE_FOO=1 ``` to the compiler flags to tell Google Test to change the macro's name from `FOO` to `GTEST_FOO`. For example, with `-DGTEST_DONT_DEFINE_TEST=1`, you'll need to write ``` cpp   GTEST_TEST(SomeTest, DoesThis) { ... } ``` instead of ``` cpp   TEST(SomeTest, DoesThis) { ... } ``` in order to define a test.
Currently, the following `TEST`, `FAIL`, `SUCCEED`, and the basic comparison assertion macros can have alternative names. You can see the full list of covered macros [here](http://www.google.com/codesearch?q=if+!GTEST_DONT_DEFINE_\w%2B+package:http://googletest\.googlecode\.com+file:/include/gtest/gtest.h). More information can be found in the "Avoiding Macro Name Clashes" section of the README file.
Yes.
The rule is **all test methods in the same test case must use the same fixture class**. This means that the following is **allowed** because both tests use the same fixture class (`::testing::Test`).
``` cpp namespace foo { TEST(CoolTest, DoSomething) {   SUCCEED(); } }  // namespace foo
namespace bar { TEST(CoolTest, DoSomething) {   SUCCEED(); } }  // namespace foo ```
However, the following code is **not allowed** and will produce a runtime error from Google Test because the test methods are using different test fixture classes with the same test case name.
``` cpp namespace foo { class CoolTest : public ::testing::Test {};  // Fixture foo::CoolTest TEST_F(CoolTest, DoSomething) {   SUCCEED(); } }  // namespace foo
namespace bar { class CoolTest : public ::testing::Test {};  // Fixture: bar::CoolTest TEST_F(CoolTest, DoSomething) {   SUCCEED(); } }  // namespace foo ```
If you try to build Google Test's Xcode project with Xcode 4.0 or later, you may encounter an error message that looks like "Missing SDK in target gtest\_framework: /Developer/SDKs/MacOSX10.4u.sdk". That means that Xcode does not support the SDK the project is targeting. See the Xcode section in the [README](../README.md) file on how to resolve this.
If you cannot find the answer to your question in this FAQ, there are some other resources you can use:
1. read other [wiki pages](../docs),   1. search the mailing list [archive](https://groups.google.com/forum/#!forum/googletestframework),   1. ask it on [googletestframework@googlegroups.com](mailto:googletestframework@googlegroups.com) and someone will answer it (to prevent spam, we require you to join the [discussion group](http://groups.google.com/group/googletestframework) before you can post.).
Please note that creating an issue in the [issue tracker](https://github.com/google/googletest/issues) is _not_ a good way to get your answer, as it is monitored infrequently by a very small number of people.
When asking a question, it's helpful to provide as much of the following information as possible (people cannot help you if there's not enough information in your question):
* the version (or the commit hash if you check out from Git directly) of Google Test you use (Google Test is under active development, so it's possible that your problem has been solved in a later version),   * your operating system,   * the name and version of your compiler,   * the complete command line flags you give to your compiler,   * the complete compiler error messages (if the question is about compilation),   * the _actual_ code (ideally, a minimal but complete program) that has the problem you encounter.

_Google C++ Testing Framework_ helps you write better C++ tests.
No matter whether you work on Linux, Windows, or a Mac, if you write C++ code, Google Test can help you.
So what makes a good test, and how does Google C++ Testing Framework fit in? We believe:   1. Tests should be _independent_ and _repeatable_. It's a pain to debug a test that succeeds or fails as a result of other tests.  Google C++ Testing Framework isolates the tests by running each of them on a different object. When a test fails, Google C++ Testing Framework allows you to run it in isolation for quick debugging.   1. Tests should be well _organized_ and reflect the structure of the tested code.  Google C++ Testing Framework groups related tests into test cases that can share data and subroutines. This common pattern is easy to recognize and makes tests easy to maintain. Such consistency is especially helpful when people switch projects and start to work on a new code base.   1. Tests should be _portable_ and _reusable_. The open-source community has a lot of code that is platform-neutral, its tests should also be platform-neutral.  Google C++ Testing Framework works on different OSes, with different compilers (gcc, MSVC, and others), with or without exceptions, so Google C++ Testing Framework tests can easily work with a variety of configurations.  (Note that the current release only contains build scripts for Linux - we are actively working on scripts for other platforms.)   1. When tests fail, they should provide as much _information_ about the problem as possible. Google C++ Testing Framework doesn't stop at the first test failure. Instead, it only stops the current test and continues with the next. You can also set up tests that report non-fatal failures after which the current test continues. Thus, you can detect and fix multiple bugs in a single run-edit-compile cycle.   1. The testing framework should liberate test writers from housekeeping chores and let them focus on the test _content_.  Google C++ Testing Framework automatically keeps track of all tests defined, and doesn't require the user to enumerate them in order to run them.   1. Tests should be _fast_. With Google C++ Testing Framework, you can reuse shared resources across tests and pay for the set-up/tear-down only once, without making tests depend on each other.
Since Google C++ Testing Framework is based on the popular xUnit architecture, you'll feel right at home if you've used JUnit or PyUnit before. If not, it will take you about 10 minutes to learn the basics and get started. So let's go!
_Note:_ We sometimes refer to Google C++ Testing Framework informally as _Google Test_.
To write a test program using Google Test, you need to compile Google Test into a library and link your test with it.  We provide build files for some popular build systems: `msvc/` for Visual Studio, `xcode/` for Mac Xcode, `make/` for GNU make, `codegear/` for Borland C++ Builder, and the autotools script (deprecated) and `CMakeLists.txt` for CMake (recommended) in the Google Test root directory.  If your build system is not on this list, you can take a look at `make/Makefile` to learn how Google Test should be compiled (basically you want to compile `src/gtest-all.cc` with `GTEST_ROOT` and `GTEST_ROOT/include` in the header search path, where `GTEST_ROOT` is the Google Test root directory).
Once you are able to compile the Google Test library, you should create a project or build target for your test program.  Make sure you have `GTEST_ROOT/include` in the header search path so that the compiler can find `"gtest/gtest.h"` when compiling your test.  Set up your test project to link with the Google Test library (for example, in Visual Studio, this is done by adding a dependency on `gtest.vcproj`).
If you still have questions, take a look at how Google Test's own tests are built and use them as examples.
When using Google Test, you start by writing _assertions_, which are statements that check whether a condition is true. An assertion's result can be _success_, _nonfatal failure_, or _fatal failure_. If a fatal failure occurs, it aborts the current function; otherwise the program continues normally.
_Tests_ use assertions to verify the tested code's behavior. If a test crashes or has a failed assertion, then it _fails_; otherwise it _succeeds_.
A _test case_ contains one or many tests. You should group your tests into test cases that reflect the structure of the tested code. When multiple tests in a test case need to share common objects and subroutines, you can put them into a _test fixture_ class.
A _test program_ can contain multiple test cases.
We'll now explain how to write a test program, starting at the individual assertion level and building up to tests and test cases.
Google Test assertions are macros that resemble function calls. You test a class or function by making assertions about its behavior. When an assertion fails, Google Test prints the assertion's source file and line number location, along with a failure message. You may also supply a custom failure message which will be appended to Google Test's message.
The assertions come in pairs that test the same thing but have different effects on the current function. `ASSERT_*` versions generate fatal failures when they fail, and **abort the current function**. `EXPECT_*` versions generate nonfatal failures, which don't abort the current function. Usually `EXPECT_*` are preferred, as they allow more than one failures to be reported in a test. However, you should use `ASSERT_*` if it doesn't make sense to continue when the assertion in question fails.
Since a failed `ASSERT_*` returns from the current function immediately, possibly skipping clean-up code that comes after it, it may cause a space leak. Depending on the nature of the leak, it may or may not be worth fixing - so keep this in mind if you get a heap checker error in addition to assertion errors.
To provide a custom failure message, simply stream it into the macro using the `<<` operator, or a sequence of such operators. An example: ``` ASSERT_EQ(x.size(), y.size()) << "Vectors x and y are of unequal length";
for (int i = 0; i < x.size(); ++i) {   EXPECT_EQ(x[i], y[i]) << "Vectors x and y differ at index " << i; } ```
Anything that can be streamed to an `ostream` can be streamed to an assertion macro--in particular, C strings and `string` objects. If a wide string (`wchar_t*`, `TCHAR*` in `UNICODE` mode on Windows, or `std::wstring`) is streamed to an assertion, it will be translated to UTF-8 when printed.
These assertions do basic true/false condition testing.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_TRUE(`_condition_`)`;  | `EXPECT_TRUE(`_condition_`)`;   | _condition_ is true | | `ASSERT_FALSE(`_condition_`)`; | `EXPECT_FALSE(`_condition_`)`;  | _condition_ is false |
Remember, when they fail, `ASSERT_*` yields a fatal failure and returns from the current function, while `EXPECT_*` yields a nonfatal failure, allowing the function to continue running. In either case, an assertion failure means its containing test fails.
_Availability_: Linux, Windows, Mac.
This section describes assertions that compare two values.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| |`ASSERT_EQ(`_val1_`, `_val2_`);`|`EXPECT_EQ(`_val1_`, `_val2_`);`| _val1_ `==` _val2_ | |`ASSERT_NE(`_val1_`, `_val2_`);`|`EXPECT_NE(`_val1_`, `_val2_`);`| _val1_ `!=` _val2_ | |`ASSERT_LT(`_val1_`, `_val2_`);`|`EXPECT_LT(`_val1_`, `_val2_`);`| _val1_ `<` _val2_ | |`ASSERT_LE(`_val1_`, `_val2_`);`|`EXPECT_LE(`_val1_`, `_val2_`);`| _val1_ `<=` _val2_ | |`ASSERT_GT(`_val1_`, `_val2_`);`|`EXPECT_GT(`_val1_`, `_val2_`);`| _val1_ `>` _val2_ | |`ASSERT_GE(`_val1_`, `_val2_`);`|`EXPECT_GE(`_val1_`, `_val2_`);`| _val1_ `>=` _val2_ |
In the event of a failure, Google Test prints both _val1_ and _val2_.
Value arguments must be comparable by the assertion's comparison operator or you'll get a compiler error.  We used to require the arguments to support the `<<` operator for streaming to an `ostream`, but it's no longer necessary since v1.6.0 (if `<<` is supported, it will be called to print the arguments when the assertion fails; otherwise Google Test will attempt to print them in the best way it can. For more details and how to customize the printing of the arguments, see this Google Mock [recipe](../../googlemock/docs/CookBook.md#teaching-google-mock-how-to-print-your-values).).
These assertions can work with a user-defined type, but only if you define the corresponding comparison operator (e.g. `==`, `<`, etc).  If the corresponding operator is defined, prefer using the `ASSERT_*()` macros because they will print out not only the result of the comparison, but the two operands as well.
Arguments are always evaluated exactly once. Therefore, it's OK for the arguments to have side effects. However, as with any ordinary C/C++ function, the arguments' evaluation order is undefined (i.e. the compiler is free to choose any order) and your code should not depend on any particular argument evaluation order.
`ASSERT_EQ()` does pointer equality on pointers. If used on two C strings, it tests if they are in the same memory location, not if they have the same value. Therefore, if you want to compare C strings (e.g. `const char*`) by value, use `ASSERT_STREQ()` , which will be described later on. In particular, to assert that a C string is `NULL`, use `ASSERT_STREQ(NULL, c_string)` . However, to compare two `string` objects, you should use `ASSERT_EQ`.
Macros in this section work with both narrow and wide string objects (`string` and `wstring`).
_Availability_: Linux, Windows, Mac.
_Historical note_: Before February 2016 `*_EQ` had a convention of calling it as `ASSERT_EQ(expected, actual)`, so lots of existing code uses this order. Now `*_EQ` treats both parameters in the same way.
The assertions in this group compare two **C strings**. If you want to compare two `string` objects, use `EXPECT_EQ`, `EXPECT_NE`, and etc instead.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_STREQ(`_str1_`, `_str2_`);`    | `EXPECT_STREQ(`_str1_`, `_str_2`);`     | the two C strings have the same content | | `ASSERT_STRNE(`_str1_`, `_str2_`);`    | `EXPECT_STRNE(`_str1_`, `_str2_`);`     | the two C strings have different content | | `ASSERT_STRCASEEQ(`_str1_`, `_str2_`);`| `EXPECT_STRCASEEQ(`_str1_`, `_str2_`);` | the two C strings have the same content, ignoring case | | `ASSERT_STRCASENE(`_str1_`, `_str2_`);`| `EXPECT_STRCASENE(`_str1_`, `_str2_`);` | the two C strings have different content, ignoring case |
Note that "CASE" in an assertion name means that case is ignored.
`*STREQ*` and `*STRNE*` also accept wide C strings (`wchar_t*`). If a comparison of two wide strings fails, their values will be printed as UTF-8 narrow strings.
A `NULL` pointer and an empty string are considered _different_.
_Availability_: Linux, Windows, Mac.
See also: For more string comparison tricks (substring, prefix, suffix, and regular expression matching, for example), see the [Advanced Google Test Guide](AdvancedGuide.md).
To create a test:   1. Use the `TEST()` macro to define and name a test function, These are ordinary C++ functions that don't return a value.   1. In this function, along with any valid C++ statements you want to include, use the various Google Test assertions to check values.   1. The test's result is determined by the assertions; if any assertion in the test fails (either fatally or non-fatally), or if the test crashes, the entire test fails. Otherwise, it succeeds.
``` TEST(test_case_name, test_name) {  ... test body ... } ```
`TEST()` arguments go from general to specific. The _first_ argument is the name of the test case, and the _second_ argument is the test's name within the test case. Both names must be valid C++ identifiers, and they should not contain underscore (`_`). A test's _full name_ consists of its containing test case and its individual name. Tests from different test cases can have the same individual name.
For example, let's take a simple integer function: ``` int Factorial(int n); // Returns the factorial of n ```
A test case for this function might look like: ``` // Tests factorial of 0. TEST(FactorialTest, HandlesZeroInput) {   EXPECT_EQ(1, Factorial(0)); }
// Tests factorial of positive numbers. TEST(FactorialTest, HandlesPositiveInput) {   EXPECT_EQ(1, Factorial(1));   EXPECT_EQ(2, Factorial(2));   EXPECT_EQ(6, Factorial(3));   EXPECT_EQ(40320, Factorial(8)); } ```
Google Test groups the test results by test cases, so logically-related tests should be in the same test case; in other words, the first argument to their `TEST()` should be the same. In the above example, we have two tests, `HandlesZeroInput` and `HandlesPositiveInput`, that belong to the same test case `FactorialTest`.
_Availability_: Linux, Windows, Mac.
If you find yourself writing two or more tests that operate on similar data, you can use a _test fixture_. It allows you to reuse the same configuration of objects for several different tests.
To create a fixture, just:   1. Derive a class from `::testing::Test` . Start its body with `protected:` or `public:` as we'll want to access fixture members from sub-classes.   1. Inside the class, declare any objects you plan to use.   1. If necessary, write a default constructor or `SetUp()` function to prepare the objects for each test. A common mistake is to spell `SetUp()` as `Setup()` with a small `u` - don't let that happen to you.   1. If necessary, write a destructor or `TearDown()` function to release any resources you allocated in `SetUp()` . To learn when you should use the constructor/destructor and when you should use `SetUp()/TearDown()`, read this [FAQ entry](FAQ.md#should-i-use-the-constructordestructor-of-the-test-fixture-or-the-set-uptear-down-function).   1. If needed, define subroutines for your tests to share.
When using a fixture, use `TEST_F()` instead of `TEST()` as it allows you to access objects and subroutines in the test fixture: ``` TEST_F(test_case_name, test_name) {  ... test body ... } ```
Like `TEST()`, the first argument is the test case name, but for `TEST_F()` this must be the name of the test fixture class. You've probably guessed: `_F` is for fixture.
Unfortunately, the C++ macro system does not allow us to create a single macro that can handle both types of tests. Using the wrong macro causes a compiler error.
Also, you must first define a test fixture class before using it in a `TEST_F()`, or you'll get the compiler error "`virtual outside class declaration`".
For each test defined with `TEST_F()`, Google Test will:   1. Create a _fresh_ test fixture at runtime   1. Immediately initialize it via `SetUp()` ,   1. Run the test   1. Clean up by calling `TearDown()`   1. Delete the test fixture.  Note that different tests in the same test case have different test fixture objects, and Google Test always deletes a test fixture before it creates the next one. Google Test does not reuse the same test fixture for multiple tests. Any changes one test makes to the fixture do not affect other tests.
As an example, let's write tests for a FIFO queue class named `Queue`, which has the following interface: ``` template <typename E> // E is the element type. class Queue {  public:   Queue();   void Enqueue(const E& element);   E* Dequeue(); // Returns NULL if the queue is empty.   size_t size() const;   ... }; ```
First, define a fixture class. By convention, you should give it the name `FooTest` where `Foo` is the class being tested. ``` class QueueTest : public ::testing::Test {  protected:   virtual void SetUp() {     q1_.Enqueue(1);     q2_.Enqueue(2);     q2_.Enqueue(3);   }
// virtual void TearDown() {}
Queue<int> q0_;   Queue<int> q1_;   Queue<int> q2_; }; ```
In this case, `TearDown()` is not needed since we don't have to clean up after each test, other than what's already done by the destructor.
Now we'll write tests using `TEST_F()` and this fixture. ``` TEST_F(QueueTest, IsEmptyInitially) {   EXPECT_EQ(0, q0_.size()); }
TEST_F(QueueTest, DequeueWorks) {   int* n = q0_.Dequeue();   EXPECT_EQ(NULL, n);
n = q1_.Dequeue();   ASSERT_TRUE(n != NULL);   EXPECT_EQ(1, *n);   EXPECT_EQ(0, q1_.size());   delete n;
n = q2_.Dequeue();   ASSERT_TRUE(n != NULL);   EXPECT_EQ(2, *n);   EXPECT_EQ(1, q2_.size());   delete n; } ```
The above uses both `ASSERT_*` and `EXPECT_*` assertions. The rule of thumb is to use `EXPECT_*` when you want the test to continue to reveal more errors after the assertion failure, and use `ASSERT_*` when continuing after failure doesn't make sense. For example, the second assertion in the `Dequeue` test is `ASSERT_TRUE(n != NULL)`, as we need to dereference the pointer `n` later, which would lead to a segfault when `n` is `NULL`.
When these tests run, the following happens:   1. Google Test constructs a `QueueTest` object (let's call it `t1` ).   1. `t1.SetUp()` initializes `t1` .   1. The first test ( `IsEmptyInitially` ) runs on `t1` .   1. `t1.TearDown()` cleans up after the test finishes.   1. `t1` is destructed.   1. The above steps are repeated on another `QueueTest` object, this time running the `DequeueWorks` test.
_Availability_: Linux, Windows, Mac.
_Note_: Google Test automatically saves all _Google Test_ flags when a test object is constructed, and restores them when it is destructed.
`TEST()` and `TEST_F()` implicitly register their tests with Google Test. So, unlike with many other C++ testing frameworks, you don't have to re-list all your defined tests in order to run them.
After defining your tests, you can run them with `RUN_ALL_TESTS()` , which returns `0` if all the tests are successful, or `1` otherwise. Note that `RUN_ALL_TESTS()` runs _all tests_ in your link unit -- they can be from different test cases, or even different source files.
When invoked, the `RUN_ALL_TESTS()` macro:   1. Saves the state of all  Google Test flags.   1. Creates a test fixture object for the first test.   1. Initializes it via `SetUp()`.   1. Runs the test on the fixture object.   1. Cleans up the fixture via `TearDown()`.   1. Deletes the fixture.   1. Restores the state of all Google Test flags.   1. Repeats the above steps for the next test, until all tests have run.
In addition, if the text fixture's constructor generates a fatal failure in step 2, there is no point for step 3 - 5 and they are thus skipped. Similarly, if step 3 generates a fatal failure, step 4 will be skipped.
_Important_: You must not ignore the return value of `RUN_ALL_TESTS()`, or `gcc` will give you a compiler error. The rationale for this design is that the automated testing service determines whether a test has passed based on its exit code, not on its stdout/stderr output; thus your `main()` function must return the value of `RUN_ALL_TESTS()`.
Also, you should call `RUN_ALL_TESTS()` only **once**. Calling it more than once conflicts with some advanced Google Test features (e.g. thread-safe death tests) and thus is not supported.
_Availability_: Linux, Windows, Mac.
You can start from this boilerplate: ``` #include "this/package/foo.h" #include "gtest/gtest.h"
namespace {
// The fixture for testing class Foo. class FooTest : public ::testing::Test {  protected:   // You can remove any or all of the following functions if its body   // is empty.
FooTest() {     // You can do set-up work for each test here.   }
virtual ~FooTest() {     // You can do clean-up work that doesn't throw exceptions here.   }
// If the constructor and destructor are not enough for setting up   // and cleaning up each test, you can define the following methods:
virtual void SetUp() {     // Code here will be called immediately after the constructor (right     // before each test).   }
virtual void TearDown() {     // Code here will be called immediately after each test (right     // before the destructor).   }
// Objects declared here can be used by all tests in the test case for Foo. };
// Tests that the Foo::Bar() method does Abc. TEST_F(FooTest, MethodBarDoesAbc) {   const string input_filepath = "this/package/testdata/myinputfile.dat";   const string output_filepath = "this/package/testdata/myoutputfile.dat";   Foo f;   EXPECT_EQ(0, f.Bar(input_filepath, output_filepath)); }
// Tests that Foo does Xyz. TEST_F(FooTest, DoesXyz) {   // Exercises the Xyz feature of Foo. }
}  // namespace
int main(int argc, char **argv) {   ::testing::InitGoogleTest(&argc, argv);   return RUN_ALL_TESTS(); } ```
The `::testing::InitGoogleTest()` function parses the command line for Google Test flags, and removes all recognized flags. This allows the user to control a test program's behavior via various flags, which we'll cover in [AdvancedGuide](AdvancedGuide.md). You must call this function before calling `RUN_ALL_TESTS()`, or the flags won't be properly initialized.
On Windows, `InitGoogleTest()` also works with wide strings, so it can be used in programs compiled in `UNICODE` mode as well.
But maybe you think that writing all those main() functions is too much work? We agree with you completely and that's why Google Test provides a basic implementation of main(). If it fits your needs, then just link your test with gtest\_main library and you are good to go.
In addition, if you define your tests in a static library, add `/OPT:NOREF` to your main program linker options. If you use MSVC++ IDE, go to your .exe project properties/Configuration Properties/Linker/Optimization and set References setting to `Keep Unreferenced Data (/OPT:NOREF)`. This will keep Visual C++ linker from discarding individual symbols generated by your tests from the final executable.
There is one more pitfall, though. If you use Google Test as a static library (that's how it is defined in gtest.vcproj) your tests must also reside in a static library. If you have to have them in a DLL, you _must_ change Google Test to build into a DLL as well. Otherwise your tests will not run correctly or will not run at all. The general conclusion here is: make your life easier - do not write your tests in libraries!
Congratulations! You've learned the Google Test basics. You can start writing and running Google Test tests, read some [samples](Samples.md), or continue with [AdvancedGuide](AdvancedGuide.md), which describes many more useful Google Test features.
Google Test is designed to be thread-safe.  The implementation is thread-safe on systems where the `pthreads` library is available.  It is currently _unsafe_ to use Google Test assertions from two threads concurrently on other systems (e.g. Windows).  In most tests this is not an issue as usually the assertions are done in the main thread. If you want to help, you can volunteer to implement the necessary synchronization primitives in `gtest-port.h` for your platform.

<b>P</b>ump is <b>U</b>seful for <b>M</b>eta <b>P</b>rogramming.
Template and macro libraries often need to define many classes, functions, or macros that vary only (or almost only) in the number of arguments they take. It's a lot of repetitive, mechanical, and error-prone work.
Variadic templates and variadic macros can alleviate the problem. However, while both are being considered by the C++ committee, neither is in the standard yet or widely supported by compilers.  Thus they are often not a good choice, especially when your code needs to be portable. And their capabilities are still limited.
As a result, authors of such libraries often have to write scripts to generate their implementation. However, our experience is that it's tedious to write such scripts, which tend to reflect the structure of the generated code poorly and are often hard to read and edit. For example, a small change needed in the generated code may require some non-intuitive, non-trivial changes in the script. This is especially painful when experimenting with the code.
Pump (for Pump is Useful for Meta Programming, Pretty Useful for Meta Programming, or Practical Utility for Meta Programming, whichever you prefer) is a simple meta-programming tool for C++. The idea is that a programmer writes a `foo.pump` file which contains C++ code plus meta code that manipulates the C++ code. The meta code can handle iterations over a range, nested iterations, local meta variable definitions, simple arithmetic, and conditional expressions. You can view it as a small Domain-Specific Language. The meta language is designed to be non-intrusive (s.t. it won't confuse Emacs' C++ mode, for example) and concise, making Pump code intuitive and easy to maintain.
* The implementation is in a single Python script and thus ultra portable: no build or installation is needed and it works cross platforms.   * Pump tries to be smart with respect to [Google's style guide](http://code.google.com/p/google-styleguide/): it breaks long lines (easy to have when they are generated) at acceptable places to fit within 80 columns and indent the continuation lines correctly.   * The format is human-readable and more concise than XML.   * The format works relatively well with Emacs' C++ mode.
The following Pump code (where meta keywords start with `$`, `[[` and `]]` are meta brackets, and `$$` starts a meta comment that ends with the line):
``` $var n = 3     $$ Defines a meta variable n. $range i 0..n  $$ Declares the range of meta iterator i (inclusive). $for i [[                $$ Meta loop. // Foo$i does blah for $i-ary predicates. $range j 1..i template <size_t N $for j [[, typename A$j]]> class Foo$i { $if i == 0 [[   blah a; ]] $elif i <= 2 [[   blah b; ]] $else [[   blah c; ]] };
]] ```
will be translated by the Pump compiler to:
``` // Foo0 does blah for 0-ary predicates. template <size_t N> class Foo0 {   blah a; };
// Foo1 does blah for 1-ary predicates. template <size_t N, typename A1> class Foo1 {   blah b; };
// Foo2 does blah for 2-ary predicates. template <size_t N, typename A1, typename A2> class Foo2 {   blah b; };
// Foo3 does blah for 3-ary predicates. template <size_t N, typename A1, typename A2, typename A3> class Foo3 {   blah c; }; ```
In another example,
``` $range i 1..n Func($for i + [[a$i]]); $$ The text between i and [[ is the separator between iterations. ```
will generate one of the following lines (without the comments), depending on the value of `n`:
``` Func();              // If n is 0. Func(a1);            // If n is 1. Func(a1 + a2);       // If n is 2. Func(a1 + a2 + a3);  // If n is 3. // And so on... ```
We support the following meta programming constructs:
| `$var id = exp` | Defines a named constant value. `$id` is valid util the end of the current meta lexical block. | |:----------------|:-----------------------------------------------------------------------------------------------| | `$range id exp..exp` | Sets the range of an iteration variable, which can be reused in multiple loops later.          | | `$for id sep [[ code ]]` | Iteration. The range of `id` must have been defined earlier. `$id` is valid in `code`.         | | `$($)`          | Generates a single `$` character.                                                              | | `$id`           | Value of the named constant or iteration variable.                                             | | `$(exp)`        | Value of the expression.                                                                       | | `$if exp [[ code ]] else_branch` | Conditional.                                                                                   | | `[[ code ]]`    | Meta lexical block.                                                                            | | `cpp_code`      | Raw C++ code.                                                                                  | | `$$ comment`    | Meta comment.                                                                                  |
**Note:** To give the user some freedom in formatting the Pump source code, Pump ignores a new-line character if it's right after `$for foo` or next to `[[` or `]]`. Without this rule you'll often be forced to write very long lines to get the desired output. Therefore sometimes you may need to insert an extra new-line in such places for a new-line to show up in your output.
``` code ::= atomic_code* atomic_code ::= $var id = exp     | $var id = [[ code ]]     | $range id exp..exp     | $for id sep [[ code ]]     | $($)     | $id     | $(exp)     | $if exp [[ code ]] else_branch     | [[ code ]]     | cpp_code sep ::= cpp_code | empty_string else_branch ::= $else [[ code ]]     | $elif exp [[ code ]] else_branch     | empty_string exp ::= simple_expression_in_Python_syntax ```
You can find the source code of Pump in [scripts/pump.py](../scripts/pump.py). It is still very unpolished and lacks automated tests, although it has been successfully used many times. If you find a chance to use it in your project, please let us know what you think!  We also welcome help on improving Pump.
You can find real-world applications of Pump in [Google Test](http://www.google.com/codesearch?q=file%3A\.pump%24+package%3Ahttp%3A%2F%2Fgoogletest\.googlecode\.com) and [Google Mock](http://www.google.com/codesearch?q=file%3A\.pump%24+package%3Ahttp%3A%2F%2Fgooglemock\.googlecode\.com).  The source file `foo.h.pump` generates `foo.h`.
* If a meta variable is followed by a letter or digit, you can separate them using `[[]]`, which inserts an empty string. For example `Foo$j[[]]Helper` generate `Foo1Helper` when `j` is 1.   * To avoid extra-long Pump source lines, you can break a line anywhere you want by inserting `[[]]` followed by a new line. Since any new-line character next to `[[` or `]]` is ignored, the generated code won't contain this new line.
If you're like us, you'd like to look at some Google Test sample code.  The [samples folder](../samples) has a number of well-commented samples showing how to use a variety of Google Test features.
* [Sample #1](../samples/sample1_unittest.cc) shows the basic steps of using Google Test to test C++ functions.   * [Sample #2](../samples/sample2_unittest.cc) shows a more complex unit test for a class with multiple member functions.   * [Sample #3](../samples/sample3_unittest.cc) uses a test fixture.   * [Sample #4](../samples/sample4_unittest.cc) is another basic example of using Google Test.   * [Sample #5](../samples/sample5_unittest.cc) teaches how to reuse a test fixture in multiple test cases by deriving sub-fixtures from it.   * [Sample #6](../samples/sample6_unittest.cc) demonstrates type-parameterized tests.   * [Sample #7](../samples/sample7_unittest.cc) teaches the basics of value-parameterized tests.   * [Sample #8](../samples/sample8_unittest.cc) shows using `Combine()` in value-parameterized tests.   * [Sample #9](../samples/sample9_unittest.cc) shows use of the listener API to modify Google Test's console output and the use of its reflection API to inspect test results.   * [Sample #10](../samples/sample10_unittest.cc) shows use of the listener API to implement a primitive memory leak checker.

Now that you have read [Primer](V1_5_Primer.md) and learned how to write tests using Google Test, it's time to learn some new tricks. This document will show you more assertions as well as how to construct complex failure messages, propagate fatal failures, reuse and speed up your test fixtures, and use various flags with your tests.
This section covers some less frequently used, but still significant, assertions.
These three assertions do not actually test a value or expression. Instead, they generate a success or failure directly. Like the macros that actually perform a test, you may stream a custom failure message into the them.
| `SUCCEED();` | |:-------------|
Generates a success. This does NOT make the overall test succeed. A test is considered successful only if none of its assertions fail during its execution.
Note: `SUCCEED()` is purely documentary and currently doesn't generate any user-visible output. However, we may add `SUCCEED()` messages to Google Test's output in the future.
| `FAIL();`  | `ADD_FAILURE();` | |:-----------|:-----------------|
`FAIL*` generates a fatal failure while `ADD_FAILURE*` generates a nonfatal failure. These are useful when control flow, rather than a Boolean expression, deteremines the test's success or failure. For example, you might want to write something like:
``` switch(expression) {   case 1: ... some checks ...   case 2: ... some other checks   ...   default: FAIL() << "We shouldn't get here."; } ```
_Availability_: Linux, Windows, Mac.
These are for verifying that a piece of code throws (or does not throw) an exception of the given type:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_THROW(`_statement_, _exception\_type_`);`  | `EXPECT_THROW(`_statement_, _exception\_type_`);`  | _statement_ throws an exception of the given type  | | `ASSERT_ANY_THROW(`_statement_`);`                | `EXPECT_ANY_THROW(`_statement_`);`                | _statement_ throws an exception of any type        | | `ASSERT_NO_THROW(`_statement_`);`                 | `EXPECT_NO_THROW(`_statement_`);`                 | _statement_ doesn't throw any exception            |
Examples:
``` ASSERT_THROW(Foo(5), bar_exception);
EXPECT_NO_THROW({   int n = 5;   Bar(&n); }); ```
_Availability_: Linux, Windows, Mac; since version 1.1.0.
Even though Google Test has a rich set of assertions, they can never be complete, as it's impossible (nor a good idea) to anticipate all the scenarios a user might run into. Therefore, sometimes a user has to use `EXPECT_TRUE()` to check a complex expression, for lack of a better macro. This has the problem of not showing you the values of the parts of the expression, making it hard to understand what went wrong. As a workaround, some users choose to construct the failure message by themselves, streaming it into `EXPECT_TRUE()`. However, this is awkward especially when the expression has side-effects or is expensive to evaluate.
Google Test gives you three different options to solve this problem:
If you already have a function or a functor that returns `bool` (or a type that can be implicitly converted to `bool`), you can use it in a _predicate assertion_ to get the function arguments printed for free:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_PRED1(`_pred1, val1_`);`       | `EXPECT_PRED1(`_pred1, val1_`);` | _pred1(val1)_ returns true | | `ASSERT_PRED2(`_pred2, val1, val2_`);` | `EXPECT_PRED2(`_pred2, val1, val2_`);` |  _pred2(val1, val2)_ returns true | |  ...                | ...                    | ...          |
In the above, _predn_ is an _n_-ary predicate function or functor, where _val1_, _val2_, ..., and _valn_ are its arguments. The assertion succeeds if the predicate returns `true` when applied to the given arguments, and fails otherwise. When the assertion fails, it prints the value of each argument. In either case, the arguments are evaluated exactly once.
Here's an example. Given
``` // Returns true iff m and n have no common divisors except 1. bool MutuallyPrime(int m, int n) { ... } const int a = 3; const int b = 4; const int c = 10; ```
the assertion `EXPECT_PRED2(MutuallyPrime, a, b);` will succeed, while the assertion `EXPECT_PRED2(MutuallyPrime, b, c);` will fail with the message
<pre> !MutuallyPrime(b, c) is false, where<br> b is 4<br> c is 10<br> </pre>
**Notes:**
1. If you see a compiler error "no matching function to call" when using `ASSERT_PRED*` or `EXPECT_PRED*`, please see [this](V1_5_FAQ.md#the-compiler-complains-about-undefined-references-to-some-static-const-member-variables-but-i-did-define-them-in-the-class-body-whats-wrong) for how to resolve it.   1. Currently we only provide predicate assertions of arity <= 5. If you need a higher-arity assertion, let us know.
_Availability_: Linux, Windows, Mac
While `EXPECT_PRED*()` and friends are handy for a quick job, the syntax is not satisfactory: you have to use different macros for different arities, and it feels more like Lisp than C++.  The `::testing::AssertionResult` class solves this problem.
An `AssertionResult` object represents the result of an assertion (whether it's a success or a failure, and an associated message).  You can create an `AssertionResult` using one of these factory functions:
``` namespace testing {
// Returns an AssertionResult object to indicate that an assertion has // succeeded. AssertionResult AssertionSuccess();
// Returns an AssertionResult object to indicate that an assertion has // failed. AssertionResult AssertionFailure();
} ```
You can then use the `<<` operator to stream messages to the `AssertionResult` object.
To provide more readable messages in Boolean assertions (e.g. `EXPECT_TRUE()`), write a predicate function that returns `AssertionResult` instead of `bool`. For example, if you define `IsEven()` as:
``` ::testing::AssertionResult IsEven(int n) {   if ((n % 2) == 0)     return ::testing::AssertionSuccess();   else     return ::testing::AssertionFailure() << n << " is odd"; } ```
instead of:
``` bool IsEven(int n) {   return (n % 2) == 0; } ```
the failed assertion `EXPECT_TRUE(IsEven(Fib(4)))` will print:
<pre> Value of: !IsEven(Fib(4))<br> Actual: false (*3 is odd*)<br> Expected: true<br> </pre>
instead of a more opaque
<pre> Value of: !IsEven(Fib(4))<br> Actual: false<br> Expected: true<br> </pre>
If you want informative messages in `EXPECT_FALSE` and `ASSERT_FALSE` as well, and are fine with making the predicate slower in the success case, you can supply a success message:
``` ::testing::AssertionResult IsEven(int n) {   if ((n % 2) == 0)     return ::testing::AssertionSuccess() << n << " is even";   else     return ::testing::AssertionFailure() << n << " is odd"; } ```
Then the statement `EXPECT_FALSE(IsEven(Fib(6)))` will print
<pre> Value of: !IsEven(Fib(6))<br> Actual: true (8 is even)<br> Expected: false<br> </pre>
_Availability_: Linux, Windows, Mac; since version 1.4.1.
If you find the default message generated by `(ASSERT|EXPECT)_PRED*` and `(ASSERT|EXPECT)_(TRUE|FALSE)` unsatisfactory, or some arguments to your predicate do not support streaming to `ostream`, you can instead use the following _predicate-formatter assertions_ to _fully_ customize how the message is formatted:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_PRED_FORMAT1(`_pred\_format1, val1_`);`        | `EXPECT_PRED_FORMAT1(`_pred\_format1, val1_`); | _pred\_format1(val1)_ is successful | | `ASSERT_PRED_FORMAT2(`_pred\_format2, val1, val2_`);` | `EXPECT_PRED_FORMAT2(`_pred\_format2, val1, val2_`);` | _pred\_format2(val1, val2)_ is successful | | `...`               | `...`                  | `...`        |
The difference between this and the previous two groups of macros is that instead of a predicate, `(ASSERT|EXPECT)_PRED_FORMAT*` take a _predicate-formatter_ (_pred\_formatn_), which is a function or functor with the signature:
`::testing::AssertionResult PredicateFormattern(const char* `_expr1_`, const char* `_expr2_`, ... const char* `_exprn_`, T1 `_val1_`, T2 `_val2_`, ... Tn `_valn_`);`
where _val1_, _val2_, ..., and _valn_ are the values of the predicate arguments, and _expr1_, _expr2_, ..., and _exprn_ are the corresponding expressions as they appear in the source code. The types `T1`, `T2`, ..., and `Tn` can be either value types or reference types. For example, if an argument has type `Foo`, you can declare it as either `Foo` or `const Foo&`, whichever is appropriate.
A predicate-formatter returns a `::testing::AssertionResult` object to indicate whether the assertion has succeeded or not. The only way to create such an object is to call one of these factory functions:
As an example, let's improve the failure message in the previous example, which uses `EXPECT_PRED2()`:
``` // Returns the smallest prime common divisor of m and n, // or 1 when m and n are mutually prime. int SmallestPrimeCommonDivisor(int m, int n) { ... }
// A predicate-formatter for asserting that two integers are mutually prime. ::testing::AssertionResult AssertMutuallyPrime(const char* m_expr,                                                const char* n_expr,                                                int m,                                                int n) {   if (MutuallyPrime(m, n))     return ::testing::AssertionSuccess();
return ::testing::AssertionFailure()       << m_expr << " and " << n_expr << " (" << m << " and " << n       << ") are not mutually prime, " << "as they have a common divisor "       << SmallestPrimeCommonDivisor(m, n); } ```
With this predicate-formatter, we can use
``` EXPECT_PRED_FORMAT2(AssertMutuallyPrime, b, c); ```
to generate the message
<pre> b and c (4 and 10) are not mutually prime, as they have a common divisor 2.<br> </pre>
As you may have realized, many of the assertions we introduced earlier are special cases of `(EXPECT|ASSERT)_PRED_FORMAT*`. In fact, most of them are indeed defined using `(EXPECT|ASSERT)_PRED_FORMAT*`.
_Availability_: Linux, Windows, Mac.
Comparing floating-point numbers is tricky. Due to round-off errors, it is very unlikely that two floating-points will match exactly. Therefore, `ASSERT_EQ` 's naive comparison usually doesn't work. And since floating-points can have a wide value range, no single fixed error bound works. It's better to compare by a fixed relative error bound, except for values close to 0 due to the loss of precision there.
In general, for floating-point comparison to make sense, the user needs to carefully choose the error bound. If they don't want or care to, comparing in terms of Units in the Last Place (ULPs) is a good default, and Google Test provides assertions to do this. Full details about ULPs are quite long; if you want to learn more, see [this article on float comparison](http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm).
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_FLOAT_EQ(`_expected, actual_`);`  | `EXPECT_FLOAT_EQ(`_expected, actual_`);` | the two `float` values are almost equal | | `ASSERT_DOUBLE_EQ(`_expected, actual_`);` | `EXPECT_DOUBLE_EQ(`_expected, actual_`);` | the two `double` values are almost equal |
By "almost equal", we mean the two values are within 4 ULP's from each other.
The following assertions allow you to choose the acceptable error bound:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_NEAR(`_val1, val2, abs\_error_`);` | `EXPECT_NEAR`_(val1, val2, abs\_error_`);` | the difference between _val1_ and _val2_ doesn't exceed the given absolute error |
_Availability_: Linux, Windows, Mac.
Some floating-point operations are useful, but not that often used. In order to avoid an explosion of new macros, we provide them as predicate-format functions that can be used in predicate assertion macros (e.g. `EXPECT_PRED_FORMAT2`, etc).
``` EXPECT_PRED_FORMAT2(::testing::FloatLE, val1, val2); EXPECT_PRED_FORMAT2(::testing::DoubleLE, val1, val2); ```
Verifies that _val1_ is less than, or almost equal to, _val2_. You can replace `EXPECT_PRED_FORMAT2` in the above table with `ASSERT_PRED_FORMAT2`.
_Availability_: Linux, Windows, Mac.
These assertions test for `HRESULT` success or failure.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_HRESULT_SUCCEEDED(`_expression_`);` | `EXPECT_HRESULT_SUCCEEDED(`_expression_`);` | _expression_ is a success `HRESULT` | | `ASSERT_HRESULT_FAILED(`_expression_`);`    | `EXPECT_HRESULT_FAILED(`_expression_`);`    | _expression_ is a failure `HRESULT` |
The generated output contains the human-readable error message associated with the `HRESULT` code returned by _expression_.
You might use them like this:
``` CComPtr shell; ASSERT_HRESULT_SUCCEEDED(shell.CoCreateInstance(L"Shell.Application")); CComVariant empty; ASSERT_HRESULT_SUCCEEDED(shell->ShellExecute(CComBSTR(url), empty, empty, empty, empty)); ```
_Availability_: Windows.
You can call the function ``` ::testing::StaticAssertTypeEq<T1, T2>(); ``` to assert that types `T1` and `T2` are the same.  The function does nothing if the assertion is satisfied.  If the types are different, the function call will fail to compile, and the compiler error message will likely (depending on the compiler) show you the actual values of `T1` and `T2`.  This is mainly useful inside template code.
_Caveat:_ When used inside a member function of a class template or a function template, `StaticAssertTypeEq<T1, T2>()` is effective _only if_ the function is instantiated.  For example, given: ``` template <typename T> class Foo {  public:   void Bar() { ::testing::StaticAssertTypeEq<int, T>(); } }; ``` the code: ``` void Test1() { Foo<bool> foo; } ``` will _not_ generate a compiler error, as `Foo<bool>::Bar()` is never actually instantiated.  Instead, you need: ``` void Test2() { Foo<bool> foo; foo.Bar(); } ``` to cause a compiler error.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
You can use assertions in any C++ function. In particular, it doesn't have to be a method of the test fixture class. The one constraint is that assertions that generate a fatal failure (`FAIL*` and `ASSERT_*`) can only be used in void-returning functions. This is a consequence of Google Test not using exceptions. By placing it in a non-void function you'll get a confusing compile error like `"error: void value not ignored as it ought to be"`.
If you need to use assertions in a function that returns non-void, one option is to make the function return the value in an out parameter instead. For example, you can rewrite `T2 Foo(T1 x)` to `void Foo(T1 x, T2* result)`. You need to make sure that `*result` contains some sensible value even when the function returns prematurely. As the function now returns `void`, you can use any assertion inside of it.
If changing the function's type is not an option, you should just use assertions that generate non-fatal failures, such as `ADD_FAILURE*` and `EXPECT_*`.
_Note_: Constructors and destructors are not considered void-returning functions, according to the C++ language specification, and so you may not use fatal assertions in them. You'll get a compilation error if you try. A simple workaround is to transfer the entire body of the constructor or destructor to a private void-returning method. However, you should be aware that a fatal assertion failure in a constructor does not terminate the current test, as your intuition might suggest; it merely returns from the constructor early, possibly leaving your object in a partially-constructed state. Likewise, a fatal assertion failure in a destructor may leave your object in a partially-destructed state. Use assertions carefully in these situations!
In many applications, there are assertions that can cause application failure if a condition is not met. These sanity checks, which ensure that the program is in a known good state, are there to fail at the earliest possible time after some program state is corrupted. If the assertion checks the wrong condition, then the program may proceed in an erroneous state, which could lead to memory corruption, security holes, or worse. Hence it is vitally important to test that such assertion statements work as expected.
Since these precondition checks cause the processes to die, we call such tests _death tests_. More generally, any test that checks that a program terminates in an expected fashion is also a death test.
If you want to test `EXPECT_*()/ASSERT_*()` failures in your test code, see [Catching Failures](#catching-failures).
Google Test has the following macros to support death tests:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_DEATH(`_statement, regex_`); | `EXPECT_DEATH(`_statement, regex_`); | _statement_ crashes with the given error | | `ASSERT_DEATH_IF_SUPPORTED(`_statement, regex_`); | `EXPECT_DEATH_IF_SUPPORTED(`_statement, regex_`); | if death tests are supported, verifies that _statement_ crashes with the given error; otherwise verifies nothing | | `ASSERT_EXIT(`_statement, predicate, regex_`); | `EXPECT_EXIT(`_statement, predicate, regex_`); |_statement_ exits with the given error and its exit code matches _predicate_ |
where _statement_ is a statement that is expected to cause the process to die, _predicate_ is a function or function object that evaluates an integer exit status, and _regex_ is a regular expression that the stderr output of _statement_ is expected to match. Note that _statement_ can be _any valid statement_ (including _compound statement_) and doesn't have to be an expression.
As usual, the `ASSERT` variants abort the current test function, while the `EXPECT` variants do not.
**Note:** We use the word "crash" here to mean that the process terminates with a _non-zero_ exit status code.  There are two possibilities: either the process has called `exit()` or `_exit()` with a non-zero value, or it may be killed by a signal.
This means that if _statement_ terminates the process with a 0 exit code, it is _not_ considered a crash by `EXPECT_DEATH`.  Use `EXPECT_EXIT` instead if this is the case, or if you want to restrict the exit code more precisely.
A predicate here must accept an `int` and return a `bool`. The death test succeeds only if the predicate returns `true`. Google Test defines a few predicates that handle the most common cases:
``` ::testing::ExitedWithCode(exit_code) ```
This expression is `true` if the program exited normally with the given exit code.
``` ::testing::KilledBySignal(signal_number)  // Not available on Windows. ```
This expression is `true` if the program was killed by the given signal.
The `*_DEATH` macros are convenient wrappers for `*_EXIT` that use a predicate that verifies the process' exit code is non-zero.
Note that a death test only cares about three things:
1. does _statement_ abort or exit the process?   1. (in the case of `ASSERT_EXIT` and `EXPECT_EXIT`) does the exit status satisfy _predicate_?  Or (in the case of `ASSERT_DEATH` and `EXPECT_DEATH`) is the exit status non-zero?  And   1. does the stderr output match _regex_?
In particular, if _statement_ generates an `ASSERT_*` or `EXPECT_*` failure, it will **not** cause the death test to fail, as Google Test assertions don't abort the process.
To write a death test, simply use one of the above macros inside your test function. For example,
``` TEST(My*DeathTest*, Foo) {   // This death test uses a compound statement.   ASSERT_DEATH({ int n = 5; Foo(&n); }, "Error on line .* of Foo()"); } TEST(MyDeathTest, NormalExit) {   EXPECT_EXIT(NormalExit(), ::testing::ExitedWithCode(0), "Success"); } TEST(MyDeathTest, KillMyself) {   EXPECT_EXIT(KillMyself(), ::testing::KilledBySignal(SIGKILL), "Sending myself unblockable signal"); } ```
verifies that:
* calling `Foo(5)` causes the process to die with the given error message,   * calling `NormalExit()` causes the process to print `"Success"` to stderr and exit with exit code 0, and   * calling `KillMyself()` kills the process with signal `SIGKILL`.
The test function body may contain other assertions and statements as well, if necessary.
_Important:_ We strongly recommend you to follow the convention of naming your test case (not test) `*DeathTest` when it contains a death test, as demonstrated in the above example. The `Death Tests And Threads` section below explains why.
If a test fixture class is shared by normal tests and death tests, you can use typedef to introduce an alias for the fixture class and avoid duplicating its code: ``` class FooTest : public ::testing::Test { ... };
typedef FooTest FooDeathTest;
TEST_F(FooTest, DoesThis) {   // normal test }
TEST_F(FooDeathTest, DoesThat) {   // death test } ```
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Cygwin, and Mac (the latter three are supported since v1.3.0).  `(ASSERT|EXPECT)_DEATH_IF_SUPPORTED` are new in v1.4.0.
On POSIX systems (e.g. Linux, Cygwin, and Mac), Google Test uses the [POSIX extended regular expression](http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html#tag_09_04) syntax in death tests. To learn about this syntax, you may want to read this [Wikipedia entry](http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions).
On Windows, Google Test uses its own simple regular expression implementation. It lacks many features you can find in POSIX extended regular expressions.  For example, we don't support union (`"x|y"`), grouping (`"(xy)"`), brackets (`"[xy]"`), and repetition count (`"x{5,7}"`), among others. Below is what we do support (`A` denotes a literal character, period (`.`), or a single `\\` escape sequence; `x` and `y` denote regular expressions.):
| `c` | matches any literal character `c` | |:----|:----------------------------------| | `\\d` | matches any decimal digit         | | `\\D` | matches any character that's not a decimal digit | | `\\f` | matches `\f`                      | | `\\n` | matches `\n`                      | | `\\r` | matches `\r`                      | | `\\s` | matches any ASCII whitespace, including `\n` | | `\\S` | matches any character that's not a whitespace | | `\\t` | matches `\t`                      | | `\\v` | matches `\v`                      | | `\\w` | matches any letter, `_`, or decimal digit | | `\\W` | matches any character that `\\w` doesn't match | | `\\c` | matches any literal character `c`, which must be a punctuation | | `.` | matches any single character except `\n` | | `A?` | matches 0 or 1 occurrences of `A` | | `A*` | matches 0 or many occurrences of `A` | | `A+` | matches 1 or many occurrences of `A` | | `^` | matches the beginning of a string (not that of each line) | | `$` | matches the end of a string (not that of each line) | | `xy` | matches `x` followed by `y`       |
To help you determine which capability is available on your system, Google Test defines macro `GTEST_USES_POSIX_RE=1` when it uses POSIX extended regular expressions, or `GTEST_USES_SIMPLE_RE=1` when it uses the simple version.  If you want your death tests to work in both cases, you can either `#if` on these macros or use the more limited syntax only.
Under the hood, `ASSERT_EXIT()` spawns a new process and executes the death test statement in that process. The details of of how precisely that happens depend on the platform and the variable `::testing::GTEST_FLAG(death_test_style)` (which is initialized from the command-line flag `--gtest_death_test_style`).
* On POSIX systems, `fork()` (or `clone()` on Linux) is used to spawn the child, after which:     * If the variable's value is `"fast"`, the death test statement is immediately executed.     * If the variable's value is `"threadsafe"`, the child process re-executes the unit test binary just as it was originally invoked, but with some extra flags to cause just the single death test under consideration to be run.   * On Windows, the child is spawned using the `CreateProcess()` API, and re-executes the binary to cause just the single death test under consideration to be run - much like the `threadsafe` mode on POSIX.
Other values for the variable are illegal and will cause the death test to fail. Currently, the flag's default value is `"fast"`. However, we reserve the right to change it in the future. Therefore, your tests should not depend on this.
In either case, the parent process waits for the child process to complete, and checks that
1. the child's exit status satisfies the predicate, and   1. the child's stderr matches the regular expression.
If the death test statement runs to completion without dying, the child process will nonetheless terminate, and the assertion fails.
The reason for the two death test styles has to do with thread safety. Due to well-known problems with forking in the presence of threads, death tests should be run in a single-threaded context. Sometimes, however, it isn't feasible to arrange that kind of environment. For example, statically-initialized modules may start threads before main is ever reached. Once threads have been created, it may be difficult or impossible to clean them up.
Google Test has three features intended to raise awareness of threading issues.
1. A warning is emitted if multiple threads are running when a death test is encountered.   1. Test cases with a name ending in "DeathTest" are run before all other tests.   1. It uses `clone()` instead of `fork()` to spawn the child process on Linux (`clone()` is not available on Cygwin and Mac), as `fork()` is more likely to cause the child to hang when the parent process has multiple threads.
It's perfectly fine to create threads inside a death test statement; they are executed in a separate process and cannot affect the parent.
The "threadsafe" death test style was introduced in order to help mitigate the risks of testing in a possibly multithreaded environment. It trades increased test execution time (potentially dramatically so) for improved thread safety. We suggest using the faster, default "fast" style unless your test has specific problems with it.
You can choose a particular style of death tests by setting the flag programmatically:
``` ::testing::FLAGS_gtest_death_test_style = "threadsafe"; ```
You can do this in `main()` to set the style for all death tests in the binary, or in individual tests. Recall that flags are saved before running each test and restored afterwards, so you need not do that yourself. For example:
``` TEST(MyDeathTest, TestOne) {   ::testing::FLAGS_gtest_death_test_style = "threadsafe";   // This test is run in the "threadsafe" style:   ASSERT_DEATH(ThisShouldDie(), ""); }
TEST(MyDeathTest, TestTwo) {   // This test is run in the "fast" style:   ASSERT_DEATH(ThisShouldDie(), ""); }
int main(int argc, char** argv) {   ::testing::InitGoogleTest(&argc, argv);   ::testing::FLAGS_gtest_death_test_style = "fast";   return RUN_ALL_TESTS(); } ```
The _statement_ argument of `ASSERT_EXIT()` can be any valid C++ statement except that it can not return from the current function. This means _statement_ should not contain `return` or a macro that might return (e.g. `ASSERT_TRUE()` ). If _statement_ returns before it crashes, Google Test will print an error message, and the test will fail.
Since _statement_ runs in the child process, any in-memory side effect (e.g. modifying a variable, releasing memory, etc) it causes will _not_ be observable in the parent process. In particular, if you release memory in a death test, your program will fail the heap check as the parent process will never see the memory reclaimed. To solve this problem, you can
1. try not to free memory in a death test;   1. free the memory again in the parent process; or   1. do not use the heap checker in your program.
Due to an implementation detail, you cannot place multiple death test assertions on the same line; otherwise, compilation will fail with an unobvious error message.
Despite the improved thread safety afforded by the "threadsafe" style of death test, thread problems such as deadlock are still possible in the presence of handlers registered with `pthread_atfork(3)`.
If a test sub-routine is called from several places, when an assertion inside it fails, it can be hard to tell which invocation of the sub-routine the failure is from.  You can alleviate this problem using extra logging or custom failure messages, but that usually clutters up your tests. A better solution is to use the `SCOPED_TRACE` macro:
| `SCOPED_TRACE(`_message_`);` | |:-----------------------------|
where _message_ can be anything streamable to `std::ostream`. This macro will cause the current file name, line number, and the given message to be added in every failure message. The effect will be undone when the control leaves the current lexical scope.
For example,
``` 10: void Sub1(int n) { 11:   EXPECT_EQ(1, Bar(n)); 12:   EXPECT_EQ(2, Bar(n + 1)); 13: } 14: 15: TEST(FooTest, Bar) { 16:   { 17:     SCOPED_TRACE("A");  // This trace point will be included in 18:                         // every failure in this scope. 19:     Sub1(1); 20:   } 21:   // Now it won't. 22:   Sub1(9); 23: } ```
could result in messages like these:
``` path/to/foo_test.cc:11: Failure Value of: Bar(n) Expected: 1   Actual: 2    Trace: path/to/foo_test.cc:17: A
path/to/foo_test.cc:12: Failure Value of: Bar(n + 1) Expected: 2   Actual: 3 ```
Without the trace, it would've been difficult to know which invocation of `Sub1()` the two failures come from respectively. (You could add an extra message to each assertion in `Sub1()` to indicate the value of `n`, but that's tedious.)
Some tips on using `SCOPED_TRACE`:
1. With a suitable message, it's often enough to use `SCOPED_TRACE` at the beginning of a sub-routine, instead of at each call site.   1. When calling sub-routines inside a loop, make the loop iterator part of the message in `SCOPED_TRACE` such that you can know which iteration the failure is from.   1. Sometimes the line number of the trace point is enough for identifying the particular invocation of a sub-routine. In this case, you don't have to choose a unique message for `SCOPED_TRACE`. You can simply use `""`.   1. You can use `SCOPED_TRACE` in an inner scope when there is one in the outer scope. In this case, all active trace points will be included in the failure messages, in reverse order they are encountered.   1. The trace dump is clickable in Emacs' compilation buffer - hit return on a line number and you'll be taken to that line in the source file!
_Availability:_ Linux, Windows, Mac.
A common pitfall when using `ASSERT_*` and `FAIL*` is not understanding that when they fail they only abort the _current function_, not the entire test. For example, the following test will segfault: ``` void Subroutine() {   // Generates a fatal failure and aborts the current function.   ASSERT_EQ(1, 2);   // The following won't be executed.   ... }
TEST(FooTest, Bar) {   Subroutine();   // The intended behavior is for the fatal failure   // in Subroutine() to abort the entire test.   // The actual behavior: the function goes on after Subroutine() returns.   int* p = NULL;   *p = 3; // Segfault! } ```
Since we don't use exceptions, it is technically impossible to implement the intended behavior here.  To alleviate this, Google Test provides two solutions.  You could use either the `(ASSERT|EXPECT)_NO_FATAL_FAILURE` assertions or the `HasFatalFailure()` function.  They are described in the following two subsections.

As shown above, if your test calls a subroutine that has an `ASSERT_*` failure in it, the test will continue after the subroutine returns. This may not be what you want.
Often people want fatal failures to propagate like exceptions.  For that Google Test offers the following macros:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_NO_FATAL_FAILURE(`_statement_`);` | `EXPECT_NO_FATAL_FAILURE(`_statement_`);` | _statement_ doesn't generate any new fatal failures in the current thread. |
Only failures in the thread that executes the assertion are checked to determine the result of this type of assertions.  If _statement_ creates new threads, failures in these threads are ignored.
Examples:
``` ASSERT_NO_FATAL_FAILURE(Foo());
int i; EXPECT_NO_FATAL_FAILURE({   i = Bar(); }); ```
_Availability:_ Linux, Windows, Mac. Assertions from multiple threads are currently not supported.
`HasFatalFailure()` in the `::testing::Test` class returns `true` if an assertion in the current test has suffered a fatal failure. This allows functions to catch fatal failures in a sub-routine and return early.
``` class Test {  public:   ...   static bool HasFatalFailure(); }; ```
The typical usage, which basically simulates the behavior of a thrown exception, is:
``` TEST(FooTest, Bar) {   Subroutine();   // Aborts if Subroutine() had a fatal failure.   if (HasFatalFailure())     return;   // The following won't be executed.   ... } ```
If `HasFatalFailure()` is used outside of `TEST()` , `TEST_F()` , or a test fixture, you must add the `::testing::Test::` prefix, as in:
``` if (::testing::Test::HasFatalFailure())   return; ```
Similarly, `HasNonfatalFailure()` returns `true` if the current test has at least one non-fatal failure, and `HasFailure()` returns `true` if the current test has at least one failure of either kind.
_Availability:_ Linux, Windows, Mac.  `HasNonfatalFailure()` and `HasFailure()` are available since version 1.4.0.
In your test code, you can call `RecordProperty("key", value)` to log additional information, where `value` can be either a C string or a 32-bit integer. The _last_ value recorded for a key will be emitted to the XML output if you specify one. For example, the test
``` TEST_F(WidgetUsageTest, MinAndMaxWidgets) {   RecordProperty("MaximumWidgets", ComputeMaxUsage());   RecordProperty("MinimumWidgets", ComputeMinUsage()); } ```
will output XML like this:
``` ...   <testcase name="MinAndMaxWidgets" status="run" time="6" classname="WidgetUsageTest"             MaximumWidgets="12"             MinimumWidgets="9" /> ... ```
_Note_:   * `RecordProperty()` is a static member of the `Test` class. Therefore it needs to be prefixed with `::testing::Test::` if used outside of the `TEST` body and the test fixture class.   * `key` must be a valid XML attribute name, and cannot conflict with the ones already used by Google Test (`name`, `status`,     `time`, and `classname`).
_Availability_: Linux, Windows, Mac.

Google Test creates a new test fixture object for each test in order to make tests independent and easier to debug. However, sometimes tests use resources that are expensive to set up, making the one-copy-per-test model prohibitively expensive.
If the tests don't change the resource, there's no harm in them sharing a single resource copy. So, in addition to per-test set-up/tear-down, Google Test also supports per-test-case set-up/tear-down. To use it:
1. In your test fixture class (say `FooTest` ), define as `static` some member variables to hold the shared resources.   1. In the same test fixture class, define a `static void SetUpTestCase()` function (remember not to spell it as **`SetupTestCase`** with a small `u`!) to set up the shared resources and a `static void TearDownTestCase()` function to tear them down.
That's it! Google Test automatically calls `SetUpTestCase()` before running the _first test_ in the `FooTest` test case (i.e. before creating the first `FooTest` object), and calls `TearDownTestCase()` after running the _last test_ in it (i.e. after deleting the last `FooTest` object). In between, the tests can use the shared resources.
Remember that the test order is undefined, so your code can't depend on a test preceding or following another. Also, the tests must either not modify the state of any shared resource, or, if they do modify the state, they must restore the state to its original value before passing control to the next test.
Here's an example of per-test-case set-up and tear-down: ``` class FooTest : public ::testing::Test {  protected:   // Per-test-case set-up.   // Called before the first test in this test case.   // Can be omitted if not needed.   static void SetUpTestCase() {     shared_resource_ = new ...;   }
// Per-test-case tear-down.   // Called after the last test in this test case.   // Can be omitted if not needed.   static void TearDownTestCase() {     delete shared_resource_;     shared_resource_ = NULL;   }
// You can define per-test set-up and tear-down logic as usual.   virtual void SetUp() { ... }   virtual void TearDown() { ... }
// Some expensive resource shared by all tests.   static T* shared_resource_; };
T* FooTest::shared_resource_ = NULL;
TEST_F(FooTest, Test1) {   ... you can refer to shared_resource here ... } TEST_F(FooTest, Test2) {   ... you can refer to shared_resource here ... } ```
_Availability:_ Linux, Windows, Mac.
Just as you can do set-up and tear-down at the test level and the test case level, you can also do it at the test program level. Here's how.
First, you subclass the `::testing::Environment` class to define a test environment, which knows how to set-up and tear-down:
``` class Environment {  public:   virtual ~Environment() {}   // Override this to define how to set up the environment.   virtual void SetUp() {}   // Override this to define how to tear down the environment.   virtual void TearDown() {} }; ```
Then, you register an instance of your environment class with Google Test by calling the `::testing::AddGlobalTestEnvironment()` function:
``` Environment* AddGlobalTestEnvironment(Environment* env); ```
Now, when `RUN_ALL_TESTS()` is called, it first calls the `SetUp()` method of the environment object, then runs the tests if there was no fatal failures, and finally calls `TearDown()` of the environment object.
It's OK to register multiple environment objects. In this case, their `SetUp()` will be called in the order they are registered, and their `TearDown()` will be called in the reverse order.
Note that Google Test takes ownership of the registered environment objects. Therefore **do not delete them** by yourself.
You should call `AddGlobalTestEnvironment()` before `RUN_ALL_TESTS()` is called, probably in `main()`. If you use `gtest_main`, you need to      call this before `main()` starts for it to take effect. One way to do this is to define a global variable like this:
``` ::testing::Environment* const foo_env = ::testing::AddGlobalTestEnvironment(new FooEnvironment); ```
However, we strongly recommend you to write your own `main()` and call `AddGlobalTestEnvironment()` there, as relying on initialization of global variables makes the code harder to read and may cause problems when you register multiple environments from different translation units and the environments have dependencies among them (remember that the compiler doesn't guarantee the order in which global variables from different translation units are initialized).
_Availability:_ Linux, Windows, Mac.
_Value-parameterized tests_ allow you to test your code with different parameters without writing multiple copies of the same test.
Suppose you write a test for your code and then realize that your code is affected by a presence of a Boolean command line flag.
``` TEST(MyCodeTest, TestFoo) {   // A code to test foo(). } ```
Usually people factor their test code into a function with a Boolean parameter in such situations. The function sets the flag, then executes the testing code.
``` void TestFooHelper(bool flag_value) {   flag = flag_value;   // A code to test foo(). }
TEST(MyCodeTest, TestFooo) {   TestFooHelper(false);   TestFooHelper(true); } ```
But this setup has serious drawbacks. First, when a test assertion fails in your tests, it becomes unclear what value of the parameter caused it to fail. You can stream a clarifying message into your `EXPECT`/`ASSERT` statements, but it you'll have to do it with all of them. Second, you have to add one such helper function per test. What if you have ten tests? Twenty? A hundred?
Value-parameterized tests will let you write your test only once and then easily instantiate and run it with an arbitrary number of parameter values.
Here are some other situations when value-parameterized tests come handy:
* You wan to test different implementations of an OO interface.   * You want to test your code over various inputs (a.k.a. data-driven testing). This feature is easy to abuse, so please exercise your good sense when doing it!
To write value-parameterized tests, first you should define a fixture class. It must be derived from `::testing::TestWithParam<T>`, where `T` is the type of your parameter values. `TestWithParam<T>` is itself derived from `::testing::Test`. `T` can be any copyable type. If it's a raw pointer, you are responsible for managing the lifespan of the pointed values.
``` class FooTest : public ::testing::TestWithParam<const char*> {   // You can implement all the usual fixture class members here.   // To access the test parameter, call GetParam() from class   // TestWithParam<T>. }; ```
Then, use the `TEST_P` macro to define as many test patterns using this fixture as you want.  The `_P` suffix is for "parameterized" or "pattern", whichever you prefer to think.
``` TEST_P(FooTest, DoesBlah) {   // Inside a test, access the test parameter with the GetParam() method   // of the TestWithParam<T> class:   EXPECT_TRUE(foo.Blah(GetParam()));   ... }
TEST_P(FooTest, HasBlahBlah) {   ... } ```
Finally, you can use `INSTANTIATE_TEST_CASE_P` to instantiate the test case with any set of parameters you want. Google Test defines a number of functions for generating test parameters. They return what we call (surprise!) _parameter generators_. Here is a summary of them, which are all in the `testing` namespace:
| `Range(begin, end[, step])` | Yields values `{begin, begin+step, begin+step+step, ...}`. The values do not include `end`. `step` defaults to 1. | |:----------------------------|:------------------------------------------------------------------------------------------------------------------| | `Values(v1, v2, ..., vN)`   | Yields values `{v1, v2, ..., vN}`.                                                                                | | `ValuesIn(container)` and `ValuesIn(begin, end)` | Yields values from a C-style array, an STL-style container, or an iterator range `[begin, end)`.                  | | `Bool()`                    | Yields sequence `{false, true}`.                                                                                  | | `Combine(g1, g2, ..., gN)`  | Yields all combinations (the Cartesian product for the math savvy) of the values generated by the `N` generators. This is only available if your system provides the `<tr1/tuple>` header. If you are sure your system does, and Google Test disagrees, you can override it by defining `GTEST_HAS_TR1_TUPLE=1`. See comments in [include/gtest/internal/gtest-port.h](../include/gtest/internal/gtest-port.h) for more information. |
For more details, see the comments at the definitions of these functions in the [source code](../include/gtest/gtest-param-test.h).
The following statement will instantiate tests from the `FooTest` test case each with parameter values `"meeny"`, `"miny"`, and `"moe"`.
``` INSTANTIATE_TEST_CASE_P(InstantiationName,                         FooTest,                         ::testing::Values("meeny", "miny", "moe")); ```
To distinguish different instances of the pattern (yes, you can instantiate it more than once), the first argument to `INSTANTIATE_TEST_CASE_P` is a prefix that will be added to the actual test case name. Remember to pick unique prefixes for different instantiations. The tests from the instantiation above will have these names:
* `InstantiationName/FooTest.DoesBlah/0` for `"meeny"`   * `InstantiationName/FooTest.DoesBlah/1` for `"miny"`   * `InstantiationName/FooTest.DoesBlah/2` for `"moe"`   * `InstantiationName/FooTest.HasBlahBlah/0` for `"meeny"`   * `InstantiationName/FooTest.HasBlahBlah/1` for `"miny"`   * `InstantiationName/FooTest.HasBlahBlah/2` for `"moe"`
You can use these names in [--gtest\-filter](#running-a-subset-of-the-tests).
This statement will instantiate all tests from `FooTest` again, each with parameter values `"cat"` and `"dog"`:
``` const char* pets[] = {"cat", "dog"}; INSTANTIATE_TEST_CASE_P(AnotherInstantiationName, FooTest,                         ::testing::ValuesIn(pets)); ```
The tests from the instantiation above will have these names:
* `AnotherInstantiationName/FooTest.DoesBlah/0` for `"cat"`   * `AnotherInstantiationName/FooTest.DoesBlah/1` for `"dog"`   * `AnotherInstantiationName/FooTest.HasBlahBlah/0` for `"cat"`   * `AnotherInstantiationName/FooTest.HasBlahBlah/1` for `"dog"`
Please note that `INSTANTIATE_TEST_CASE_P` will instantiate _all_ tests in the given test case, whether their definitions come before or _after_ the `INSTANTIATE_TEST_CASE_P` statement.
You can see [these](../samples/sample7_unittest.cc) [files](../samples/sample8_unittest.cc) for more examples.
_Availability_: Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.2.0.
In the above, we define and instantiate `FooTest` in the same source file. Sometimes you may want to define value-parameterized tests in a library and let other people instantiate them later. This pattern is known as <i>abstract tests</i>. As an example of its application, when you are designing an interface you can write a standard suite of abstract tests (perhaps using a factory function as the test parameter) that all implementations of the interface are expected to pass. When someone implements the interface, he can instantiate your suite to get all the interface-conformance tests for free.
To define abstract tests, you should organize your code like this:
1. Put the definition of the parameterized test fixture class (e.g. `FooTest`) in a header file, say `foo_param_test.h`. Think of this as _declaring_ your abstract tests.   1. Put the `TEST_P` definitions in `foo_param_test.cc`, which includes `foo_param_test.h`. Think of this as _implementing_ your abstract tests.
Once they are defined, you can instantiate them by including `foo_param_test.h`, invoking `INSTANTIATE_TEST_CASE_P()`, and linking with `foo_param_test.cc`. You can instantiate the same abstract test case multiple times, possibly in different source files.
Suppose you have multiple implementations of the same interface and want to make sure that all of them satisfy some common requirements. Or, you may have defined several types that are supposed to conform to the same "concept" and you want to verify it.  In both cases, you want the same test logic repeated for different types.
While you can write one `TEST` or `TEST_F` for each type you want to test (and you may even factor the test logic into a function template that you invoke from the `TEST`), it's tedious and doesn't scale: if you want _m_ tests over _n_ types, you'll end up writing _m\*n_ `TEST`s.
_Typed tests_ allow you to repeat the same test logic over a list of types.  You only need to write the test logic once, although you must know the type list when writing typed tests.  Here's how you do it:
First, define a fixture class template.  It should be parameterized by a type.  Remember to derive it from `::testing::Test`:
``` template <typename T> class FooTest : public ::testing::Test {  public:   ...   typedef std::list<T> List;   static T shared_;   T value_; }; ```
Next, associate a list of types with the test case, which will be repeated for each type in the list:
``` typedef ::testing::Types<char, int, unsigned int> MyTypes; TYPED_TEST_CASE(FooTest, MyTypes); ```
The `typedef` is necessary for the `TYPED_TEST_CASE` macro to parse correctly.  Otherwise the compiler will think that each comma in the type list introduces a new macro argument.
Then, use `TYPED_TEST()` instead of `TEST_F()` to define a typed test for this test case.  You can repeat this as many times as you want:
``` TYPED_TEST(FooTest, DoesBlah) {   // Inside a test, refer to the special name TypeParam to get the type   // parameter.  Since we are inside a derived class template, C++ requires   // us to visit the members of FooTest via 'this'.   TypeParam n = this->value_;
// To visit static members of the fixture, add the 'TestFixture::'   // prefix.   n += TestFixture::shared_;
// To refer to typedefs in the fixture, add the 'typename TestFixture::'   // prefix.  The 'typename' is required to satisfy the compiler.   typename TestFixture::List values;   values.push_back(n);   ... }
TYPED_TEST(FooTest, HasPropertyA) { ... } ```
You can see `samples/sample6_unittest.cc` for a complete example.
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.1.0.
_Type-parameterized tests_ are like typed tests, except that they don't require you to know the list of types ahead of time.  Instead, you can define the test logic first and instantiate it with different type lists later.  You can even instantiate it more than once in the same program.
If you are designing an interface or concept, you can define a suite of type-parameterized tests to verify properties that any valid implementation of the interface/concept should have.  Then, the author of each implementation can just instantiate the test suite with his type to verify that it conforms to the requirements, without having to write similar tests repeatedly.  Here's an example:
First, define a fixture class template, as we did with typed tests:
``` template <typename T> class FooTest : public ::testing::Test {   ... }; ```
Next, declare that you will define a type-parameterized test case:
``` TYPED_TEST_CASE_P(FooTest); ```
The `_P` suffix is for "parameterized" or "pattern", whichever you prefer to think.
Then, use `TYPED_TEST_P()` to define a type-parameterized test.  You can repeat this as many times as you want:
``` TYPED_TEST_P(FooTest, DoesBlah) {   // Inside a test, refer to TypeParam to get the type parameter.   TypeParam n = 0;   ... }
TYPED_TEST_P(FooTest, HasPropertyA) { ... } ```
Now the tricky part: you need to register all test patterns using the `REGISTER_TYPED_TEST_CASE_P` macro before you can instantiate them. The first argument of the macro is the test case name; the rest are the names of the tests in this test case:
``` REGISTER_TYPED_TEST_CASE_P(FooTest,                            DoesBlah, HasPropertyA); ```
Finally, you are free to instantiate the pattern with the types you want.  If you put the above code in a header file, you can `#include` it in multiple C++ source files and instantiate it multiple times.
``` typedef ::testing::Types<char, int, unsigned int> MyTypes; INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, MyTypes); ```
To distinguish different instances of the pattern, the first argument to the `INSTANTIATE_TYPED_TEST_CASE_P` macro is a prefix that will be added to the actual test case name.  Remember to pick unique prefixes for different instances.
In the special case where the type list contains only one type, you can write that type directly without `::testing::Types<...>`, like this:
``` INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, int); ```
You can see `samples/sample6_unittest.cc` for a complete example.
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.1.0.
If you change your software's internal implementation, your tests should not break as long as the change is not observable by users. Therefore, per the _black-box testing principle_, most of the time you should test your code through its public interfaces.
If you still find yourself needing to test internal implementation code, consider if there's a better design that wouldn't require you to do so. If you absolutely have to test non-public interface code though, you can. There are two cases to consider:
* Static functions (_not_ the same as static member functions!) or unnamed namespaces, and   * Private or protected class members
Both static functions and definitions/declarations in an unnamed namespace are only visible within the same translation unit. To test them, you can `#include` the entire `.cc` file being tested in your `*_test.cc` file. (`#include`ing `.cc` files is not a good way to reuse code - you should not do this in production code!)
However, a better approach is to move the private code into the `foo::internal` namespace, where `foo` is the namespace your project normally uses, and put the private declarations in a `*-internal.h` file. Your production `.cc` files and your tests are allowed to include this internal header, but your clients are not. This way, you can fully test your internal implementation without leaking it to your clients.
Private class members are only accessible from within the class or by friends. To access a class' private members, you can declare your test fixture as a friend to the class and define accessors in your fixture. Tests using the fixture can then access the private members of your production class via the accessors in the fixture. Note that even though your fixture is a friend to your production class, your tests are not automatically friends to it, as they are technically defined in sub-classes of the fixture.
Another way to test private members is to refactor them into an implementation class, which is then declared in a `*-internal.h` file. Your clients aren't allowed to include this header but your tests can. Such is called the Pimpl (Private Implementation) idiom.
Or, you can declare an individual test as a friend of your class by adding this line in the class body:
``` FRIEND_TEST(TestCaseName, TestName); ```
For example, ``` // foo.h #include <gtest/gtest_prod.h>
// Defines FRIEND_TEST. class Foo {   ...  private:   FRIEND_TEST(FooTest, BarReturnsZeroOnNull);   int Bar(void* x); };
// foo_test.cc ... TEST(FooTest, BarReturnsZeroOnNull) {   Foo foo;   EXPECT_EQ(0, foo.Bar(NULL));   // Uses Foo's private member Bar(). } ```
Pay special attention when your class is defined in a namespace, as you should define your test fixtures and tests in the same namespace if you want them to be friends of your class. For example, if the code to be tested looks like:
``` namespace my_namespace {
class Foo {   friend class FooTest;   FRIEND_TEST(FooTest, Bar);   FRIEND_TEST(FooTest, Baz);   ...   definition of the class Foo   ... };
}  // namespace my_namespace ```
Your test code should be something like:
``` namespace my_namespace { class FooTest : public ::testing::Test {  protected:   ... };
TEST_F(FooTest, Bar) { ... } TEST_F(FooTest, Baz) { ... }
}  // namespace my_namespace ```
If you are building a testing utility on top of Google Test, you'll want to test your utility.  What framework would you use to test it? Google Test, of course.
The challenge is to verify that your testing utility reports failures correctly.  In frameworks that report a failure by throwing an exception, you could catch the exception and assert on it.  But Google Test doesn't use exceptions, so how do we test that a piece of code generates an expected failure?
`<gtest/gtest-spi.h>` contains some constructs to do this.  After `#include`ing this header, you can use
| `EXPECT_FATAL_FAILURE(`_statement, substring_`);` | |:--------------------------------------------------|
to assert that _statement_ generates a fatal (e.g. `ASSERT_*`) failure whose message contains the given _substring_, or use
| `EXPECT_NONFATAL_FAILURE(`_statement, substring_`);` | |:-----------------------------------------------------|
if you are expecting a non-fatal (e.g. `EXPECT_*`) failure.
For technical reasons, there are some caveats:
1. You cannot stream a failure message to either macro.   1. _statement_ in `EXPECT_FATAL_FAILURE()` cannot reference local non-static variables or non-static members of `this` object.   1. _statement_ in `EXPECT_FATAL_FAILURE()` cannot return a value.
_Note:_ Google Test is designed with threads in mind.  Once the synchronization primitives in `<gtest/internal/gtest-port.h>` have been implemented, Google Test will become thread-safe, meaning that you can then use assertions in multiple threads concurrently.  Before
that, however, Google Test only supports single-threaded usage.  Once thread-safe, `EXPECT_FATAL_FAILURE()` and `EXPECT_NONFATAL_FAILURE()` will capture failures in the current thread only. If _statement_ creates new threads, failures in these threads will be ignored.  If you want to capture failures from all threads instead, you should use the following macros:
| `EXPECT_FATAL_FAILURE_ON_ALL_THREADS(`_statement, substring_`);` | |:-----------------------------------------------------------------| | `EXPECT_NONFATAL_FAILURE_ON_ALL_THREADS(`_statement, substring_`);` |
Sometimes a function may need to know the name of the currently running test. For example, you may be using the `SetUp()` method of your test fixture to set the golden file name based on which test is running. The `::testing::TestInfo` class has this information:
``` namespace testing {
class TestInfo {  public:   // Returns the test case name and the test name, respectively.   //   // Do NOT delete or free the return value - it's managed by the   // TestInfo class.   const char* test_case_name() const;   const char* name() const; };
}  // namespace testing ```
> To obtain a `TestInfo` object for the currently running test, call `current_test_info()` on the `UnitTest` singleton object:
``` // Gets information about the currently running test. // Do NOT delete the returned object - it's managed by the UnitTest class. const ::testing::TestInfo* const test_info =   ::testing::UnitTest::GetInstance()->current_test_info(); printf("We are in test %s of test case %s.\n",        test_info->name(), test_info->test_case_name()); ```
`current_test_info()` returns a null pointer if no test is running. In particular, you cannot find the test case name in `TestCaseSetUp()`, `TestCaseTearDown()` (where you know the test case name implicitly), or functions called from them.
_Availability:_ Linux, Windows, Mac.
Google Test provides an <b>event listener API</b> to let you receive notifications about the progress of a test program and test failures. The events you can listen to include the start and end of the test program, a test case, or a test method, among others. You may use this API to augment or replace the standard console output, replace the XML output, or provide a completely different form of output, such as a GUI or a database. You can also use test events as checkpoints to implement a resource leak checker, for example.
_Availability:_ Linux, Windows, Mac; since v1.4.0.
To define a event listener, you subclass either [testing::TestEventListener](../include/gtest/gtest.h#L855) or [testing::EmptyTestEventListener](../include/gtest/gtest.h#L905). The former is an (abstract) interface, where <i>each pure virtual method<br> can be overridden to handle a test event</i> (For example, when a test starts, the `OnTestStart()` method will be called.). The latter provides an empty implementation of all methods in the interface, such that a subclass only needs to override the methods it cares about.
When an event is fired, its context is passed to the handler function as an argument. The following argument types are used:   * [UnitTest](../include/gtest/gtest.h#L1007) reflects the state of the entire test program,   * [TestCase](../include/gtest/gtest.h#L689) has information about a test case, which can contain one or more tests,   * [TestInfo](../include/gtest/gtest.h#L599) contains the state of a test, and   * [TestPartResult](../include/gtest/gtest-test-part.h#L42) represents the result of a test assertion.
An event handler function can examine the argument it receives to find out interesting information about the event and the test program's state.  Here's an example:
```   class MinimalistPrinter : public ::testing::EmptyTestEventListener {     // Called before a test starts.     virtual void OnTestStart(const ::testing::TestInfo& test_info) {       printf("*** Test %s.%s starting.\n",              test_info.test_case_name(), test_info.name());     }
// Called after a failed assertion or a SUCCESS().     virtual void OnTestPartResult(         const ::testing::TestPartResult& test_part_result) {       printf("%s in %s:%d\n%s\n",              test_part_result.failed() ? "*** Failure" : "Success",              test_part_result.file_name(),              test_part_result.line_number(),              test_part_result.summary());     }
// Called after a test ends.     virtual void OnTestEnd(const ::testing::TestInfo& test_info) {       printf("*** Test %s.%s ending.\n",              test_info.test_case_name(), test_info.name());     }   }; ```
To use the event listener you have defined, add an instance of it to the Google Test event listener list (represented by class [TestEventListeners](../include/gtest/gtest.h#L929) - note the "s" at the end of the name) in your `main()` function, before calling `RUN_ALL_TESTS()`: ``` int main(int argc, char** argv) {   ::testing::InitGoogleTest(&argc, argv);   // Gets hold of the event listener list.   ::testing::TestEventListeners& listeners =       ::testing::UnitTest::GetInstance()->listeners();   // Adds a listener to the end.  Google Test takes the ownership.   listeners.Append(new MinimalistPrinter);   return RUN_ALL_TESTS(); } ```
There's only one problem: the default test result printer is still in effect, so its output will mingle with the output from your minimalist printer. To suppress the default printer, just release it from the event listener list and delete it. You can do so by adding one line: ```   ...   delete listeners.Release(listeners.default_result_printer());   listeners.Append(new MinimalistPrinter);   return RUN_ALL_TESTS(); ```
Now, sit back and enjoy a completely different output from your tests. For more details, you can read this [sample](../samples/sample9_unittest.cc).
You may append more than one listener to the list. When an `On*Start()` or `OnTestPartResult()` event is fired, the listeners will receive it in the order they appear in the list (since new listeners are added to the end of the list, the default text printer and the default XML generator will receive the event first). An `On*End()` event will be received by the listeners in the _reverse_ order. This allows output by listeners added later to be framed by output from listeners added earlier.
You may use failure-raising macros (`EXPECT_*()`, `ASSERT_*()`, `FAIL()`, etc) when processing an event. There are some restrictions:
1. You cannot generate any failure in `OnTestPartResult()` (otherwise it will cause `OnTestPartResult()` to be called recursively).   1. A listener that handles `OnTestPartResult()` is not allowed to generate any failure.
When you add listeners to the listener list, you should put listeners that handle `OnTestPartResult()` _before_ listeners that can generate failures. This ensures that failures generated by the latter are attributed to the right test by the former.
We have a sample of failure-raising listener [here](../samples/sample10_unittest.cc).
Google Test test programs are ordinary executables. Once built, you can run them directly and affect their behavior via the following environment variables and/or command line flags. For the flags to work, your programs must call `::testing::InitGoogleTest()` before calling `RUN_ALL_TESTS()`.
To see a list of supported flags and their usage, please run your test program with the `--help` flag.  You can also use `-h`, `-?`, or `/?` for short.  This feature is added in version 1.3.0.
If an option is specified both by an environment variable and by a flag, the latter takes precedence.  Most of the options can also be set/read in code: to access the value of command line flag `--gtest_foo`, write `::testing::GTEST_FLAG(foo)`.  A common pattern is to set the value of a flag before calling `::testing::InitGoogleTest()` to change the default value of the flag: ``` int main(int argc, char** argv) {   // Disables elapsed time by default.   ::testing::GTEST_FLAG(print_time) = false;
// This allows the user to override the flag on the command line.   ::testing::InitGoogleTest(&argc, argv);
return RUN_ALL_TESTS(); } ```
This section shows various options for choosing which tests to run.
Sometimes it is necessary to list the available tests in a program before running them so that a filter may be applied if needed. Including the flag `--gtest_list_tests` overrides all other flags and lists tests in the following format: ``` TestCase1.   TestName1   TestName2 TestCase2.   TestName ```
None of the tests listed are actually run if the flag is provided. There is no corresponding environment variable for this flag.
_Availability:_ Linux, Windows, Mac.
By default, a Google Test program runs all tests the user has defined. Sometimes, you want to run only a subset of the tests (e.g. for debugging or quickly verifying a change). If you set the `GTEST_FILTER` environment variable or the `--gtest_filter` flag to a filter string, Google Test will only run the tests whose full names (in the form of `TestCaseName.TestName`) match the filter.
The format of a filter is a '`:`'-separated list of wildcard patterns (called the positive patterns) optionally followed by a '`-`' and another '`:`'-separated pattern list (called the negative patterns). A test matches the filter if and only if it matches any of the positive patterns but does not match any of the negative patterns.
A pattern may contain `'*'` (matches any string) or `'?'` (matches any single character). For convenience, the filter `'*-NegativePatterns'` can be also written as `'-NegativePatterns'`.
For example:
* `./foo_test` Has no flag, and thus runs all its tests.   * `./foo_test --gtest_filter=*` Also runs everything, due to the single match-everything `*` value.   * `./foo_test --gtest_filter=FooTest.*` Runs everything in test case `FooTest`.   * `./foo_test --gtest_filter=*Null*:*Constructor*` Runs any test whose full name contains either `"Null"` or `"Constructor"`.   * `./foo_test --gtest_filter=-*DeathTest.*` Runs all non-death tests.   * `./foo_test --gtest_filter=FooTest.*-FooTest.Bar` Runs everything in test case `FooTest` except `FooTest.Bar`.
_Availability:_ Linux, Windows, Mac.
If you have a broken test that you cannot fix right away, you can add the `DISABLED_` prefix to its name. This will exclude it from execution. This is better than commenting out the code or using `#if 0`, as disabled tests are still compiled (and thus won't rot).
If you need to disable all tests in a test case, you can either add `DISABLED_` to the front of the name of each test, or alternatively add it to the front of the test case name.
For example, the following tests won't be run by Google Test, even though they will still be compiled:
``` // Tests that Foo does Abc. TEST(FooTest, DISABLED_DoesAbc) { ... }
class DISABLED_BarTest : public ::testing::Test { ... };
// Tests that Bar does Xyz. TEST_F(DISABLED_BarTest, DoesXyz) { ... } ```
_Note:_ This feature should only be used for temporary pain-relief. You still have to fix the disabled tests at a later date. As a reminder, Google Test will print a banner warning you if a test program contains any disabled tests.
_Tip:_ You can easily count the number of disabled tests you have using `grep`. This number can be used as a metric for improving your test quality.
_Availability:_ Linux, Windows, Mac.
To include [disabled tests](#temporarily-disabling-tests) in test execution, just invoke the test program with the `--gtest_also_run_disabled_tests` flag or set the `GTEST_ALSO_RUN_DISABLED_TESTS` environment variable to a value other than `0`.  You can combine this with the [--gtest\_filter](#running-a-subset-of-the-tests) flag to further select which disabled tests to run.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
Once in a while you'll run into a test whose result is hit-or-miss. Perhaps it will fail only 1% of the time, making it rather hard to reproduce the bug under a debugger. This can be a major source of frustration.
The `--gtest_repeat` flag allows you to repeat all (or selected) test methods in a program many times. Hopefully, a flaky test will eventually fail and give you a chance to debug. Here's how to use it:
| `$ foo_test --gtest_repeat=1000` | Repeat foo\_test 1000 times and don't stop at failures. | |:---------------------------------|:--------------------------------------------------------| | `$ foo_test --gtest_repeat=-1`   | A negative count means repeating forever.               | | `$ foo_test --gtest_repeat=1000 --gtest_break_on_failure` | Repeat foo\_test 1000 times, stopping at the first failure. This is especially useful when running under a debugger: when the testfails, it will drop into the debugger and you can then inspect variables and stacks. | | `$ foo_test --gtest_repeat=1000 --gtest_filter=FooBar` | Repeat the tests whose name matches the filter 1000 times. |
If your test program contains global set-up/tear-down code registered using `AddGlobalTestEnvironment()`, it will be repeated in each iteration as well, as the flakiness may be in it. You can also specify the repeat count by setting the `GTEST_REPEAT` environment variable.
_Availability:_ Linux, Windows, Mac.
You can specify the `--gtest_shuffle` flag (or set the `GTEST_SHUFFLE` environment variable to `1`) to run the tests in a program in a random order. This helps to reveal bad dependencies between tests.
By default, Google Test uses a random seed calculated from the current time. Therefore you'll get a different order every time. The console output includes the random seed value, such that you can reproduce an order-related test failure later. To specify the random seed explicitly, use the `--gtest_random_seed=SEED` flag (or set the `GTEST_RANDOM_SEED` environment variable), where `SEED` is an integer between 0 and 99999. The seed value 0 is special: it tells Google Test to do the default behavior of calculating the seed from the current time.
If you combine this with `--gtest_repeat=N`, Google Test will pick a different random seed and re-shuffle the tests in each iteration.
_Availability:_ Linux, Windows, Mac; since v1.4.0.
This section teaches how to tweak the way test results are reported.
Google Test can use colors in its terminal output to make it easier to spot the separation between tests, and whether tests passed.
You can set the GTEST\_COLOR environment variable or set the `--gtest_color` command line flag to `yes`, `no`, or `auto` (the default) to enable colors, disable colors, or let Google Test decide. When the value is `auto`, Google Test will use colors if and only if the output goes to a terminal and (on non-Windows platforms) the `TERM` environment variable is set to `xterm` or `xterm-color`.
_Availability:_ Linux, Windows, Mac.
By default, Google Test prints the time it takes to run each test.  To suppress that, run the test program with the `--gtest_print_time=0` command line flag.  Setting the `GTEST_PRINT_TIME` environment variable to `0` has the same effect.
_Availability:_ Linux, Windows, Mac.  (In Google Test 1.3.0 and lower, the default behavior is that the elapsed time is **not** printed.)
Google Test can emit a detailed XML report to a file in addition to its normal textual output. The report contains the duration of each test, and thus can help you identify slow tests.
To generate the XML report, set the `GTEST_OUTPUT` environment variable or the `--gtest_output` flag to the string `"xml:_path_to_output_file_"`, which will create the file at the given location. You can also just use the string `"xml"`, in which case the output can be found in the `test_detail.xml` file in the current directory.
If you specify a directory (for example, `"xml:output/directory/"` on Linux or `"xml:output\directory\"` on Windows), Google Test will create the XML file in that directory, named after the test executable (e.g. `foo_test.xml` for test program `foo_test` or `foo_test.exe`). If the file already exists (perhaps left over from a previous run), Google Test will pick a different name (e.g. `foo_test_1.xml`) to avoid overwriting it.
The report uses the format described here.  It is based on the `junitreport` Ant task and can be parsed by popular continuous build systems like [Hudson](https://hudson.dev.java.net/). Since that format was originally intended for Java, a little interpretation is required to make it apply to Google Test tests, as shown here:
``` <testsuites name="AllTests" ...>   <testsuite name="test_case_name" ...>     <testcase name="test_name" ...>       <failure message="..."/>       <failure message="..."/>       <failure message="..."/>     </testcase>   </testsuite> </testsuites> ```
* The root `<testsuites>` element corresponds to the entire test program.   * `<testsuite>` elements correspond to Google Test test cases.   * `<testcase>` elements correspond to Google Test test functions.
For instance, the following program
``` TEST(MathTest, Addition) { ... } TEST(MathTest, Subtraction) { ... } TEST(LogicTest, NonContradiction) { ... } ```
could generate this report:
``` <?xml version="1.0" encoding="UTF-8"?> <testsuites tests="3" failures="1" errors="0" time="35" name="AllTests">   <testsuite name="MathTest" tests="2" failures="1"* errors="0" time="15">     <testcase name="Addition" status="run" time="7" classname="">       <failure message="Value of: add(1, 1)&#x0A; Actual: 3&#x0A;Expected: 2" type=""/>       <failure message="Value of: add(1, -1)&#x0A; Actual: 1&#x0A;Expected: 0" type=""/>     </testcase>     <testcase name="Subtraction" status="run" time="5" classname="">     </testcase>   </testsuite>   <testsuite name="LogicTest" tests="1" failures="0" errors="0" time="5">     <testcase name="NonContradiction" status="run" time="5" classname="">     </testcase>   </testsuite> </testsuites> ```
Things to note:
* The `tests` attribute of a `<testsuites>` or `<testsuite>` element tells how many test functions the Google Test program or test case contains, while the `failures` attribute tells how many of them failed.   * The `time` attribute expresses the duration of the test, test case, or entire test program in milliseconds.   * Each `<failure>` element corresponds to a single failed Google Test assertion.   * Some JUnit concepts don't apply to Google Test, yet we have to conform to the DTD. Therefore you'll see some dummy elements and attributes in the report. You can safely ignore these parts.
_Availability:_ Linux, Windows, Mac.
When running test programs under a debugger, it's very convenient if the debugger can catch an assertion failure and automatically drop into interactive mode. Google Test's _break-on-failure_ mode supports this behavior.
To enable it, set the `GTEST_BREAK_ON_FAILURE` environment variable to a value other than `0` . Alternatively, you can use the `--gtest_break_on_failure` command line flag.
_Availability:_ Linux, Windows, Mac.
On Windows, Google Test may be used with exceptions enabled. Even when exceptions are disabled, an application can still throw structured exceptions (SEH's). If a test throws an exception, by default Google Test doesn't try to catch it. Instead, you'll see a pop-up dialog, at which point you can attach the process to a debugger and easily find out what went wrong.
However, if you don't want to see the pop-ups (for example, if you run the tests in a batch job), set the `GTEST_CATCH_EXCEPTIONS` environment variable to a non- `0` value, or use the `--gtest_catch_exceptions` flag. Google Test now catches all test-thrown exceptions and logs them as failures.
_Availability:_ Windows. `GTEST_CATCH_EXCEPTIONS` and `--gtest_catch_exceptions` have no effect on Google Test's behavior on Linux or Mac, even if exceptions are enabled. It is possible to add support for catching exceptions on these platforms, but it is not implemented yet.
If you work on a project that has already been using another testing framework and is not ready to completely switch to Google Test yet, you can get much of Google Test's benefit by using its assertions in your existing tests.  Just change your `main()` function to look like:
``` #include <gtest/gtest.h>
int main(int argc, char** argv) {   ::testing::GTEST_FLAG(throw_on_failure) = true;   // Important: Google Test must be initialized.   ::testing::InitGoogleTest(&argc, argv);
... whatever your existing testing framework requires ... } ```
With that, you can use Google Test assertions in addition to the native assertions your testing framework provides, for example:
``` void TestFooDoesBar() {   Foo foo;   EXPECT_LE(foo.Bar(1), 100);     // A Google Test assertion.   CPPUNIT_ASSERT(foo.IsEmpty());  // A native assertion. } ```
If a Google Test assertion fails, it will print an error message and throw an exception, which will be treated as a failure by your host testing framework.  If you compile your code with exceptions disabled, a failed Google Test assertion will instead exit your program with a non-zero code, which will also signal a test failure to your test runner.
If you don't write `::testing::GTEST_FLAG(throw_on_failure) = true;` in your `main()`, you can alternatively enable this feature by specifying the `--gtest_throw_on_failure` flag on the command-line or setting the `GTEST_THROW_ON_FAILURE` environment variable to a non-zero value.
_Availability:_ Linux, Windows, Mac; since v1.3.0.
If you have more than one machine you can use to run a test program, you might want to run the test functions in parallel and get the result faster.  We call this technique _sharding_, where each machine is called a _shard_.
Google Test is compatible with test sharding.  To take advantage of this feature, your test runner (not part of Google Test) needs to do the following:
1. Allocate a number of machines (shards) to run the tests.   1. On each shard, set the `GTEST_TOTAL_SHARDS` environment variable to the total number of shards.  It must be the same for all shards.   1. On each shard, set the `GTEST_SHARD_INDEX` environment variable to the index of the shard.  Different shards must be assigned different indices, which must be in the range `[0, GTEST_TOTAL_SHARDS - 1]`.   1. Run the same test program on all shards.  When Google Test sees the above two environment variables, it will select a subset of the test functions to run.  Across all shards, each test function in the program will be run exactly once.   1. Wait for all shards to finish, then collect and report the results.
Your project may have tests that were written without Google Test and thus don't understand this protocol.  In order for your test runner to figure out which test supports sharding, it can set the environment variable `GTEST_SHARD_STATUS_FILE` to a non-existent file path.  If a test program supports sharding, it will create this file to acknowledge the fact (the actual contents of the file are not important at this time; although we may stick some useful information in it in the future.); otherwise it will not create it.
Here's an example to make it clear.  Suppose you have a test program `foo_test` that contains the following 5 test functions: ``` TEST(A, V) TEST(A, W) TEST(B, X) TEST(B, Y) TEST(B, Z) ``` and you have 3 machines at your disposal.  To run the test functions in parallel, you would set `GTEST_TOTAL_SHARDS` to 3 on all machines, and set `GTEST_SHARD_INDEX` to 0, 1, and 2 on the machines respectively. Then you would run the same `foo_test` on each machine.
Google Test reserves the right to change how the work is distributed across the shards, but here's one possible scenario:
* Machine #0 runs `A.V` and `B.X`.   * Machine #1 runs `A.W` and `B.Y`.   * Machine #2 runs `B.Z`.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
Google Test's implementation consists of ~30 files (excluding its own tests).  Sometimes you may want them to be packaged up in two files (a `.h` and a `.cc`) instead, such that you can easily copy them to a new machine and start hacking there.  For this we provide an experimental Python script `fuse_gtest_files.py` in the `scripts/` directory (since release 1.3.0). Assuming you have Python 2.4 or above installed on your machine, just go to that directory and run ``` python fuse_gtest_files.py OUTPUT_DIR ```
and you should see an `OUTPUT_DIR` directory being created with files `gtest/gtest.h` and `gtest/gtest-all.cc` in it.  These files contain everything you need to use Google Test.  Just copy them to anywhere you want and you are ready to write tests.  You can use the [scrpts/test/Makefile](../scripts/test/Makefile) file as an example on how to compile your tests against them.
Congratulations! You've now learned more advanced Google Test tools and are ready to tackle more complex testing tasks. If you want to dive even deeper, you can read the [FAQ](V1_5_FAQ.md).
This page lists all official documentation wiki pages for Google Test **1.5.0** -- **if you use a different version of Google Test, make sure to read the documentation for that version instead.**
* [Primer](V1_5_Primer.md) -- start here if you are new to Google Test.   * [Samples](Samples.md) -- learn from examples.   * [AdvancedGuide](V1_5_AdvancedGuide.md) -- learn more about Google Test.   * [XcodeGuide](V1_5_XcodeGuide.md) -- how to use Google Test in Xcode on Mac.   * [Frequently-Asked Questions](V1_5_FAQ.md) -- check here before asking a question on the mailing list.
To contribute code to Google Test, read:
* DevGuide -- read this _before_ writing your first patch.   * [PumpManual](V1_5_PumpManual.md) -- how we generate some of Google Test's source files.

If you cannot find the answer to your question here, and you have read [Primer](V1_5_Primer.md) and [AdvancedGuide](V1_5_AdvancedGuide.md), send it to googletestframework@googlegroups.com.
First, let's say clearly that we don't want to get into the debate of which C++ testing framework is **the best**.  There exist many fine frameworks for writing C++ tests, and we have tremendous respect for the developers and users of them.  We don't think there is (or will be) a single best framework - you have to pick the right tool for the particular task you are tackling.
We created Google Test because we couldn't find the right combination of features and conveniences in an existing framework to satisfy _our_ needs.  The following is a list of things that _we_ like about Google Test.  We don't claim them to be unique to Google Test - rather, the combination of them makes Google Test the choice for us.  We hope this list can help you decide whether it is for you too.
* Google Test is designed to be portable.  It works where many STL types (e.g. `std::string` and `std::vector`) don't compile.  It doesn't require exceptions or RTTI.  As a result, it runs on Linux, Mac OS X, Windows and several embedded operating systems.   * Nonfatal assertions (`EXPECT_*`) have proven to be great time savers, as they allow a test to report multiple failures in a single edit-compile-test cycle.   * It's easy to write assertions that generate informative messages: you just use the stream syntax to append any additional information, e.g. `ASSERT_EQ(5, Foo(i)) << " where i = " << i;`.  It doesn't require a new set of macros or special functions.   * Google Test automatically detects your tests and doesn't require you to enumerate them in order to run them.   * No framework can anticipate all your needs, so Google Test provides `EXPECT_PRED*` to make it easy to extend your assertion vocabulary.  For a nicer syntax, you can define your own assertion macros trivially in terms of `EXPECT_PRED*`.   * Death tests are pretty handy for ensuring that your asserts in production code are triggered by the right conditions.   * `SCOPED_TRACE` helps you understand the context of an assertion failure when it comes from inside a sub-routine or loop.   * You can decide which tests to run using name patterns.  This saves time when you want to quickly reproduce a test failure.
(Answered by Trevor Robinson)
Load the supplied Visual Studio solution file, either `msvc\gtest-md.sln` or `msvc\gtest.sln`. Go through the migration wizard to migrate the solution and project files to Visual Studio 2008. Select `Configuration Manager...` from the `Build` menu. Select `<New...>` from the `Active solution platform` dropdown.  Select `x64` from the new platform dropdown, leave `Copy settings from` set to `Win32` and `Create new project platforms` checked, then click `OK`. You now have `Win32` and `x64` platform configurations, selectable from the `Standard` toolbar, which allow you to toggle between building 32-bit or 64-bit binaries (or both at once using Batch Build).
In order to prevent build output files from overwriting one another, you'll need to change the `Intermediate Directory` settings for the newly created platform configuration across all the projects. To do this, multi-select (e.g. using shift-click) all projects (but not the solution) in the `Solution Explorer`. Right-click one of them and select `Properties`. In the left pane, select `Configuration Properties`, and from the `Configuration` dropdown, select `All Configurations`. Make sure the selected platform is `x64`. For the `Intermediate Directory` setting, change the value from `$(PlatformName)\$(ConfigurationName)` to `$(OutDir)\$(ProjectName)`. Click `OK` and then build the solution. When the build is complete, the 64-bit binaries will be in the `msvc\x64\Debug` directory.
We haven't tested this ourselves, but Per Abrahamsen reported that he was able to compile and install Google Test successfully when using MinGW from Cygwin.  You'll need to configure it with:
`PATH/TO/configure CC="gcc -mno-cygwin" CXX="g++ -mno-cygwin"`
You should be able to replace the `-mno-cygwin` option with direct links to the real MinGW binaries, but we haven't tried that.
Caveats:
* There are many warnings when compiling.   * `make check` will produce some errors as not all tests for Google Test itself are compatible with MinGW.
We also have reports on successful cross compilation of Google Test MinGW binaries on Linux using [these instructions](http://wiki.wxwidgets.org/Cross-Compiling_Under_Linux#Cross-compiling_under_Linux_for_MS_Windows) on the WxWidgets site.
Please contact `googletestframework@googlegroups.com` if you are interested in improving the support for MinGW.
Due to some peculiarity of C++, it requires some non-trivial template meta programming tricks to support using `NULL` as an argument of the `EXPECT_XX()` and `ASSERT_XX()` macros. Therefore we only do it where it's most needed (otherwise we make the implementation of Google Test harder to maintain and more error-prone than necessary).
The `EXPECT_EQ()` macro takes the _expected_ value as its first argument and the _actual_ value as the second. It's reasonable that someone wants to write `EXPECT_EQ(NULL, some_expression)`, and this indeed was requested several times. Therefore we implemented it.
The need for `EXPECT_NE(NULL, ptr)` isn't nearly as strong. When the assertion fails, you already know that `ptr` must be `NULL`, so it doesn't add any information to print ptr in this case. That means `EXPECT_TRUE(ptr ! NULL)` works just as well.
If we were to support `EXPECT_NE(NULL, ptr)`, for consistency we'll have to support `EXPECT_NE(ptr, NULL)` as well, as unlike `EXPECT_EQ`, we don't have a convention on the order of the two arguments for `EXPECT_NE`. This means using the template meta programming tricks twice in the implementation, making it even harder to understand and maintain. We believe the benefit doesn't justify the cost.
Finally, with the growth of Google Mock's [matcher](../../CookBook.md#using-matchers-in-google-test-assertions) library, we are encouraging people to use the unified `EXPECT_THAT(value, matcher)` syntax more often in tests. One significant advantage of the matcher approach is that matchers can be easily combined to form new matchers, while the `EXPECT_NE`, etc, macros cannot be easily combined. Therefore we want to invest more in the matchers than in the `EXPECT_XX()` macros.
Test runners tend to be tightly coupled with the build/test environment, and Google Test doesn't try to solve the problem of running tests in parallel.  Instead, we tried to make Google Test work nicely with test runners.  For example, Google Test's XML report contains the time spent on each test, and its `gtest_list_tests` and `gtest_filter` flags can be used for splitting the execution of test methods into multiple processes.  These functionalities can help the test runner run the tests in parallel.
It's difficult to write thread-safe code.  Most tests are not written with thread-safety in mind, and thus may not work correctly in a multi-threaded setting.
If you think about it, it's already hard to make your code work when you know what other threads are doing.  It's much harder, and sometimes even impossible, to make your code work when you don't know what other threads are doing (remember that test methods can be added, deleted, or modified after your test was written).  If you want to run the tests in parallel, you'd better run them in different processes.
Our original motivation was to be able to use Google Test in projects that disable exceptions.  Later we realized some additional benefits of this approach:
1. Throwing in a destructor is undefined behavior in C++.  Not using exceptions means Google Test's assertions are safe to use in destructors.   1. The `EXPECT_*` family of macros will continue even after a failure, allowing multiple failures in a `TEST` to be reported in a single run. This is a popular feature, as in C++ the edit-compile-test cycle is usually quite long and being able to fixing more than one thing at a time is a blessing.   1. If assertions are implemented using exceptions, a test may falsely ignore a failure if it's caught by user code: ``` try { ... ASSERT_TRUE(...) ... } catch (...) { ... } ``` The above code will pass even if the `ASSERT_TRUE` throws.  While it's unlikely for someone to write this in a test, it's possible to run into this pattern when you write assertions in callbacks that are called by the code under test.
The downside of not using exceptions is that `ASSERT_*` (implemented using `return`) will only abort the current function, not the current `TEST`.
Unfortunately, C++'s macro system doesn't allow us to use the same macro for both cases.  One possibility is to provide only one macro for tests with fixtures, and require the user to define an empty fixture sometimes:
``` class FooTest : public ::testing::Test {};
TEST_F(FooTest, DoesThis) { ... } ``` or ``` typedef ::testing::Test FooTest;
TEST_F(FooTest, DoesThat) { ... } ```
Yet, many people think this is one line too many. :-) Our goal was to make it really easy to write tests, so we tried to make simple tests trivial to create.  That means using a separate macro for such tests.
We think neither approach is ideal, yet either of them is reasonable. In the end, it probably doesn't matter much either way.
We like to use structs only when representing passive data.  This distinction between structs and classes is good for documenting the intent of the code's author.  Since test fixtures have logic like `SetUp()` and `TearDown()`, they are better defined as classes.
Our goal was to make death tests as convenient for a user as C++ possibly allows.  In particular:
* The runner-style requires to split the information into two pieces: the definition of the death test itself, and the specification for the runner on how to run the death test and what to expect.  The death test would be written in C++, while the runner spec may or may not be.  A user needs to carefully keep the two in sync. `ASSERT_DEATH(statement, expected_message)` specifies all necessary information in one place, in one language, without boilerplate code. It is very declarative.   * `ASSERT_DEATH` has a similar syntax and error-reporting semantics as other Google Test assertions, and thus is easy to learn.   * `ASSERT_DEATH` can be mixed with other assertions and other logic at your will.  You are not limited to one death test per test method. For example, you can write something like: ```     if (FooCondition()) {       ASSERT_DEATH(Bar(), "blah");     } else {       ASSERT_EQ(5, Bar());     } ``` If you prefer one death test per test method, you can write your tests in that style too, but we don't want to impose that on the users.  The fewer artificial limitations the better.   * `ASSERT_DEATH` can reference local variables in the current function, and you can decide how many death tests you want based on run-time information.  For example, ```     const int count = GetCount();  // Only known at run time.     for (int i = 1; i <= count; i++) {       ASSERT_DEATH({         double* buffer = new double[i];         ... initializes buffer ...         Foo(buffer, i)       }, "blah blah");     } ``` The runner-based approach tends to be more static and less flexible, or requires more user effort to get this kind of flexibility.
Another interesting thing about `ASSERT_DEATH` is that it calls `fork()` to create a child process to run the death test.  This is lightening fast, as `fork()` uses copy-on-write pages and incurs almost zero overhead, and the child process starts from the user-supplied statement directly, skipping all global and local initialization and any code leading to the given statement.  If you launch the child process from scratch, it can take seconds just to load everything and start running if the test links to many libraries dynamically.
Death tests (`EXPECT_DEATH`, etc) are executed in a sub-process s.t. the expected crash won't kill the test program (i.e. the parent process). As a result, any in-memory side effects they incur are observable in their respective sub-processes, but not in the parent process. You can think of them as running in a parallel universe, more or less.
If your class has a static data member:
``` // foo.h class Foo {   ...   static const int kBar = 100; }; ```
You also need to define it _outside_ of the class body in `foo.cc`:
``` const int Foo::kBar;  // No initializer here. ```
Otherwise your code is **invalid C++**, and may break in unexpected ways. In particular, using it in Google Test comparison assertions (`EXPECT_EQ`, etc) will generate an "undefined reference" linker error.
Google Test doesn't yet have good support for this kind of tests, or data-driven tests in general. We hope to be able to make improvements in this area soon.
Yes.
Each test fixture has a corresponding and same named test case. This means only one test case can use a particular fixture. Sometimes, however, multiple test cases may want to use the same or slightly different fixtures. For example, you may want to make sure that all of a GUI library's test cases don't leak important system resources like fonts and brushes.
In Google Test, you share a fixture among test cases by putting the shared logic in a base test fixture, then deriving from that base a separate fixture for each test case that wants to use this common logic. You then use `TEST_F()` to write tests using each derived fixture.
Typically, your code looks like this:
``` // Defines a base test fixture. class BaseTest : public ::testing::Test {   protected:    ... };
// Derives a fixture FooTest from BaseTest. class FooTest : public BaseTest {   protected:     virtual void SetUp() {       BaseTest::SetUp();  // Sets up the base fixture first.       ... additional set-up work ...     }     virtual void TearDown() {       ... clean-up work for FooTest ...       BaseTest::TearDown();  // Remember to tear down the base fixture                              // after cleaning up FooTest!     }     ... functions and variables for FooTest ... };
// Tests that use the fixture FooTest. TEST_F(FooTest, Bar) { ... } TEST_F(FooTest, Baz) { ... }
... additional fixtures derived from BaseTest ... ```
If necessary, you can continue to derive test fixtures from a derived fixture. Google Test has no limit on how deep the hierarchy can be.
For a complete example using derived test fixtures, see `samples/sample5_unittest.cc`.
You're probably using an `ASSERT_*()` in a function that doesn't return `void`. `ASSERT_*()` can only be used in `void` functions.
In Google Test, death tests are run in a child process and the way they work is delicate. To write death tests you really need to understand how they work. Please make sure you have read this.
In particular, death tests don't like having multiple threads in the parent process. So the first thing you can try is to eliminate creating threads outside of `EXPECT_DEATH()`.
Sometimes this is impossible as some library you must use may be creating threads before `main()` is even reached. In this case, you can try to minimize the chance of conflicts by either moving as many activities as possible inside `EXPECT_DEATH()` (in the extreme case, you want to move everything inside), or leaving as few things as possible in it. Also, you can try to set the death test style to `"threadsafe"`, which is safer but slower, and see if it helps.
If you go with thread-safe death tests, remember that they rerun the test program from the beginning in the child process. Therefore make sure your program can run side-by-side with itself and is deterministic.
In the end, this boils down to good concurrent programming. You have to make sure that there is no race conditions or dead locks in your program. No silver bullet - sorry!
The first thing to remember is that Google Test does not reuse the same test fixture object across multiple tests. For each `TEST_F`, Google Test will create a fresh test fixture object, _immediately_ call `SetUp()`, run the test, call `TearDown()`, and then _immediately_ delete the test fixture object. Therefore, there is no need to write a `SetUp()` or `TearDown()` function if the constructor or destructor already does the job.
You may still want to use `SetUp()/TearDown()` in the following cases:   * If the tear-down operation could throw an exception, you must use `TearDown()` as opposed to the destructor, as throwing in a destructor leads to undefined behavior and usually will kill your program right away. Note that many standard libraries (like STL) may throw when exceptions are enabled in the compiler. Therefore you should prefer `TearDown()` if you want to write portable tests that work with or without exceptions.   * The Google Test team is considering making the assertion macros throw on platforms where exceptions are enabled (e.g. Windows, Mac OS, and Linux client-side), which will eliminate the need for the user to propagate failures from a subroutine to its caller. Therefore, you shouldn't use Google Test assertions in a destructor if your code could run on such a platform.   * In a constructor or destructor, you cannot make a virtual function call on this object. (You can call a method declared as virtual, but it will be statically bound.) Therefore, if you need to call a method that will be overriden in a derived class, you have to use `SetUp()/TearDown()`.
If the predicate function you use in `ASSERT_PRED*` or `EXPECT_PRED*` is overloaded or a template, the compiler will have trouble figuring out which overloaded version it should use. `ASSERT_PRED_FORMAT*` and `EXPECT_PRED_FORMAT*` don't have this problem.
If you see this error, you might want to switch to `(ASSERT|EXPECT)_PRED_FORMAT*`, which will also give you a better failure message. If, however, that is not an option, you can resolve the problem by explicitly telling the compiler which version to pick.
For example, suppose you have
``` bool IsPositive(int n) {   return n > 0; } bool IsPositive(double x) {   return x > 0; } ```
you will get a compiler error if you write
``` EXPECT_PRED1(IsPositive, 5); ```
However, this will work:
``` EXPECT_PRED1(*static_cast<bool (*)(int)>*(IsPositive), 5); ```
(The stuff inside the angled brackets for the `static_cast` operator is the type of the function pointer for the `int`-version of `IsPositive()`.)
As another example, when you have a template function
``` template <typename T> bool IsNegative(T x) {   return x < 0; } ```
you can use it in a predicate assertion like this:
``` ASSERT_PRED1(IsNegative*<int>*, -5); ```
Things are more interesting if your template has more than one parameters. The following won't compile:
``` ASSERT_PRED2(*GreaterThan<int, int>*, 5, 0); ```
as the C++ pre-processor thinks you are giving `ASSERT_PRED2` 4 arguments, which is one more than expected. The workaround is to wrap the predicate function in parentheses:
``` ASSERT_PRED2(*(GreaterThan<int, int>)*, 5, 0); ```
Some people had been ignoring the return value of `RUN_ALL_TESTS()`. That is, instead of
``` return RUN_ALL_TESTS(); ```
they write
``` RUN_ALL_TESTS(); ```
This is wrong and dangerous. A test runner needs to see the return value of `RUN_ALL_TESTS()` in order to determine if a test has passed. If your `main()` function ignores it, your test will be considered successful even if it has a Google Test assertion failure. Very bad.
To help the users avoid this dangerous bug, the implementation of `RUN_ALL_TESTS()` causes gcc to raise this warning, when the return value is ignored. If you see this warning, the fix is simple: just make sure its value is used as the return value of `main()`.
Due to a peculiarity of C++, in order to support the syntax for streaming messages to an `ASSERT_*`, e.g.
``` ASSERT_EQ(1, Foo()) << "blah blah" << foo; ```
we had to give up using `ASSERT*` and `FAIL*` (but not `EXPECT*` and `ADD_FAILURE*`) in constructors and destructors. The workaround is to move the content of your constructor/destructor to a private void member function, or switch to `EXPECT_*()` if that works. This section in the user's guide explains it.
C++ is case-sensitive. It should be spelled as `SetUp()`.  Did you spell it as `Setup()`?
Similarly, sometimes people spell `SetUpTestCase()` as `SetupTestCase()` and wonder why it's never called.
Google Test's failure message format is understood by Emacs and many other IDEs, like acme and XCode. If a Google Test message is in a compilation buffer in Emacs, then it's clickable. You can now hit `enter` on a message to jump to the corresponding source code, or use `C-x `` to jump to the next failure.
You don't have to. Instead of
``` class FooTest : public BaseTest {};
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
class BarTest : public BaseTest {};
TEST_F(BarTest, Abc) { ... } TEST_F(BarTest, Def) { ... } ```
you can simply `typedef` the test fixtures: ``` typedef BaseTest FooTest;
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
typedef BaseTest BarTest;
TEST_F(BarTest, Abc) { ... } TEST_F(BarTest, Def) { ... } ```
The Google Test output is meant to be a concise and human-friendly report. If your test generates textual output itself, it will mix with the Google Test output, making it hard to read. However, there is an easy solution to this problem.
Since most log messages go to stderr, we decided to let Google Test output go to stdout. This way, you can easily separate the two using redirection. For example: ``` ./my_test > googletest_output.txt ```
There are several good reasons:   1. It's likely your test needs to change the states of its global variables. This makes it difficult to keep side effects from escaping one test and contaminating others, making debugging difficult. By using fixtures, each test has a fresh set of variables that's different (but with the same names). Thus, tests are kept independent of each other.   1. Global variables pollute the global namespace.   1. Test fixtures can be reused via subclassing, which cannot be done easily with global variables. This is useful if many test cases have something in common.
You should try to write testable code, which means classes should be easily tested from their public interface. One way to achieve this is the Pimpl idiom: you move all private members of a class into a helper class, and make all members of the helper class public.
You have several other options that don't require using `FRIEND_TEST`:   * Write the tests as members of the fixture class: ``` class Foo {   friend class FooTest;   ... };
class FooTest : public ::testing::Test {  protected:   ...   void Test1() {...} // This accesses private members of class Foo.   void Test2() {...} // So does this one. };
TEST_F(FooTest, Test1) {   Test1(); }
TEST_F(FooTest, Test2) {   Test2(); } ```   * In the fixture class, write accessors for the tested class' private members, then use the accessors in your tests: ``` class Foo {   friend class FooTest;   ... };
class FooTest : public ::testing::Test {  protected:   ...   T1 get_private_member1(Foo* obj) {     return obj->private_member1_;   } };
TEST_F(FooTest, Test1) {   ...   get_private_member1(x)   ... } ```   * If the methods are declared **protected**, you can change their access level in a test-only subclass: ``` class YourClass {   ...  protected: // protected access for testability.   int DoSomethingReturningInt();   ... };
// in the your_class_test.cc file: class TestableYourClass : public YourClass {   ...  public: using YourClass::DoSomethingReturningInt; // changes access rights   ... };
TEST_F(YourClassTest, DoSomethingTest) {   TestableYourClass obj;   assertEquals(expected_value, obj.DoSomethingReturningInt()); } ```
We find private static methods clutter the header file.  They are implementation details and ideally should be kept out of a .h. So often I make them free functions instead.
Instead of: ``` // foo.h class Foo {   ...  private:   static bool Func(int n); };
// foo.cc bool Foo::Func(int n) { ... }
// foo_test.cc EXPECT_TRUE(Foo::Func(12345)); ```
You probably should better write: ``` // foo.h class Foo {   ... };
// foo.cc namespace internal {   bool Func(int n) { ... } }
// foo_test.cc namespace internal {   bool Func(int n); }
EXPECT_TRUE(internal::Func(12345)); ```
No. You can use a feature called [value-parameterized tests](V1_5_AdvancedGuide.md#Value_Parameterized_Tests) which lets you repeat your tests with different parameters, without defining it more than once.
To test a `foo.cc` file, you need to compile and link it into your unit test program. However, when the file contains a definition for the `main()` function, it will clash with the `main()` of your unit test, and will result in a build error.
The right solution is to split it into three files:   1. `foo.h` which contains the declarations,   1. `foo.cc` which contains the definitions except `main()`, and   1. `foo_main.cc` which contains nothing but the definition of `main()`.
Then `foo.cc` can be easily tested.
If you are adding tests to an existing file and don't want an intrusive change like this, there is a hack: just include the entire `foo.cc` file in your unit test. For example: ``` // File foo_unittest.cc
// The headers section ...
// Renames main() in foo.cc to make room for the unit test main() #define main FooMain
#include "a/b/foo.cc"
// The tests start here. ... ```
However, please remember this is a hack and should only be used as the last resort.
`ASSERT_DEATH(_statement_, _regex_)` (or any death assertion macro) can be used wherever `_statement_` is valid. So basically `_statement_` can be any C++ statement that makes sense in the current context. In particular, it can reference global and/or local variables, and can be:   * a simple function call (often the case),   * a complex expression, or   * a compound statement.
> Some examples are shown here:
``` // A death test can be a simple function call. TEST(MyDeathTest, FunctionCall) {   ASSERT_DEATH(Xyz(5), "Xyz failed"); }
// Or a complex expression that references variables and functions. TEST(MyDeathTest, ComplexExpression) {   const bool c = Condition();   ASSERT_DEATH((c ? Func1(0) : object2.Method("test")),                "(Func1|Method) failed"); }
// Death assertions can be used any where in a function. In // particular, they can be inside a loop. TEST(MyDeathTest, InsideLoop) {   // Verifies that Foo(0), Foo(1), ..., and Foo(4) all die.   for (int i = 0; i < 5; i++) {     EXPECT_DEATH_M(Foo(i), "Foo has \\d+ errors",                    ::testing::Message() << "where i is " << i);   } }
// A death assertion can contain a compound statement. TEST(MyDeathTest, CompoundStatement) {   // Verifies that at lease one of Bar(0), Bar(1), ..., and   // Bar(4) dies.   ASSERT_DEATH({     for (int i = 0; i < 5; i++) {       Bar(i);     }   },   "Bar has \\d+ errors");} ```
`googletest_unittest.cc` contains more examples if you are interested.
On POSIX systems, Google Test uses the POSIX Extended regular expression syntax (http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions). On Windows, it uses a limited variant of regular expression syntax. For more details, see the [regular expression syntax](V1_5_AdvancedGuide.md#Regular_Expression_Syntax).
Google Test needs to be able to create objects of your test fixture class, so it must have a default constructor. Normally the compiler will define one for you. However, there are cases where you have to define your own:   * If you explicitly declare a non-default constructor for class `Foo`, then you need to define a default constructor, even if it would be empty.   * If `Foo` has a const non-static data member, then you have to define the default constructor _and_ initialize the const member in the initializer list of the constructor. (Early versions of `gcc` doesn't force you to initialize the const member. It's a bug that has been fixed in `gcc 4`.)
With the Linux pthread library, there is no turning back once you cross the line from single thread to multiple threads. The first time you create a thread, a manager thread is created in addition, so you get 3, not 2, threads. Later when the thread you create joins the main thread, the thread count decrements by 1, but the manager thread will never be killed, so you still have 2 threads, which means you cannot safely run a death test.
The new NPTL thread library doesn't suffer from this problem, as it doesn't create a manager thread. However, if you don't control which machine your test runs on, you shouldn't depend on this.
Google Test does not interleave tests from different test cases. That is, it runs all tests in one test case first, and then runs all tests in the next test case, and so on. Google Test does this because it needs to set up a test case before the first test in it is run, and tear it down afterwords. Splitting up the test case would require multiple set-up and tear-down processes, which is inefficient and makes the semantics unclean.
If we were to determine the order of tests based on test name instead of test case name, then we would have a problem with the following situation:
``` TEST_F(FooTest, AbcDeathTest) { ... } TEST_F(FooTest, Uvw) { ... }
TEST_F(BarTest, DefDeathTest) { ... } TEST_F(BarTest, Xyz) { ... } ```
Since `FooTest.AbcDeathTest` needs to run before `BarTest.Xyz`, and we don't interleave tests from different test cases, we need to run all tests in the `FooTest` case before running any test in the `BarTest` case. This contradicts with the requirement to run `BarTest.DefDeathTest` before `FooTest.Uvw`.
You don't have to, but if you like, you may split up the test case into `FooTest` and `FooDeathTest`, where the names make it clear that they are related:
``` class FooTest : public ::testing::Test { ... };
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
typedef FooTest FooDeathTest;
TEST_F(FooDeathTest, Uvw) { ... EXPECT_DEATH(...) ... } TEST_F(FooDeathTest, Xyz) { ... ASSERT_DEATH(...) ... } ```
If you use a user-defined type `FooType` in an assertion, you must make sure there is an `std::ostream& operator<<(std::ostream&, const FooType&)` function defined such that we can print a value of `FooType`.
In addition, if `FooType` is declared in a name space, the `<<` operator also needs to be defined in the _same_ name space.
Since the statically initialized Google Test singleton requires allocations on the heap, the Visual C++ memory leak detector will report memory leaks at the end of the program run. The easiest way to avoid this is to use the `_CrtMemCheckpoint` and `_CrtMemDumpAllObjectsSince` calls to not report any statically initialized heap objects. See MSDN for more details and additional heap check/debug routines.
You may get a number of the following linker error or warnings if you attempt to link your test project with the Google Test library when your project and the are not built using the same compiler settings.
* LNK2005: symbol already defined in object   * LNK4217: locally defined symbol 'symbol' imported in function 'function'   * LNK4049: locally defined symbol 'symbol' imported
The Google Test project (gtest.vcproj) has the Runtime Library option set to /MT (use multi-threaded static libraries, /MTd for debug). If your project uses something else, for example /MD (use multi-threaded DLLs, /MDd for debug), you need to change the setting in the Google Test project to match your project's.
To update this setting open the project properties in the Visual Studio IDE then select the branch Configuration Properties | C/C++ | Code Generation and change the option "Runtime Library".  You may also try using gtest-md.vcproj instead of gtest.vcproj.
If you cannot find the answer to your question in this FAQ, there are some other resources you can use:
1. read other [wiki pages](http://code.google.com/p/googletest/w/list),   1. search the mailing list [archive](http://groups.google.com/group/googletestframework/topics),   1. ask it on [googletestframework@googlegroups.com](mailto:googletestframework@googlegroups.com) and someone will answer it (to prevent spam, we require you to join the [discussion group](http://groups.google.com/group/googletestframework) before you can post.).
Please note that creating an issue in the [issue tracker](http://code.google.com/p/googletest/issues/list) is _not_ a good way to get your answer, as it is monitored infrequently by a very small number of people.
When asking a question, it's helpful to provide as much of the following information as possible (people cannot help you if there's not enough information in your question):
* the version (or the revision number if you check out from SVN directly) of Google Test you use (Google Test is under active development, so it's possible that your problem has been solved in a later version),   * your operating system,   * the name and version of your compiler,   * the complete command line flags you give to your compiler,   * the complete compiler error messages (if the question is about compilation),   * the _actual_ code (ideally, a minimal but complete program) that has the problem you encounter.

_Google C++ Testing Framework_ helps you write better C++ tests.
No matter whether you work on Linux, Windows, or a Mac, if you write C++ code, Google Test can help you.
So what makes a good test, and how does Google C++ Testing Framework fit in? We believe:   1. Tests should be _independent_ and _repeatable_. It's a pain to debug a test that succeeds or fails as a result of other tests.  Google C++ Testing Framework isolates the tests by running each of them on a different object. When a test fails, Google C++ Testing Framework allows you to run it in isolation for quick debugging.   1. Tests should be well _organized_ and reflect the structure of the tested code.  Google C++ Testing Framework groups related tests into test cases that can share data and subroutines. This common pattern is easy to recognize and makes tests easy to maintain. Such consistency is especially helpful when people switch projects and start to work on a new code base.   1. Tests should be _portable_ and _reusable_. The open-source community has a lot of code that is platform-neutral, its tests should also be platform-neutral.  Google C++ Testing Framework works on different OSes, with different compilers (gcc, MSVC, and others), with or without exceptions, so Google C++ Testing Framework tests can easily work with a variety of configurations.  (Note that the current release only contains build scripts for Linux - we are actively working on scripts for other platforms.)   1. When tests fail, they should provide as much _information_ about the problem as possible. Google C++ Testing Framework doesn't stop at the first test failure. Instead, it only stops the current test and continues with the next. You can also set up tests that report non-fatal failures after which the current test continues. Thus, you can detect and fix multiple bugs in a single run-edit-compile cycle.   1. The testing framework should liberate test writers from housekeeping chores and let them focus on the test _content_.  Google C++ Testing Framework automatically keeps track of all tests defined, and doesn't require the user to enumerate them in order to run them.   1. Tests should be _fast_. With Google C++ Testing Framework, you can reuse shared resources across tests and pay for the set-up/tear-down only once, without making tests depend on each other.
Since Google C++ Testing Framework is based on the popular xUnit architecture, you'll feel right at home if you've used JUnit or PyUnit before. If not, it will take you about 10 minutes to learn the basics and get started. So let's go!
_Note:_ We sometimes refer to Google C++ Testing Framework informally as _Google Test_.
To write a test program using Google Test, you need to compile Google Test into a library and link your test with it.  We provide build files for some popular build systems (`msvc/` for Visual Studio, `xcode/` for Mac Xcode, `make/` for GNU make, `codegear/` for Borland C++ Builder, and the autotools script in the Google Test root directory).  If your build system is not on this list, you can take a look at `make/Makefile` to learn how Google Test should be compiled (basically you want to compile `src/gtest-all.cc` with `GTEST_ROOT` and `GTEST_ROOT/include` in the header search path, where `GTEST_ROOT` is the Google Test root directory).
Once you are able to compile the Google Test library, you should create a project or build target for your test program.  Make sure you have `GTEST_ROOT/include` in the header search path so that the compiler can find `<gtest/gtest.h>` when compiling your test.  Set up your test project to link with the Google Test library (for example, in Visual Studio, this is done by adding a dependency on `gtest.vcproj`).
If you still have questions, take a look at how Google Test's own tests are built and use them as examples.
When using Google Test, you start by writing _assertions_, which are statements that check whether a condition is true. An assertion's result can be _success_, _nonfatal failure_, or _fatal failure_. If a fatal failure occurs, it aborts the current function; otherwise the program continues normally.
_Tests_ use assertions to verify the tested code's behavior. If a test crashes or has a failed assertion, then it _fails_; otherwise it _succeeds_.
A _test case_ contains one or many tests. You should group your tests into test cases that reflect the structure of the tested code. When multiple tests in a test case need to share common objects and subroutines, you can put them into a _test fixture_ class.
A _test program_ can contain multiple test cases.
We'll now explain how to write a test program, starting at the individual assertion level and building up to tests and test cases.
Google Test assertions are macros that resemble function calls. You test a class or function by making assertions about its behavior. When an assertion fails, Google Test prints the assertion's source file and line number location, along with a failure message. You may also supply a custom failure message which will be appended to Google Test's message.
The assertions come in pairs that test the same thing but have different effects on the current function. `ASSERT_*` versions generate fatal failures when they fail, and **abort the current function**. `EXPECT_*` versions generate nonfatal failures, which don't abort the current function. Usually `EXPECT_*` are preferred, as they allow more than one failures to be reported in a test. However, you should use `ASSERT_*` if it doesn't make sense to continue when the assertion in question fails.
Since a failed `ASSERT_*` returns from the current function immediately, possibly skipping clean-up code that comes after it, it may cause a space leak. Depending on the nature of the leak, it may or may not be worth fixing - so keep this in mind if you get a heap checker error in addition to assertion errors.
To provide a custom failure message, simply stream it into the macro using the `<<` operator, or a sequence of such operators. An example: ``` ASSERT_EQ(x.size(), y.size()) << "Vectors x and y are of unequal length";
for (int i = 0; i < x.size(); ++i) {   EXPECT_EQ(x[i], y[i]) << "Vectors x and y differ at index " << i; } ```
Anything that can be streamed to an `ostream` can be streamed to an assertion macro--in particular, C strings and `string` objects. If a wide string (`wchar_t*`, `TCHAR*` in `UNICODE` mode on Windows, or `std::wstring`) is streamed to an assertion, it will be translated to UTF-8 when printed.
These assertions do basic true/false condition testing. | **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_TRUE(`_condition_`)`;  | `EXPECT_TRUE(`_condition_`)`;   | _condition_ is true | | `ASSERT_FALSE(`_condition_`)`; | `EXPECT_FALSE(`_condition_`)`;  | _condition_ is false |
Remember, when they fail, `ASSERT_*` yields a fatal failure and returns from the current function, while `EXPECT_*` yields a nonfatal failure, allowing the function to continue running. In either case, an assertion failure means its containing test fails.
_Availability_: Linux, Windows, Mac.
This section describes assertions that compare two values.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| |`ASSERT_EQ(`_expected_`, `_actual_`);`|`EXPECT_EQ(`_expected_`, `_actual_`);`| _expected_ `==` _actual_ | |`ASSERT_NE(`_val1_`, `_val2_`);`      |`EXPECT_NE(`_val1_`, `_val2_`);`      | _val1_ `!=` _val2_ | |`ASSERT_LT(`_val1_`, `_val2_`);`      |`EXPECT_LT(`_val1_`, `_val2_`);`      | _val1_ `<` _val2_ | |`ASSERT_LE(`_val1_`, `_val2_`);`      |`EXPECT_LE(`_val1_`, `_val2_`);`      | _val1_ `<=` _val2_ | |`ASSERT_GT(`_val1_`, `_val2_`);`      |`EXPECT_GT(`_val1_`, `_val2_`);`      | _val1_ `>` _val2_ | |`ASSERT_GE(`_val1_`, `_val2_`);`      |`EXPECT_GE(`_val1_`, `_val2_`);`      | _val1_ `>=` _val2_ |
In the event of a failure, Google Test prints both _val1_ and _val2_ . In `ASSERT_EQ*` and `EXPECT_EQ*` (and all other equality assertions we'll introduce later), you should put the expression you want to test in the position of _actual_, and put its expected value in _expected_, as Google Test's failure messages are optimized for this convention.
Value arguments must be comparable by the assertion's comparison operator or you'll get a compiler error. Values must also support the `<<` operator for streaming to an `ostream`. All built-in types support this.
These assertions can work with a user-defined type, but only if you define the corresponding comparison operator (e.g. `==`, `<`, etc).  If the corresponding operator is defined, prefer using the `ASSERT_*()` macros because they will print out not only the result of the comparison, but the two operands as well.
Arguments are always evaluated exactly once. Therefore, it's OK for the arguments to have side effects. However, as with any ordinary C/C++ function, the arguments' evaluation order is undefined (i.e. the compiler is free to choose any order) and your code should not depend on any particular argument evaluation order.
`ASSERT_EQ()` does pointer equality on pointers. If used on two C strings, it tests if they are in the same memory location, not if they have the same value. Therefore, if you want to compare C strings (e.g. `const char*`) by value, use `ASSERT_STREQ()` , which will be described later on. In particular, to assert that a C string is `NULL`, use `ASSERT_STREQ(NULL, c_string)` . However, to compare two `string` objects, you should use `ASSERT_EQ`.
Macros in this section work with both narrow and wide string objects (`string` and `wstring`).
_Availability_: Linux, Windows, Mac.
The assertions in this group compare two **C strings**. If you want to compare two `string` objects, use `EXPECT_EQ`, `EXPECT_NE`, and etc instead.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_STREQ(`_expected\_str_`, `_actual\_str_`);`    | `EXPECT_STREQ(`_expected\_str_`, `_actual\_str_`);`     | the two C strings have the same content | | `ASSERT_STRNE(`_str1_`, `_str2_`);`    | `EXPECT_STRNE(`_str1_`, `_str2_`);`     | the two C strings have different content | | `ASSERT_STRCASEEQ(`_expected\_str_`, `_actual\_str_`);`| `EXPECT_STRCASEEQ(`_expected\_str_`, `_actual\_str_`);` | the two C strings have the same content, ignoring case | | `ASSERT_STRCASENE(`_str1_`, `_str2_`);`| `EXPECT_STRCASENE(`_str1_`, `_str2_`);` | the two C strings have different content, ignoring case |
Note that "CASE" in an assertion name means that case is ignored.
`*STREQ*` and `*STRNE*` also accept wide C strings (`wchar_t*`). If a comparison of two wide strings fails, their values will be printed as UTF-8 narrow strings.
A `NULL` pointer and an empty string are considered _different_.
_Availability_: Linux, Windows, Mac.
See also: For more string comparison tricks (substring, prefix, suffix, and regular expression matching, for example), see the [AdvancedGuide Advanced Google Test Guide].
To create a test:   1. Use the `TEST()` macro to define and name a test function, These are ordinary C++ functions that don't return a value.   1. In this function, along with any valid C++ statements you want to include, use the various Google Test assertions to check values.   1. The test's result is determined by the assertions; if any assertion in the test fails (either fatally or non-fatally), or if the test crashes, the entire test fails. Otherwise, it succeeds.
``` TEST(test_case_name, test_name) {  ... test body ... } ```
`TEST()` arguments go from general to specific. The _first_ argument is the name of the test case, and the _second_ argument is the test's name within the test case. Remember that a test case can contain any number of individual tests. A test's _full name_ consists of its containing test case and its individual name. Tests from different test cases can have the same individual name.
For example, let's take a simple integer function: ``` int Factorial(int n); // Returns the factorial of n ```
A test case for this function might look like: ``` // Tests factorial of 0. TEST(FactorialTest, HandlesZeroInput) {   EXPECT_EQ(1, Factorial(0)); }
// Tests factorial of positive numbers. TEST(FactorialTest, HandlesPositiveInput) {   EXPECT_EQ(1, Factorial(1));   EXPECT_EQ(2, Factorial(2));   EXPECT_EQ(6, Factorial(3));   EXPECT_EQ(40320, Factorial(8)); } ```
Google Test groups the test results by test cases, so logically-related tests should be in the same test case; in other words, the first argument to their `TEST()` should be the same. In the above example, we have two tests, `HandlesZeroInput` and `HandlesPositiveInput`, that belong to the same test case `FactorialTest`.
_Availability_: Linux, Windows, Mac.
If you find yourself writing two or more tests that operate on similar data, you can use a _test fixture_. It allows you to reuse the same configuration of objects for several different tests.
To create a fixture, just:   1. Derive a class from `::testing::Test` . Start its body with `protected:` or `public:` as we'll want to access fixture members from sub-classes.   1. Inside the class, declare any objects you plan to use.   1. If necessary, write a default constructor or `SetUp()` function to prepare the objects for each test. A common mistake is to spell `SetUp()` as `Setup()` with a small `u` - don't let that happen to you.   1. If necessary, write a destructor or `TearDown()` function to release any resources you allocated in `SetUp()` . To learn when you should use the constructor/destructor and when you should use `SetUp()/TearDown()`, read this [FAQ entry](V1_5_FAQ.md#should-i-use-the-constructordestructor-of-the-test-fixture-or-the-set-uptear-down-function).   1. If needed, define subroutines for your tests to share.
When using a fixture, use `TEST_F()` instead of `TEST()` as it allows you to access objects and subroutines in the test fixture: ``` TEST_F(test_case_name, test_name) {  ... test body ... } ```
Like `TEST()`, the first argument is the test case name, but for `TEST_F()` this must be the name of the test fixture class. You've probably guessed: `_F` is for fixture.
Unfortunately, the C++ macro system does not allow us to create a single macro that can handle both types of tests. Using the wrong macro causes a compiler error.
Also, you must first define a test fixture class before using it in a `TEST_F()`, or you'll get the compiler error "`virtual outside class declaration`".
For each test defined with `TEST_F()`, Google Test will:   1. Create a _fresh_ test fixture at runtime   1. Immediately initialize it via `SetUp()` ,   1. Run the test   1. Clean up by calling `TearDown()`   1. Delete the test fixture.  Note that different tests in the same test case have different test fixture objects, and Google Test always deletes a test fixture before it creates the next one. Google Test does not reuse the same test fixture for multiple tests. Any changes one test makes to the fixture do not affect other tests.
As an example, let's write tests for a FIFO queue class named `Queue`, which has the following interface: ``` template <typename E> // E is the element type. class Queue {  public:   Queue();   void Enqueue(const E& element);   E* Dequeue(); // Returns NULL if the queue is empty.   size_t size() const;   ... }; ```
First, define a fixture class. By convention, you should give it the name `FooTest` where `Foo` is the class being tested. ``` class QueueTest : public ::testing::Test {  protected:   virtual void SetUp() {     q1_.Enqueue(1);     q2_.Enqueue(2);     q2_.Enqueue(3);   }
// virtual void TearDown() {}
Queue<int> q0_;   Queue<int> q1_;   Queue<int> q2_; }; ```
In this case, `TearDown()` is not needed since we don't have to clean up after each test, other than what's already done by the destructor.
Now we'll write tests using `TEST_F()` and this fixture. ``` TEST_F(QueueTest, IsEmptyInitially) {   EXPECT_EQ(0, q0_.size()); }
TEST_F(QueueTest, DequeueWorks) {   int* n = q0_.Dequeue();   EXPECT_EQ(NULL, n);
n = q1_.Dequeue();   ASSERT_TRUE(n != NULL);   EXPECT_EQ(1, *n);   EXPECT_EQ(0, q1_.size());   delete n;
n = q2_.Dequeue();   ASSERT_TRUE(n != NULL);   EXPECT_EQ(2, *n);   EXPECT_EQ(1, q2_.size());   delete n; } ```
The above uses both `ASSERT_*` and `EXPECT_*` assertions. The rule of thumb is to use `EXPECT_*` when you want the test to continue to reveal more errors after the assertion failure, and use `ASSERT_*` when continuing after failure doesn't make sense. For example, the second assertion in the `Dequeue` test is `ASSERT_TRUE(n != NULL)`, as we need to dereference the pointer `n` later, which would lead to a segfault when `n` is `NULL`.
When these tests run, the following happens:   1. Google Test constructs a `QueueTest` object (let's call it `t1` ).   1. `t1.SetUp()` initializes `t1` .   1. The first test ( `IsEmptyInitially` ) runs on `t1` .   1. `t1.TearDown()` cleans up after the test finishes.   1. `t1` is destructed.   1. The above steps are repeated on another `QueueTest` object, this time running the `DequeueWorks` test.
_Availability_: Linux, Windows, Mac.
_Note_: Google Test automatically saves all _Google Test_ flags when a test object is constructed, and restores them when it is destructed.
`TEST()` and `TEST_F()` implicitly register their tests with Google Test. So, unlike with many other C++ testing frameworks, you don't have to re-list all your defined tests in order to run them.
After defining your tests, you can run them with `RUN_ALL_TESTS()` , which returns `0` if all the tests are successful, or `1` otherwise. Note that `RUN_ALL_TESTS()` runs _all tests_ in your link unit -- they can be from different test cases, or even different source files.
When invoked, the `RUN_ALL_TESTS()` macro:   1. Saves the state of all  Google Test flags.   1. Creates a test fixture object for the first test.   1. Initializes it via `SetUp()`.   1. Runs the test on the fixture object.   1. Cleans up the fixture via `TearDown()`.   1. Deletes the fixture.   1. Restores the state of all Google Test flags.   1. Repeats the above steps for the next test, until all tests have run.
In addition, if the text fixture's constructor generates a fatal failure in step 2, there is no point for step 3 - 5 and they are thus skipped. Similarly, if step 3 generates a fatal failure, step 4 will be skipped.
_Important_: You must not ignore the return value of `RUN_ALL_TESTS()`, or `gcc` will give you a compiler error. The rationale for this design is that the automated testing service determines whether a test has passed based on its exit code, not on its stdout/stderr output; thus your `main()` function must return the value of `RUN_ALL_TESTS()`.
Also, you should call `RUN_ALL_TESTS()` only **once**. Calling it more than once conflicts with some advanced Google Test features (e.g. thread-safe death tests) and thus is not supported.
_Availability_: Linux, Windows, Mac.
You can start from this boilerplate: ``` #include "this/package/foo.h" #include <gtest/gtest.h>
namespace {
// The fixture for testing class Foo. class FooTest : public ::testing::Test {  protected:   // You can remove any or all of the following functions if its body   // is empty.
FooTest() {     // You can do set-up work for each test here.   }
virtual ~FooTest() {     // You can do clean-up work that doesn't throw exceptions here.   }
// If the constructor and destructor are not enough for setting up   // and cleaning up each test, you can define the following methods:
virtual void SetUp() {     // Code here will be called immediately after the constructor (right     // before each test).   }
virtual void TearDown() {     // Code here will be called immediately after each test (right     // before the destructor).   }
// Objects declared here can be used by all tests in the test case for Foo. };
// Tests that the Foo::Bar() method does Abc. TEST_F(FooTest, MethodBarDoesAbc) {   const string input_filepath = "this/package/testdata/myinputfile.dat";   const string output_filepath = "this/package/testdata/myoutputfile.dat";   Foo f;   EXPECT_EQ(0, f.Bar(input_filepath, output_filepath)); }
// Tests that Foo does Xyz. TEST_F(FooTest, DoesXyz) {   // Exercises the Xyz feature of Foo. }
}  // namespace
int main(int argc, char **argv) {   ::testing::InitGoogleTest(&argc, argv);   return RUN_ALL_TESTS(); } ```
The `::testing::InitGoogleTest()` function parses the command line for Google Test flags, and removes all recognized flags. This allows the user to control a test program's behavior via various flags, which we'll cover in [AdvancedGuide](V1_5_AdvancedGuide.md). You must call this function before calling `RUN_ALL_TESTS()`, or the flags won't be properly initialized.
On Windows, `InitGoogleTest()` also works with wide strings, so it can be used in programs compiled in `UNICODE` mode as well.
But maybe you think that writing all those main() functions is too much work? We agree with you completely and that's why Google Test provides a basic implementation of main(). If it fits your needs, then just link your test with gtest\_main library and you are good to go.
In addition, if you define your tests in a static library, add `/OPT:NOREF` to your main program linker options. If you use MSVC++ IDE, go to your .exe project properties/Configuration Properties/Linker/Optimization and set References setting to `Keep Unreferenced Data (/OPT:NOREF)`. This will keep Visual C++ linker from discarding individual symbols generated by your tests from the final executable.
There is one more pitfall, though. If you use Google Test as a static library (that's how it is defined in gtest.vcproj) your tests must also reside in a static library. If you have to have them in a DLL, you _must_ change Google Test to build into a DLL as well. Otherwise your tests will not run correctly or will not run at all. The general conclusion here is: make your life easier - do not write your tests in libraries!
Congratulations! You've learned the Google Test basics. You can start writing and running Google Test tests, read some [samples](Samples.md), or continue with [AdvancedGuide](V1_5_AdvancedGuide.md), which describes many more useful Google Test features.
Google Test is designed to be thread-safe.  The implementation is thread-safe on systems where the `pthreads` library is available.  It is currently _unsafe_ to use Google Test assertions from two threads concurrently on other systems (e.g. Windows).  In most tests this is not an issue as usually the assertions are done in the main thread. If you want to help, you can volunteer to implement the necessary synchronization primitives in `gtest-port.h` for your platform.

<b>P</b>ump is <b>U</b>seful for <b>M</b>eta <b>P</b>rogramming.
Template and macro libraries often need to define many classes, functions, or macros that vary only (or almost only) in the number of arguments they take. It's a lot of repetitive, mechanical, and error-prone work.
Variadic templates and variadic macros can alleviate the problem. However, while both are being considered by the C++ committee, neither is in the standard yet or widely supported by compilers.  Thus they are often not a good choice, especially when your code needs to be portable. And their capabilities are still limited.
As a result, authors of such libraries often have to write scripts to generate their implementation. However, our experience is that it's tedious to write such scripts, which tend to reflect the structure of the generated code poorly and are often hard to read and edit. For example, a small change needed in the generated code may require some non-intuitive, non-trivial changes in the script. This is especially painful when experimenting with the code.
Pump (for Pump is Useful for Meta Programming, Pretty Useful for Meta Programming, or Practical Utility for Meta Programming, whichever you prefer) is a simple meta-programming tool for C++. The idea is that a programmer writes a `foo.pump` file which contains C++ code plus meta code that manipulates the C++ code. The meta code can handle iterations over a range, nested iterations, local meta variable definitions, simple arithmetic, and conditional expressions. You can view it as a small Domain-Specific Language. The meta language is designed to be non-intrusive (s.t. it won't confuse Emacs' C++ mode, for example) and concise, making Pump code intuitive and easy to maintain.
* The implementation is in a single Python script and thus ultra portable: no build or installation is needed and it works cross platforms.   * Pump tries to be smart with respect to [Google's style guide](http://code.google.com/p/google-styleguide/): it breaks long lines (easy to have when they are generated) at acceptable places to fit within 80 columns and indent the continuation lines correctly.   * The format is human-readable and more concise than XML.   * The format works relatively well with Emacs' C++ mode.
The following Pump code (where meta keywords start with `$`, `[[` and `]]` are meta brackets, and `$$` starts a meta comment that ends with the line):
``` $var n = 3     $$ Defines a meta variable n. $range i 0..n  $$ Declares the range of meta iterator i (inclusive). $for i [[                $$ Meta loop. // Foo$i does blah for $i-ary predicates. $range j 1..i template <size_t N $for j [[, typename A$j]]> class Foo$i { $if i == 0 [[   blah a; ]] $elif i <= 2 [[   blah b; ]] $else [[   blah c; ]] };
]] ```
will be translated by the Pump compiler to:
``` // Foo0 does blah for 0-ary predicates. template <size_t N> class Foo0 {   blah a; };
// Foo1 does blah for 1-ary predicates. template <size_t N, typename A1> class Foo1 {   blah b; };
// Foo2 does blah for 2-ary predicates. template <size_t N, typename A1, typename A2> class Foo2 {   blah b; };
// Foo3 does blah for 3-ary predicates. template <size_t N, typename A1, typename A2, typename A3> class Foo3 {   blah c; }; ```
In another example,
``` $range i 1..n Func($for i + [[a$i]]); $$ The text between i and [[ is the separator between iterations. ```
will generate one of the following lines (without the comments), depending on the value of `n`:
``` Func();              // If n is 0. Func(a1);            // If n is 1. Func(a1 + a2);       // If n is 2. Func(a1 + a2 + a3);  // If n is 3. // And so on... ```
We support the following meta programming constructs:
| `$var id = exp` | Defines a named constant value. `$id` is valid util the end of the current meta lexical block. | |:----------------|:-----------------------------------------------------------------------------------------------| | $range id exp..exp | Sets the range of an iteration variable, which can be reused in multiple loops later.          | | $for id sep [[code ](.md)] | Iteration. The range of `id` must have been defined earlier. `$id` is valid in `code`.         | | `$($)`          | Generates a single `$` character.                                                              | | `$id`           | Value of the named constant or iteration variable.                                             | | `$(exp)`        | Value of the expression.                                                                       | | `$if exp [[ code ]] else_branch` | Conditional.                                                                                   | | `[[ code ]]`    | Meta lexical block.                                                                            | | `cpp_code`      | Raw C++ code.                                                                                  | | `$$ comment`    | Meta comment.                                                                                  |
**Note:** To give the user some freedom in formatting the Pump source code, Pump ignores a new-line character if it's right after `$for foo` or next to `[[` or `]]`. Without this rule you'll often be forced to write very long lines to get the desired output. Therefore sometimes you may need to insert an extra new-line in such places for a new-line to show up in your output.
``` code ::= atomic_code* atomic_code ::= $var id = exp     | $var id = [[ code ]]     | $range id exp..exp     | $for id sep [[ code ]]     | $($)     | $id     | $(exp)     | $if exp [[ code ]] else_branch     | [[ code ]]     | cpp_code sep ::= cpp_code | empty_string else_branch ::= $else [[ code ]]     | $elif exp [[ code ]] else_branch     | empty_string exp ::= simple_expression_in_Python_syntax ```
You can find the source code of Pump in [scripts/pump.py](http://code.google.com/p/googletest/source/browse/trunk/scripts/pump.py). It is still very unpolished and lacks automated tests, although it has been successfully used many times. If you find a chance to use it in your project, please let us know what you think!  We also welcome help on improving Pump.
You can find real-world applications of Pump in [Google Test](http://www.google.com/codesearch?q=file%3A\.pump%24+package%3Ahttp%3A%2F%2Fgoogletest\.googlecode\.com) and [Google Mock](http://www.google.com/codesearch?q=file%3A\.pump%24+package%3Ahttp%3A%2F%2Fgooglemock\.googlecode\.com).  The source file `foo.h.pump` generates `foo.h`.
* If a meta variable is followed by a letter or digit, you can separate them using `[[]]`, which inserts an empty string. For example `Foo$j[[]]Helper` generate `Foo1Helper` when `j` is 1.   * To avoid extra-long Pump source lines, you can break a line anywhere you want by inserting `[[]]` followed by a new line. Since any new-line character next to `[[` or `]]` is ignored, the generated code won't contain this new line.

This guide will explain how to use the Google Testing Framework in your Xcode projects on Mac OS X. This tutorial begins by quickly explaining what to do for experienced users. After the quick start, the guide goes provides additional explanation about each step.
Here is the quick guide for using Google Test in your Xcode project.
1. Download the source from the [website](http://code.google.com/p/googletest) using this command: `svn checkout http://googletest.googlecode.com/svn/trunk/ googletest-read-only`   1. Open up the `gtest.xcodeproj` in the `googletest-read-only/xcode/` directory and build the gtest.framework.   1. Create a new "Shell Tool" target in your Xcode project called something like "UnitTests"   1. Add the gtest.framework to your project and add it to the "Link Binary with Libraries" build phase of "UnitTests"   1. Add your unit test source code to the "Compile Sources" build phase of "UnitTests"   1. Edit the "UnitTests" executable and add an environment variable named "DYLD\_FRAMEWORK\_PATH" with a value equal to the path to the framework containing the gtest.framework relative to the compiled executable.   1. Build and Go
The following sections further explain each of the steps listed above in depth, describing in more detail how to complete it including some variations.
Currently, the gtest.framework discussed here isn't available in a tagged release of Google Test, it is only available in the trunk. As explained at the Google Test [site](http://code.google.com/p/googletest/source/checkout">svn), you can get the code from anonymous SVN with this command:
``` svn checkout http://googletest.googlecode.com/svn/trunk/ googletest-read-only ```
Alternatively, if you are working with Subversion in your own code base, you can add Google Test as an external dependency to your own Subversion repository. By following this approach, everyone that checks out your svn repository will also receive a copy of Google Test (a specific version, if you wish) without having to check it out explicitly. This makes the set up of your project simpler and reduces the copied code in the repository.
To use `svn:externals`, decide where you would like to have the external source reside. You might choose to put the external source inside the trunk, because you want it to be part of the branch when you make a release. However, keeping it outside the trunk in a version-tagged directory called something like `third-party/googletest/1.0.1`, is another option. Once the location is established, use `svn propedit svn:externals _directory_` to set the svn:externals property on a directory in your repository. This directory won't contain the code, but be its versioned parent directory.
The command `svn propedit` will bring up your Subversion editor, making editing the long, (potentially multi-line) property simpler. This same method can be used to check out a tagged branch, by using the appropriate URL (e.g. `http://googletest.googlecode.com/svn/tags/release-1.0.1`). Additionally, the svn:externals property allows the specification of a particular revision of the trunk with the `-r_##_` option (e.g. `externals/src/googletest -r60 http://googletest.googlecode.com/svn/trunk`).
Here is an example of using the svn:externals properties on a trunk (read via `svn propget`) of a project. This value checks out a copy of Google Test into the `trunk/externals/src/googletest/` directory.
``` [Computer:svn] user$ svn propget svn:externals trunk externals/src/googletest http://googletest.googlecode.com/svn/trunk ```
The next step is to build and add the gtest.framework to your own project. This guide describes two common ways below.
* **Option 1** --- The simplest way to add Google Test to your own project, is to open gtest.xcodeproj (found in the xcode/ directory of the Google Test trunk) and build the framework manually. Then, add the built framework into your project using the "Add->Existing Framework..." from the context menu or "Project->Add..." from the main menu. The gtest.framework is relocatable and contains the headers and object code that you'll need to make tests. This method requires rebuilding every time you upgrade Google Test in your project.   * **Option 2** --- If you are going to be living off the trunk of Google Test, incorporating its latest features into your unit tests (or are a Google Test developer yourself). You'll want to rebuild the framework every time the source updates. to do this, you'll need to add the gtest.xcodeproj file, not the framework itself, to your own Xcode project. Then, from the build products that are revealed by the project's disclosure triangle, you can find the gtest.framework, which can be added to your targets (discussed below).
To start writing tests, make a new "Shell Tool" target. This target template is available under BSD, Cocoa, or Carbon. Add your unit test source code to the "Compile Sources" build phase of the target.
Next, you'll want to add gtest.framework in two different ways, depending upon which option you chose above.
* **Option 1** --- During compilation, Xcode will need to know that you are linking against the gtest.framework. Add the gtest.framework to the "Link Binary with Libraries" build phase of your test target. This will include the Google Test headers in your header search path, and will tell the linker where to find the library.   * **Option 2** --- If your working out of the trunk, you'll also want to add gtest.framework to your "Link Binary with Libraries" build phase of your test target. In addition, you'll  want to add the gtest.framework as a dependency to your unit test target. This way, Xcode will make sure that gtest.framework is up to date, every time your build your target. Finally, if you don't share build directories with Google Test, you'll have to copy the gtest.framework into your own build products directory using a "Run Script" build phase.
Since the unit test executable is a shell tool, it doesn't have a bundle with a `Contents/Frameworks` directory, in which to place gtest.framework. Instead, the dynamic linker must be told at runtime to search for the framework in another location. This can be accomplished by setting the "DYLD\_FRAMEWORK\_PATH" environment variable in the "Edit Active Executable ..." Arguments tab, under "Variables to be set in the environment:". The path for this value is the path (relative or absolute) of the directory containing the gtest.framework.
If you haven't set up the DYLD\_FRAMEWORK\_PATH, correctly, you might get a message like this:
``` [Session started at 2008-08-15 06:23:57 -0600.]   dyld: Library not loaded: @loader_path/../Frameworks/gtest.framework/Versions/A/gtest     Referenced from: /Users/username/Documents/Sandbox/gtestSample/build/Debug/WidgetFrameworkTest     Reason: image not found ```
To correct this problem, got to the directory containing the executable named in "Referenced from:" value in the error message above. Then, with the terminal in this location, find the relative path to the directory containing the gtest.framework. That is the value you'll need to set as the DYLD\_FRAMEWORK\_PATH.
Now, when you click "Build and Go", the test will be executed. Dumping out something like this:
``` [Session started at 2008-08-06 06:36:13 -0600.] [==========] Running 2 tests from 1 test case. [----------] Global test environment set-up. [----------] 2 tests from WidgetInitializerTest [ RUN      ] WidgetInitializerTest.TestConstructor [       OK ] WidgetInitializerTest.TestConstructor [ RUN      ] WidgetInitializerTest.TestConversion [       OK ] WidgetInitializerTest.TestConversion [----------] Global test environment tear-down [==========] 2 tests from 1 test case ran. [  PASSED  ] 2 tests.
The Debugger has exited with status 0.   ```
Unit testing is a valuable way to ensure your data model stays valid even during rapid development or refactoring. The Google Testing Framework is a great unit testing framework for C and C++ which integrates well with an Xcode development environment.

Now that you have read [Primer](V1_6_Primer.md) and learned how to write tests using Google Test, it's time to learn some new tricks. This document will show you more assertions as well as how to construct complex failure messages, propagate fatal failures, reuse and speed up your test fixtures, and use various flags with your tests.
This section covers some less frequently used, but still significant, assertions.
These three assertions do not actually test a value or expression. Instead, they generate a success or failure directly. Like the macros that actually perform a test, you may stream a custom failure message into the them.
| `SUCCEED();` | |:-------------|
Generates a success. This does NOT make the overall test succeed. A test is considered successful only if none of its assertions fail during its execution.
Note: `SUCCEED()` is purely documentary and currently doesn't generate any user-visible output. However, we may add `SUCCEED()` messages to Google Test's output in the future.
| `FAIL();`  | `ADD_FAILURE();` | `ADD_FAILURE_AT("`_file\_path_`", `_line\_number_`);` | |:-----------|:-----------------|:------------------------------------------------------|
`FAIL()` generates a fatal failure, while `ADD_FAILURE()` and `ADD_FAILURE_AT()` generate a nonfatal failure. These are useful when control flow, rather than a Boolean expression, deteremines the test's success or failure. For example, you might want to write something like:
``` switch(expression) {   case 1: ... some checks ...   case 2: ... some other checks   ...   default: FAIL() << "We shouldn't get here."; } ```
_Availability_: Linux, Windows, Mac.
These are for verifying that a piece of code throws (or does not throw) an exception of the given type:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_THROW(`_statement_, _exception\_type_`);`  | `EXPECT_THROW(`_statement_, _exception\_type_`);`  | _statement_ throws an exception of the given type  | | `ASSERT_ANY_THROW(`_statement_`);`                | `EXPECT_ANY_THROW(`_statement_`);`                | _statement_ throws an exception of any type        | | `ASSERT_NO_THROW(`_statement_`);`                 | `EXPECT_NO_THROW(`_statement_`);`                 | _statement_ doesn't throw any exception            |
Examples:
``` ASSERT_THROW(Foo(5), bar_exception);
EXPECT_NO_THROW({   int n = 5;   Bar(&n); }); ```
_Availability_: Linux, Windows, Mac; since version 1.1.0.
Even though Google Test has a rich set of assertions, they can never be complete, as it's impossible (nor a good idea) to anticipate all the scenarios a user might run into. Therefore, sometimes a user has to use `EXPECT_TRUE()` to check a complex expression, for lack of a better macro. This has the problem of not showing you the values of the parts of the expression, making it hard to understand what went wrong. As a workaround, some users choose to construct the failure message by themselves, streaming it into `EXPECT_TRUE()`. However, this is awkward especially when the expression has side-effects or is expensive to evaluate.
Google Test gives you three different options to solve this problem:
If you already have a function or a functor that returns `bool` (or a type that can be implicitly converted to `bool`), you can use it in a _predicate assertion_ to get the function arguments printed for free:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_PRED1(`_pred1, val1_`);`       | `EXPECT_PRED1(`_pred1, val1_`);` | _pred1(val1)_ returns true | | `ASSERT_PRED2(`_pred2, val1, val2_`);` | `EXPECT_PRED2(`_pred2, val1, val2_`);` |  _pred2(val1, val2)_ returns true | |  ...                | ...                    | ...          |
In the above, _predn_ is an _n_-ary predicate function or functor, where _val1_, _val2_, ..., and _valn_ are its arguments. The assertion succeeds if the predicate returns `true` when applied to the given arguments, and fails otherwise. When the assertion fails, it prints the value of each argument. In either case, the arguments are evaluated exactly once.
Here's an example. Given
``` // Returns true iff m and n have no common divisors except 1. bool MutuallyPrime(int m, int n) { ... } const int a = 3; const int b = 4; const int c = 10; ```
the assertion `EXPECT_PRED2(MutuallyPrime, a, b);` will succeed, while the assertion `EXPECT_PRED2(MutuallyPrime, b, c);` will fail with the message
<pre> !MutuallyPrime(b, c) is false, where<br> b is 4<br> c is 10<br> </pre>
**Notes:**
1. If you see a compiler error "no matching function to call" when using `ASSERT_PRED*` or `EXPECT_PRED*`, please see [this](v1_6_FAQ.md#ithe-compiler-complains-about-undefined-references-to-some-static-const-member-variables-but-i-did-define-them-in-the-class-body-whats-wrong) for how to resolve it.   1. Currently we only provide predicate assertions of arity <= 5. If you need a higher-arity assertion, let us know.
_Availability_: Linux, Windows, Mac
While `EXPECT_PRED*()` and friends are handy for a quick job, the syntax is not satisfactory: you have to use different macros for different arities, and it feels more like Lisp than C++.  The `::testing::AssertionResult` class solves this problem.
An `AssertionResult` object represents the result of an assertion (whether it's a success or a failure, and an associated message).  You can create an `AssertionResult` using one of these factory functions:
``` namespace testing {
// Returns an AssertionResult object to indicate that an assertion has // succeeded. AssertionResult AssertionSuccess();
// Returns an AssertionResult object to indicate that an assertion has // failed. AssertionResult AssertionFailure();
} ```
You can then use the `<<` operator to stream messages to the `AssertionResult` object.
To provide more readable messages in Boolean assertions (e.g. `EXPECT_TRUE()`), write a predicate function that returns `AssertionResult` instead of `bool`. For example, if you define `IsEven()` as:
``` ::testing::AssertionResult IsEven(int n) {   if ((n % 2) == 0)     return ::testing::AssertionSuccess();   else     return ::testing::AssertionFailure() << n << " is odd"; } ```
instead of:
``` bool IsEven(int n) {   return (n % 2) == 0; } ```
the failed assertion `EXPECT_TRUE(IsEven(Fib(4)))` will print:
<pre> Value of: !IsEven(Fib(4))<br> Actual: false (*3 is odd*)<br> Expected: true<br> </pre>
instead of a more opaque
<pre> Value of: !IsEven(Fib(4))<br> Actual: false<br> Expected: true<br> </pre>
If you want informative messages in `EXPECT_FALSE` and `ASSERT_FALSE` as well, and are fine with making the predicate slower in the success case, you can supply a success message:
``` ::testing::AssertionResult IsEven(int n) {   if ((n % 2) == 0)     return ::testing::AssertionSuccess() << n << " is even";   else     return ::testing::AssertionFailure() << n << " is odd"; } ```
Then the statement `EXPECT_FALSE(IsEven(Fib(6)))` will print
<pre> Value of: !IsEven(Fib(6))<br> Actual: true (8 is even)<br> Expected: false<br> </pre>
_Availability_: Linux, Windows, Mac; since version 1.4.1.
If you find the default message generated by `(ASSERT|EXPECT)_PRED*` and `(ASSERT|EXPECT)_(TRUE|FALSE)` unsatisfactory, or some arguments to your predicate do not support streaming to `ostream`, you can instead use the following _predicate-formatter assertions_ to _fully_ customize how the message is formatted:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_PRED_FORMAT1(`_pred\_format1, val1_`);`        | `EXPECT_PRED_FORMAT1(`_pred\_format1, val1_`); | _pred\_format1(val1)_ is successful | | `ASSERT_PRED_FORMAT2(`_pred\_format2, val1, val2_`);` | `EXPECT_PRED_FORMAT2(`_pred\_format2, val1, val2_`);` | _pred\_format2(val1, val2)_ is successful | | `...`               | `...`                  | `...`        |
The difference between this and the previous two groups of macros is that instead of a predicate, `(ASSERT|EXPECT)_PRED_FORMAT*` take a _predicate-formatter_ (_pred\_formatn_), which is a function or functor with the signature:
`::testing::AssertionResult PredicateFormattern(const char* `_expr1_`, const char* `_expr2_`, ... const char* `_exprn_`, T1 `_val1_`, T2 `_val2_`, ... Tn `_valn_`);`
where _val1_, _val2_, ..., and _valn_ are the values of the predicate arguments, and _expr1_, _expr2_, ..., and _exprn_ are the corresponding expressions as they appear in the source code. The types `T1`, `T2`, ..., and `Tn` can be either value types or reference types. For example, if an argument has type `Foo`, you can declare it as either `Foo` or `const Foo&`, whichever is appropriate.
A predicate-formatter returns a `::testing::AssertionResult` object to indicate whether the assertion has succeeded or not. The only way to create such an object is to call one of these factory functions:
As an example, let's improve the failure message in the previous example, which uses `EXPECT_PRED2()`:
``` // Returns the smallest prime common divisor of m and n, // or 1 when m and n are mutually prime. int SmallestPrimeCommonDivisor(int m, int n) { ... }
// A predicate-formatter for asserting that two integers are mutually prime. ::testing::AssertionResult AssertMutuallyPrime(const char* m_expr,                                                const char* n_expr,                                                int m,                                                int n) {   if (MutuallyPrime(m, n))     return ::testing::AssertionSuccess();
return ::testing::AssertionFailure()       << m_expr << " and " << n_expr << " (" << m << " and " << n       << ") are not mutually prime, " << "as they have a common divisor "       << SmallestPrimeCommonDivisor(m, n); } ```
With this predicate-formatter, we can use
``` EXPECT_PRED_FORMAT2(AssertMutuallyPrime, b, c); ```
to generate the message
<pre> b and c (4 and 10) are not mutually prime, as they have a common divisor 2.<br> </pre>
As you may have realized, many of the assertions we introduced earlier are special cases of `(EXPECT|ASSERT)_PRED_FORMAT*`. In fact, most of them are indeed defined using `(EXPECT|ASSERT)_PRED_FORMAT*`.
_Availability_: Linux, Windows, Mac.
Comparing floating-point numbers is tricky. Due to round-off errors, it is very unlikely that two floating-points will match exactly. Therefore, `ASSERT_EQ` 's naive comparison usually doesn't work. And since floating-points can have a wide value range, no single fixed error bound works. It's better to compare by a fixed relative error bound, except for values close to 0 due to the loss of precision there.
In general, for floating-point comparison to make sense, the user needs to carefully choose the error bound. If they don't want or care to, comparing in terms of Units in the Last Place (ULPs) is a good default, and Google Test provides assertions to do this. Full details about ULPs are quite long; if you want to learn more, see [this article on float comparison](http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm).
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_FLOAT_EQ(`_expected, actual_`);`  | `EXPECT_FLOAT_EQ(`_expected, actual_`);` | the two `float` values are almost equal | | `ASSERT_DOUBLE_EQ(`_expected, actual_`);` | `EXPECT_DOUBLE_EQ(`_expected, actual_`);` | the two `double` values are almost equal |
By "almost equal", we mean the two values are within 4 ULP's from each other.
The following assertions allow you to choose the acceptable error bound:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_NEAR(`_val1, val2, abs\_error_`);` | `EXPECT_NEAR`_(val1, val2, abs\_error_`);` | the difference between _val1_ and _val2_ doesn't exceed the given absolute error |
_Availability_: Linux, Windows, Mac.
Some floating-point operations are useful, but not that often used. In order to avoid an explosion of new macros, we provide them as predicate-format functions that can be used in predicate assertion macros (e.g. `EXPECT_PRED_FORMAT2`, etc).
``` EXPECT_PRED_FORMAT2(::testing::FloatLE, val1, val2); EXPECT_PRED_FORMAT2(::testing::DoubleLE, val1, val2); ```
Verifies that _val1_ is less than, or almost equal to, _val2_. You can replace `EXPECT_PRED_FORMAT2` in the above table with `ASSERT_PRED_FORMAT2`.
_Availability_: Linux, Windows, Mac.
These assertions test for `HRESULT` success or failure.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_HRESULT_SUCCEEDED(`_expression_`);` | `EXPECT_HRESULT_SUCCEEDED(`_expression_`);` | _expression_ is a success `HRESULT` | | `ASSERT_HRESULT_FAILED(`_expression_`);`    | `EXPECT_HRESULT_FAILED(`_expression_`);`    | _expression_ is a failure `HRESULT` |
The generated output contains the human-readable error message associated with the `HRESULT` code returned by _expression_.
You might use them like this:
``` CComPtr shell; ASSERT_HRESULT_SUCCEEDED(shell.CoCreateInstance(L"Shell.Application")); CComVariant empty; ASSERT_HRESULT_SUCCEEDED(shell->ShellExecute(CComBSTR(url), empty, empty, empty, empty)); ```
_Availability_: Windows.
You can call the function ``` ::testing::StaticAssertTypeEq<T1, T2>(); ``` to assert that types `T1` and `T2` are the same.  The function does nothing if the assertion is satisfied.  If the types are different, the function call will fail to compile, and the compiler error message will likely (depending on the compiler) show you the actual values of `T1` and `T2`.  This is mainly useful inside template code.
_Caveat:_ When used inside a member function of a class template or a function template, `StaticAssertTypeEq<T1, T2>()` is effective _only if_ the function is instantiated.  For example, given: ``` template <typename T> class Foo {  public:   void Bar() { ::testing::StaticAssertTypeEq<int, T>(); } }; ``` the code: ``` void Test1() { Foo<bool> foo; } ``` will _not_ generate a compiler error, as `Foo<bool>::Bar()` is never actually instantiated.  Instead, you need: ``` void Test2() { Foo<bool> foo; foo.Bar(); } ``` to cause a compiler error.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
You can use assertions in any C++ function. In particular, it doesn't have to be a method of the test fixture class. The one constraint is that assertions that generate a fatal failure (`FAIL*` and `ASSERT_*`) can only be used in void-returning functions. This is a consequence of Google Test not using exceptions. By placing it in a non-void function you'll get a confusing compile error like `"error: void value not ignored as it ought to be"`.
If you need to use assertions in a function that returns non-void, one option is to make the function return the value in an out parameter instead. For example, you can rewrite `T2 Foo(T1 x)` to `void Foo(T1 x, T2* result)`. You need to make sure that `*result` contains some sensible value even when the function returns prematurely. As the function now returns `void`, you can use any assertion inside of it.
If changing the function's type is not an option, you should just use assertions that generate non-fatal failures, such as `ADD_FAILURE*` and `EXPECT_*`.
_Note_: Constructors and destructors are not considered void-returning functions, according to the C++ language specification, and so you may not use fatal assertions in them. You'll get a compilation error if you try. A simple workaround is to transfer the entire body of the constructor or destructor to a private void-returning method. However, you should be aware that a fatal assertion failure in a constructor does not terminate the current test, as your intuition might suggest; it merely returns from the constructor early, possibly leaving your object in a partially-constructed state. Likewise, a fatal assertion failure in a destructor may leave your object in a partially-destructed state. Use assertions carefully in these situations!
When a test assertion such as `EXPECT_EQ` fails, Google Test prints the argument values to help you debug.  It does this using a user-extensible value printer.
This printer knows how to print built-in C++ types, native arrays, STL containers, and any type that supports the `<<` operator.  For other types, it prints the raw bytes in the value and hopes that you the user can figure it out.
As mentioned earlier, the printer is _extensible_.  That means you can teach it to do a better job at printing your particular type than to dump the bytes.  To do that, define `<<` for your type:
``` #include <iostream>
namespace foo {
class Bar { ... };  // We want Google Test to be able to print instances of this.
// It's important that the << operator is defined in the SAME // namespace that defines Bar.  C++'s look-up rules rely on that. ::std::ostream& operator<<(::std::ostream& os, const Bar& bar) {   return os << bar.DebugString();  // whatever needed to print bar to os }
}  // namespace foo ```
Sometimes, this might not be an option: your team may consider it bad style to have a `<<` operator for `Bar`, or `Bar` may already have a `<<` operator that doesn't do what you want (and you cannot change it).  If so, you can instead define a `PrintTo()` function like this:
``` #include <iostream>
namespace foo {
class Bar { ... };
// It's important that PrintTo() is defined in the SAME // namespace that defines Bar.  C++'s look-up rules rely on that. void PrintTo(const Bar& bar, ::std::ostream* os) {   *os << bar.DebugString();  // whatever needed to print bar to os }
}  // namespace foo ```
If you have defined both `<<` and `PrintTo()`, the latter will be used when Google Test is concerned.  This allows you to customize how the value appears in Google Test's output without affecting code that relies on the behavior of its `<<` operator.
If you want to print a value `x` using Google Test's value printer yourself, just call `::testing::PrintToString(`_x_`)`, which returns an `std::string`:
``` vector<pair<Bar, int> > bar_ints = GetBarIntVector();
EXPECT_TRUE(IsCorrectBarIntVector(bar_ints))     << "bar_ints = " << ::testing::PrintToString(bar_ints); ```
In many applications, there are assertions that can cause application failure if a condition is not met. These sanity checks, which ensure that the program is in a known good state, are there to fail at the earliest possible time after some program state is corrupted. If the assertion checks the wrong condition, then the program may proceed in an erroneous state, which could lead to memory corruption, security holes, or worse. Hence it is vitally important to test that such assertion statements work as expected.
Since these precondition checks cause the processes to die, we call such tests _death tests_. More generally, any test that checks that a program terminates (except by throwing an exception) in an expected fashion is also a death test.
Note that if a piece of code throws an exception, we don't consider it "death" for the purpose of death tests, as the caller of the code could catch the exception and avoid the crash. If you want to verify exceptions thrown by your code, see [Exception Assertions](#exception-assertions).
If you want to test `EXPECT_*()/ASSERT_*()` failures in your test code, see [Catching Failures](#catching-failures).
Google Test has the following macros to support death tests:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_DEATH(`_statement, regex_`); | `EXPECT_DEATH(`_statement, regex_`); | _statement_ crashes with the given error | | `ASSERT_DEATH_IF_SUPPORTED(`_statement, regex_`); | `EXPECT_DEATH_IF_SUPPORTED(`_statement, regex_`); | if death tests are supported, verifies that _statement_ crashes with the given error; otherwise verifies nothing | | `ASSERT_EXIT(`_statement, predicate, regex_`); | `EXPECT_EXIT(`_statement, predicate, regex_`); |_statement_ exits with the given error and its exit code matches _predicate_ |
where _statement_ is a statement that is expected to cause the process to die, _predicate_ is a function or function object that evaluates an integer exit status, and _regex_ is a regular expression that the stderr output of _statement_ is expected to match. Note that _statement_ can be _any valid statement_ (including _compound statement_) and doesn't have to be an expression.
As usual, the `ASSERT` variants abort the current test function, while the `EXPECT` variants do not.
**Note:** We use the word "crash" here to mean that the process terminates with a _non-zero_ exit status code.  There are two possibilities: either the process has called `exit()` or `_exit()` with a non-zero value, or it may be killed by a signal.
This means that if _statement_ terminates the process with a 0 exit code, it is _not_ considered a crash by `EXPECT_DEATH`.  Use `EXPECT_EXIT` instead if this is the case, or if you want to restrict the exit code more precisely.
A predicate here must accept an `int` and return a `bool`. The death test succeeds only if the predicate returns `true`. Google Test defines a few predicates that handle the most common cases:
``` ::testing::ExitedWithCode(exit_code) ```
This expression is `true` if the program exited normally with the given exit code.
``` ::testing::KilledBySignal(signal_number)  // Not available on Windows. ```
This expression is `true` if the program was killed by the given signal.
The `*_DEATH` macros are convenient wrappers for `*_EXIT` that use a predicate that verifies the process' exit code is non-zero.
Note that a death test only cares about three things:
1. does _statement_ abort or exit the process?   1. (in the case of `ASSERT_EXIT` and `EXPECT_EXIT`) does the exit status satisfy _predicate_?  Or (in the case of `ASSERT_DEATH` and `EXPECT_DEATH`) is the exit status non-zero?  And   1. does the stderr output match _regex_?
In particular, if _statement_ generates an `ASSERT_*` or `EXPECT_*` failure, it will **not** cause the death test to fail, as Google Test assertions don't abort the process.
To write a death test, simply use one of the above macros inside your test function. For example,
``` TEST(My*DeathTest*, Foo) {   // This death test uses a compound statement.   ASSERT_DEATH({ int n = 5; Foo(&n); }, "Error on line .* of Foo()"); } TEST(MyDeathTest, NormalExit) {   EXPECT_EXIT(NormalExit(), ::testing::ExitedWithCode(0), "Success"); } TEST(MyDeathTest, KillMyself) {   EXPECT_EXIT(KillMyself(), ::testing::KilledBySignal(SIGKILL), "Sending myself unblockable signal"); } ```
verifies that:
* calling `Foo(5)` causes the process to die with the given error message,   * calling `NormalExit()` causes the process to print `"Success"` to stderr and exit with exit code 0, and   * calling `KillMyself()` kills the process with signal `SIGKILL`.
The test function body may contain other assertions and statements as well, if necessary.
_Important:_ We strongly recommend you to follow the convention of naming your test case (not test) `*DeathTest` when it contains a death test, as demonstrated in the above example. The `Death Tests And Threads` section below explains why.
If a test fixture class is shared by normal tests and death tests, you can use typedef to introduce an alias for the fixture class and avoid duplicating its code: ``` class FooTest : public ::testing::Test { ... };
typedef FooTest FooDeathTest;
TEST_F(FooTest, DoesThis) {   // normal test }
TEST_F(FooDeathTest, DoesThat) {   // death test } ```
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Cygwin, and Mac (the latter three are supported since v1.3.0).  `(ASSERT|EXPECT)_DEATH_IF_SUPPORTED` are new in v1.4.0.
On POSIX systems (e.g. Linux, Cygwin, and Mac), Google Test uses the [POSIX extended regular expression](http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html#tag_09_04) syntax in death tests. To learn about this syntax, you may want to read this [Wikipedia entry](http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions).
On Windows, Google Test uses its own simple regular expression implementation. It lacks many features you can find in POSIX extended regular expressions.  For example, we don't support union (`"x|y"`), grouping (`"(xy)"`), brackets (`"[xy]"`), and repetition count (`"x{5,7}"`), among others. Below is what we do support (`A` denotes a literal character, period (`.`), or a single `\\` escape sequence; `x` and `y` denote regular expressions.):
| `c` | matches any literal character `c` | |:----|:----------------------------------| | `\\d` | matches any decimal digit         | | `\\D` | matches any character that's not a decimal digit | | `\\f` | matches `\f`                      | | `\\n` | matches `\n`                      | | `\\r` | matches `\r`                      | | `\\s` | matches any ASCII whitespace, including `\n` | | `\\S` | matches any character that's not a whitespace | | `\\t` | matches `\t`                      | | `\\v` | matches `\v`                      | | `\\w` | matches any letter, `_`, or decimal digit | | `\\W` | matches any character that `\\w` doesn't match | | `\\c` | matches any literal character `c`, which must be a punctuation | | `.` | matches any single character except `\n` | | `A?` | matches 0 or 1 occurrences of `A` | | `A*` | matches 0 or many occurrences of `A` | | `A+` | matches 1 or many occurrences of `A` | | `^` | matches the beginning of a string (not that of each line) | | `$` | matches the end of a string (not that of each line) | | `xy` | matches `x` followed by `y`       |
To help you determine which capability is available on your system, Google Test defines macro `GTEST_USES_POSIX_RE=1` when it uses POSIX extended regular expressions, or `GTEST_USES_SIMPLE_RE=1` when it uses the simple version.  If you want your death tests to work in both cases, you can either `#if` on these macros or use the more limited syntax only.
Under the hood, `ASSERT_EXIT()` spawns a new process and executes the death test statement in that process. The details of of how precisely that happens depend on the platform and the variable `::testing::GTEST_FLAG(death_test_style)` (which is initialized from the command-line flag `--gtest_death_test_style`).
* On POSIX systems, `fork()` (or `clone()` on Linux) is used to spawn the child, after which:     * If the variable's value is `"fast"`, the death test statement is immediately executed.     * If the variable's value is `"threadsafe"`, the child process re-executes the unit test binary just as it was originally invoked, but with some extra flags to cause just the single death test under consideration to be run.   * On Windows, the child is spawned using the `CreateProcess()` API, and re-executes the binary to cause just the single death test under consideration to be run - much like the `threadsafe` mode on POSIX.
Other values for the variable are illegal and will cause the death test to fail. Currently, the flag's default value is `"fast"`. However, we reserve the right to change it in the future. Therefore, your tests should not depend on this.
In either case, the parent process waits for the child process to complete, and checks that
1. the child's exit status satisfies the predicate, and   1. the child's stderr matches the regular expression.
If the death test statement runs to completion without dying, the child process will nonetheless terminate, and the assertion fails.
The reason for the two death test styles has to do with thread safety. Due to well-known problems with forking in the presence of threads, death tests should be run in a single-threaded context. Sometimes, however, it isn't feasible to arrange that kind of environment. For example, statically-initialized modules may start threads before main is ever reached. Once threads have been created, it may be difficult or impossible to clean them up.
Google Test has three features intended to raise awareness of threading issues.
1. A warning is emitted if multiple threads are running when a death test is encountered.   1. Test cases with a name ending in "DeathTest" are run before all other tests.   1. It uses `clone()` instead of `fork()` to spawn the child process on Linux (`clone()` is not available on Cygwin and Mac), as `fork()` is more likely to cause the child to hang when the parent process has multiple threads.
It's perfectly fine to create threads inside a death test statement; they are executed in a separate process and cannot affect the parent.
The "threadsafe" death test style was introduced in order to help mitigate the risks of testing in a possibly multithreaded environment. It trades increased test execution time (potentially dramatically so) for improved thread safety. We suggest using the faster, default "fast" style unless your test has specific problems with it.
You can choose a particular style of death tests by setting the flag programmatically:
``` ::testing::FLAGS_gtest_death_test_style = "threadsafe"; ```
You can do this in `main()` to set the style for all death tests in the binary, or in individual tests. Recall that flags are saved before running each test and restored afterwards, so you need not do that yourself. For example:
``` TEST(MyDeathTest, TestOne) {   ::testing::FLAGS_gtest_death_test_style = "threadsafe";   // This test is run in the "threadsafe" style:   ASSERT_DEATH(ThisShouldDie(), ""); }
TEST(MyDeathTest, TestTwo) {   // This test is run in the "fast" style:   ASSERT_DEATH(ThisShouldDie(), ""); }
int main(int argc, char** argv) {   ::testing::InitGoogleTest(&argc, argv);   ::testing::FLAGS_gtest_death_test_style = "fast";   return RUN_ALL_TESTS(); } ```
The _statement_ argument of `ASSERT_EXIT()` can be any valid C++ statement. If it leaves the current function via a `return` statement or by throwing an exception, the death test is considered to have failed.  Some Google Test macros may return from the current function (e.g. `ASSERT_TRUE()`), so be sure to avoid them in _statement_.
Since _statement_ runs in the child process, any in-memory side effect (e.g. modifying a variable, releasing memory, etc) it causes will _not_ be observable in the parent process. In particular, if you release memory in a death test, your program will fail the heap check as the parent process will never see the memory reclaimed. To solve this problem, you can
1. try not to free memory in a death test;   1. free the memory again in the parent process; or   1. do not use the heap checker in your program.
Due to an implementation detail, you cannot place multiple death test assertions on the same line; otherwise, compilation will fail with an unobvious error message.
Despite the improved thread safety afforded by the "threadsafe" style of death test, thread problems such as deadlock are still possible in the presence of handlers registered with `pthread_atfork(3)`.
If a test sub-routine is called from several places, when an assertion inside it fails, it can be hard to tell which invocation of the sub-routine the failure is from.  You can alleviate this problem using extra logging or custom failure messages, but that usually clutters up your tests. A better solution is to use the `SCOPED_TRACE` macro:
| `SCOPED_TRACE(`_message_`);` | |:-----------------------------|
where _message_ can be anything streamable to `std::ostream`. This macro will cause the current file name, line number, and the given message to be added in every failure message. The effect will be undone when the control leaves the current lexical scope.
For example,
``` 10: void Sub1(int n) { 11:   EXPECT_EQ(1, Bar(n)); 12:   EXPECT_EQ(2, Bar(n + 1)); 13: } 14: 15: TEST(FooTest, Bar) { 16:   { 17:     SCOPED_TRACE("A");  // This trace point will be included in 18:                         // every failure in this scope. 19:     Sub1(1); 20:   } 21:   // Now it won't. 22:   Sub1(9); 23: } ```
could result in messages like these:
``` path/to/foo_test.cc:11: Failure Value of: Bar(n) Expected: 1   Actual: 2    Trace: path/to/foo_test.cc:17: A
path/to/foo_test.cc:12: Failure Value of: Bar(n + 1) Expected: 2   Actual: 3 ```
Without the trace, it would've been difficult to know which invocation of `Sub1()` the two failures come from respectively. (You could add an extra message to each assertion in `Sub1()` to indicate the value of `n`, but that's tedious.)
Some tips on using `SCOPED_TRACE`:
1. With a suitable message, it's often enough to use `SCOPED_TRACE` at the beginning of a sub-routine, instead of at each call site.   1. When calling sub-routines inside a loop, make the loop iterator part of the message in `SCOPED_TRACE` such that you can know which iteration the failure is from.   1. Sometimes the line number of the trace point is enough for identifying the particular invocation of a sub-routine. In this case, you don't have to choose a unique message for `SCOPED_TRACE`. You can simply use `""`.   1. You can use `SCOPED_TRACE` in an inner scope when there is one in the outer scope. In this case, all active trace points will be included in the failure messages, in reverse order they are encountered.   1. The trace dump is clickable in Emacs' compilation buffer - hit return on a line number and you'll be taken to that line in the source file!
_Availability:_ Linux, Windows, Mac.
A common pitfall when using `ASSERT_*` and `FAIL*` is not understanding that when they fail they only abort the _current function_, not the entire test. For example, the following test will segfault: ``` void Subroutine() {   // Generates a fatal failure and aborts the current function.   ASSERT_EQ(1, 2);   // The following won't be executed.   ... }
TEST(FooTest, Bar) {   Subroutine();   // The intended behavior is for the fatal failure   // in Subroutine() to abort the entire test.   // The actual behavior: the function goes on after Subroutine() returns.   int* p = NULL;   *p = 3; // Segfault! } ```
Since we don't use exceptions, it is technically impossible to implement the intended behavior here.  To alleviate this, Google Test provides two solutions.  You could use either the `(ASSERT|EXPECT)_NO_FATAL_FAILURE` assertions or the `HasFatalFailure()` function.  They are described in the following two subsections.
As shown above, if your test calls a subroutine that has an `ASSERT_*` failure in it, the test will continue after the subroutine returns. This may not be what you want.
Often people want fatal failures to propagate like exceptions.  For that Google Test offers the following macros:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_NO_FATAL_FAILURE(`_statement_`);` | `EXPECT_NO_FATAL_FAILURE(`_statement_`);` | _statement_ doesn't generate any new fatal failures in the current thread. |
Only failures in the thread that executes the assertion are checked to determine the result of this type of assertions.  If _statement_ creates new threads, failures in these threads are ignored.
Examples:
``` ASSERT_NO_FATAL_FAILURE(Foo());
int i; EXPECT_NO_FATAL_FAILURE({   i = Bar(); }); ```
_Availability:_ Linux, Windows, Mac. Assertions from multiple threads are currently not supported.
`HasFatalFailure()` in the `::testing::Test` class returns `true` if an assertion in the current test has suffered a fatal failure. This allows functions to catch fatal failures in a sub-routine and return early.
``` class Test {  public:   ...   static bool HasFatalFailure(); }; ```
The typical usage, which basically simulates the behavior of a thrown exception, is:
``` TEST(FooTest, Bar) {   Subroutine();   // Aborts if Subroutine() had a fatal failure.   if (HasFatalFailure())     return;   // The following won't be executed.   ... } ```
If `HasFatalFailure()` is used outside of `TEST()` , `TEST_F()` , or a test fixture, you must add the `::testing::Test::` prefix, as in:
``` if (::testing::Test::HasFatalFailure())   return; ```
Similarly, `HasNonfatalFailure()` returns `true` if the current test has at least one non-fatal failure, and `HasFailure()` returns `true` if the current test has at least one failure of either kind.
_Availability:_ Linux, Windows, Mac.  `HasNonfatalFailure()` and `HasFailure()` are available since version 1.4.0.
In your test code, you can call `RecordProperty("key", value)` to log additional information, where `value` can be either a C string or a 32-bit integer. The _last_ value recorded for a key will be emitted to the XML output if you specify one. For example, the test
``` TEST_F(WidgetUsageTest, MinAndMaxWidgets) {   RecordProperty("MaximumWidgets", ComputeMaxUsage());   RecordProperty("MinimumWidgets", ComputeMinUsage()); } ```
will output XML like this:
``` ...   <testcase name="MinAndMaxWidgets" status="run" time="6" classname="WidgetUsageTest"             MaximumWidgets="12"             MinimumWidgets="9" /> ... ```
_Note_:   * `RecordProperty()` is a static member of the `Test` class. Therefore it needs to be prefixed with `::testing::Test::` if used outside of the `TEST` body and the test fixture class.   * `key` must be a valid XML attribute name, and cannot conflict with the ones already used by Google Test (`name`, `status`,     `time`, and `classname`).
_Availability_: Linux, Windows, Mac.

Google Test creates a new test fixture object for each test in order to make tests independent and easier to debug. However, sometimes tests use resources that are expensive to set up, making the one-copy-per-test model prohibitively expensive.
If the tests don't change the resource, there's no harm in them sharing a single resource copy. So, in addition to per-test set-up/tear-down, Google Test also supports per-test-case set-up/tear-down. To use it:
1. In your test fixture class (say `FooTest` ), define as `static` some member variables to hold the shared resources.   1. In the same test fixture class, define a `static void SetUpTestCase()` function (remember not to spell it as **`SetupTestCase`** with a small `u`!) to set up the shared resources and a `static void TearDownTestCase()` function to tear them down.
That's it! Google Test automatically calls `SetUpTestCase()` before running the _first test_ in the `FooTest` test case (i.e. before creating the first `FooTest` object), and calls `TearDownTestCase()` after running the _last test_ in it (i.e. after deleting the last `FooTest` object). In between, the tests can use the shared resources.
Remember that the test order is undefined, so your code can't depend on a test preceding or following another. Also, the tests must either not modify the state of any shared resource, or, if they do modify the state, they must restore the state to its original value before passing control to the next test.
Here's an example of per-test-case set-up and tear-down: ``` class FooTest : public ::testing::Test {  protected:   // Per-test-case set-up.   // Called before the first test in this test case.   // Can be omitted if not needed.   static void SetUpTestCase() {     shared_resource_ = new ...;   }
// Per-test-case tear-down.   // Called after the last test in this test case.   // Can be omitted if not needed.   static void TearDownTestCase() {     delete shared_resource_;     shared_resource_ = NULL;   }
// You can define per-test set-up and tear-down logic as usual.   virtual void SetUp() { ... }   virtual void TearDown() { ... }
// Some expensive resource shared by all tests.   static T* shared_resource_; };
T* FooTest::shared_resource_ = NULL;
TEST_F(FooTest, Test1) {   ... you can refer to shared_resource here ... } TEST_F(FooTest, Test2) {   ... you can refer to shared_resource here ... } ```
_Availability:_ Linux, Windows, Mac.
Just as you can do set-up and tear-down at the test level and the test case level, you can also do it at the test program level. Here's how.
First, you subclass the `::testing::Environment` class to define a test environment, which knows how to set-up and tear-down:
``` class Environment {  public:   virtual ~Environment() {}   // Override this to define how to set up the environment.   virtual void SetUp() {}   // Override this to define how to tear down the environment.   virtual void TearDown() {} }; ```
Then, you register an instance of your environment class with Google Test by calling the `::testing::AddGlobalTestEnvironment()` function:
``` Environment* AddGlobalTestEnvironment(Environment* env); ```
Now, when `RUN_ALL_TESTS()` is called, it first calls the `SetUp()` method of the environment object, then runs the tests if there was no fatal failures, and finally calls `TearDown()` of the environment object.
It's OK to register multiple environment objects. In this case, their `SetUp()` will be called in the order they are registered, and their `TearDown()` will be called in the reverse order.
Note that Google Test takes ownership of the registered environment objects. Therefore **do not delete them** by yourself.
You should call `AddGlobalTestEnvironment()` before `RUN_ALL_TESTS()` is called, probably in `main()`. If you use `gtest_main`, you need to      call this before `main()` starts for it to take effect. One way to do this is to define a global variable like this:
``` ::testing::Environment* const foo_env = ::testing::AddGlobalTestEnvironment(new FooEnvironment); ```
However, we strongly recommend you to write your own `main()` and call `AddGlobalTestEnvironment()` there, as relying on initialization of global variables makes the code harder to read and may cause problems when you register multiple environments from different translation units and the environments have dependencies among them (remember that the compiler doesn't guarantee the order in which global variables from different translation units are initialized).
_Availability:_ Linux, Windows, Mac.
_Value-parameterized tests_ allow you to test your code with different parameters without writing multiple copies of the same test.
Suppose you write a test for your code and then realize that your code is affected by a presence of a Boolean command line flag.
``` TEST(MyCodeTest, TestFoo) {   // A code to test foo(). } ```
Usually people factor their test code into a function with a Boolean parameter in such situations. The function sets the flag, then executes the testing code.
``` void TestFooHelper(bool flag_value) {   flag = flag_value;   // A code to test foo(). }
TEST(MyCodeTest, TestFooo) {   TestFooHelper(false);   TestFooHelper(true); } ```
But this setup has serious drawbacks. First, when a test assertion fails in your tests, it becomes unclear what value of the parameter caused it to fail. You can stream a clarifying message into your `EXPECT`/`ASSERT` statements, but it you'll have to do it with all of them. Second, you have to add one such helper function per test. What if you have ten tests? Twenty? A hundred?
Value-parameterized tests will let you write your test only once and then easily instantiate and run it with an arbitrary number of parameter values.
Here are some other situations when value-parameterized tests come handy:
* You want to test different implementations of an OO interface.   * You want to test your code over various inputs (a.k.a. data-driven testing). This feature is easy to abuse, so please exercise your good sense when doing it!
To write value-parameterized tests, first you should define a fixture class.  It must be derived from both `::testing::Test` and `::testing::WithParamInterface<T>` (the latter is a pure interface), where `T` is the type of your parameter values.  For convenience, you can just derive the fixture class from `::testing::TestWithParam<T>`, which itself is derived from both `::testing::Test` and `::testing::WithParamInterface<T>`. `T` can be any copyable type. If it's a raw pointer, you are responsible for managing the lifespan of the pointed values.
``` class FooTest : public ::testing::TestWithParam<const char*> {   // You can implement all the usual fixture class members here.   // To access the test parameter, call GetParam() from class   // TestWithParam<T>. };
// Or, when you want to add parameters to a pre-existing fixture class: class BaseTest : public ::testing::Test {   ... }; class BarTest : public BaseTest,                 public ::testing::WithParamInterface<const char*> {   ... }; ```
Then, use the `TEST_P` macro to define as many test patterns using this fixture as you want.  The `_P` suffix is for "parameterized" or "pattern", whichever you prefer to think.
``` TEST_P(FooTest, DoesBlah) {   // Inside a test, access the test parameter with the GetParam() method   // of the TestWithParam<T> class:   EXPECT_TRUE(foo.Blah(GetParam()));   ... }
TEST_P(FooTest, HasBlahBlah) {   ... } ```
Finally, you can use `INSTANTIATE_TEST_CASE_P` to instantiate the test case with any set of parameters you want. Google Test defines a number of functions for generating test parameters. They return what we call (surprise!) _parameter generators_. Here is a summary of them, which are all in the `testing` namespace:
| `Range(begin, end[, step])` | Yields values `{begin, begin+step, begin+step+step, ...}`. The values do not include `end`. `step` defaults to 1. | |:----------------------------|:------------------------------------------------------------------------------------------------------------------| | `Values(v1, v2, ..., vN)`   | Yields values `{v1, v2, ..., vN}`.                                                                                | | `ValuesIn(container)` and `ValuesIn(begin, end)` | Yields values from a C-style array, an STL-style container, or an iterator range `[begin, end)`. `container`, `begin`, and `end` can be expressions whose values are determined at run time.  | | `Bool()`                    | Yields sequence `{false, true}`.                                                                                  | | `Combine(g1, g2, ..., gN)`  | Yields all combinations (the Cartesian product for the math savvy) of the values generated by the `N` generators. This is only available if your system provides the `<tr1/tuple>` header. If you are sure your system does, and Google Test disagrees, you can override it by defining `GTEST_HAS_TR1_TUPLE=1`. See comments in [include/gtest/internal/gtest-port.h](../include/gtest/internal/gtest-port.h) for more information. |
For more details, see the comments at the definitions of these functions in the [source code](../include/gtest/gtest-param-test.h).
The following statement will instantiate tests from the `FooTest` test case each with parameter values `"meeny"`, `"miny"`, and `"moe"`.
``` INSTANTIATE_TEST_CASE_P(InstantiationName,                         FooTest,                         ::testing::Values("meeny", "miny", "moe")); ```
To distinguish different instances of the pattern (yes, you can instantiate it more than once), the first argument to `INSTANTIATE_TEST_CASE_P` is a prefix that will be added to the actual test case name. Remember to pick unique prefixes for different instantiations. The tests from the instantiation above will have these names:
* `InstantiationName/FooTest.DoesBlah/0` for `"meeny"`   * `InstantiationName/FooTest.DoesBlah/1` for `"miny"`   * `InstantiationName/FooTest.DoesBlah/2` for `"moe"`   * `InstantiationName/FooTest.HasBlahBlah/0` for `"meeny"`   * `InstantiationName/FooTest.HasBlahBlah/1` for `"miny"`   * `InstantiationName/FooTest.HasBlahBlah/2` for `"moe"`
You can use these names in [--gtest\-filter](#running-a-subset-of-the-tests).
This statement will instantiate all tests from `FooTest` again, each with parameter values `"cat"` and `"dog"`:
``` const char* pets[] = {"cat", "dog"}; INSTANTIATE_TEST_CASE_P(AnotherInstantiationName, FooTest,                         ::testing::ValuesIn(pets)); ```
The tests from the instantiation above will have these names:
* `AnotherInstantiationName/FooTest.DoesBlah/0` for `"cat"`   * `AnotherInstantiationName/FooTest.DoesBlah/1` for `"dog"`   * `AnotherInstantiationName/FooTest.HasBlahBlah/0` for `"cat"`   * `AnotherInstantiationName/FooTest.HasBlahBlah/1` for `"dog"`
Please note that `INSTANTIATE_TEST_CASE_P` will instantiate _all_ tests in the given test case, whether their definitions come before or _after_ the `INSTANTIATE_TEST_CASE_P` statement.
You can see [these](../samples/sample7_unittest.cc) [files](../samples/sample8_unittest.cc) for more examples.
_Availability_: Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.2.0.
In the above, we define and instantiate `FooTest` in the same source file. Sometimes you may want to define value-parameterized tests in a library and let other people instantiate them later. This pattern is known as <i>abstract tests</i>. As an example of its application, when you are designing an interface you can write a standard suite of abstract tests (perhaps using a factory function as the test parameter) that all implementations of the interface are expected to pass. When someone implements the interface, he can instantiate your suite to get all the interface-conformance tests for free.
To define abstract tests, you should organize your code like this:
1. Put the definition of the parameterized test fixture class (e.g. `FooTest`) in a header file, say `foo_param_test.h`. Think of this as _declaring_ your abstract tests.   1. Put the `TEST_P` definitions in `foo_param_test.cc`, which includes `foo_param_test.h`. Think of this as _implementing_ your abstract tests.
Once they are defined, you can instantiate them by including `foo_param_test.h`, invoking `INSTANTIATE_TEST_CASE_P()`, and linking with `foo_param_test.cc`. You can instantiate the same abstract test case multiple times, possibly in different source files.
Suppose you have multiple implementations of the same interface and want to make sure that all of them satisfy some common requirements. Or, you may have defined several types that are supposed to conform to the same "concept" and you want to verify it.  In both cases, you want the same test logic repeated for different types.
While you can write one `TEST` or `TEST_F` for each type you want to test (and you may even factor the test logic into a function template that you invoke from the `TEST`), it's tedious and doesn't scale: if you want _m_ tests over _n_ types, you'll end up writing _m\*n_ `TEST`s.
_Typed tests_ allow you to repeat the same test logic over a list of types.  You only need to write the test logic once, although you must know the type list when writing typed tests.  Here's how you do it:
First, define a fixture class template.  It should be parameterized by a type.  Remember to derive it from `::testing::Test`:
``` template <typename T> class FooTest : public ::testing::Test {  public:   ...   typedef std::list<T> List;   static T shared_;   T value_; }; ```
Next, associate a list of types with the test case, which will be repeated for each type in the list:
``` typedef ::testing::Types<char, int, unsigned int> MyTypes; TYPED_TEST_CASE(FooTest, MyTypes); ```
The `typedef` is necessary for the `TYPED_TEST_CASE` macro to parse correctly.  Otherwise the compiler will think that each comma in the type list introduces a new macro argument.
Then, use `TYPED_TEST()` instead of `TEST_F()` to define a typed test for this test case.  You can repeat this as many times as you want:
``` TYPED_TEST(FooTest, DoesBlah) {   // Inside a test, refer to the special name TypeParam to get the type   // parameter.  Since we are inside a derived class template, C++ requires   // us to visit the members of FooTest via 'this'.   TypeParam n = this->value_;
// To visit static members of the fixture, add the 'TestFixture::'   // prefix.   n += TestFixture::shared_;
// To refer to typedefs in the fixture, add the 'typename TestFixture::'   // prefix.  The 'typename' is required to satisfy the compiler.   typename TestFixture::List values;   values.push_back(n);   ... }
TYPED_TEST(FooTest, HasPropertyA) { ... } ```
You can see `samples/sample6_unittest.cc` for a complete example.
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.1.0.
_Type-parameterized tests_ are like typed tests, except that they don't require you to know the list of types ahead of time.  Instead, you can define the test logic first and instantiate it with different type lists later.  You can even instantiate it more than once in the same program.
If you are designing an interface or concept, you can define a suite of type-parameterized tests to verify properties that any valid implementation of the interface/concept should have.  Then, the author of each implementation can just instantiate the test suite with his type to verify that it conforms to the requirements, without having to write similar tests repeatedly.  Here's an example:
First, define a fixture class template, as we did with typed tests:
``` template <typename T> class FooTest : public ::testing::Test {   ... }; ```
Next, declare that you will define a type-parameterized test case:
``` TYPED_TEST_CASE_P(FooTest); ```
The `_P` suffix is for "parameterized" or "pattern", whichever you prefer to think.
Then, use `TYPED_TEST_P()` to define a type-parameterized test.  You can repeat this as many times as you want:
``` TYPED_TEST_P(FooTest, DoesBlah) {   // Inside a test, refer to TypeParam to get the type parameter.   TypeParam n = 0;   ... }
TYPED_TEST_P(FooTest, HasPropertyA) { ... } ```
Now the tricky part: you need to register all test patterns using the `REGISTER_TYPED_TEST_CASE_P` macro before you can instantiate them. The first argument of the macro is the test case name; the rest are the names of the tests in this test case:
``` REGISTER_TYPED_TEST_CASE_P(FooTest,                            DoesBlah, HasPropertyA); ```
Finally, you are free to instantiate the pattern with the types you want.  If you put the above code in a header file, you can `#include` it in multiple C++ source files and instantiate it multiple times.
``` typedef ::testing::Types<char, int, unsigned int> MyTypes; INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, MyTypes); ```
To distinguish different instances of the pattern, the first argument to the `INSTANTIATE_TYPED_TEST_CASE_P` macro is a prefix that will be added to the actual test case name.  Remember to pick unique prefixes for different instances.
In the special case where the type list contains only one type, you can write that type directly without `::testing::Types<...>`, like this:
``` INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, int); ```
You can see `samples/sample6_unittest.cc` for a complete example.
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.1.0.
If you change your software's internal implementation, your tests should not break as long as the change is not observable by users. Therefore, per the _black-box testing principle_, most of the time you should test your code through its public interfaces.
If you still find yourself needing to test internal implementation code, consider if there's a better design that wouldn't require you to do so. If you absolutely have to test non-public interface code though, you can. There are two cases to consider:
* Static functions (_not_ the same as static member functions!) or unnamed namespaces, and   * Private or protected class members
Both static functions and definitions/declarations in an unnamed namespace are only visible within the same translation unit. To test them, you can `#include` the entire `.cc` file being tested in your `*_test.cc` file. (`#include`ing `.cc` files is not a good way to reuse code - you should not do this in production code!)
However, a better approach is to move the private code into the `foo::internal` namespace, where `foo` is the namespace your project normally uses, and put the private declarations in a `*-internal.h` file. Your production `.cc` files and your tests are allowed to include this internal header, but your clients are not. This way, you can fully test your internal implementation without leaking it to your clients.
Private class members are only accessible from within the class or by friends. To access a class' private members, you can declare your test fixture as a friend to the class and define accessors in your fixture. Tests using the fixture can then access the private members of your production class via the accessors in the fixture. Note that even though your fixture is a friend to your production class, your tests are not automatically friends to it, as they are technically defined in sub-classes of the fixture.
Another way to test private members is to refactor them into an implementation class, which is then declared in a `*-internal.h` file. Your clients aren't allowed to include this header but your tests can. Such is called the Pimpl (Private Implementation) idiom.
Or, you can declare an individual test as a friend of your class by adding this line in the class body:
``` FRIEND_TEST(TestCaseName, TestName); ```
For example, ``` // foo.h #include "gtest/gtest_prod.h"
// Defines FRIEND_TEST. class Foo {   ...  private:   FRIEND_TEST(FooTest, BarReturnsZeroOnNull);   int Bar(void* x); };
// foo_test.cc ... TEST(FooTest, BarReturnsZeroOnNull) {   Foo foo;   EXPECT_EQ(0, foo.Bar(NULL));   // Uses Foo's private member Bar(). } ```
Pay special attention when your class is defined in a namespace, as you should define your test fixtures and tests in the same namespace if you want them to be friends of your class. For example, if the code to be tested looks like:
``` namespace my_namespace {
class Foo {   friend class FooTest;   FRIEND_TEST(FooTest, Bar);   FRIEND_TEST(FooTest, Baz);   ...   definition of the class Foo   ... };
}  // namespace my_namespace ```
Your test code should be something like:
``` namespace my_namespace { class FooTest : public ::testing::Test {  protected:   ... };
TEST_F(FooTest, Bar) { ... } TEST_F(FooTest, Baz) { ... }
}  // namespace my_namespace ```
If you are building a testing utility on top of Google Test, you'll want to test your utility.  What framework would you use to test it? Google Test, of course.
The challenge is to verify that your testing utility reports failures correctly.  In frameworks that report a failure by throwing an exception, you could catch the exception and assert on it.  But Google Test doesn't use exceptions, so how do we test that a piece of code generates an expected failure?
`"gtest/gtest-spi.h"` contains some constructs to do this.  After `#include`ing this header, you can use
| `EXPECT_FATAL_FAILURE(`_statement, substring_`);` | |:--------------------------------------------------|
to assert that _statement_ generates a fatal (e.g. `ASSERT_*`) failure whose message contains the given _substring_, or use
| `EXPECT_NONFATAL_FAILURE(`_statement, substring_`);` | |:-----------------------------------------------------|
if you are expecting a non-fatal (e.g. `EXPECT_*`) failure.
For technical reasons, there are some caveats:
1. You cannot stream a failure message to either macro.   1. _statement_ in `EXPECT_FATAL_FAILURE()` cannot reference local non-static variables or non-static members of `this` object.   1. _statement_ in `EXPECT_FATAL_FAILURE()` cannot return a value.
_Note:_ Google Test is designed with threads in mind.  Once the synchronization primitives in `"gtest/internal/gtest-port.h"` have been implemented, Google Test will become thread-safe, meaning that you can then use assertions in multiple threads concurrently.  Before
that, however, Google Test only supports single-threaded usage.  Once thread-safe, `EXPECT_FATAL_FAILURE()` and `EXPECT_NONFATAL_FAILURE()` will capture failures in the current thread only. If _statement_ creates new threads, failures in these threads will be ignored.  If you want to capture failures from all threads instead, you should use the following macros:
| `EXPECT_FATAL_FAILURE_ON_ALL_THREADS(`_statement, substring_`);` | |:-----------------------------------------------------------------| | `EXPECT_NONFATAL_FAILURE_ON_ALL_THREADS(`_statement, substring_`);` |
Sometimes a function may need to know the name of the currently running test. For example, you may be using the `SetUp()` method of your test fixture to set the golden file name based on which test is running. The `::testing::TestInfo` class has this information:
``` namespace testing {
class TestInfo {  public:   // Returns the test case name and the test name, respectively.   //   // Do NOT delete or free the return value - it's managed by the   // TestInfo class.   const char* test_case_name() const;   const char* name() const; };
}  // namespace testing ```
> To obtain a `TestInfo` object for the currently running test, call `current_test_info()` on the `UnitTest` singleton object:
``` // Gets information about the currently running test. // Do NOT delete the returned object - it's managed by the UnitTest class. const ::testing::TestInfo* const test_info =   ::testing::UnitTest::GetInstance()->current_test_info(); printf("We are in test %s of test case %s.\n",        test_info->name(), test_info->test_case_name()); ```
`current_test_info()` returns a null pointer if no test is running. In particular, you cannot find the test case name in `TestCaseSetUp()`, `TestCaseTearDown()` (where you know the test case name implicitly), or functions called from them.
_Availability:_ Linux, Windows, Mac.
Google Test provides an <b>event listener API</b> to let you receive notifications about the progress of a test program and test failures. The events you can listen to include the start and end of the test program, a test case, or a test method, among others. You may use this API to augment or replace the standard console output, replace the XML output, or provide a completely different form of output, such as a GUI or a database. You can also use test events as checkpoints to implement a resource leak checker, for example.
_Availability:_ Linux, Windows, Mac; since v1.4.0.
To define a event listener, you subclass either [testing::TestEventListener](../include/gtest/gtest.h#L855) or [testing::EmptyTestEventListener](../include/gtest/gtest.h#L905). The former is an (abstract) interface, where <i>each pure virtual method<br> can be overridden to handle a test event</i> (For example, when a test starts, the `OnTestStart()` method will be called.). The latter provides an empty implementation of all methods in the interface, such that a subclass only needs to override the methods it cares about.
When an event is fired, its context is passed to the handler function as an argument. The following argument types are used:   * [UnitTest](../include/gtest/gtest.h#L1007) reflects the state of the entire test program,   * [TestCase](../include/gtest/gtest.h#L689) has information about a test case, which can contain one or more tests,   * [TestInfo](../include/gtest/gtest.h#L599) contains the state of a test, and   * [TestPartResult](../include/gtest/gtest-test-part.h#L42) represents the result of a test assertion.
An event handler function can examine the argument it receives to find out interesting information about the event and the test program's state.  Here's an example:
```   class MinimalistPrinter : public ::testing::EmptyTestEventListener {     // Called before a test starts.     virtual void OnTestStart(const ::testing::TestInfo& test_info) {       printf("*** Test %s.%s starting.\n",              test_info.test_case_name(), test_info.name());     }
// Called after a failed assertion or a SUCCEED() invocation.     virtual void OnTestPartResult(         const ::testing::TestPartResult& test_part_result) {       printf("%s in %s:%d\n%s\n",              test_part_result.failed() ? "*** Failure" : "Success",              test_part_result.file_name(),              test_part_result.line_number(),              test_part_result.summary());     }
// Called after a test ends.     virtual void OnTestEnd(const ::testing::TestInfo& test_info) {       printf("*** Test %s.%s ending.\n",              test_info.test_case_name(), test_info.name());     }   }; ```
To use the event listener you have defined, add an instance of it to the Google Test event listener list (represented by class [TestEventListeners](../include/gtest/gtest.h#L929) - note the "s" at the end of the name) in your `main()` function, before calling `RUN_ALL_TESTS()`: ``` int main(int argc, char** argv) {   ::testing::InitGoogleTest(&argc, argv);   // Gets hold of the event listener list.   ::testing::TestEventListeners& listeners =       ::testing::UnitTest::GetInstance()->listeners();   // Adds a listener to the end.  Google Test takes the ownership.   listeners.Append(new MinimalistPrinter);   return RUN_ALL_TESTS(); } ```
There's only one problem: the default test result printer is still in effect, so its output will mingle with the output from your minimalist printer. To suppress the default printer, just release it from the event listener list and delete it. You can do so by adding one line: ```   ...   delete listeners.Release(listeners.default_result_printer());   listeners.Append(new MinimalistPrinter);   return RUN_ALL_TESTS(); ```
Now, sit back and enjoy a completely different output from your tests. For more details, you can read this [sample](../samples/sample9_unittest.cc).
You may append more than one listener to the list. When an `On*Start()` or `OnTestPartResult()` event is fired, the listeners will receive it in the order they appear in the list (since new listeners are added to the end of the list, the default text printer and the default XML generator will receive the event first). An `On*End()` event will be received by the listeners in the _reverse_ order. This allows output by listeners added later to be framed by output from listeners added earlier.
You may use failure-raising macros (`EXPECT_*()`, `ASSERT_*()`, `FAIL()`, etc) when processing an event. There are some restrictions:
1. You cannot generate any failure in `OnTestPartResult()` (otherwise it will cause `OnTestPartResult()` to be called recursively).   1. A listener that handles `OnTestPartResult()` is not allowed to generate any failure.
When you add listeners to the listener list, you should put listeners that handle `OnTestPartResult()` _before_ listeners that can generate failures. This ensures that failures generated by the latter are attributed to the right test by the former.
We have a sample of failure-raising listener [here](../samples/sample10_unittest.cc).
Google Test test programs are ordinary executables. Once built, you can run them directly and affect their behavior via the following environment variables and/or command line flags. For the flags to work, your programs must call `::testing::InitGoogleTest()` before calling `RUN_ALL_TESTS()`.
To see a list of supported flags and their usage, please run your test program with the `--help` flag.  You can also use `-h`, `-?`, or `/?` for short.  This feature is added in version 1.3.0.
If an option is specified both by an environment variable and by a flag, the latter takes precedence.  Most of the options can also be set/read in code: to access the value of command line flag `--gtest_foo`, write `::testing::GTEST_FLAG(foo)`.  A common pattern is to set the value of a flag before calling `::testing::InitGoogleTest()` to change the default value of the flag: ``` int main(int argc, char** argv) {   // Disables elapsed time by default.   ::testing::GTEST_FLAG(print_time) = false;
// This allows the user to override the flag on the command line.   ::testing::InitGoogleTest(&argc, argv);
return RUN_ALL_TESTS(); } ```
This section shows various options for choosing which tests to run.
Sometimes it is necessary to list the available tests in a program before running them so that a filter may be applied if needed. Including the flag `--gtest_list_tests` overrides all other flags and lists tests in the following format: ``` TestCase1.   TestName1   TestName2 TestCase2.   TestName ```
None of the tests listed are actually run if the flag is provided. There is no corresponding environment variable for this flag.
_Availability:_ Linux, Windows, Mac.
By default, a Google Test program runs all tests the user has defined. Sometimes, you want to run only a subset of the tests (e.g. for debugging or quickly verifying a change). If you set the `GTEST_FILTER` environment variable or the `--gtest_filter` flag to a filter string, Google Test will only run the tests whose full names (in the form of `TestCaseName.TestName`) match the filter.
The format of a filter is a '`:`'-separated list of wildcard patterns (called the positive patterns) optionally followed by a '`-`' and another '`:`'-separated pattern list (called the negative patterns). A test matches the filter if and only if it matches any of the positive patterns but does not match any of the negative patterns.
A pattern may contain `'*'` (matches any string) or `'?'` (matches any single character). For convenience, the filter `'*-NegativePatterns'` can be also written as `'-NegativePatterns'`.
For example:
* `./foo_test` Has no flag, and thus runs all its tests.   * `./foo_test --gtest_filter=*` Also runs everything, due to the single match-everything `*` value.   * `./foo_test --gtest_filter=FooTest.*` Runs everything in test case `FooTest`.   * `./foo_test --gtest_filter=*Null*:*Constructor*` Runs any test whose full name contains either `"Null"` or `"Constructor"`.   * `./foo_test --gtest_filter=-*DeathTest.*` Runs all non-death tests.   * `./foo_test --gtest_filter=FooTest.*-FooTest.Bar` Runs everything in test case `FooTest` except `FooTest.Bar`.
_Availability:_ Linux, Windows, Mac.
If you have a broken test that you cannot fix right away, you can add the `DISABLED_` prefix to its name. This will exclude it from execution. This is better than commenting out the code or using `#if 0`, as disabled tests are still compiled (and thus won't rot).
If you need to disable all tests in a test case, you can either add `DISABLED_` to the front of the name of each test, or alternatively add it to the front of the test case name.
For example, the following tests won't be run by Google Test, even though they will still be compiled:
``` // Tests that Foo does Abc. TEST(FooTest, DISABLED_DoesAbc) { ... }
class DISABLED_BarTest : public ::testing::Test { ... };
// Tests that Bar does Xyz. TEST_F(DISABLED_BarTest, DoesXyz) { ... } ```
_Note:_ This feature should only be used for temporary pain-relief. You still have to fix the disabled tests at a later date. As a reminder, Google Test will print a banner warning you if a test program contains any disabled tests.
_Tip:_ You can easily count the number of disabled tests you have using `grep`. This number can be used as a metric for improving your test quality.
_Availability:_ Linux, Windows, Mac.
To include [disabled tests](#temporarily-disabling-tests) in test execution, just invoke the test program with the `--gtest_also_run_disabled_tests` flag or set the `GTEST_ALSO_RUN_DISABLED_TESTS` environment variable to a value other than `0`.  You can combine this with the [--gtest\-filter](#running-a-subset-of-the_tests) flag to further select which disabled tests to run.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
Once in a while you'll run into a test whose result is hit-or-miss. Perhaps it will fail only 1% of the time, making it rather hard to reproduce the bug under a debugger. This can be a major source of frustration.
The `--gtest_repeat` flag allows you to repeat all (or selected) test methods in a program many times. Hopefully, a flaky test will eventually fail and give you a chance to debug. Here's how to use it:
| `$ foo_test --gtest_repeat=1000` | Repeat foo\_test 1000 times and don't stop at failures. | |:---------------------------------|:--------------------------------------------------------| | `$ foo_test --gtest_repeat=-1`   | A negative count means repeating forever.               | | `$ foo_test --gtest_repeat=1000 --gtest_break_on_failure` | Repeat foo\_test 1000 times, stopping at the first failure. This is especially useful when running under a debugger: when the testfails, it will drop into the debugger and you can then inspect variables and stacks. | | `$ foo_test --gtest_repeat=1000 --gtest_filter=FooBar` | Repeat the tests whose name matches the filter 1000 times. |
If your test program contains global set-up/tear-down code registered using `AddGlobalTestEnvironment()`, it will be repeated in each iteration as well, as the flakiness may be in it. You can also specify the repeat count by setting the `GTEST_REPEAT` environment variable.
_Availability:_ Linux, Windows, Mac.
You can specify the `--gtest_shuffle` flag (or set the `GTEST_SHUFFLE` environment variable to `1`) to run the tests in a program in a random order. This helps to reveal bad dependencies between tests.
By default, Google Test uses a random seed calculated from the current time. Therefore you'll get a different order every time. The console output includes the random seed value, such that you can reproduce an order-related test failure later. To specify the random seed explicitly, use the `--gtest_random_seed=SEED` flag (or set the `GTEST_RANDOM_SEED` environment variable), where `SEED` is an integer between 0 and 99999. The seed value 0 is special: it tells Google Test to do the default behavior of calculating the seed from the current time.
If you combine this with `--gtest_repeat=N`, Google Test will pick a different random seed and re-shuffle the tests in each iteration.
_Availability:_ Linux, Windows, Mac; since v1.4.0.
This section teaches how to tweak the way test results are reported.
Google Test can use colors in its terminal output to make it easier to spot the separation between tests, and whether tests passed.
You can set the GTEST\_COLOR environment variable or set the `--gtest_color` command line flag to `yes`, `no`, or `auto` (the default) to enable colors, disable colors, or let Google Test decide. When the value is `auto`, Google Test will use colors if and only if the output goes to a terminal and (on non-Windows platforms) the `TERM` environment variable is set to `xterm` or `xterm-color`.
_Availability:_ Linux, Windows, Mac.
By default, Google Test prints the time it takes to run each test.  To suppress that, run the test program with the `--gtest_print_time=0` command line flag.  Setting the `GTEST_PRINT_TIME` environment variable to `0` has the same effect.
_Availability:_ Linux, Windows, Mac.  (In Google Test 1.3.0 and lower, the default behavior is that the elapsed time is **not** printed.)
Google Test can emit a detailed XML report to a file in addition to its normal textual output. The report contains the duration of each test, and thus can help you identify slow tests.
To generate the XML report, set the `GTEST_OUTPUT` environment variable or the `--gtest_output` flag to the string `"xml:_path_to_output_file_"`, which will create the file at the given location. You can also just use the string `"xml"`, in which case the output can be found in the `test_detail.xml` file in the current directory.
If you specify a directory (for example, `"xml:output/directory/"` on Linux or `"xml:output\directory\"` on Windows), Google Test will create the XML file in that directory, named after the test executable (e.g. `foo_test.xml` for test program `foo_test` or `foo_test.exe`). If the file already exists (perhaps left over from a previous run), Google Test will pick a different name (e.g. `foo_test_1.xml`) to avoid overwriting it.
The report uses the format described here.  It is based on the `junitreport` Ant task and can be parsed by popular continuous build systems like [Hudson](https://hudson.dev.java.net/). Since that format was originally intended for Java, a little interpretation is required to make it apply to Google Test tests, as shown here:
``` <testsuites name="AllTests" ...>   <testsuite name="test_case_name" ...>     <testcase name="test_name" ...>       <failure message="..."/>       <failure message="..."/>       <failure message="..."/>     </testcase>   </testsuite> </testsuites> ```
* The root `<testsuites>` element corresponds to the entire test program.   * `<testsuite>` elements correspond to Google Test test cases.   * `<testcase>` elements correspond to Google Test test functions.
For instance, the following program
``` TEST(MathTest, Addition) { ... } TEST(MathTest, Subtraction) { ... } TEST(LogicTest, NonContradiction) { ... } ```
could generate this report:
``` <?xml version="1.0" encoding="UTF-8"?> <testsuites tests="3" failures="1" errors="0" time="35" name="AllTests">   <testsuite name="MathTest" tests="2" failures="1" errors="0" time="15">     <testcase name="Addition" status="run" time="7" classname="">       <failure message="Value of: add(1, 1)&#x0A; Actual: 3&#x0A;Expected: 2" type=""/>       <failure message="Value of: add(1, -1)&#x0A; Actual: 1&#x0A;Expected: 0" type=""/>     </testcase>     <testcase name="Subtraction" status="run" time="5" classname="">     </testcase>   </testsuite>   <testsuite name="LogicTest" tests="1" failures="0" errors="0" time="5">     <testcase name="NonContradiction" status="run" time="5" classname="">     </testcase>   </testsuite> </testsuites> ```
Things to note:
* The `tests` attribute of a `<testsuites>` or `<testsuite>` element tells how many test functions the Google Test program or test case contains, while the `failures` attribute tells how many of them failed.   * The `time` attribute expresses the duration of the test, test case, or entire test program in milliseconds.   * Each `<failure>` element corresponds to a single failed Google Test assertion.   * Some JUnit concepts don't apply to Google Test, yet we have to conform to the DTD. Therefore you'll see some dummy elements and attributes in the report. You can safely ignore these parts.
_Availability:_ Linux, Windows, Mac.
When running test programs under a debugger, it's very convenient if the debugger can catch an assertion failure and automatically drop into interactive mode. Google Test's _break-on-failure_ mode supports this behavior.
To enable it, set the `GTEST_BREAK_ON_FAILURE` environment variable to a value other than `0` . Alternatively, you can use the `--gtest_break_on_failure` command line flag.
_Availability:_ Linux, Windows, Mac.
Google Test can be used either with or without exceptions enabled.  If a test throws a C++ exception or (on Windows) a structured exception (SEH), by default Google Test catches it, reports it as a test failure, and continues with the next test method.  This maximizes the coverage of a test run.  Also, on Windows an uncaught exception will cause a pop-up window, so catching the exceptions allows you to run the tests automatically.
When debugging the test failures, however, you may instead want the exceptions to be handled by the debugger, such that you can examine the call stack when an exception is thrown.  To achieve that, set the `GTEST_CATCH_EXCEPTIONS` environment variable to `0`, or use the `--gtest_catch_exceptions=0` flag when running the tests.
**Availability**: Linux, Windows, Mac.
If you work on a project that has already been using another testing framework and is not ready to completely switch to Google Test yet, you can get much of Google Test's benefit by using its assertions in your existing tests.  Just change your `main()` function to look like:
``` #include "gtest/gtest.h"
int main(int argc, char** argv) {   ::testing::GTEST_FLAG(throw_on_failure) = true;   // Important: Google Test must be initialized.   ::testing::InitGoogleTest(&argc, argv);
... whatever your existing testing framework requires ... } ```
With that, you can use Google Test assertions in addition to the native assertions your testing framework provides, for example:
``` void TestFooDoesBar() {   Foo foo;   EXPECT_LE(foo.Bar(1), 100);     // A Google Test assertion.   CPPUNIT_ASSERT(foo.IsEmpty());  // A native assertion. } ```
If a Google Test assertion fails, it will print an error message and throw an exception, which will be treated as a failure by your host testing framework.  If you compile your code with exceptions disabled, a failed Google Test assertion will instead exit your program with a non-zero code, which will also signal a test failure to your test runner.
If you don't write `::testing::GTEST_FLAG(throw_on_failure) = true;` in your `main()`, you can alternatively enable this feature by specifying the `--gtest_throw_on_failure` flag on the command-line or setting the `GTEST_THROW_ON_FAILURE` environment variable to a non-zero value.
_Availability:_ Linux, Windows, Mac; since v1.3.0.
If you have more than one machine you can use to run a test program, you might want to run the test functions in parallel and get the result faster.  We call this technique _sharding_, where each machine is called a _shard_.
Google Test is compatible with test sharding.  To take advantage of this feature, your test runner (not part of Google Test) needs to do the following:
1. Allocate a number of machines (shards) to run the tests.   1. On each shard, set the `GTEST_TOTAL_SHARDS` environment variable to the total number of shards.  It must be the same for all shards.   1. On each shard, set the `GTEST_SHARD_INDEX` environment variable to the index of the shard.  Different shards must be assigned different indices, which must be in the range `[0, GTEST_TOTAL_SHARDS - 1]`.   1. Run the same test program on all shards.  When Google Test sees the above two environment variables, it will select a subset of the test functions to run.  Across all shards, each test function in the program will be run exactly once.   1. Wait for all shards to finish, then collect and report the results.
Your project may have tests that were written without Google Test and thus don't understand this protocol.  In order for your test runner to figure out which test supports sharding, it can set the environment variable `GTEST_SHARD_STATUS_FILE` to a non-existent file path.  If a test program supports sharding, it will create this file to acknowledge the fact (the actual contents of the file are not important at this time; although we may stick some useful information in it in the future.); otherwise it will not create it.
Here's an example to make it clear.  Suppose you have a test program `foo_test` that contains the following 5 test functions: ``` TEST(A, V) TEST(A, W) TEST(B, X) TEST(B, Y) TEST(B, Z) ``` and you have 3 machines at your disposal.  To run the test functions in parallel, you would set `GTEST_TOTAL_SHARDS` to 3 on all machines, and set `GTEST_SHARD_INDEX` to 0, 1, and 2 on the machines respectively. Then you would run the same `foo_test` on each machine.
Google Test reserves the right to change how the work is distributed across the shards, but here's one possible scenario:
* Machine #0 runs `A.V` and `B.X`.   * Machine #1 runs `A.W` and `B.Y`.   * Machine #2 runs `B.Z`.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
Google Test's implementation consists of ~30 files (excluding its own tests).  Sometimes you may want them to be packaged up in two files (a `.h` and a `.cc`) instead, such that you can easily copy them to a new machine and start hacking there.  For this we provide an experimental Python script `fuse_gtest_files.py` in the `scripts/` directory (since release 1.3.0). Assuming you have Python 2.4 or above installed on your machine, just go to that directory and run ``` python fuse_gtest_files.py OUTPUT_DIR ```
and you should see an `OUTPUT_DIR` directory being created with files `gtest/gtest.h` and `gtest/gtest-all.cc` in it.  These files contain everything you need to use Google Test.  Just copy them to anywhere you want and you are ready to write tests.  You can use the [scripts/test/Makefile](../scripts/test/Makefile) file as an example on how to compile your tests against them.
Congratulations! You've now learned more advanced Google Test tools and are ready to tackle more complex testing tasks. If you want to dive even deeper, you can read the [Frequently-Asked Questions](V1_6_FAQ.md).
This page lists all documentation wiki pages for Google Test **1.6** -- **if you use a released version of Google Test, please read the documentation for that specific version instead.**
* [Primer](V1_6_Primer.md) -- start here if you are new to Google Test.   * [Samples](V1_6_Samples.md) -- learn from examples.   * [AdvancedGuide](V1_6_AdvancedGuide.md) -- learn more about Google Test.   * [XcodeGuide](V1_6_XcodeGuide.md) -- how to use Google Test in Xcode on Mac.   * [Frequently-Asked Questions](V1_6_FAQ.md) -- check here before asking a question on the mailing list.
To contribute code to Google Test, read:
* [DevGuide](DevGuide.md) -- read this _before_ writing your first patch.   * [PumpManual](V1_6_PumpManual.md) -- how we generate some of Google Test's source files.

If you cannot find the answer to your question here, and you have read [Primer](V1_6_Primer.md) and [AdvancedGuide](V1_6_AdvancedGuide.md), send it to googletestframework@googlegroups.com.
First, let us say clearly that we don't want to get into the debate of which C++ testing framework is **the best**.  There exist many fine frameworks for writing C++ tests, and we have tremendous respect for the developers and users of them.  We don't think there is (or will be) a single best framework - you have to pick the right tool for the particular task you are tackling.
We created Google Test because we couldn't find the right combination of features and conveniences in an existing framework to satisfy _our_ needs.  The following is a list of things that _we_ like about Google Test.  We don't claim them to be unique to Google Test - rather, the combination of them makes Google Test the choice for us.  We hope this list can help you decide whether it is for you too.
* Google Test is designed to be portable: it doesn't require exceptions or RTTI; it works around various bugs in various compilers and environments; etc.  As a result, it works on Linux, Mac OS X, Windows and several embedded operating systems.   * Nonfatal assertions (`EXPECT_*`) have proven to be great time savers, as they allow a test to report multiple failures in a single edit-compile-test cycle.   * It's easy to write assertions that generate informative messages: you just use the stream syntax to append any additional information, e.g. `ASSERT_EQ(5, Foo(i)) << " where i = " << i;`.  It doesn't require a new set of macros or special functions.   * Google Test automatically detects your tests and doesn't require you to enumerate them in order to run them.   * Death tests are pretty handy for ensuring that your asserts in production code are triggered by the right conditions.   * `SCOPED_TRACE` helps you understand the context of an assertion failure when it comes from inside a sub-routine or loop.   * You can decide which tests to run using name patterns.  This saves time when you want to quickly reproduce a test failure.   * Google Test can generate XML test result reports that can be parsed by popular continuous build system like Hudson.   * Simple things are easy in Google Test, while hard things are possible: in addition to advanced features like [global test environments](V1_6_AdvancedGuide.md#Global_Set-Up_and_Tear-Down) and tests parameterized by [values](V1_6_AdvancedGuide.md#value-parameterized-tests) or [types](V1_6_AdvancedGuide.md#typed-tests), Google Test supports various ways for the user to extend the framework -- if Google Test doesn't do something out of the box, chances are that a user can implement the feature using Google Test's public API, without changing Google Test itself.  In particular, you can:     * expand your testing vocabulary by defining [custom predicates](V1_6_AdvancedGuide.md#predicate-assertions-for-better-error-messages),     * teach Google Test how to [print your types](V1_6_AdvancedGuide.md#teaching-google-test-how-to-print-your-values),     * define your own testing macros or utilities and verify them using Google Test's [Service Provider Interface](V1_6_AdvancedGuide.md#catching-failures), and     * reflect on the test cases or change the test output format by intercepting the [test events](V1_6_AdvancedGuide.md#extending-google-test-by-handling-test-events).
We strive to minimize compiler warnings Google Test generates.  Before releasing a new version, we test to make sure that it doesn't generate warnings when compiled using its CMake script on Windows, Linux, and Mac OS.
Unfortunately, this doesn't mean you are guaranteed to see no warnings when compiling Google Test in your environment:
* You may be using a different compiler as we use, or a different version of the same compiler.  We cannot possibly test for all compilers.   * You may be compiling on a different platform as we do.   * Your project may be using different compiler flags as we do.
It is not always possible to make Google Test warning-free for everyone.  Or, it may not be desirable if the warning is rarely enabled and fixing the violations makes the code more complex.
If you see warnings when compiling Google Test, we suggest that you use the `-isystem` flag (assuming your are using GCC) to mark Google Test headers as system headers.  That'll suppress warnings from Google Test headers.
Underscore (`_`) is special, as C++ reserves the following to be used by the compiler and the standard library:
1. any identifier that starts with an `_` followed by an upper-case letter, and   1. any identifier that containers two consecutive underscores (i.e. `__`) _anywhere_ in its name.
User code is _prohibited_ from using such identifiers.
Now let's look at what this means for `TEST` and `TEST_F`.
Currently `TEST(TestCaseName, TestName)` generates a class named `TestCaseName_TestName_Test`.  What happens if `TestCaseName` or `TestName` contains `_`?
1. If `TestCaseName` starts with an `_` followed by an upper-case letter (say, `_Foo`), we end up with `_Foo_TestName_Test`, which is reserved and thus invalid.   1. If `TestCaseName` ends with an `_` (say, `Foo_`), we get `Foo__TestName_Test`, which is invalid.   1. If `TestName` starts with an `_` (say, `_Bar`), we get `TestCaseName__Bar_Test`, which is invalid.   1. If `TestName` ends with an `_` (say, `Bar_`), we get `TestCaseName_Bar__Test`, which is invalid.
So clearly `TestCaseName` and `TestName` cannot start or end with `_` (Actually, `TestCaseName` can start with `_` -- as long as the `_` isn't followed by an upper-case letter.  But that's getting complicated.  So for simplicity we just say that it cannot start with `_`.).
It may seem fine for `TestCaseName` and `TestName` to contain `_` in the middle.  However, consider this: ``` TEST(Time, Flies_Like_An_Arrow) { ... } TEST(Time_Flies, Like_An_Arrow) { ... } ```
Now, the two `TEST`s will both generate the same class (`Time_Files_Like_An_Arrow_Test`).  That's not good.
So for simplicity, we just ask the users to avoid `_` in `TestCaseName` and `TestName`.  The rule is more constraining than necessary, but it's simple and easy to remember.  It also gives Google Test some wiggle room in case its implementation needs to change in the future.
If you violate the rule, there may not be immediately consequences, but your test may (just may) break with a new compiler (or a new version of the compiler you are using) or with a new version of Google Test.  Therefore it's best to follow the rule.
In the early days, we said that you could install compiled Google Test libraries on `*`nix systems using `make install`. Then every user of your machine can write tests without recompiling Google Test.
This seemed like a good idea, but it has a got-cha: every user needs to compile his tests using the _same_ compiler flags used to compile the installed Google Test libraries; otherwise he may run into undefined behaviors (i.e. the tests can behave strangely and may even crash for no obvious reasons).
Why?  Because C++ has this thing called the One-Definition Rule: if two C++ source files contain different definitions of the same class/function/variable, and you link them together, you violate the rule.  The linker may or may not catch the error (in many cases it's not required by the C++ standard to catch the violation).  If it doesn't, you get strange run-time behaviors that are unexpected and hard to debug.
If you compile Google Test and your test code using different compiler flags, they may see different definitions of the same class/function/variable (e.g. due to the use of `#if` in Google Test). Therefore, for your sanity, we recommend to avoid installing pre-compiled Google Test libraries.  Instead, each project should compile Google Test itself such that it can be sure that the same flags are used for both Google Test and the tests.
(Answered by Trevor Robinson)
Load the supplied Visual Studio solution file, either `msvc\gtest-md.sln` or `msvc\gtest.sln`. Go through the migration wizard to migrate the solution and project files to Visual Studio 2008. Select `Configuration Manager...` from the `Build` menu. Select `<New...>` from the `Active solution platform` dropdown.  Select `x64` from the new platform dropdown, leave `Copy settings from` set to `Win32` and `Create new project platforms` checked, then click `OK`. You now have `Win32` and `x64` platform configurations, selectable from the `Standard` toolbar, which allow you to toggle between building 32-bit or 64-bit binaries (or both at once using Batch Build).
In order to prevent build output files from overwriting one another, you'll need to change the `Intermediate Directory` settings for the newly created platform configuration across all the projects. To do this, multi-select (e.g. using shift-click) all projects (but not the solution) in the `Solution Explorer`. Right-click one of them and select `Properties`. In the left pane, select `Configuration Properties`, and from the `Configuration` dropdown, select `All Configurations`. Make sure the selected platform is `x64`. For the `Intermediate Directory` setting, change the value from `$(PlatformName)\$(ConfigurationName)` to `$(OutDir)\$(ProjectName)`. Click `OK` and then build the solution. When the build is complete, the 64-bit binaries will be in the `msvc\x64\Debug` directory.
We haven't tested this ourselves, but Per Abrahamsen reported that he was able to compile and install Google Test successfully when using MinGW from Cygwin.  You'll need to configure it with:
`PATH/TO/configure CC="gcc -mno-cygwin" CXX="g++ -mno-cygwin"`
You should be able to replace the `-mno-cygwin` option with direct links to the real MinGW binaries, but we haven't tried that.
Caveats:
* There are many warnings when compiling.   * `make check` will produce some errors as not all tests for Google Test itself are compatible with MinGW.
We also have reports on successful cross compilation of Google Test MinGW binaries on Linux using [these instructions](http://wiki.wxwidgets.org/Cross-Compiling_Under_Linux#Cross-compiling_under_Linux_for_MS_Windows) on the WxWidgets site.
Please contact `googletestframework@googlegroups.com` if you are interested in improving the support for MinGW.
Due to some peculiarity of C++, it requires some non-trivial template meta programming tricks to support using `NULL` as an argument of the `EXPECT_XX()` and `ASSERT_XX()` macros. Therefore we only do it where it's most needed (otherwise we make the implementation of Google Test harder to maintain and more error-prone than necessary).
The `EXPECT_EQ()` macro takes the _expected_ value as its first argument and the _actual_ value as the second. It's reasonable that someone wants to write `EXPECT_EQ(NULL, some_expression)`, and this indeed was requested several times. Therefore we implemented it.
The need for `EXPECT_NE(NULL, ptr)` isn't nearly as strong. When the assertion fails, you already know that `ptr` must be `NULL`, so it doesn't add any information to print ptr in this case. That means `EXPECT_TRUE(ptr ! NULL)` works just as well.
If we were to support `EXPECT_NE(NULL, ptr)`, for consistency we'll have to support `EXPECT_NE(ptr, NULL)` as well, as unlike `EXPECT_EQ`, we don't have a convention on the order of the two arguments for `EXPECT_NE`. This means using the template meta programming tricks twice in the implementation, making it even harder to understand and maintain. We believe the benefit doesn't justify the cost.
Finally, with the growth of Google Mock's [matcher](../../CookBook.md#using-matchers-in-google-test-assertions) library, we are encouraging people to use the unified `EXPECT_THAT(value, matcher)` syntax more often in tests. One significant advantage of the matcher approach is that matchers can be easily combined to form new matchers, while the `EXPECT_NE`, etc, macros cannot be easily combined. Therefore we want to invest more in the matchers than in the `EXPECT_XX()` macros.
Test runners tend to be tightly coupled with the build/test environment, and Google Test doesn't try to solve the problem of running tests in parallel.  Instead, we tried to make Google Test work nicely with test runners.  For example, Google Test's XML report contains the time spent on each test, and its `gtest_list_tests` and `gtest_filter` flags can be used for splitting the execution of test methods into multiple processes.  These functionalities can help the test runner run the tests in parallel.
It's difficult to write thread-safe code.  Most tests are not written with thread-safety in mind, and thus may not work correctly in a multi-threaded setting.
If you think about it, it's already hard to make your code work when you know what other threads are doing.  It's much harder, and sometimes even impossible, to make your code work when you don't know what other threads are doing (remember that test methods can be added, deleted, or modified after your test was written).  If you want to run the tests in parallel, you'd better run them in different processes.
Our original motivation was to be able to use Google Test in projects that disable exceptions.  Later we realized some additional benefits of this approach:
1. Throwing in a destructor is undefined behavior in C++.  Not using exceptions means Google Test's assertions are safe to use in destructors.   1. The `EXPECT_*` family of macros will continue even after a failure, allowing multiple failures in a `TEST` to be reported in a single run. This is a popular feature, as in C++ the edit-compile-test cycle is usually quite long and being able to fixing more than one thing at a time is a blessing.   1. If assertions are implemented using exceptions, a test may falsely ignore a failure if it's caught by user code: ``` try { ... ASSERT_TRUE(...) ... } catch (...) { ... } ``` The above code will pass even if the `ASSERT_TRUE` throws.  While it's unlikely for someone to write this in a test, it's possible to run into this pattern when you write assertions in callbacks that are called by the code under test.
The downside of not using exceptions is that `ASSERT_*` (implemented using `return`) will only abort the current function, not the current `TEST`.
Unfortunately, C++'s macro system doesn't allow us to use the same macro for both cases.  One possibility is to provide only one macro for tests with fixtures, and require the user to define an empty fixture sometimes:
``` class FooTest : public ::testing::Test {};
TEST_F(FooTest, DoesThis) { ... } ``` or ``` typedef ::testing::Test FooTest;
TEST_F(FooTest, DoesThat) { ... } ```
Yet, many people think this is one line too many. :-) Our goal was to make it really easy to write tests, so we tried to make simple tests trivial to create.  That means using a separate macro for such tests.
We think neither approach is ideal, yet either of them is reasonable. In the end, it probably doesn't matter much either way.
We like to use structs only when representing passive data.  This distinction between structs and classes is good for documenting the intent of the code's author.  Since test fixtures have logic like `SetUp()` and `TearDown()`, they are better defined as classes.
Our goal was to make death tests as convenient for a user as C++ possibly allows.  In particular:
* The runner-style requires to split the information into two pieces: the definition of the death test itself, and the specification for the runner on how to run the death test and what to expect.  The death test would be written in C++, while the runner spec may or may not be.  A user needs to carefully keep the two in sync. `ASSERT_DEATH(statement, expected_message)` specifies all necessary information in one place, in one language, without boilerplate code. It is very declarative.   * `ASSERT_DEATH` has a similar syntax and error-reporting semantics as other Google Test assertions, and thus is easy to learn.   * `ASSERT_DEATH` can be mixed with other assertions and other logic at your will.  You are not limited to one death test per test method. For example, you can write something like: ```     if (FooCondition()) {       ASSERT_DEATH(Bar(), "blah");     } else {       ASSERT_EQ(5, Bar());     } ``` If you prefer one death test per test method, you can write your tests in that style too, but we don't want to impose that on the users.  The fewer artificial limitations the better.   * `ASSERT_DEATH` can reference local variables in the current function, and you can decide how many death tests you want based on run-time information.  For example, ```     const int count = GetCount();  // Only known at run time.     for (int i = 1; i <= count; i++) {       ASSERT_DEATH({         double* buffer = new double[i];         ... initializes buffer ...         Foo(buffer, i)       }, "blah blah");     } ``` The runner-based approach tends to be more static and less flexible, or requires more user effort to get this kind of flexibility.
Another interesting thing about `ASSERT_DEATH` is that it calls `fork()` to create a child process to run the death test.  This is lightening fast, as `fork()` uses copy-on-write pages and incurs almost zero overhead, and the child process starts from the user-supplied statement directly, skipping all global and local initialization and any code leading to the given statement.  If you launch the child process from scratch, it can take seconds just to load everything and start running if the test links to many libraries dynamically.
Death tests (`EXPECT_DEATH`, etc) are executed in a sub-process s.t. the expected crash won't kill the test program (i.e. the parent process). As a result, any in-memory side effects they incur are observable in their respective sub-processes, but not in the parent process. You can think of them as running in a parallel universe, more or less.
If your class has a static data member:
``` // foo.h class Foo {   ...   static const int kBar = 100; }; ```
You also need to define it _outside_ of the class body in `foo.cc`:
``` const int Foo::kBar;  // No initializer here. ```
Otherwise your code is **invalid C++**, and may break in unexpected ways. In particular, using it in Google Test comparison assertions (`EXPECT_EQ`, etc) will generate an "undefined reference" linker error.
Google Test doesn't yet have good support for this kind of tests, or data-driven tests in general. We hope to be able to make improvements in this area soon.
Yes.
Each test fixture has a corresponding and same named test case. This means only one test case can use a particular fixture. Sometimes, however, multiple test cases may want to use the same or slightly different fixtures. For example, you may want to make sure that all of a GUI library's test cases don't leak important system resources like fonts and brushes.
In Google Test, you share a fixture among test cases by putting the shared logic in a base test fixture, then deriving from that base a separate fixture for each test case that wants to use this common logic. You then use `TEST_F()` to write tests using each derived fixture.
Typically, your code looks like this:
``` // Defines a base test fixture. class BaseTest : public ::testing::Test {   protected:    ... };
// Derives a fixture FooTest from BaseTest. class FooTest : public BaseTest {   protected:     virtual void SetUp() {       BaseTest::SetUp();  // Sets up the base fixture first.       ... additional set-up work ...     }     virtual void TearDown() {       ... clean-up work for FooTest ...       BaseTest::TearDown();  // Remember to tear down the base fixture                              // after cleaning up FooTest!     }     ... functions and variables for FooTest ... };
// Tests that use the fixture FooTest. TEST_F(FooTest, Bar) { ... } TEST_F(FooTest, Baz) { ... }
... additional fixtures derived from BaseTest ... ```
If necessary, you can continue to derive test fixtures from a derived fixture. Google Test has no limit on how deep the hierarchy can be.
For a complete example using derived test fixtures, see [sample5](../samples/sample5_unittest.cc).
You're probably using an `ASSERT_*()` in a function that doesn't return `void`. `ASSERT_*()` can only be used in `void` functions.
In Google Test, death tests are run in a child process and the way they work is delicate. To write death tests you really need to understand how they work. Please make sure you have read this.
In particular, death tests don't like having multiple threads in the parent process. So the first thing you can try is to eliminate creating threads outside of `EXPECT_DEATH()`.
Sometimes this is impossible as some library you must use may be creating threads before `main()` is even reached. In this case, you can try to minimize the chance of conflicts by either moving as many activities as possible inside `EXPECT_DEATH()` (in the extreme case, you want to move everything inside), or leaving as few things as possible in it. Also, you can try to set the death test style to `"threadsafe"`, which is safer but slower, and see if it helps.
If you go with thread-safe death tests, remember that they rerun the test program from the beginning in the child process. Therefore make sure your program can run side-by-side with itself and is deterministic.
In the end, this boils down to good concurrent programming. You have to make sure that there is no race conditions or dead locks in your program. No silver bullet - sorry!
The first thing to remember is that Google Test does not reuse the same test fixture object across multiple tests. For each `TEST_F`, Google Test will create a fresh test fixture object, _immediately_ call `SetUp()`, run the test, call `TearDown()`, and then _immediately_ delete the test fixture object. Therefore, there is no need to write a `SetUp()` or `TearDown()` function if the constructor or destructor already does the job.
You may still want to use `SetUp()/TearDown()` in the following cases:   * If the tear-down operation could throw an exception, you must use `TearDown()` as opposed to the destructor, as throwing in a destructor leads to undefined behavior and usually will kill your program right away. Note that many standard libraries (like STL) may throw when exceptions are enabled in the compiler. Therefore you should prefer `TearDown()` if you want to write portable tests that work with or without exceptions.   * The Google Test team is considering making the assertion macros throw on platforms where exceptions are enabled (e.g. Windows, Mac OS, and Linux client-side), which will eliminate the need for the user to propagate failures from a subroutine to its caller. Therefore, you shouldn't use Google Test assertions in a destructor if your code could run on such a platform.   * In a constructor or destructor, you cannot make a virtual function call on this object. (You can call a method declared as virtual, but it will be statically bound.) Therefore, if you need to call a method that will be overriden in a derived class, you have to use `SetUp()/TearDown()`.
If the predicate function you use in `ASSERT_PRED*` or `EXPECT_PRED*` is overloaded or a template, the compiler will have trouble figuring out which overloaded version it should use. `ASSERT_PRED_FORMAT*` and `EXPECT_PRED_FORMAT*` don't have this problem.
If you see this error, you might want to switch to `(ASSERT|EXPECT)_PRED_FORMAT*`, which will also give you a better failure message. If, however, that is not an option, you can resolve the problem by explicitly telling the compiler which version to pick.
For example, suppose you have
``` bool IsPositive(int n) {   return n > 0; } bool IsPositive(double x) {   return x > 0; } ```
you will get a compiler error if you write
``` EXPECT_PRED1(IsPositive, 5); ```
However, this will work:
``` EXPECT_PRED1(*static_cast<bool (*)(int)>*(IsPositive), 5); ```
(The stuff inside the angled brackets for the `static_cast` operator is the type of the function pointer for the `int`-version of `IsPositive()`.)
As another example, when you have a template function
``` template <typename T> bool IsNegative(T x) {   return x < 0; } ```
you can use it in a predicate assertion like this:
``` ASSERT_PRED1(IsNegative*<int>*, -5); ```
Things are more interesting if your template has more than one parameters. The following won't compile:
``` ASSERT_PRED2(*GreaterThan<int, int>*, 5, 0); ```
as the C++ pre-processor thinks you are giving `ASSERT_PRED2` 4 arguments, which is one more than expected. The workaround is to wrap the predicate function in parentheses:
``` ASSERT_PRED2(*(GreaterThan<int, int>)*, 5, 0); ```
Some people had been ignoring the return value of `RUN_ALL_TESTS()`. That is, instead of
``` return RUN_ALL_TESTS(); ```
they write
``` RUN_ALL_TESTS(); ```
This is wrong and dangerous. A test runner needs to see the return value of `RUN_ALL_TESTS()` in order to determine if a test has passed. If your `main()` function ignores it, your test will be considered successful even if it has a Google Test assertion failure. Very bad.
To help the users avoid this dangerous bug, the implementation of `RUN_ALL_TESTS()` causes gcc to raise this warning, when the return value is ignored. If you see this warning, the fix is simple: just make sure its value is used as the return value of `main()`.
Due to a peculiarity of C++, in order to support the syntax for streaming messages to an `ASSERT_*`, e.g.
``` ASSERT_EQ(1, Foo()) << "blah blah" << foo; ```
we had to give up using `ASSERT*` and `FAIL*` (but not `EXPECT*` and `ADD_FAILURE*`) in constructors and destructors. The workaround is to move the content of your constructor/destructor to a private void member function, or switch to `EXPECT_*()` if that works. This section in the user's guide explains it.
C++ is case-sensitive. It should be spelled as `SetUp()`.  Did you spell it as `Setup()`?
Similarly, sometimes people spell `SetUpTestCase()` as `SetupTestCase()` and wonder why it's never called.
Google Test's failure message format is understood by Emacs and many other IDEs, like acme and XCode. If a Google Test message is in a compilation buffer in Emacs, then it's clickable. You can now hit `enter` on a message to jump to the corresponding source code, or use `C-x `` to jump to the next failure.
You don't have to. Instead of
``` class FooTest : public BaseTest {};
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
class BarTest : public BaseTest {};
TEST_F(BarTest, Abc) { ... } TEST_F(BarTest, Def) { ... } ```
you can simply `typedef` the test fixtures: ``` typedef BaseTest FooTest;
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
typedef BaseTest BarTest;
TEST_F(BarTest, Abc) { ... } TEST_F(BarTest, Def) { ... } ```
The Google Test output is meant to be a concise and human-friendly report. If your test generates textual output itself, it will mix with the Google Test output, making it hard to read. However, there is an easy solution to this problem.
Since most log messages go to stderr, we decided to let Google Test output go to stdout. This way, you can easily separate the two using redirection. For example: ``` ./my_test > googletest_output.txt ```
There are several good reasons:   1. It's likely your test needs to change the states of its global variables. This makes it difficult to keep side effects from escaping one test and contaminating others, making debugging difficult. By using fixtures, each test has a fresh set of variables that's different (but with the same names). Thus, tests are kept independent of each other.   1. Global variables pollute the global namespace.   1. Test fixtures can be reused via subclassing, which cannot be done easily with global variables. This is useful if many test cases have something in common.
You should try to write testable code, which means classes should be easily tested from their public interface. One way to achieve this is the Pimpl idiom: you move all private members of a class into a helper class, and make all members of the helper class public.
You have several other options that don't require using `FRIEND_TEST`:   * Write the tests as members of the fixture class: ``` class Foo {   friend class FooTest;   ... };
class FooTest : public ::testing::Test {  protected:   ...   void Test1() {...} // This accesses private members of class Foo.   void Test2() {...} // So does this one. };
TEST_F(FooTest, Test1) {   Test1(); }
TEST_F(FooTest, Test2) {   Test2(); } ```   * In the fixture class, write accessors for the tested class' private members, then use the accessors in your tests: ``` class Foo {   friend class FooTest;   ... };
class FooTest : public ::testing::Test {  protected:   ...   T1 get_private_member1(Foo* obj) {     return obj->private_member1_;   } };
TEST_F(FooTest, Test1) {   ...   get_private_member1(x)   ... } ```   * If the methods are declared **protected**, you can change their access level in a test-only subclass: ``` class YourClass {   ...  protected: // protected access for testability.   int DoSomethingReturningInt();   ... };
// in the your_class_test.cc file: class TestableYourClass : public YourClass {   ...  public: using YourClass::DoSomethingReturningInt; // changes access rights   ... };
TEST_F(YourClassTest, DoSomethingTest) {   TestableYourClass obj;   assertEquals(expected_value, obj.DoSomethingReturningInt()); } ```
We find private static methods clutter the header file.  They are implementation details and ideally should be kept out of a .h. So often I make them free functions instead.
Instead of: ``` // foo.h class Foo {   ...  private:   static bool Func(int n); };
// foo.cc bool Foo::Func(int n) { ... }
// foo_test.cc EXPECT_TRUE(Foo::Func(12345)); ```
You probably should better write: ``` // foo.h class Foo {   ... };
// foo.cc namespace internal {   bool Func(int n) { ... } }
// foo_test.cc namespace internal {   bool Func(int n); }
EXPECT_TRUE(internal::Func(12345)); ```
No. You can use a feature called [value-parameterized tests](V1_6_AdvancedGuide.md#Value_Parameterized_Tests) which lets you repeat your tests with different parameters, without defining it more than once.
To test a `foo.cc` file, you need to compile and link it into your unit test program. However, when the file contains a definition for the `main()` function, it will clash with the `main()` of your unit test, and will result in a build error.
The right solution is to split it into three files:   1. `foo.h` which contains the declarations,   1. `foo.cc` which contains the definitions except `main()`, and   1. `foo_main.cc` which contains nothing but the definition of `main()`.
Then `foo.cc` can be easily tested.
If you are adding tests to an existing file and don't want an intrusive change like this, there is a hack: just include the entire `foo.cc` file in your unit test. For example: ``` // File foo_unittest.cc
// The headers section ...
// Renames main() in foo.cc to make room for the unit test main() #define main FooMain
#include "a/b/foo.cc"
// The tests start here. ... ```
However, please remember this is a hack and should only be used as the last resort.
`ASSERT_DEATH(_statement_, _regex_)` (or any death assertion macro) can be used wherever `_statement_` is valid. So basically `_statement_` can be any C++ statement that makes sense in the current context. In particular, it can reference global and/or local variables, and can be:   * a simple function call (often the case),   * a complex expression, or   * a compound statement.
> Some examples are shown here:
``` // A death test can be a simple function call. TEST(MyDeathTest, FunctionCall) {   ASSERT_DEATH(Xyz(5), "Xyz failed"); }
// Or a complex expression that references variables and functions. TEST(MyDeathTest, ComplexExpression) {   const bool c = Condition();   ASSERT_DEATH((c ? Func1(0) : object2.Method("test")),                "(Func1|Method) failed"); }
// Death assertions can be used any where in a function. In // particular, they can be inside a loop. TEST(MyDeathTest, InsideLoop) {   // Verifies that Foo(0), Foo(1), ..., and Foo(4) all die.   for (int i = 0; i < 5; i++) {     EXPECT_DEATH_M(Foo(i), "Foo has \\d+ errors",                    ::testing::Message() << "where i is " << i);   } }
// A death assertion can contain a compound statement. TEST(MyDeathTest, CompoundStatement) {   // Verifies that at lease one of Bar(0), Bar(1), ..., and   // Bar(4) dies.   ASSERT_DEATH({     for (int i = 0; i < 5; i++) {       Bar(i);     }   },   "Bar has \\d+ errors");} ```
`googletest_unittest.cc` contains more examples if you are interested.
On POSIX systems, Google Test uses the POSIX Extended regular expression syntax (http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions). On Windows, it uses a limited variant of regular expression syntax. For more details, see the [regular expression syntax](V1_6_AdvancedGuide.md#Regular_Expression_Syntax).
Google Test needs to be able to create objects of your test fixture class, so it must have a default constructor. Normally the compiler will define one for you. However, there are cases where you have to define your own:   * If you explicitly declare a non-default constructor for class `Foo`, then you need to define a default constructor, even if it would be empty.   * If `Foo` has a const non-static data member, then you have to define the default constructor _and_ initialize the const member in the initializer list of the constructor. (Early versions of `gcc` doesn't force you to initialize the const member. It's a bug that has been fixed in `gcc 4`.)
With the Linux pthread library, there is no turning back once you cross the line from single thread to multiple threads. The first time you create a thread, a manager thread is created in addition, so you get 3, not 2, threads. Later when the thread you create joins the main thread, the thread count decrements by 1, but the manager thread will never be killed, so you still have 2 threads, which means you cannot safely run a death test.
The new NPTL thread library doesn't suffer from this problem, as it doesn't create a manager thread. However, if you don't control which machine your test runs on, you shouldn't depend on this.
Google Test does not interleave tests from different test cases. That is, it runs all tests in one test case first, and then runs all tests in the next test case, and so on. Google Test does this because it needs to set up a test case before the first test in it is run, and tear it down afterwords. Splitting up the test case would require multiple set-up and tear-down processes, which is inefficient and makes the semantics unclean.
If we were to determine the order of tests based on test name instead of test case name, then we would have a problem with the following situation:
``` TEST_F(FooTest, AbcDeathTest) { ... } TEST_F(FooTest, Uvw) { ... }
TEST_F(BarTest, DefDeathTest) { ... } TEST_F(BarTest, Xyz) { ... } ```
Since `FooTest.AbcDeathTest` needs to run before `BarTest.Xyz`, and we don't interleave tests from different test cases, we need to run all tests in the `FooTest` case before running any test in the `BarTest` case. This contradicts with the requirement to run `BarTest.DefDeathTest` before `FooTest.Uvw`.
You don't have to, but if you like, you may split up the test case into `FooTest` and `FooDeathTest`, where the names make it clear that they are related:
``` class FooTest : public ::testing::Test { ... };
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
typedef FooTest FooDeathTest;
TEST_F(FooDeathTest, Uvw) { ... EXPECT_DEATH(...) ... } TEST_F(FooDeathTest, Xyz) { ... ASSERT_DEATH(...) ... } ```
If you use a user-defined type `FooType` in an assertion, you must make sure there is an `std::ostream& operator<<(std::ostream&, const FooType&)` function defined such that we can print a value of `FooType`.
In addition, if `FooType` is declared in a name space, the `<<` operator also needs to be defined in the _same_ name space.
Since the statically initialized Google Test singleton requires allocations on the heap, the Visual C++ memory leak detector will report memory leaks at the end of the program run. The easiest way to avoid this is to use the `_CrtMemCheckpoint` and `_CrtMemDumpAllObjectsSince` calls to not report any statically initialized heap objects. See MSDN for more details and additional heap check/debug routines.
You may get a number of the following linker error or warnings if you attempt to link your test project with the Google Test library when your project and the are not built using the same compiler settings.
* LNK2005: symbol already defined in object   * LNK4217: locally defined symbol 'symbol' imported in function 'function'   * LNK4049: locally defined symbol 'symbol' imported
The Google Test project (gtest.vcproj) has the Runtime Library option set to /MT (use multi-threaded static libraries, /MTd for debug). If your project uses something else, for example /MD (use multi-threaded DLLs, /MDd for debug), you need to change the setting in the Google Test project to match your project's.
To update this setting open the project properties in the Visual Studio IDE then select the branch Configuration Properties | C/C++ | Code Generation and change the option "Runtime Library".  You may also try using gtest-md.vcproj instead of gtest.vcproj.
`export CC=cc CXX=CC CXXFLAGS='-library=stlport4'`
If you write code that sniffs whether it's running in a test and does different things accordingly, you are leaking test-only logic into production code and there is no easy way to ensure that the test-only code paths aren't run by mistake in production.  Such cleverness also leads to [Heisenbugs](http://en.wikipedia.org/wiki/Unusual_software_bug#Heisenbug). Therefore we strongly advise against the practice, and Google Test doesn't provide a way to do it.
In general, the recommended way to cause the code to behave differently under test is [dependency injection](http://jamesshore.com/Blog/Dependency-Injection-Demystified.html). You can inject different functionality from the test and from the production code.  Since your production code doesn't link in the for-test logic at all, there is no danger in accidentally running it.
However, if you _really_, _really_, _really_ have no choice, and if you follow the rule of ending your test program names with `_test`, you can use the _horrible_ hack of sniffing your executable name (`argv[0]` in `main()`) to know whether the code is under test.
In C++, macros don't obey namespaces.  Therefore two libraries that both define a macro of the same name will clash if you `#include` both definitions.  In case a Google Test macro clashes with another library, you can force Google Test to rename its macro to avoid the conflict.
Specifically, if both Google Test and some other code define macro `FOO`, you can add ```   -DGTEST_DONT_DEFINE_FOO=1 ``` to the compiler flags to tell Google Test to change the macro's name from `FOO` to `GTEST_FOO`. For example, with `-DGTEST_DONT_DEFINE_TEST=1`, you'll need to write ```   GTEST_TEST(SomeTest, DoesThis) { ... } ``` instead of ```   TEST(SomeTest, DoesThis) { ... } ``` in order to define a test.
Currently, the following `TEST`, `FAIL`, `SUCCEED`, and the basic comparison assertion macros can have alternative names. You can see the full list of covered macros [here](http://www.google.com/codesearch?q=if+!GTEST_DONT_DEFINE_\w%2B+package:http://googletest\.googlecode\.com+file:/include/gtest/gtest.h). More information can be found in the "Avoiding Macro Name Clashes" section of the README file.
If you cannot find the answer to your question in this FAQ, there are some other resources you can use:
1. read other [wiki pages](http://code.google.com/p/googletest/w/list),   1. search the mailing list [archive](http://groups.google.com/group/googletestframework/topics),   1. ask it on [googletestframework@googlegroups.com](mailto:googletestframework@googlegroups.com) and someone will answer it (to prevent spam, we require you to join the [discussion group](http://groups.google.com/group/googletestframework) before you can post.).
Please note that creating an issue in the [issue tracker](http://code.google.com/p/googletest/issues/list) is _not_ a good way to get your answer, as it is monitored infrequently by a very small number of people.
When asking a question, it's helpful to provide as much of the following information as possible (people cannot help you if there's not enough information in your question):
* the version (or the revision number if you check out from SVN directly) of Google Test you use (Google Test is under active development, so it's possible that your problem has been solved in a later version),   * your operating system,   * the name and version of your compiler,   * the complete command line flags you give to your compiler,   * the complete compiler error messages (if the question is about compilation),   * the _actual_ code (ideally, a minimal but complete program) that has the problem you encounter.

_Google C++ Testing Framework_ helps you write better C++ tests.
No matter whether you work on Linux, Windows, or a Mac, if you write C++ code, Google Test can help you.
So what makes a good test, and how does Google C++ Testing Framework fit in? We believe:   1. Tests should be _independent_ and _repeatable_. It's a pain to debug a test that succeeds or fails as a result of other tests.  Google C++ Testing Framework isolates the tests by running each of them on a different object. When a test fails, Google C++ Testing Framework allows you to run it in isolation for quick debugging.   1. Tests should be well _organized_ and reflect the structure of the tested code.  Google C++ Testing Framework groups related tests into test cases that can share data and subroutines. This common pattern is easy to recognize and makes tests easy to maintain. Such consistency is especially helpful when people switch projects and start to work on a new code base.   1. Tests should be _portable_ and _reusable_. The open-source community has a lot of code that is platform-neutral, its tests should also be platform-neutral.  Google C++ Testing Framework works on different OSes, with different compilers (gcc, MSVC, and others), with or without exceptions, so Google C++ Testing Framework tests can easily work with a variety of configurations.  (Note that the current release only contains build scripts for Linux - we are actively working on scripts for other platforms.)   1. When tests fail, they should provide as much _information_ about the problem as possible. Google C++ Testing Framework doesn't stop at the first test failure. Instead, it only stops the current test and continues with the next. You can also set up tests that report non-fatal failures after which the current test continues. Thus, you can detect and fix multiple bugs in a single run-edit-compile cycle.   1. The testing framework should liberate test writers from housekeeping chores and let them focus on the test _content_.  Google C++ Testing Framework automatically keeps track of all tests defined, and doesn't require the user to enumerate them in order to run them.   1. Tests should be _fast_. With Google C++ Testing Framework, you can reuse shared resources across tests and pay for the set-up/tear-down only once, without making tests depend on each other.
Since Google C++ Testing Framework is based on the popular xUnit architecture, you'll feel right at home if you've used JUnit or PyUnit before. If not, it will take you about 10 minutes to learn the basics and get started. So let's go!
_Note:_ We sometimes refer to Google C++ Testing Framework informally as _Google Test_.
To write a test program using Google Test, you need to compile Google Test into a library and link your test with it.  We provide build files for some popular build systems: `msvc/` for Visual Studio, `xcode/` for Mac Xcode, `make/` for GNU make, `codegear/` for Borland C++ Builder, and the autotools script (deprecated) and `CMakeLists.txt` for CMake (recommended) in the Google Test root directory.  If your build system is not on this list, you can take a look at `make/Makefile` to learn how Google Test should be compiled (basically you want to compile `src/gtest-all.cc` with `GTEST_ROOT` and `GTEST_ROOT/include` in the header search path, where `GTEST_ROOT` is the Google Test root directory).
Once you are able to compile the Google Test library, you should create a project or build target for your test program.  Make sure you have `GTEST_ROOT/include` in the header search path so that the compiler can find `"gtest/gtest.h"` when compiling your test.  Set up your test project to link with the Google Test library (for example, in Visual Studio, this is done by adding a dependency on `gtest.vcproj`).
If you still have questions, take a look at how Google Test's own tests are built and use them as examples.
When using Google Test, you start by writing _assertions_, which are statements that check whether a condition is true. An assertion's result can be _success_, _nonfatal failure_, or _fatal failure_. If a fatal failure occurs, it aborts the current function; otherwise the program continues normally.
_Tests_ use assertions to verify the tested code's behavior. If a test crashes or has a failed assertion, then it _fails_; otherwise it _succeeds_.
A _test case_ contains one or many tests. You should group your tests into test cases that reflect the structure of the tested code. When multiple tests in a test case need to share common objects and subroutines, you can put them into a _test fixture_ class.
A _test program_ can contain multiple test cases.
We'll now explain how to write a test program, starting at the individual assertion level and building up to tests and test cases.
Google Test assertions are macros that resemble function calls. You test a class or function by making assertions about its behavior. When an assertion fails, Google Test prints the assertion's source file and line number location, along with a failure message. You may also supply a custom failure message which will be appended to Google Test's message.
The assertions come in pairs that test the same thing but have different effects on the current function. `ASSERT_*` versions generate fatal failures when they fail, and **abort the current function**. `EXPECT_*` versions generate nonfatal failures, which don't abort the current function. Usually `EXPECT_*` are preferred, as they allow more than one failures to be reported in a test. However, you should use `ASSERT_*` if it doesn't make sense to continue when the assertion in question fails.
Since a failed `ASSERT_*` returns from the current function immediately, possibly skipping clean-up code that comes after it, it may cause a space leak. Depending on the nature of the leak, it may or may not be worth fixing - so keep this in mind if you get a heap checker error in addition to assertion errors.
To provide a custom failure message, simply stream it into the macro using the `<<` operator, or a sequence of such operators. An example: ``` ASSERT_EQ(x.size(), y.size()) << "Vectors x and y are of unequal length";
for (int i = 0; i < x.size(); ++i) {   EXPECT_EQ(x[i], y[i]) << "Vectors x and y differ at index " << i; } ```
Anything that can be streamed to an `ostream` can be streamed to an assertion macro--in particular, C strings and `string` objects. If a wide string (`wchar_t*`, `TCHAR*` in `UNICODE` mode on Windows, or `std::wstring`) is streamed to an assertion, it will be translated to UTF-8 when printed.
These assertions do basic true/false condition testing. | **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_TRUE(`_condition_`)`;  | `EXPECT_TRUE(`_condition_`)`;   | _condition_ is true | | `ASSERT_FALSE(`_condition_`)`; | `EXPECT_FALSE(`_condition_`)`;  | _condition_ is false |
Remember, when they fail, `ASSERT_*` yields a fatal failure and returns from the current function, while `EXPECT_*` yields a nonfatal failure, allowing the function to continue running. In either case, an assertion failure means its containing test fails.
_Availability_: Linux, Windows, Mac.
This section describes assertions that compare two values.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| |`ASSERT_EQ(`_expected_`, `_actual_`);`|`EXPECT_EQ(`_expected_`, `_actual_`);`| _expected_ `==` _actual_ | |`ASSERT_NE(`_val1_`, `_val2_`);`      |`EXPECT_NE(`_val1_`, `_val2_`);`      | _val1_ `!=` _val2_ | |`ASSERT_LT(`_val1_`, `_val2_`);`      |`EXPECT_LT(`_val1_`, `_val2_`);`      | _val1_ `<` _val2_ | |`ASSERT_LE(`_val1_`, `_val2_`);`      |`EXPECT_LE(`_val1_`, `_val2_`);`      | _val1_ `<=` _val2_ | |`ASSERT_GT(`_val1_`, `_val2_`);`      |`EXPECT_GT(`_val1_`, `_val2_`);`      | _val1_ `>` _val2_ | |`ASSERT_GE(`_val1_`, `_val2_`);`      |`EXPECT_GE(`_val1_`, `_val2_`);`      | _val1_ `>=` _val2_ |
In the event of a failure, Google Test prints both _val1_ and _val2_ . In `ASSERT_EQ*` and `EXPECT_EQ*` (and all other equality assertions we'll introduce later), you should put the expression you want to test in the position of _actual_, and put its expected value in _expected_, as Google Test's failure messages are optimized for this convention.
Value arguments must be comparable by the assertion's comparison operator or you'll get a compiler error.  We used to require the arguments to support the `<<` operator for streaming to an `ostream`, but it's no longer necessary since v1.6.0 (if `<<` is supported, it will be called to print the arguments when the assertion fails; otherwise Google Test will attempt to print them in the best way it can. For more details and how to customize the printing of the arguments, see this Google Mock [recipe](../../googlemock/docs/CookBook.md#teaching-google-mock-how-to-print-your-values).).
These assertions can work with a user-defined type, but only if you define the corresponding comparison operator (e.g. `==`, `<`, etc).  If the corresponding operator is defined, prefer using the `ASSERT_*()` macros because they will print out not only the result of the comparison, but the two operands as well.
Arguments are always evaluated exactly once. Therefore, it's OK for the arguments to have side effects. However, as with any ordinary C/C++ function, the arguments' evaluation order is undefined (i.e. the compiler is free to choose any order) and your code should not depend on any particular argument evaluation order.
`ASSERT_EQ()` does pointer equality on pointers. If used on two C strings, it tests if they are in the same memory location, not if they have the same value. Therefore, if you want to compare C strings (e.g. `const char*`) by value, use `ASSERT_STREQ()` , which will be described later on. In particular, to assert that a C string is `NULL`, use `ASSERT_STREQ(NULL, c_string)` . However, to compare two `string` objects, you should use `ASSERT_EQ`.
Macros in this section work with both narrow and wide string objects (`string` and `wstring`).
_Availability_: Linux, Windows, Mac.
The assertions in this group compare two **C strings**. If you want to compare two `string` objects, use `EXPECT_EQ`, `EXPECT_NE`, and etc instead.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_STREQ(`_expected\_str_`, `_actual\_str_`);`    | `EXPECT_STREQ(`_expected\_str_`, `_actual\_str_`);`     | the two C strings have the same content | | `ASSERT_STRNE(`_str1_`, `_str2_`);`    | `EXPECT_STRNE(`_str1_`, `_str2_`);`     | the two C strings have different content | | `ASSERT_STRCASEEQ(`_expected\_str_`, `_actual\_str_`);`| `EXPECT_STRCASEEQ(`_expected\_str_`, `_actual\_str_`);` | the two C strings have the same content, ignoring case | | `ASSERT_STRCASENE(`_str1_`, `_str2_`);`| `EXPECT_STRCASENE(`_str1_`, `_str2_`);` | the two C strings have different content, ignoring case |
Note that "CASE" in an assertion name means that case is ignored.
`*STREQ*` and `*STRNE*` also accept wide C strings (`wchar_t*`). If a comparison of two wide strings fails, their values will be printed as UTF-8 narrow strings.
A `NULL` pointer and an empty string are considered _different_.
_Availability_: Linux, Windows, Mac.
See also: For more string comparison tricks (substring, prefix, suffix, and regular expression matching, for example), see the [Advanced Google Test Guide](V1_6_AdvancedGuide.md).
To create a test:   1. Use the `TEST()` macro to define and name a test function, These are ordinary C++ functions that don't return a value.   1. In this function, along with any valid C++ statements you want to include, use the various Google Test assertions to check values.   1. The test's result is determined by the assertions; if any assertion in the test fails (either fatally or non-fatally), or if the test crashes, the entire test fails. Otherwise, it succeeds.
``` TEST(test_case_name, test_name) {  ... test body ... } ```
`TEST()` arguments go from general to specific. The _first_ argument is the name of the test case, and the _second_ argument is the test's name within the test case. Both names must be valid C++ identifiers, and they should not contain underscore (`_`). A test's _full name_ consists of its containing test case and its individual name. Tests from different test cases can have the same individual name.
For example, let's take a simple integer function: ``` int Factorial(int n); // Returns the factorial of n ```
A test case for this function might look like: ``` // Tests factorial of 0. TEST(FactorialTest, HandlesZeroInput) {   EXPECT_EQ(1, Factorial(0)); }
// Tests factorial of positive numbers. TEST(FactorialTest, HandlesPositiveInput) {   EXPECT_EQ(1, Factorial(1));   EXPECT_EQ(2, Factorial(2));   EXPECT_EQ(6, Factorial(3));   EXPECT_EQ(40320, Factorial(8)); } ```
Google Test groups the test results by test cases, so logically-related tests should be in the same test case; in other words, the first argument to their `TEST()` should be the same. In the above example, we have two tests, `HandlesZeroInput` and `HandlesPositiveInput`, that belong to the same test case `FactorialTest`.
_Availability_: Linux, Windows, Mac.
If you find yourself writing two or more tests that operate on similar data, you can use a _test fixture_. It allows you to reuse the same configuration of objects for several different tests.
To create a fixture, just:   1. Derive a class from `::testing::Test` . Start its body with `protected:` or `public:` as we'll want to access fixture members from sub-classes.   1. Inside the class, declare any objects you plan to use.   1. If necessary, write a default constructor or `SetUp()` function to prepare the objects for each test. A common mistake is to spell `SetUp()` as `Setup()` with a small `u` - don't let that happen to you.   1. If necessary, write a destructor or `TearDown()` function to release any resources you allocated in `SetUp()` . To learn when you should use the constructor/destructor and when you should use `SetUp()/TearDown()`, read this [FAQ entry](V1_6_FAQ.md#should-i-use-the-constructordestructor-of-the-test-fixture-or-the-set-uptear-down-function).   1. If needed, define subroutines for your tests to share.
When using a fixture, use `TEST_F()` instead of `TEST()` as it allows you to access objects and subroutines in the test fixture: ``` TEST_F(test_case_name, test_name) {  ... test body ... } ```
Like `TEST()`, the first argument is the test case name, but for `TEST_F()` this must be the name of the test fixture class. You've probably guessed: `_F` is for fixture.
Unfortunately, the C++ macro system does not allow us to create a single macro that can handle both types of tests. Using the wrong macro causes a compiler error.
Also, you must first define a test fixture class before using it in a `TEST_F()`, or you'll get the compiler error "`virtual outside class declaration`".
For each test defined with `TEST_F()`, Google Test will:   1. Create a _fresh_ test fixture at runtime   1. Immediately initialize it via `SetUp()` ,   1. Run the test   1. Clean up by calling `TearDown()`   1. Delete the test fixture.  Note that different tests in the same test case have different test fixture objects, and Google Test always deletes a test fixture before it creates the next one. Google Test does not reuse the same test fixture for multiple tests. Any changes one test makes to the fixture do not affect other tests.
As an example, let's write tests for a FIFO queue class named `Queue`, which has the following interface: ``` template <typename E> // E is the element type. class Queue {  public:   Queue();   void Enqueue(const E& element);   E* Dequeue(); // Returns NULL if the queue is empty.   size_t size() const;   ... }; ```
First, define a fixture class. By convention, you should give it the name `FooTest` where `Foo` is the class being tested. ``` class QueueTest : public ::testing::Test {  protected:   virtual void SetUp() {     q1_.Enqueue(1);     q2_.Enqueue(2);     q2_.Enqueue(3);   }
// virtual void TearDown() {}
Queue<int> q0_;   Queue<int> q1_;   Queue<int> q2_; }; ```
In this case, `TearDown()` is not needed since we don't have to clean up after each test, other than what's already done by the destructor.
Now we'll write tests using `TEST_F()` and this fixture. ``` TEST_F(QueueTest, IsEmptyInitially) {   EXPECT_EQ(0, q0_.size()); }
TEST_F(QueueTest, DequeueWorks) {   int* n = q0_.Dequeue();   EXPECT_EQ(NULL, n);
n = q1_.Dequeue();   ASSERT_TRUE(n != NULL);   EXPECT_EQ(1, *n);   EXPECT_EQ(0, q1_.size());   delete n;
n = q2_.Dequeue();   ASSERT_TRUE(n != NULL);   EXPECT_EQ(2, *n);   EXPECT_EQ(1, q2_.size());   delete n; } ```
The above uses both `ASSERT_*` and `EXPECT_*` assertions. The rule of thumb is to use `EXPECT_*` when you want the test to continue to reveal more errors after the assertion failure, and use `ASSERT_*` when continuing after failure doesn't make sense. For example, the second assertion in the `Dequeue` test is `ASSERT_TRUE(n != NULL)`, as we need to dereference the pointer `n` later, which would lead to a segfault when `n` is `NULL`.
When these tests run, the following happens:   1. Google Test constructs a `QueueTest` object (let's call it `t1` ).   1. `t1.SetUp()` initializes `t1` .   1. The first test ( `IsEmptyInitially` ) runs on `t1` .   1. `t1.TearDown()` cleans up after the test finishes.   1. `t1` is destructed.   1. The above steps are repeated on another `QueueTest` object, this time running the `DequeueWorks` test.
_Availability_: Linux, Windows, Mac.
_Note_: Google Test automatically saves all _Google Test_ flags when a test object is constructed, and restores them when it is destructed.
`TEST()` and `TEST_F()` implicitly register their tests with Google Test. So, unlike with many other C++ testing frameworks, you don't have to re-list all your defined tests in order to run them.
After defining your tests, you can run them with `RUN_ALL_TESTS()` , which returns `0` if all the tests are successful, or `1` otherwise. Note that `RUN_ALL_TESTS()` runs _all tests_ in your link unit -- they can be from different test cases, or even different source files.
When invoked, the `RUN_ALL_TESTS()` macro:   1. Saves the state of all  Google Test flags.   1. Creates a test fixture object for the first test.   1. Initializes it via `SetUp()`.   1. Runs the test on the fixture object.   1. Cleans up the fixture via `TearDown()`.   1. Deletes the fixture.   1. Restores the state of all Google Test flags.   1. Repeats the above steps for the next test, until all tests have run.
In addition, if the text fixture's constructor generates a fatal failure in step 2, there is no point for step 3 - 5 and they are thus skipped. Similarly, if step 3 generates a fatal failure, step 4 will be skipped.
_Important_: You must not ignore the return value of `RUN_ALL_TESTS()`, or `gcc` will give you a compiler error. The rationale for this design is that the automated testing service determines whether a test has passed based on its exit code, not on its stdout/stderr output; thus your `main()` function must return the value of `RUN_ALL_TESTS()`.
Also, you should call `RUN_ALL_TESTS()` only **once**. Calling it more than once conflicts with some advanced Google Test features (e.g. thread-safe death tests) and thus is not supported.
_Availability_: Linux, Windows, Mac.
You can start from this boilerplate: ``` #include "this/package/foo.h" #include "gtest/gtest.h"
namespace {
// The fixture for testing class Foo. class FooTest : public ::testing::Test {  protected:   // You can remove any or all of the following functions if its body   // is empty.
FooTest() {     // You can do set-up work for each test here.   }
virtual ~FooTest() {     // You can do clean-up work that doesn't throw exceptions here.   }
// If the constructor and destructor are not enough for setting up   // and cleaning up each test, you can define the following methods:
virtual void SetUp() {     // Code here will be called immediately after the constructor (right     // before each test).   }
virtual void TearDown() {     // Code here will be called immediately after each test (right     // before the destructor).   }
// Objects declared here can be used by all tests in the test case for Foo. };
// Tests that the Foo::Bar() method does Abc. TEST_F(FooTest, MethodBarDoesAbc) {   const string input_filepath = "this/package/testdata/myinputfile.dat";   const string output_filepath = "this/package/testdata/myoutputfile.dat";   Foo f;   EXPECT_EQ(0, f.Bar(input_filepath, output_filepath)); }
// Tests that Foo does Xyz. TEST_F(FooTest, DoesXyz) {   // Exercises the Xyz feature of Foo. }
}  // namespace
int main(int argc, char **argv) {   ::testing::InitGoogleTest(&argc, argv);   return RUN_ALL_TESTS(); } ```
The `::testing::InitGoogleTest()` function parses the command line for Google Test flags, and removes all recognized flags. This allows the user to control a test program's behavior via various flags, which we'll cover in [AdvancedGuide](V1_6_AdvancedGuide.md). You must call this function before calling `RUN_ALL_TESTS()`, or the flags won't be properly initialized.
On Windows, `InitGoogleTest()` also works with wide strings, so it can be used in programs compiled in `UNICODE` mode as well.
But maybe you think that writing all those main() functions is too much work? We agree with you completely and that's why Google Test provides a basic implementation of main(). If it fits your needs, then just link your test with gtest\_main library and you are good to go.
In addition, if you define your tests in a static library, add `/OPT:NOREF` to your main program linker options. If you use MSVC++ IDE, go to your .exe project properties/Configuration Properties/Linker/Optimization and set References setting to `Keep Unreferenced Data (/OPT:NOREF)`. This will keep Visual C++ linker from discarding individual symbols generated by your tests from the final executable.
There is one more pitfall, though. If you use Google Test as a static library (that's how it is defined in gtest.vcproj) your tests must also reside in a static library. If you have to have them in a DLL, you _must_ change Google Test to build into a DLL as well. Otherwise your tests will not run correctly or will not run at all. The general conclusion here is: make your life easier - do not write your tests in libraries!
Congratulations! You've learned the Google Test basics. You can start writing and running Google Test tests, read some [samples](V1_6_Samples.md), or continue with [AdvancedGuide](V1_6_AdvancedGuide.md), which describes many more useful Google Test features.
Google Test is designed to be thread-safe.  The implementation is thread-safe on systems where the `pthreads` library is available.  It is currently _unsafe_ to use Google Test assertions from two threads concurrently on other systems (e.g. Windows).  In most tests this is not an issue as usually the assertions are done in the main thread. If you want to help, you can volunteer to implement the necessary synchronization primitives in `gtest-port.h` for your platform.

<b>P</b>ump is <b>U</b>seful for <b>M</b>eta <b>P</b>rogramming.
Template and macro libraries often need to define many classes, functions, or macros that vary only (or almost only) in the number of arguments they take. It's a lot of repetitive, mechanical, and error-prone work.
Variadic templates and variadic macros can alleviate the problem. However, while both are being considered by the C++ committee, neither is in the standard yet or widely supported by compilers.  Thus they are often not a good choice, especially when your code needs to be portable. And their capabilities are still limited.
As a result, authors of such libraries often have to write scripts to generate their implementation. However, our experience is that it's tedious to write such scripts, which tend to reflect the structure of the generated code poorly and are often hard to read and edit. For example, a small change needed in the generated code may require some non-intuitive, non-trivial changes in the script. This is especially painful when experimenting with the code.
Pump (for Pump is Useful for Meta Programming, Pretty Useful for Meta Programming, or Practical Utility for Meta Programming, whichever you prefer) is a simple meta-programming tool for C++. The idea is that a programmer writes a `foo.pump` file which contains C++ code plus meta code that manipulates the C++ code. The meta code can handle iterations over a range, nested iterations, local meta variable definitions, simple arithmetic, and conditional expressions. You can view it as a small Domain-Specific Language. The meta language is designed to be non-intrusive (s.t. it won't confuse Emacs' C++ mode, for example) and concise, making Pump code intuitive and easy to maintain.
* The implementation is in a single Python script and thus ultra portable: no build or installation is needed and it works cross platforms.   * Pump tries to be smart with respect to [Google's style guide](http://code.google.com/p/google-styleguide/): it breaks long lines (easy to have when they are generated) at acceptable places to fit within 80 columns and indent the continuation lines correctly.   * The format is human-readable and more concise than XML.   * The format works relatively well with Emacs' C++ mode.
The following Pump code (where meta keywords start with `$`, `[[` and `]]` are meta brackets, and `$$` starts a meta comment that ends with the line):
``` $var n = 3     $$ Defines a meta variable n. $range i 0..n  $$ Declares the range of meta iterator i (inclusive). $for i [[                $$ Meta loop. // Foo$i does blah for $i-ary predicates. $range j 1..i template <size_t N $for j [[, typename A$j]]> class Foo$i { $if i == 0 [[   blah a; ]] $elif i <= 2 [[   blah b; ]] $else [[   blah c; ]] };
]] ```
will be translated by the Pump compiler to:
``` // Foo0 does blah for 0-ary predicates. template <size_t N> class Foo0 {   blah a; };
// Foo1 does blah for 1-ary predicates. template <size_t N, typename A1> class Foo1 {   blah b; };
// Foo2 does blah for 2-ary predicates. template <size_t N, typename A1, typename A2> class Foo2 {   blah b; };
// Foo3 does blah for 3-ary predicates. template <size_t N, typename A1, typename A2, typename A3> class Foo3 {   blah c; }; ```
In another example,
``` $range i 1..n Func($for i + [[a$i]]); $$ The text between i and [[ is the separator between iterations. ```
will generate one of the following lines (without the comments), depending on the value of `n`:
``` Func();              // If n is 0. Func(a1);            // If n is 1. Func(a1 + a2);       // If n is 2. Func(a1 + a2 + a3);  // If n is 3. // And so on... ```
We support the following meta programming constructs:
| `$var id = exp` | Defines a named constant value. `$id` is valid util the end of the current meta lexical block. | |:----------------|:-----------------------------------------------------------------------------------------------| | `$range id exp..exp` | Sets the range of an iteration variable, which can be reused in multiple loops later.          | | `$for id sep [[ code ]]` | Iteration. The range of `id` must have been defined earlier. `$id` is valid in `code`.         | | `$($)`          | Generates a single `$` character.                                                              | | `$id`           | Value of the named constant or iteration variable.                                             | | `$(exp)`        | Value of the expression.                                                                       | | `$if exp [[ code ]] else_branch` | Conditional.                                                                                   | | `[[ code ]]`    | Meta lexical block.                                                                            | | `cpp_code`      | Raw C++ code.                                                                                  | | `$$ comment`    | Meta comment.                                                                                  |
**Note:** To give the user some freedom in formatting the Pump source code, Pump ignores a new-line character if it's right after `$for foo` or next to `[[` or `]]`. Without this rule you'll often be forced to write very long lines to get the desired output. Therefore sometimes you may need to insert an extra new-line in such places for a new-line to show up in your output.
``` code ::= atomic_code* atomic_code ::= $var id = exp     | $var id = [[ code ]]     | $range id exp..exp     | $for id sep [[ code ]]     | $($)     | $id     | $(exp)     | $if exp [[ code ]] else_branch     | [[ code ]]     | cpp_code sep ::= cpp_code | empty_string else_branch ::= $else [[ code ]]     | $elif exp [[ code ]] else_branch     | empty_string exp ::= simple_expression_in_Python_syntax ```
You can find the source code of Pump in [scripts/pump.py](../scripts/pump.py). It is still very unpolished and lacks automated tests, although it has been successfully used many times. If you find a chance to use it in your project, please let us know what you think!  We also welcome help on improving Pump.
You can find real-world applications of Pump in [Google Test](http://www.google.com/codesearch?q=file%3A\.pump%24+package%3Ahttp%3A%2F%2Fgoogletest\.googlecode\.com) and [Google Mock](http://www.google.com/codesearch?q=file%3A\.pump%24+package%3Ahttp%3A%2F%2Fgooglemock\.googlecode\.com).  The source file `foo.h.pump` generates `foo.h`.
* If a meta variable is followed by a letter or digit, you can separate them using `[[]]`, which inserts an empty string. For example `Foo$j[[]]Helper` generate `Foo1Helper` when `j` is 1.   * To avoid extra-long Pump source lines, you can break a line anywhere you want by inserting `[[]]` followed by a new line. Since any new-line character next to `[[` or `]]` is ignored, the generated code won't contain this new line.
If you're like us, you'd like to look at some Google Test sample code.  The [samples folder](../samples) has a number of well-commented samples showing how to use a variety of Google Test features.
* [Sample #1](../samples/sample1_unittest.cc) shows the basic steps of using Google Test to test C++ functions.   * [Sample #2](../samples/sample2_unittest.cc) shows a more complex unit test for a class with multiple member functions.   * [Sample #3](../samples/sample3_unittest.cc) uses a test fixture.   * [Sample #4](../samples/sample4_unittest.cc) is another basic example of using Google Test.   * [Sample #5](../samples/sample5_unittest.cc) teaches how to reuse a test fixture in multiple test cases by deriving sub-fixtures from it.   * [Sample #6](../samples/sample6_unittest.cc) demonstrates type-parameterized tests.   * [Sample #7](../samples/sample7_unittest.cc) teaches the basics of value-parameterized tests.   * [Sample #8](../samples/sample8_unittest.cc) shows using `Combine()` in value-parameterized tests.   * [Sample #9](../samples/sample9_unittest.cc) shows use of the listener API to modify Google Test's console output and the use of its reflection API to inspect test results.   * [Sample #10](../samples/sample10_unittest.cc) shows use of the listener API to implement a primitive memory leak checker.

This guide will explain how to use the Google Testing Framework in your Xcode projects on Mac OS X. This tutorial begins by quickly explaining what to do for experienced users. After the quick start, the guide goes provides additional explanation about each step.
Here is the quick guide for using Google Test in your Xcode project.
1. Download the source from the [website](http://code.google.com/p/googletest) using this command: `svn checkout http://googletest.googlecode.com/svn/trunk/ googletest-read-only`   1. Open up the `gtest.xcodeproj` in the `googletest-read-only/xcode/` directory and build the gtest.framework.   1. Create a new "Shell Tool" target in your Xcode project called something like "UnitTests"   1. Add the gtest.framework to your project and add it to the "Link Binary with Libraries" build phase of "UnitTests"   1. Add your unit test source code to the "Compile Sources" build phase of "UnitTests"   1. Edit the "UnitTests" executable and add an environment variable named "DYLD\_FRAMEWORK\_PATH" with a value equal to the path to the framework containing the gtest.framework relative to the compiled executable.   1. Build and Go
The following sections further explain each of the steps listed above in depth, describing in more detail how to complete it including some variations.
Currently, the gtest.framework discussed here isn't available in a tagged release of Google Test, it is only available in the trunk. As explained at the Google Test [site](http://code.google.com/p/googletest/source/checkout">svn), you can get the code from anonymous SVN with this command:
``` svn checkout http://googletest.googlecode.com/svn/trunk/ googletest-read-only ```
Alternatively, if you are working with Subversion in your own code base, you can add Google Test as an external dependency to your own Subversion repository. By following this approach, everyone that checks out your svn repository will also receive a copy of Google Test (a specific version, if you wish) without having to check it out explicitly. This makes the set up of your project simpler and reduces the copied code in the repository.
To use `svn:externals`, decide where you would like to have the external source reside. You might choose to put the external source inside the trunk, because you want it to be part of the branch when you make a release. However, keeping it outside the trunk in a version-tagged directory called something like `third-party/googletest/1.0.1`, is another option. Once the location is established, use `svn propedit svn:externals _directory_` to set the svn:externals property on a directory in your repository. This directory won't contain the code, but be its versioned parent directory.
The command `svn propedit` will bring up your Subversion editor, making editing the long, (potentially multi-line) property simpler. This same method can be used to check out a tagged branch, by using the appropriate URL (e.g. `http://googletest.googlecode.com/svn/tags/release-1.0.1`). Additionally, the svn:externals property allows the specification of a particular revision of the trunk with the `-r_##_` option (e.g. `externals/src/googletest -r60 http://googletest.googlecode.com/svn/trunk`).
Here is an example of using the svn:externals properties on a trunk (read via `svn propget`) of a project. This value checks out a copy of Google Test into the `trunk/externals/src/googletest/` directory.
``` [Computer:svn] user$ svn propget svn:externals trunk externals/src/googletest http://googletest.googlecode.com/svn/trunk ```
The next step is to build and add the gtest.framework to your own project. This guide describes two common ways below.
* **Option 1** --- The simplest way to add Google Test to your own project, is to open gtest.xcodeproj (found in the xcode/ directory of the Google Test trunk) and build the framework manually. Then, add the built framework into your project using the "Add->Existing Framework..." from the context menu or "Project->Add..." from the main menu. The gtest.framework is relocatable and contains the headers and object code that you'll need to make tests. This method requires rebuilding every time you upgrade Google Test in your project.   * **Option 2** --- If you are going to be living off the trunk of Google Test, incorporating its latest features into your unit tests (or are a Google Test developer yourself). You'll want to rebuild the framework every time the source updates. to do this, you'll need to add the gtest.xcodeproj file, not the framework itself, to your own Xcode project. Then, from the build products that are revealed by the project's disclosure triangle, you can find the gtest.framework, which can be added to your targets (discussed below).
To start writing tests, make a new "Shell Tool" target. This target template is available under BSD, Cocoa, or Carbon. Add your unit test source code to the "Compile Sources" build phase of the target.
Next, you'll want to add gtest.framework in two different ways, depending upon which option you chose above.
* **Option 1** --- During compilation, Xcode will need to know that you are linking against the gtest.framework. Add the gtest.framework to the "Link Binary with Libraries" build phase of your test target. This will include the Google Test headers in your header search path, and will tell the linker where to find the library.   * **Option 2** --- If your working out of the trunk, you'll also want to add gtest.framework to your "Link Binary with Libraries" build phase of your test target. In addition, you'll  want to add the gtest.framework as a dependency to your unit test target. This way, Xcode will make sure that gtest.framework is up to date, every time your build your target. Finally, if you don't share build directories with Google Test, you'll have to copy the gtest.framework into your own build products directory using a "Run Script" build phase.
Since the unit test executable is a shell tool, it doesn't have a bundle with a `Contents/Frameworks` directory, in which to place gtest.framework. Instead, the dynamic linker must be told at runtime to search for the framework in another location. This can be accomplished by setting the "DYLD\_FRAMEWORK\_PATH" environment variable in the "Edit Active Executable ..." Arguments tab, under "Variables to be set in the environment:". The path for this value is the path (relative or absolute) of the directory containing the gtest.framework.
If you haven't set up the DYLD\_FRAMEWORK\_PATH, correctly, you might get a message like this:
``` [Session started at 2008-08-15 06:23:57 -0600.]   dyld: Library not loaded: @loader_path/../Frameworks/gtest.framework/Versions/A/gtest     Referenced from: /Users/username/Documents/Sandbox/gtestSample/build/Debug/WidgetFrameworkTest     Reason: image not found ```
To correct this problem, got to the directory containing the executable named in "Referenced from:" value in the error message above. Then, with the terminal in this location, find the relative path to the directory containing the gtest.framework. That is the value you'll need to set as the DYLD\_FRAMEWORK\_PATH.
Now, when you click "Build and Go", the test will be executed. Dumping out something like this:
``` [Session started at 2008-08-06 06:36:13 -0600.] [==========] Running 2 tests from 1 test case. [----------] Global test environment set-up. [----------] 2 tests from WidgetInitializerTest [ RUN      ] WidgetInitializerTest.TestConstructor [       OK ] WidgetInitializerTest.TestConstructor [ RUN      ] WidgetInitializerTest.TestConversion [       OK ] WidgetInitializerTest.TestConversion [----------] Global test environment tear-down [==========] 2 tests from 1 test case ran. [  PASSED  ] 2 tests.
The Debugger has exited with status 0.   ```
Unit testing is a valuable way to ensure your data model stays valid even during rapid development or refactoring. The Google Testing Framework is a great unit testing framework for C and C++ which integrates well with an Xcode development environment.

Now that you have read [Primer](V1_7_Primer.md) and learned how to write tests using Google Test, it's time to learn some new tricks. This document will show you more assertions as well as how to construct complex failure messages, propagate fatal failures, reuse and speed up your test fixtures, and use various flags with your tests.
This section covers some less frequently used, but still significant, assertions.
These three assertions do not actually test a value or expression. Instead, they generate a success or failure directly. Like the macros that actually perform a test, you may stream a custom failure message into the them.
| `SUCCEED();` | |:-------------|
Generates a success. This does NOT make the overall test succeed. A test is considered successful only if none of its assertions fail during its execution.
Note: `SUCCEED()` is purely documentary and currently doesn't generate any user-visible output. However, we may add `SUCCEED()` messages to Google Test's output in the future.
| `FAIL();`  | `ADD_FAILURE();` | `ADD_FAILURE_AT("`_file\_path_`", `_line\_number_`);` | |:-----------|:-----------------|:------------------------------------------------------|
`FAIL()` generates a fatal failure, while `ADD_FAILURE()` and `ADD_FAILURE_AT()` generate a nonfatal failure. These are useful when control flow, rather than a Boolean expression, deteremines the test's success or failure. For example, you might want to write something like:
``` switch(expression) {   case 1: ... some checks ...   case 2: ... some other checks   ...   default: FAIL() << "We shouldn't get here."; } ```
_Availability_: Linux, Windows, Mac.
These are for verifying that a piece of code throws (or does not throw) an exception of the given type:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_THROW(`_statement_, _exception\_type_`);`  | `EXPECT_THROW(`_statement_, _exception\_type_`);`  | _statement_ throws an exception of the given type  | | `ASSERT_ANY_THROW(`_statement_`);`                | `EXPECT_ANY_THROW(`_statement_`);`                | _statement_ throws an exception of any type        | | `ASSERT_NO_THROW(`_statement_`);`                 | `EXPECT_NO_THROW(`_statement_`);`                 | _statement_ doesn't throw any exception            |
Examples:
``` ASSERT_THROW(Foo(5), bar_exception);
EXPECT_NO_THROW({   int n = 5;   Bar(&n); }); ```
_Availability_: Linux, Windows, Mac; since version 1.1.0.
Even though Google Test has a rich set of assertions, they can never be complete, as it's impossible (nor a good idea) to anticipate all the scenarios a user might run into. Therefore, sometimes a user has to use `EXPECT_TRUE()` to check a complex expression, for lack of a better macro. This has the problem of not showing you the values of the parts of the expression, making it hard to understand what went wrong. As a workaround, some users choose to construct the failure message by themselves, streaming it into `EXPECT_TRUE()`. However, this is awkward especially when the expression has side-effects or is expensive to evaluate.
Google Test gives you three different options to solve this problem:
If you already have a function or a functor that returns `bool` (or a type that can be implicitly converted to `bool`), you can use it in a _predicate assertion_ to get the function arguments printed for free:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_PRED1(`_pred1, val1_`);`       | `EXPECT_PRED1(`_pred1, val1_`);` | _pred1(val1)_ returns true | | `ASSERT_PRED2(`_pred2, val1, val2_`);` | `EXPECT_PRED2(`_pred2, val1, val2_`);` |  _pred2(val1, val2)_ returns true | |  ...                | ...                    | ...          |
In the above, _predn_ is an _n_-ary predicate function or functor, where _val1_, _val2_, ..., and _valn_ are its arguments. The assertion succeeds if the predicate returns `true` when applied to the given arguments, and fails otherwise. When the assertion fails, it prints the value of each argument. In either case, the arguments are evaluated exactly once.
Here's an example. Given
``` // Returns true iff m and n have no common divisors except 1. bool MutuallyPrime(int m, int n) { ... } const int a = 3; const int b = 4; const int c = 10; ```
the assertion `EXPECT_PRED2(MutuallyPrime, a, b);` will succeed, while the assertion `EXPECT_PRED2(MutuallyPrime, b, c);` will fail with the message
<pre> !MutuallyPrime(b, c) is false, where<br> b is 4<br> c is 10<br> </pre>
**Notes:**
1. If you see a compiler error "no matching function to call" when using `ASSERT_PRED*` or `EXPECT_PRED*`, please see [this](V1_7_FAQ.md#the-compiler-complains-about-undefined-references-to-some-static-const-member-variables-but-i-did-define-them-in-the-class-body-whats-wrong) for how to resolve it.   1. Currently we only provide predicate assertions of arity <= 5. If you need a higher-arity assertion, let us know.
_Availability_: Linux, Windows, Mac
While `EXPECT_PRED*()` and friends are handy for a quick job, the syntax is not satisfactory: you have to use different macros for different arities, and it feels more like Lisp than C++.  The `::testing::AssertionResult` class solves this problem.
An `AssertionResult` object represents the result of an assertion (whether it's a success or a failure, and an associated message).  You can create an `AssertionResult` using one of these factory functions:
``` namespace testing {
// Returns an AssertionResult object to indicate that an assertion has // succeeded. AssertionResult AssertionSuccess();
// Returns an AssertionResult object to indicate that an assertion has // failed. AssertionResult AssertionFailure();
} ```
You can then use the `<<` operator to stream messages to the `AssertionResult` object.
To provide more readable messages in Boolean assertions (e.g. `EXPECT_TRUE()`), write a predicate function that returns `AssertionResult` instead of `bool`. For example, if you define `IsEven()` as:
``` ::testing::AssertionResult IsEven(int n) {   if ((n % 2) == 0)     return ::testing::AssertionSuccess();   else     return ::testing::AssertionFailure() << n << " is odd"; } ```
instead of:
``` bool IsEven(int n) {   return (n % 2) == 0; } ```
the failed assertion `EXPECT_TRUE(IsEven(Fib(4)))` will print:
<pre> Value of: IsEven(Fib(4))<br> Actual: false (*3 is odd*)<br> Expected: true<br> </pre>
instead of a more opaque
<pre> Value of: IsEven(Fib(4))<br> Actual: false<br> Expected: true<br> </pre>
If you want informative messages in `EXPECT_FALSE` and `ASSERT_FALSE` as well, and are fine with making the predicate slower in the success case, you can supply a success message:
``` ::testing::AssertionResult IsEven(int n) {   if ((n % 2) == 0)     return ::testing::AssertionSuccess() << n << " is even";   else     return ::testing::AssertionFailure() << n << " is odd"; } ```
Then the statement `EXPECT_FALSE(IsEven(Fib(6)))` will print
<pre> Value of: IsEven(Fib(6))<br> Actual: true (8 is even)<br> Expected: false<br> </pre>
_Availability_: Linux, Windows, Mac; since version 1.4.1.
If you find the default message generated by `(ASSERT|EXPECT)_PRED*` and `(ASSERT|EXPECT)_(TRUE|FALSE)` unsatisfactory, or some arguments to your predicate do not support streaming to `ostream`, you can instead use the following _predicate-formatter assertions_ to _fully_ customize how the message is formatted:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_PRED_FORMAT1(`_pred\_format1, val1_`);`        | `EXPECT_PRED_FORMAT1(`_pred\_format1, val1_`); | _pred\_format1(val1)_ is successful | | `ASSERT_PRED_FORMAT2(`_pred\_format2, val1, val2_`);` | `EXPECT_PRED_FORMAT2(`_pred\_format2, val1, val2_`);` | _pred\_format2(val1, val2)_ is successful | | `...`               | `...`                  | `...`        |
The difference between this and the previous two groups of macros is that instead of a predicate, `(ASSERT|EXPECT)_PRED_FORMAT*` take a _predicate-formatter_ (_pred\_formatn_), which is a function or functor with the signature:
`::testing::AssertionResult PredicateFormattern(const char* `_expr1_`, const char* `_expr2_`, ... const char* `_exprn_`, T1 `_val1_`, T2 `_val2_`, ... Tn `_valn_`);`
where _val1_, _val2_, ..., and _valn_ are the values of the predicate arguments, and _expr1_, _expr2_, ..., and _exprn_ are the corresponding expressions as they appear in the source code. The types `T1`, `T2`, ..., and `Tn` can be either value types or reference types. For example, if an argument has type `Foo`, you can declare it as either `Foo` or `const Foo&`, whichever is appropriate.
A predicate-formatter returns a `::testing::AssertionResult` object to indicate whether the assertion has succeeded or not. The only way to create such an object is to call one of these factory functions:
As an example, let's improve the failure message in the previous example, which uses `EXPECT_PRED2()`:
``` // Returns the smallest prime common divisor of m and n, // or 1 when m and n are mutually prime. int SmallestPrimeCommonDivisor(int m, int n) { ... }
// A predicate-formatter for asserting that two integers are mutually prime. ::testing::AssertionResult AssertMutuallyPrime(const char* m_expr,                                                const char* n_expr,                                                int m,                                                int n) {   if (MutuallyPrime(m, n))     return ::testing::AssertionSuccess();
return ::testing::AssertionFailure()       << m_expr << " and " << n_expr << " (" << m << " and " << n       << ") are not mutually prime, " << "as they have a common divisor "       << SmallestPrimeCommonDivisor(m, n); } ```
With this predicate-formatter, we can use
``` EXPECT_PRED_FORMAT2(AssertMutuallyPrime, b, c); ```
to generate the message
<pre> b and c (4 and 10) are not mutually prime, as they have a common divisor 2.<br> </pre>
As you may have realized, many of the assertions we introduced earlier are special cases of `(EXPECT|ASSERT)_PRED_FORMAT*`. In fact, most of them are indeed defined using `(EXPECT|ASSERT)_PRED_FORMAT*`.
_Availability_: Linux, Windows, Mac.
Comparing floating-point numbers is tricky. Due to round-off errors, it is very unlikely that two floating-points will match exactly. Therefore, `ASSERT_EQ` 's naive comparison usually doesn't work. And since floating-points can have a wide value range, no single fixed error bound works. It's better to compare by a fixed relative error bound, except for values close to 0 due to the loss of precision there.
In general, for floating-point comparison to make sense, the user needs to carefully choose the error bound. If they don't want or care to, comparing in terms of Units in the Last Place (ULPs) is a good default, and Google Test provides assertions to do this. Full details about ULPs are quite long; if you want to learn more, see [this article on float comparison](http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm).
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_FLOAT_EQ(`_expected, actual_`);`  | `EXPECT_FLOAT_EQ(`_expected, actual_`);` | the two `float` values are almost equal | | `ASSERT_DOUBLE_EQ(`_expected, actual_`);` | `EXPECT_DOUBLE_EQ(`_expected, actual_`);` | the two `double` values are almost equal |
By "almost equal", we mean the two values are within 4 ULP's from each other.
The following assertions allow you to choose the acceptable error bound:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_NEAR(`_val1, val2, abs\_error_`);` | `EXPECT_NEAR`_(val1, val2, abs\_error_`);` | the difference between _val1_ and _val2_ doesn't exceed the given absolute error |
_Availability_: Linux, Windows, Mac.
Some floating-point operations are useful, but not that often used. In order to avoid an explosion of new macros, we provide them as predicate-format functions that can be used in predicate assertion macros (e.g. `EXPECT_PRED_FORMAT2`, etc).
``` EXPECT_PRED_FORMAT2(::testing::FloatLE, val1, val2); EXPECT_PRED_FORMAT2(::testing::DoubleLE, val1, val2); ```
Verifies that _val1_ is less than, or almost equal to, _val2_. You can replace `EXPECT_PRED_FORMAT2` in the above table with `ASSERT_PRED_FORMAT2`.
_Availability_: Linux, Windows, Mac.
These assertions test for `HRESULT` success or failure.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_HRESULT_SUCCEEDED(`_expression_`);` | `EXPECT_HRESULT_SUCCEEDED(`_expression_`);` | _expression_ is a success `HRESULT` | | `ASSERT_HRESULT_FAILED(`_expression_`);`    | `EXPECT_HRESULT_FAILED(`_expression_`);`    | _expression_ is a failure `HRESULT` |
The generated output contains the human-readable error message associated with the `HRESULT` code returned by _expression_.
You might use them like this:
``` CComPtr shell; ASSERT_HRESULT_SUCCEEDED(shell.CoCreateInstance(L"Shell.Application")); CComVariant empty; ASSERT_HRESULT_SUCCEEDED(shell->ShellExecute(CComBSTR(url), empty, empty, empty, empty)); ```
_Availability_: Windows.
You can call the function ``` ::testing::StaticAssertTypeEq<T1, T2>(); ``` to assert that types `T1` and `T2` are the same.  The function does nothing if the assertion is satisfied.  If the types are different, the function call will fail to compile, and the compiler error message will likely (depending on the compiler) show you the actual values of `T1` and `T2`.  This is mainly useful inside template code.
_Caveat:_ When used inside a member function of a class template or a function template, `StaticAssertTypeEq<T1, T2>()` is effective _only if_ the function is instantiated.  For example, given: ``` template <typename T> class Foo {  public:   void Bar() { ::testing::StaticAssertTypeEq<int, T>(); } }; ``` the code: ``` void Test1() { Foo<bool> foo; } ``` will _not_ generate a compiler error, as `Foo<bool>::Bar()` is never actually instantiated.  Instead, you need: ``` void Test2() { Foo<bool> foo; foo.Bar(); } ``` to cause a compiler error.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
You can use assertions in any C++ function. In particular, it doesn't have to be a method of the test fixture class. The one constraint is that assertions that generate a fatal failure (`FAIL*` and `ASSERT_*`) can only be used in void-returning functions. This is a consequence of Google Test not using exceptions. By placing it in a non-void function you'll get a confusing compile error like `"error: void value not ignored as it ought to be"`.
If you need to use assertions in a function that returns non-void, one option is to make the function return the value in an out parameter instead. For example, you can rewrite `T2 Foo(T1 x)` to `void Foo(T1 x, T2* result)`. You need to make sure that `*result` contains some sensible value even when the function returns prematurely. As the function now returns `void`, you can use any assertion inside of it.
If changing the function's type is not an option, you should just use assertions that generate non-fatal failures, such as `ADD_FAILURE*` and `EXPECT_*`.
_Note_: Constructors and destructors are not considered void-returning functions, according to the C++ language specification, and so you may not use fatal assertions in them. You'll get a compilation error if you try. A simple workaround is to transfer the entire body of the constructor or destructor to a private void-returning method. However, you should be aware that a fatal assertion failure in a constructor does not terminate the current test, as your intuition might suggest; it merely returns from the constructor early, possibly leaving your object in a partially-constructed state. Likewise, a fatal assertion failure in a destructor may leave your object in a partially-destructed state. Use assertions carefully in these situations!
When a test assertion such as `EXPECT_EQ` fails, Google Test prints the argument values to help you debug.  It does this using a user-extensible value printer.
This printer knows how to print built-in C++ types, native arrays, STL containers, and any type that supports the `<<` operator.  For other types, it prints the raw bytes in the value and hopes that you the user can figure it out.
As mentioned earlier, the printer is _extensible_.  That means you can teach it to do a better job at printing your particular type than to dump the bytes.  To do that, define `<<` for your type:
``` #include <iostream>
namespace foo {
class Bar { ... };  // We want Google Test to be able to print instances of this.
// It's important that the << operator is defined in the SAME // namespace that defines Bar.  C++'s look-up rules rely on that. ::std::ostream& operator<<(::std::ostream& os, const Bar& bar) {   return os << bar.DebugString();  // whatever needed to print bar to os }
}  // namespace foo ```
Sometimes, this might not be an option: your team may consider it bad style to have a `<<` operator for `Bar`, or `Bar` may already have a `<<` operator that doesn't do what you want (and you cannot change it).  If so, you can instead define a `PrintTo()` function like this:
``` #include <iostream>
namespace foo {
class Bar { ... };
// It's important that PrintTo() is defined in the SAME // namespace that defines Bar.  C++'s look-up rules rely on that. void PrintTo(const Bar& bar, ::std::ostream* os) {   *os << bar.DebugString();  // whatever needed to print bar to os }
}  // namespace foo ```
If you have defined both `<<` and `PrintTo()`, the latter will be used when Google Test is concerned.  This allows you to customize how the value appears in Google Test's output without affecting code that relies on the behavior of its `<<` operator.
If you want to print a value `x` using Google Test's value printer yourself, just call `::testing::PrintToString(`_x_`)`, which returns an `std::string`:
``` vector<pair<Bar, int> > bar_ints = GetBarIntVector();
EXPECT_TRUE(IsCorrectBarIntVector(bar_ints))     << "bar_ints = " << ::testing::PrintToString(bar_ints); ```
In many applications, there are assertions that can cause application failure if a condition is not met. These sanity checks, which ensure that the program is in a known good state, are there to fail at the earliest possible time after some program state is corrupted. If the assertion checks the wrong condition, then the program may proceed in an erroneous state, which could lead to memory corruption, security holes, or worse. Hence it is vitally important to test that such assertion statements work as expected.
Since these precondition checks cause the processes to die, we call such tests _death tests_. More generally, any test that checks that a program terminates (except by throwing an exception) in an expected fashion is also a death test.
Note that if a piece of code throws an exception, we don't consider it "death" for the purpose of death tests, as the caller of the code could catch the exception and avoid the crash. If you want to verify exceptions thrown by your code, see [Exception Assertions](#exception-assertions).
If you want to test `EXPECT_*()/ASSERT_*()` failures in your test code, see [Catching Failures](#catching-failures).
Google Test has the following macros to support death tests:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_DEATH(`_statement, regex_`); | `EXPECT_DEATH(`_statement, regex_`); | _statement_ crashes with the given error | | `ASSERT_DEATH_IF_SUPPORTED(`_statement, regex_`); | `EXPECT_DEATH_IF_SUPPORTED(`_statement, regex_`); | if death tests are supported, verifies that _statement_ crashes with the given error; otherwise verifies nothing | | `ASSERT_EXIT(`_statement, predicate, regex_`); | `EXPECT_EXIT(`_statement, predicate, regex_`); |_statement_ exits with the given error and its exit code matches _predicate_ |
where _statement_ is a statement that is expected to cause the process to die, _predicate_ is a function or function object that evaluates an integer exit status, and _regex_ is a regular expression that the stderr output of _statement_ is expected to match. Note that _statement_ can be _any valid statement_ (including _compound statement_) and doesn't have to be an expression.
As usual, the `ASSERT` variants abort the current test function, while the `EXPECT` variants do not.
**Note:** We use the word "crash" here to mean that the process terminates with a _non-zero_ exit status code.  There are two possibilities: either the process has called `exit()` or `_exit()` with a non-zero value, or it may be killed by a signal.
This means that if _statement_ terminates the process with a 0 exit code, it is _not_ considered a crash by `EXPECT_DEATH`.  Use `EXPECT_EXIT` instead if this is the case, or if you want to restrict the exit code more precisely.
A predicate here must accept an `int` and return a `bool`. The death test succeeds only if the predicate returns `true`. Google Test defines a few predicates that handle the most common cases:
``` ::testing::ExitedWithCode(exit_code) ```
This expression is `true` if the program exited normally with the given exit code.
``` ::testing::KilledBySignal(signal_number)  // Not available on Windows. ```
This expression is `true` if the program was killed by the given signal.
The `*_DEATH` macros are convenient wrappers for `*_EXIT` that use a predicate that verifies the process' exit code is non-zero.
Note that a death test only cares about three things:
1. does _statement_ abort or exit the process?   1. (in the case of `ASSERT_EXIT` and `EXPECT_EXIT`) does the exit status satisfy _predicate_?  Or (in the case of `ASSERT_DEATH` and `EXPECT_DEATH`) is the exit status non-zero?  And   1. does the stderr output match _regex_?
In particular, if _statement_ generates an `ASSERT_*` or `EXPECT_*` failure, it will **not** cause the death test to fail, as Google Test assertions don't abort the process.
To write a death test, simply use one of the above macros inside your test function. For example,
``` TEST(MyDeathTest, Foo) {   // This death test uses a compound statement.   ASSERT_DEATH({ int n = 5; Foo(&n); }, "Error on line .* of Foo()"); } TEST(MyDeathTest, NormalExit) {   EXPECT_EXIT(NormalExit(), ::testing::ExitedWithCode(0), "Success"); } TEST(MyDeathTest, KillMyself) {   EXPECT_EXIT(KillMyself(), ::testing::KilledBySignal(SIGKILL), "Sending myself unblockable signal"); } ```
verifies that:
* calling `Foo(5)` causes the process to die with the given error message,   * calling `NormalExit()` causes the process to print `"Success"` to stderr and exit with exit code 0, and   * calling `KillMyself()` kills the process with signal `SIGKILL`.
The test function body may contain other assertions and statements as well, if necessary.
_Important:_ We strongly recommend you to follow the convention of naming your test case (not test) `*DeathTest` when it contains a death test, as demonstrated in the above example. The `Death Tests And Threads` section below explains why.
If a test fixture class is shared by normal tests and death tests, you can use typedef to introduce an alias for the fixture class and avoid duplicating its code: ``` class FooTest : public ::testing::Test { ... };
typedef FooTest FooDeathTest;
TEST_F(FooTest, DoesThis) {   // normal test }
TEST_F(FooDeathTest, DoesThat) {   // death test } ```
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Cygwin, and Mac (the latter three are supported since v1.3.0).  `(ASSERT|EXPECT)_DEATH_IF_SUPPORTED` are new in v1.4.0.
On POSIX systems (e.g. Linux, Cygwin, and Mac), Google Test uses the [POSIX extended regular expression](http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html#tag_09_04) syntax in death tests. To learn about this syntax, you may want to read this [Wikipedia entry](http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions).
On Windows, Google Test uses its own simple regular expression implementation. It lacks many features you can find in POSIX extended regular expressions.  For example, we don't support union (`"x|y"`), grouping (`"(xy)"`), brackets (`"[xy]"`), and repetition count (`"x{5,7}"`), among others. Below is what we do support (Letter `A` denotes a literal character, period (`.`), or a single `\\` escape sequence; `x` and `y` denote regular expressions.):
| `c` | matches any literal character `c` | |:----|:----------------------------------| | `\\d` | matches any decimal digit         | | `\\D` | matches any character that's not a decimal digit | | `\\f` | matches `\f`                      | | `\\n` | matches `\n`                      | | `\\r` | matches `\r`                      | | `\\s` | matches any ASCII whitespace, including `\n` | | `\\S` | matches any character that's not a whitespace | | `\\t` | matches `\t`                      | | `\\v` | matches `\v`                      | | `\\w` | matches any letter, `_`, or decimal digit | | `\\W` | matches any character that `\\w` doesn't match | | `\\c` | matches any literal character `c`, which must be a punctuation | | `\\.` | matches the `.` character         | | `.` | matches any single character except `\n` | | `A?` | matches 0 or 1 occurrences of `A` | | `A*` | matches 0 or many occurrences of `A` | | `A+` | matches 1 or many occurrences of `A` | | `^` | matches the beginning of a string (not that of each line) | | `$` | matches the end of a string (not that of each line) | | `xy` | matches `x` followed by `y`       |
To help you determine which capability is available on your system, Google Test defines macro `GTEST_USES_POSIX_RE=1` when it uses POSIX extended regular expressions, or `GTEST_USES_SIMPLE_RE=1` when it uses the simple version.  If you want your death tests to work in both cases, you can either `#if` on these macros or use the more limited syntax only.
Under the hood, `ASSERT_EXIT()` spawns a new process and executes the death test statement in that process. The details of of how precisely that happens depend on the platform and the variable `::testing::GTEST_FLAG(death_test_style)` (which is initialized from the command-line flag `--gtest_death_test_style`).
* On POSIX systems, `fork()` (or `clone()` on Linux) is used to spawn the child, after which:     * If the variable's value is `"fast"`, the death test statement is immediately executed.     * If the variable's value is `"threadsafe"`, the child process re-executes the unit test binary just as it was originally invoked, but with some extra flags to cause just the single death test under consideration to be run.   * On Windows, the child is spawned using the `CreateProcess()` API, and re-executes the binary to cause just the single death test under consideration to be run - much like the `threadsafe` mode on POSIX.
Other values for the variable are illegal and will cause the death test to fail. Currently, the flag's default value is `"fast"`. However, we reserve the right to change it in the future. Therefore, your tests should not depend on this.
In either case, the parent process waits for the child process to complete, and checks that
1. the child's exit status satisfies the predicate, and   1. the child's stderr matches the regular expression.
If the death test statement runs to completion without dying, the child process will nonetheless terminate, and the assertion fails.
The reason for the two death test styles has to do with thread safety. Due to well-known problems with forking in the presence of threads, death tests should be run in a single-threaded context. Sometimes, however, it isn't feasible to arrange that kind of environment. For example, statically-initialized modules may start threads before main is ever reached. Once threads have been created, it may be difficult or impossible to clean them up.
Google Test has three features intended to raise awareness of threading issues.
1. A warning is emitted if multiple threads are running when a death test is encountered.   1. Test cases with a name ending in "DeathTest" are run before all other tests.   1. It uses `clone()` instead of `fork()` to spawn the child process on Linux (`clone()` is not available on Cygwin and Mac), as `fork()` is more likely to cause the child to hang when the parent process has multiple threads.
It's perfectly fine to create threads inside a death test statement; they are executed in a separate process and cannot affect the parent.
The "threadsafe" death test style was introduced in order to help mitigate the risks of testing in a possibly multithreaded environment. It trades increased test execution time (potentially dramatically so) for improved thread safety. We suggest using the faster, default "fast" style unless your test has specific problems with it.
You can choose a particular style of death tests by setting the flag programmatically:
``` ::testing::FLAGS_gtest_death_test_style = "threadsafe"; ```
You can do this in `main()` to set the style for all death tests in the binary, or in individual tests. Recall that flags are saved before running each test and restored afterwards, so you need not do that yourself. For example:
``` TEST(MyDeathTest, TestOne) {   ::testing::FLAGS_gtest_death_test_style = "threadsafe";   // This test is run in the "threadsafe" style:   ASSERT_DEATH(ThisShouldDie(), ""); }
TEST(MyDeathTest, TestTwo) {   // This test is run in the "fast" style:   ASSERT_DEATH(ThisShouldDie(), ""); }
int main(int argc, char** argv) {   ::testing::InitGoogleTest(&argc, argv);   ::testing::FLAGS_gtest_death_test_style = "fast";   return RUN_ALL_TESTS(); } ```
The _statement_ argument of `ASSERT_EXIT()` can be any valid C++ statement. If it leaves the current function via a `return` statement or by throwing an exception, the death test is considered to have failed.  Some Google Test macros may return from the current function (e.g. `ASSERT_TRUE()`), so be sure to avoid them in _statement_.
Since _statement_ runs in the child process, any in-memory side effect (e.g. modifying a variable, releasing memory, etc) it causes will _not_ be observable in the parent process. In particular, if you release memory in a death test, your program will fail the heap check as the parent process will never see the memory reclaimed. To solve this problem, you can
1. try not to free memory in a death test;   1. free the memory again in the parent process; or   1. do not use the heap checker in your program.
Due to an implementation detail, you cannot place multiple death test assertions on the same line; otherwise, compilation will fail with an unobvious error message.
Despite the improved thread safety afforded by the "threadsafe" style of death test, thread problems such as deadlock are still possible in the presence of handlers registered with `pthread_atfork(3)`.
If a test sub-routine is called from several places, when an assertion inside it fails, it can be hard to tell which invocation of the sub-routine the failure is from.  You can alleviate this problem using extra logging or custom failure messages, but that usually clutters up your tests. A better solution is to use the `SCOPED_TRACE` macro:
| `SCOPED_TRACE(`_message_`);` | |:-----------------------------|
where _message_ can be anything streamable to `std::ostream`. This macro will cause the current file name, line number, and the given message to be added in every failure message. The effect will be undone when the control leaves the current lexical scope.
For example,
``` 10: void Sub1(int n) { 11:   EXPECT_EQ(1, Bar(n)); 12:   EXPECT_EQ(2, Bar(n + 1)); 13: } 14: 15: TEST(FooTest, Bar) { 16:   { 17:     SCOPED_TRACE("A");  // This trace point will be included in 18:                         // every failure in this scope. 19:     Sub1(1); 20:   } 21:   // Now it won't. 22:   Sub1(9); 23: } ```
could result in messages like these:
``` path/to/foo_test.cc:11: Failure Value of: Bar(n) Expected: 1   Actual: 2    Trace: path/to/foo_test.cc:17: A
path/to/foo_test.cc:12: Failure Value of: Bar(n + 1) Expected: 2   Actual: 3 ```
Without the trace, it would've been difficult to know which invocation of `Sub1()` the two failures come from respectively. (You could add an extra message to each assertion in `Sub1()` to indicate the value of `n`, but that's tedious.)
Some tips on using `SCOPED_TRACE`:
1. With a suitable message, it's often enough to use `SCOPED_TRACE` at the beginning of a sub-routine, instead of at each call site.   1. When calling sub-routines inside a loop, make the loop iterator part of the message in `SCOPED_TRACE` such that you can know which iteration the failure is from.   1. Sometimes the line number of the trace point is enough for identifying the particular invocation of a sub-routine. In this case, you don't have to choose a unique message for `SCOPED_TRACE`. You can simply use `""`.   1. You can use `SCOPED_TRACE` in an inner scope when there is one in the outer scope. In this case, all active trace points will be included in the failure messages, in reverse order they are encountered.   1. The trace dump is clickable in Emacs' compilation buffer - hit return on a line number and you'll be taken to that line in the source file!
_Availability:_ Linux, Windows, Mac.
A common pitfall when using `ASSERT_*` and `FAIL*` is not understanding that when they fail they only abort the _current function_, not the entire test. For example, the following test will segfault: ``` void Subroutine() {   // Generates a fatal failure and aborts the current function.   ASSERT_EQ(1, 2);   // The following won't be executed.   ... }
TEST(FooTest, Bar) {   Subroutine();   // The intended behavior is for the fatal failure   // in Subroutine() to abort the entire test.   // The actual behavior: the function goes on after Subroutine() returns.   int* p = NULL;   *p = 3; // Segfault! } ```
Since we don't use exceptions, it is technically impossible to implement the intended behavior here.  To alleviate this, Google Test provides two solutions.  You could use either the `(ASSERT|EXPECT)_NO_FATAL_FAILURE` assertions or the `HasFatalFailure()` function.  They are described in the following two subsections.
As shown above, if your test calls a subroutine that has an `ASSERT_*` failure in it, the test will continue after the subroutine returns. This may not be what you want.
Often people want fatal failures to propagate like exceptions.  For that Google Test offers the following macros:
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_NO_FATAL_FAILURE(`_statement_`);` | `EXPECT_NO_FATAL_FAILURE(`_statement_`);` | _statement_ doesn't generate any new fatal failures in the current thread. |
Only failures in the thread that executes the assertion are checked to determine the result of this type of assertions.  If _statement_ creates new threads, failures in these threads are ignored.
Examples:
``` ASSERT_NO_FATAL_FAILURE(Foo());
int i; EXPECT_NO_FATAL_FAILURE({   i = Bar(); }); ```
_Availability:_ Linux, Windows, Mac. Assertions from multiple threads are currently not supported.
`HasFatalFailure()` in the `::testing::Test` class returns `true` if an assertion in the current test has suffered a fatal failure. This allows functions to catch fatal failures in a sub-routine and return early.
``` class Test {  public:   ...   static bool HasFatalFailure(); }; ```
The typical usage, which basically simulates the behavior of a thrown exception, is:
``` TEST(FooTest, Bar) {   Subroutine();   // Aborts if Subroutine() had a fatal failure.   if (HasFatalFailure())     return;   // The following won't be executed.   ... } ```
If `HasFatalFailure()` is used outside of `TEST()` , `TEST_F()` , or a test fixture, you must add the `::testing::Test::` prefix, as in:
``` if (::testing::Test::HasFatalFailure())   return; ```
Similarly, `HasNonfatalFailure()` returns `true` if the current test has at least one non-fatal failure, and `HasFailure()` returns `true` if the current test has at least one failure of either kind.
_Availability:_ Linux, Windows, Mac.  `HasNonfatalFailure()` and `HasFailure()` are available since version 1.4.0.
In your test code, you can call `RecordProperty("key", value)` to log additional information, where `value` can be either a string or an `int`. The _last_ value recorded for a key will be emitted to the XML output if you specify one. For example, the test
``` TEST_F(WidgetUsageTest, MinAndMaxWidgets) {   RecordProperty("MaximumWidgets", ComputeMaxUsage());   RecordProperty("MinimumWidgets", ComputeMinUsage()); } ```
will output XML like this:
``` ...   <testcase name="MinAndMaxWidgets" status="run" time="6" classname="WidgetUsageTest"             MaximumWidgets="12"             MinimumWidgets="9" /> ... ```
_Note_:   * `RecordProperty()` is a static member of the `Test` class. Therefore it needs to be prefixed with `::testing::Test::` if used outside of the `TEST` body and the test fixture class.   * `key` must be a valid XML attribute name, and cannot conflict with the ones already used by Google Test (`name`, `status`, `time`, `classname`, `type_param`, and `value_param`).   * Calling `RecordProperty()` outside of the lifespan of a test is allowed. If it's called outside of a test but between a test case's `SetUpTestCase()` and `TearDownTestCase()` methods, it will be attributed to the XML element for the test case. If it's called outside of all test cases (e.g. in a test environment), it will be attributed to the top-level XML element.
_Availability_: Linux, Windows, Mac.

Google Test creates a new test fixture object for each test in order to make tests independent and easier to debug. However, sometimes tests use resources that are expensive to set up, making the one-copy-per-test model prohibitively expensive.
If the tests don't change the resource, there's no harm in them sharing a single resource copy. So, in addition to per-test set-up/tear-down, Google Test also supports per-test-case set-up/tear-down. To use it:
1. In your test fixture class (say `FooTest` ), define as `static` some member variables to hold the shared resources.   1. In the same test fixture class, define a `static void SetUpTestCase()` function (remember not to spell it as **`SetupTestCase`** with a small `u`!) to set up the shared resources and a `static void TearDownTestCase()` function to tear them down.
That's it! Google Test automatically calls `SetUpTestCase()` before running the _first test_ in the `FooTest` test case (i.e. before creating the first `FooTest` object), and calls `TearDownTestCase()` after running the _last test_ in it (i.e. after deleting the last `FooTest` object). In between, the tests can use the shared resources.
Remember that the test order is undefined, so your code can't depend on a test preceding or following another. Also, the tests must either not modify the state of any shared resource, or, if they do modify the state, they must restore the state to its original value before passing control to the next test.
Here's an example of per-test-case set-up and tear-down: ``` class FooTest : public ::testing::Test {  protected:   // Per-test-case set-up.   // Called before the first test in this test case.   // Can be omitted if not needed.   static void SetUpTestCase() {     shared_resource_ = new ...;   }
// Per-test-case tear-down.   // Called after the last test in this test case.   // Can be omitted if not needed.   static void TearDownTestCase() {     delete shared_resource_;     shared_resource_ = NULL;   }
// You can define per-test set-up and tear-down logic as usual.   virtual void SetUp() { ... }   virtual void TearDown() { ... }
// Some expensive resource shared by all tests.   static T* shared_resource_; };
T* FooTest::shared_resource_ = NULL;
TEST_F(FooTest, Test1) {   ... you can refer to shared_resource here ... } TEST_F(FooTest, Test2) {   ... you can refer to shared_resource here ... } ```
_Availability:_ Linux, Windows, Mac.
Just as you can do set-up and tear-down at the test level and the test case level, you can also do it at the test program level. Here's how.
First, you subclass the `::testing::Environment` class to define a test environment, which knows how to set-up and tear-down:
``` class Environment {  public:   virtual ~Environment() {}   // Override this to define how to set up the environment.   virtual void SetUp() {}   // Override this to define how to tear down the environment.   virtual void TearDown() {} }; ```
Then, you register an instance of your environment class with Google Test by calling the `::testing::AddGlobalTestEnvironment()` function:
``` Environment* AddGlobalTestEnvironment(Environment* env); ```
Now, when `RUN_ALL_TESTS()` is called, it first calls the `SetUp()` method of the environment object, then runs the tests if there was no fatal failures, and finally calls `TearDown()` of the environment object.
It's OK to register multiple environment objects. In this case, their `SetUp()` will be called in the order they are registered, and their `TearDown()` will be called in the reverse order.
Note that Google Test takes ownership of the registered environment objects. Therefore **do not delete them** by yourself.
You should call `AddGlobalTestEnvironment()` before `RUN_ALL_TESTS()` is called, probably in `main()`. If you use `gtest_main`, you need to      call this before `main()` starts for it to take effect. One way to do this is to define a global variable like this:
``` ::testing::Environment* const foo_env = ::testing::AddGlobalTestEnvironment(new FooEnvironment); ```
However, we strongly recommend you to write your own `main()` and call `AddGlobalTestEnvironment()` there, as relying on initialization of global variables makes the code harder to read and may cause problems when you register multiple environments from different translation units and the environments have dependencies among them (remember that the compiler doesn't guarantee the order in which global variables from different translation units are initialized).
_Availability:_ Linux, Windows, Mac.
_Value-parameterized tests_ allow you to test your code with different parameters without writing multiple copies of the same test.
Suppose you write a test for your code and then realize that your code is affected by a presence of a Boolean command line flag.
``` TEST(MyCodeTest, TestFoo) {   // A code to test foo(). } ```
Usually people factor their test code into a function with a Boolean parameter in such situations. The function sets the flag, then executes the testing code.
``` void TestFooHelper(bool flag_value) {   flag = flag_value;   // A code to test foo(). }
TEST(MyCodeTest, TestFoo) {   TestFooHelper(false);   TestFooHelper(true); } ```
But this setup has serious drawbacks. First, when a test assertion fails in your tests, it becomes unclear what value of the parameter caused it to fail. You can stream a clarifying message into your `EXPECT`/`ASSERT` statements, but it you'll have to do it with all of them. Second, you have to add one such helper function per test. What if you have ten tests? Twenty? A hundred?
Value-parameterized tests will let you write your test only once and then easily instantiate and run it with an arbitrary number of parameter values.
Here are some other situations when value-parameterized tests come handy:
* You want to test different implementations of an OO interface.   * You want to test your code over various inputs (a.k.a. data-driven testing). This feature is easy to abuse, so please exercise your good sense when doing it!
To write value-parameterized tests, first you should define a fixture class.  It must be derived from both `::testing::Test` and `::testing::WithParamInterface<T>` (the latter is a pure interface), where `T` is the type of your parameter values.  For convenience, you can just derive the fixture class from `::testing::TestWithParam<T>`, which itself is derived from both `::testing::Test` and `::testing::WithParamInterface<T>`. `T` can be any copyable type. If it's a raw pointer, you are responsible for managing the lifespan of the pointed values.
``` class FooTest : public ::testing::TestWithParam<const char*> {   // You can implement all the usual fixture class members here.   // To access the test parameter, call GetParam() from class   // TestWithParam<T>. };
// Or, when you want to add parameters to a pre-existing fixture class: class BaseTest : public ::testing::Test {   ... }; class BarTest : public BaseTest,                 public ::testing::WithParamInterface<const char*> {   ... }; ```
Then, use the `TEST_P` macro to define as many test patterns using this fixture as you want.  The `_P` suffix is for "parameterized" or "pattern", whichever you prefer to think.
``` TEST_P(FooTest, DoesBlah) {   // Inside a test, access the test parameter with the GetParam() method   // of the TestWithParam<T> class:   EXPECT_TRUE(foo.Blah(GetParam()));   ... }
TEST_P(FooTest, HasBlahBlah) {   ... } ```
Finally, you can use `INSTANTIATE_TEST_CASE_P` to instantiate the test case with any set of parameters you want. Google Test defines a number of functions for generating test parameters. They return what we call (surprise!) _parameter generators_. Here is a summary of them, which are all in the `testing` namespace:
| `Range(begin, end[, step])` | Yields values `{begin, begin+step, begin+step+step, ...}`. The values do not include `end`. `step` defaults to 1. | |:----------------------------|:------------------------------------------------------------------------------------------------------------------| | `Values(v1, v2, ..., vN)`   | Yields values `{v1, v2, ..., vN}`.                                                                                | | `ValuesIn(container)` and `ValuesIn(begin, end)` | Yields values from a C-style array, an STL-style container, or an iterator range `[begin, end)`. `container`, `begin`, and `end` can be expressions whose values are determined at run time.  | | `Bool()`                    | Yields sequence `{false, true}`.                                                                                  | | `Combine(g1, g2, ..., gN)`  | Yields all combinations (the Cartesian product for the math savvy) of the values generated by the `N` generators. This is only available if your system provides the `<tr1/tuple>` header. If you are sure your system does, and Google Test disagrees, you can override it by defining `GTEST_HAS_TR1_TUPLE=1`. See comments in [include/gtest/internal/gtest-port.h](../include/gtest/internal/gtest-port.h) for more information. |
For more details, see the comments at the definitions of these functions in the [source code](../include/gtest/gtest-param-test.h).
The following statement will instantiate tests from the `FooTest` test case each with parameter values `"meeny"`, `"miny"`, and `"moe"`.
``` INSTANTIATE_TEST_CASE_P(InstantiationName,                         FooTest,                         ::testing::Values("meeny", "miny", "moe")); ```
To distinguish different instances of the pattern (yes, you can instantiate it more than once), the first argument to `INSTANTIATE_TEST_CASE_P` is a prefix that will be added to the actual test case name. Remember to pick unique prefixes for different instantiations. The tests from the instantiation above will have these names:
* `InstantiationName/FooTest.DoesBlah/0` for `"meeny"`   * `InstantiationName/FooTest.DoesBlah/1` for `"miny"`   * `InstantiationName/FooTest.DoesBlah/2` for `"moe"`   * `InstantiationName/FooTest.HasBlahBlah/0` for `"meeny"`   * `InstantiationName/FooTest.HasBlahBlah/1` for `"miny"`   * `InstantiationName/FooTest.HasBlahBlah/2` for `"moe"`
You can use these names in [--gtest\_filter](#running-a-subset-of-the-tests).
This statement will instantiate all tests from `FooTest` again, each with parameter values `"cat"` and `"dog"`:
``` const char* pets[] = {"cat", "dog"}; INSTANTIATE_TEST_CASE_P(AnotherInstantiationName, FooTest,                         ::testing::ValuesIn(pets)); ```
The tests from the instantiation above will have these names:
* `AnotherInstantiationName/FooTest.DoesBlah/0` for `"cat"`   * `AnotherInstantiationName/FooTest.DoesBlah/1` for `"dog"`   * `AnotherInstantiationName/FooTest.HasBlahBlah/0` for `"cat"`   * `AnotherInstantiationName/FooTest.HasBlahBlah/1` for `"dog"`
Please note that `INSTANTIATE_TEST_CASE_P` will instantiate _all_ tests in the given test case, whether their definitions come before or _after_ the `INSTANTIATE_TEST_CASE_P` statement.
You can see [these](../samples/sample7_unittest.cc) [files](../samples/sample8_unittest.cc) for more examples.
_Availability_: Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.2.0.
In the above, we define and instantiate `FooTest` in the same source file. Sometimes you may want to define value-parameterized tests in a library and let other people instantiate them later. This pattern is known as <i>abstract tests</i>. As an example of its application, when you are designing an interface you can write a standard suite of abstract tests (perhaps using a factory function as the test parameter) that all implementations of the interface are expected to pass. When someone implements the interface, he can instantiate your suite to get all the interface-conformance tests for free.
To define abstract tests, you should organize your code like this:
1. Put the definition of the parameterized test fixture class (e.g. `FooTest`) in a header file, say `foo_param_test.h`. Think of this as _declaring_ your abstract tests.   1. Put the `TEST_P` definitions in `foo_param_test.cc`, which includes `foo_param_test.h`. Think of this as _implementing_ your abstract tests.
Once they are defined, you can instantiate them by including `foo_param_test.h`, invoking `INSTANTIATE_TEST_CASE_P()`, and linking with `foo_param_test.cc`. You can instantiate the same abstract test case multiple times, possibly in different source files.
Suppose you have multiple implementations of the same interface and want to make sure that all of them satisfy some common requirements. Or, you may have defined several types that are supposed to conform to the same "concept" and you want to verify it.  In both cases, you want the same test logic repeated for different types.
While you can write one `TEST` or `TEST_F` for each type you want to test (and you may even factor the test logic into a function template that you invoke from the `TEST`), it's tedious and doesn't scale: if you want _m_ tests over _n_ types, you'll end up writing _m\*n_ `TEST`s.
_Typed tests_ allow you to repeat the same test logic over a list of types.  You only need to write the test logic once, although you must know the type list when writing typed tests.  Here's how you do it:
First, define a fixture class template.  It should be parameterized by a type.  Remember to derive it from `::testing::Test`:
``` template <typename T> class FooTest : public ::testing::Test {  public:   ...   typedef std::list<T> List;   static T shared_;   T value_; }; ```
Next, associate a list of types with the test case, which will be repeated for each type in the list:
``` typedef ::testing::Types<char, int, unsigned int> MyTypes; TYPED_TEST_CASE(FooTest, MyTypes); ```
The `typedef` is necessary for the `TYPED_TEST_CASE` macro to parse correctly.  Otherwise the compiler will think that each comma in the type list introduces a new macro argument.
Then, use `TYPED_TEST()` instead of `TEST_F()` to define a typed test for this test case.  You can repeat this as many times as you want:
``` TYPED_TEST(FooTest, DoesBlah) {   // Inside a test, refer to the special name TypeParam to get the type   // parameter.  Since we are inside a derived class template, C++ requires   // us to visit the members of FooTest via 'this'.   TypeParam n = this->value_;
// To visit static members of the fixture, add the 'TestFixture::'   // prefix.   n += TestFixture::shared_;
// To refer to typedefs in the fixture, add the 'typename TestFixture::'   // prefix.  The 'typename' is required to satisfy the compiler.   typename TestFixture::List values;   values.push_back(n);   ... }
TYPED_TEST(FooTest, HasPropertyA) { ... } ```
You can see `samples/sample6_unittest.cc` for a complete example.
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.1.0.
_Type-parameterized tests_ are like typed tests, except that they don't require you to know the list of types ahead of time.  Instead, you can define the test logic first and instantiate it with different type lists later.  You can even instantiate it more than once in the same program.
If you are designing an interface or concept, you can define a suite of type-parameterized tests to verify properties that any valid implementation of the interface/concept should have.  Then, the author of each implementation can just instantiate the test suite with his type to verify that it conforms to the requirements, without having to write similar tests repeatedly.  Here's an example:
First, define a fixture class template, as we did with typed tests:
``` template <typename T> class FooTest : public ::testing::Test {   ... }; ```
Next, declare that you will define a type-parameterized test case:
``` TYPED_TEST_CASE_P(FooTest); ```
The `_P` suffix is for "parameterized" or "pattern", whichever you prefer to think.
Then, use `TYPED_TEST_P()` to define a type-parameterized test.  You can repeat this as many times as you want:
``` TYPED_TEST_P(FooTest, DoesBlah) {   // Inside a test, refer to TypeParam to get the type parameter.   TypeParam n = 0;   ... }
TYPED_TEST_P(FooTest, HasPropertyA) { ... } ```
Now the tricky part: you need to register all test patterns using the `REGISTER_TYPED_TEST_CASE_P` macro before you can instantiate them. The first argument of the macro is the test case name; the rest are the names of the tests in this test case:
``` REGISTER_TYPED_TEST_CASE_P(FooTest,                            DoesBlah, HasPropertyA); ```
Finally, you are free to instantiate the pattern with the types you want.  If you put the above code in a header file, you can `#include` it in multiple C++ source files and instantiate it multiple times.
``` typedef ::testing::Types<char, int, unsigned int> MyTypes; INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, MyTypes); ```
To distinguish different instances of the pattern, the first argument to the `INSTANTIATE_TYPED_TEST_CASE_P` macro is a prefix that will be added to the actual test case name.  Remember to pick unique prefixes for different instances.
In the special case where the type list contains only one type, you can write that type directly without `::testing::Types<...>`, like this:
``` INSTANTIATE_TYPED_TEST_CASE_P(My, FooTest, int); ```
You can see `samples/sample6_unittest.cc` for a complete example.
_Availability:_ Linux, Windows (requires MSVC 8.0 or above), Mac; since version 1.1.0.
If you change your software's internal implementation, your tests should not break as long as the change is not observable by users. Therefore, per the _black-box testing principle_, most of the time you should test your code through its public interfaces.
If you still find yourself needing to test internal implementation code, consider if there's a better design that wouldn't require you to do so. If you absolutely have to test non-public interface code though, you can. There are two cases to consider:
* Static functions (_not_ the same as static member functions!) or unnamed namespaces, and   * Private or protected class members
Both static functions and definitions/declarations in an unnamed namespace are only visible within the same translation unit. To test them, you can `#include` the entire `.cc` file being tested in your `*_test.cc` file. (`#include`ing `.cc` files is not a good way to reuse code - you should not do this in production code!)
However, a better approach is to move the private code into the `foo::internal` namespace, where `foo` is the namespace your project normally uses, and put the private declarations in a `*-internal.h` file. Your production `.cc` files and your tests are allowed to include this internal header, but your clients are not. This way, you can fully test your internal implementation without leaking it to your clients.
Private class members are only accessible from within the class or by friends. To access a class' private members, you can declare your test fixture as a friend to the class and define accessors in your fixture. Tests using the fixture can then access the private members of your production class via the accessors in the fixture. Note that even though your fixture is a friend to your production class, your tests are not automatically friends to it, as they are technically defined in sub-classes of the fixture.
Another way to test private members is to refactor them into an implementation class, which is then declared in a `*-internal.h` file. Your clients aren't allowed to include this header but your tests can. Such is called the Pimpl (Private Implementation) idiom.
Or, you can declare an individual test as a friend of your class by adding this line in the class body:
``` FRIEND_TEST(TestCaseName, TestName); ```
For example, ``` // foo.h #include "gtest/gtest_prod.h"
// Defines FRIEND_TEST. class Foo {   ...  private:   FRIEND_TEST(FooTest, BarReturnsZeroOnNull);   int Bar(void* x); };
// foo_test.cc ... TEST(FooTest, BarReturnsZeroOnNull) {   Foo foo;   EXPECT_EQ(0, foo.Bar(NULL));   // Uses Foo's private member Bar(). } ```
Pay special attention when your class is defined in a namespace, as you should define your test fixtures and tests in the same namespace if you want them to be friends of your class. For example, if the code to be tested looks like:
``` namespace my_namespace {
class Foo {   friend class FooTest;   FRIEND_TEST(FooTest, Bar);   FRIEND_TEST(FooTest, Baz);   ...   definition of the class Foo   ... };
}  // namespace my_namespace ```
Your test code should be something like:
``` namespace my_namespace { class FooTest : public ::testing::Test {  protected:   ... };
TEST_F(FooTest, Bar) { ... } TEST_F(FooTest, Baz) { ... }
}  // namespace my_namespace ```
If you are building a testing utility on top of Google Test, you'll want to test your utility.  What framework would you use to test it? Google Test, of course.
The challenge is to verify that your testing utility reports failures correctly.  In frameworks that report a failure by throwing an exception, you could catch the exception and assert on it.  But Google Test doesn't use exceptions, so how do we test that a piece of code generates an expected failure?
`"gtest/gtest-spi.h"` contains some constructs to do this.  After `#include`ing this header, you can use
| `EXPECT_FATAL_FAILURE(`_statement, substring_`);` | |:--------------------------------------------------|
to assert that _statement_ generates a fatal (e.g. `ASSERT_*`) failure whose message contains the given _substring_, or use
| `EXPECT_NONFATAL_FAILURE(`_statement, substring_`);` | |:-----------------------------------------------------|
if you are expecting a non-fatal (e.g. `EXPECT_*`) failure.
For technical reasons, there are some caveats:
1. You cannot stream a failure message to either macro.   1. _statement_ in `EXPECT_FATAL_FAILURE()` cannot reference local non-static variables or non-static members of `this` object.   1. _statement_ in `EXPECT_FATAL_FAILURE()` cannot return a value.
_Note:_ Google Test is designed with threads in mind.  Once the synchronization primitives in `"gtest/internal/gtest-port.h"` have been implemented, Google Test will become thread-safe, meaning that you can then use assertions in multiple threads concurrently.  Before
that, however, Google Test only supports single-threaded usage.  Once thread-safe, `EXPECT_FATAL_FAILURE()` and `EXPECT_NONFATAL_FAILURE()` will capture failures in the current thread only. If _statement_ creates new threads, failures in these threads will be ignored.  If you want to capture failures from all threads instead, you should use the following macros:
| `EXPECT_FATAL_FAILURE_ON_ALL_THREADS(`_statement, substring_`);` | |:-----------------------------------------------------------------| | `EXPECT_NONFATAL_FAILURE_ON_ALL_THREADS(`_statement, substring_`);` |
Sometimes a function may need to know the name of the currently running test. For example, you may be using the `SetUp()` method of your test fixture to set the golden file name based on which test is running. The `::testing::TestInfo` class has this information:
``` namespace testing {
class TestInfo {  public:   // Returns the test case name and the test name, respectively.   //   // Do NOT delete or free the return value - it's managed by the   // TestInfo class.   const char* test_case_name() const;   const char* name() const; };
}  // namespace testing ```
> To obtain a `TestInfo` object for the currently running test, call `current_test_info()` on the `UnitTest` singleton object:
``` // Gets information about the currently running test. // Do NOT delete the returned object - it's managed by the UnitTest class. const ::testing::TestInfo* const test_info =   ::testing::UnitTest::GetInstance()->current_test_info(); printf("We are in test %s of test case %s.\n",        test_info->name(), test_info->test_case_name()); ```
`current_test_info()` returns a null pointer if no test is running. In particular, you cannot find the test case name in `TestCaseSetUp()`, `TestCaseTearDown()` (where you know the test case name implicitly), or functions called from them.
_Availability:_ Linux, Windows, Mac.
Google Test provides an <b>event listener API</b> to let you receive notifications about the progress of a test program and test failures. The events you can listen to include the start and end of the test program, a test case, or a test method, among others. You may use this API to augment or replace the standard console output, replace the XML output, or provide a completely different form of output, such as a GUI or a database. You can also use test events as checkpoints to implement a resource leak checker, for example.
_Availability:_ Linux, Windows, Mac; since v1.4.0.
To define a event listener, you subclass either [testing::TestEventListener](../include/gtest/gtest.h#L855) or [testing::EmptyTestEventListener](../include/gtest/gtest.h#L905). The former is an (abstract) interface, where <i>each pure virtual method<br> can be overridden to handle a test event</i> (For example, when a test starts, the `OnTestStart()` method will be called.). The latter provides an empty implementation of all methods in the interface, such that a subclass only needs to override the methods it cares about.
When an event is fired, its context is passed to the handler function as an argument. The following argument types are used:   * [UnitTest](../include/gtest/gtest.h#L1007) reflects the state of the entire test program,   * [TestCase](../include/gtest/gtest.h#L689) has information about a test case, which can contain one or more tests,   * [TestInfo](../include/gtest/gtest.h#L599) contains the state of a test, and   * [TestPartResult](../include/gtest/gtest-test-part.h#L42) represents the result of a test assertion.
An event handler function can examine the argument it receives to find out interesting information about the event and the test program's state.  Here's an example:
```   class MinimalistPrinter : public ::testing::EmptyTestEventListener {     // Called before a test starts.     virtual void OnTestStart(const ::testing::TestInfo& test_info) {       printf("*** Test %s.%s starting.\n",              test_info.test_case_name(), test_info.name());     }
// Called after a failed assertion or a SUCCEED() invocation.     virtual void OnTestPartResult(         const ::testing::TestPartResult& test_part_result) {       printf("%s in %s:%d\n%s\n",              test_part_result.failed() ? "*** Failure" : "Success",              test_part_result.file_name(),              test_part_result.line_number(),              test_part_result.summary());     }
// Called after a test ends.     virtual void OnTestEnd(const ::testing::TestInfo& test_info) {       printf("*** Test %s.%s ending.\n",              test_info.test_case_name(), test_info.name());     }   }; ```
To use the event listener you have defined, add an instance of it to the Google Test event listener list (represented by class [TestEventListeners](../include/gtest/gtest.h#L929) - note the "s" at the end of the name) in your `main()` function, before calling `RUN_ALL_TESTS()`: ``` int main(int argc, char** argv) {   ::testing::InitGoogleTest(&argc, argv);   // Gets hold of the event listener list.   ::testing::TestEventListeners& listeners =       ::testing::UnitTest::GetInstance()->listeners();   // Adds a listener to the end.  Google Test takes the ownership.   listeners.Append(new MinimalistPrinter);   return RUN_ALL_TESTS(); } ```
There's only one problem: the default test result printer is still in effect, so its output will mingle with the output from your minimalist printer. To suppress the default printer, just release it from the event listener list and delete it. You can do so by adding one line: ```   ...   delete listeners.Release(listeners.default_result_printer());   listeners.Append(new MinimalistPrinter);   return RUN_ALL_TESTS(); ```
Now, sit back and enjoy a completely different output from your tests. For more details, you can read this [sample](../samples/sample9_unittest.cc).
You may append more than one listener to the list. When an `On*Start()` or `OnTestPartResult()` event is fired, the listeners will receive it in the order they appear in the list (since new listeners are added to the end of the list, the default text printer and the default XML generator will receive the event first). An `On*End()` event will be received by the listeners in the _reverse_ order. This allows output by listeners added later to be framed by output from listeners added earlier.
You may use failure-raising macros (`EXPECT_*()`, `ASSERT_*()`, `FAIL()`, etc) when processing an event. There are some restrictions:
1. You cannot generate any failure in `OnTestPartResult()` (otherwise it will cause `OnTestPartResult()` to be called recursively).   1. A listener that handles `OnTestPartResult()` is not allowed to generate any failure.
When you add listeners to the listener list, you should put listeners that handle `OnTestPartResult()` _before_ listeners that can generate failures. This ensures that failures generated by the latter are attributed to the right test by the former.
We have a sample of failure-raising listener [here](../samples/sample10_unittest.cc).
Google Test test programs are ordinary executables. Once built, you can run them directly and affect their behavior via the following environment variables and/or command line flags. For the flags to work, your programs must call `::testing::InitGoogleTest()` before calling `RUN_ALL_TESTS()`.
To see a list of supported flags and their usage, please run your test program with the `--help` flag.  You can also use `-h`, `-?`, or `/?` for short.  This feature is added in version 1.3.0.
If an option is specified both by an environment variable and by a flag, the latter takes precedence.  Most of the options can also be set/read in code: to access the value of command line flag `--gtest_foo`, write `::testing::GTEST_FLAG(foo)`.  A common pattern is to set the value of a flag before calling `::testing::InitGoogleTest()` to change the default value of the flag: ``` int main(int argc, char** argv) {   // Disables elapsed time by default.   ::testing::GTEST_FLAG(print_time) = false;
// This allows the user to override the flag on the command line.   ::testing::InitGoogleTest(&argc, argv);
return RUN_ALL_TESTS(); } ```
This section shows various options for choosing which tests to run.
Sometimes it is necessary to list the available tests in a program before running them so that a filter may be applied if needed. Including the flag `--gtest_list_tests` overrides all other flags and lists tests in the following format: ``` TestCase1.   TestName1   TestName2 TestCase2.   TestName ```
None of the tests listed are actually run if the flag is provided. There is no corresponding environment variable for this flag.
_Availability:_ Linux, Windows, Mac.
By default, a Google Test program runs all tests the user has defined. Sometimes, you want to run only a subset of the tests (e.g. for debugging or quickly verifying a change). If you set the `GTEST_FILTER` environment variable or the `--gtest_filter` flag to a filter string, Google Test will only run the tests whose full names (in the form of `TestCaseName.TestName`) match the filter.
The format of a filter is a '`:`'-separated list of wildcard patterns (called the positive patterns) optionally followed by a '`-`' and another '`:`'-separated pattern list (called the negative patterns). A test matches the filter if and only if it matches any of the positive patterns but does not match any of the negative patterns.
A pattern may contain `'*'` (matches any string) or `'?'` (matches any single character). For convenience, the filter `'*-NegativePatterns'` can be also written as `'-NegativePatterns'`.
For example:
* `./foo_test` Has no flag, and thus runs all its tests.   * `./foo_test --gtest_filter=*` Also runs everything, due to the single match-everything `*` value.   * `./foo_test --gtest_filter=FooTest.*` Runs everything in test case `FooTest`.   * `./foo_test --gtest_filter=*Null*:*Constructor*` Runs any test whose full name contains either `"Null"` or `"Constructor"`.   * `./foo_test --gtest_filter=-*DeathTest.*` Runs all non-death tests.   * `./foo_test --gtest_filter=FooTest.*-FooTest.Bar` Runs everything in test case `FooTest` except `FooTest.Bar`.
_Availability:_ Linux, Windows, Mac.
If you have a broken test that you cannot fix right away, you can add the `DISABLED_` prefix to its name. This will exclude it from execution. This is better than commenting out the code or using `#if 0`, as disabled tests are still compiled (and thus won't rot).
If you need to disable all tests in a test case, you can either add `DISABLED_` to the front of the name of each test, or alternatively add it to the front of the test case name.
For example, the following tests won't be run by Google Test, even though they will still be compiled:
``` // Tests that Foo does Abc. TEST(FooTest, DISABLED_DoesAbc) { ... }
class DISABLED_BarTest : public ::testing::Test { ... };
// Tests that Bar does Xyz. TEST_F(DISABLED_BarTest, DoesXyz) { ... } ```
_Note:_ This feature should only be used for temporary pain-relief. You still have to fix the disabled tests at a later date. As a reminder, Google Test will print a banner warning you if a test program contains any disabled tests.
_Tip:_ You can easily count the number of disabled tests you have using `grep`. This number can be used as a metric for improving your test quality.
_Availability:_ Linux, Windows, Mac.
To include [disabled tests](#temporarily-disabling-tests) in test execution, just invoke the test program with the `--gtest_also_run_disabled_tests` flag or set the `GTEST_ALSO_RUN_DISABLED_TESTS` environment variable to a value other than `0`.  You can combine this with the [--gtest\_filter](#running-a-subset-of-the-tests) flag to further select which disabled tests to run.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
Once in a while you'll run into a test whose result is hit-or-miss. Perhaps it will fail only 1% of the time, making it rather hard to reproduce the bug under a debugger. This can be a major source of frustration.
The `--gtest_repeat` flag allows you to repeat all (or selected) test methods in a program many times. Hopefully, a flaky test will eventually fail and give you a chance to debug. Here's how to use it:
| `$ foo_test --gtest_repeat=1000` | Repeat foo\_test 1000 times and don't stop at failures. | |:---------------------------------|:--------------------------------------------------------| | `$ foo_test --gtest_repeat=-1`   | A negative count means repeating forever.               | | `$ foo_test --gtest_repeat=1000 --gtest_break_on_failure` | Repeat foo\_test 1000 times, stopping at the first failure. This is especially useful when running under a debugger: when the testfails, it will drop into the debugger and you can then inspect variables and stacks. | | `$ foo_test --gtest_repeat=1000 --gtest_filter=FooBar` | Repeat the tests whose name matches the filter 1000 times. |
If your test program contains global set-up/tear-down code registered using `AddGlobalTestEnvironment()`, it will be repeated in each iteration as well, as the flakiness may be in it. You can also specify the repeat count by setting the `GTEST_REPEAT` environment variable.
_Availability:_ Linux, Windows, Mac.
You can specify the `--gtest_shuffle` flag (or set the `GTEST_SHUFFLE` environment variable to `1`) to run the tests in a program in a random order. This helps to reveal bad dependencies between tests.
By default, Google Test uses a random seed calculated from the current time. Therefore you'll get a different order every time. The console output includes the random seed value, such that you can reproduce an order-related test failure later. To specify the random seed explicitly, use the `--gtest_random_seed=SEED` flag (or set the `GTEST_RANDOM_SEED` environment variable), where `SEED` is an integer between 0 and 99999. The seed value 0 is special: it tells Google Test to do the default behavior of calculating the seed from the current time.
If you combine this with `--gtest_repeat=N`, Google Test will pick a different random seed and re-shuffle the tests in each iteration.
_Availability:_ Linux, Windows, Mac; since v1.4.0.
This section teaches how to tweak the way test results are reported.
Google Test can use colors in its terminal output to make it easier to spot the separation between tests, and whether tests passed.
You can set the GTEST\_COLOR environment variable or set the `--gtest_color` command line flag to `yes`, `no`, or `auto` (the default) to enable colors, disable colors, or let Google Test decide. When the value is `auto`, Google Test will use colors if and only if the output goes to a terminal and (on non-Windows platforms) the `TERM` environment variable is set to `xterm` or `xterm-color`.
_Availability:_ Linux, Windows, Mac.
By default, Google Test prints the time it takes to run each test.  To suppress that, run the test program with the `--gtest_print_time=0` command line flag.  Setting the `GTEST_PRINT_TIME` environment variable to `0` has the same effect.
_Availability:_ Linux, Windows, Mac.  (In Google Test 1.3.0 and lower, the default behavior is that the elapsed time is **not** printed.)
Google Test can emit a detailed XML report to a file in addition to its normal textual output. The report contains the duration of each test, and thus can help you identify slow tests.
To generate the XML report, set the `GTEST_OUTPUT` environment variable or the `--gtest_output` flag to the string `"xml:_path_to_output_file_"`, which will create the file at the given location. You can also just use the string `"xml"`, in which case the output can be found in the `test_detail.xml` file in the current directory.
If you specify a directory (for example, `"xml:output/directory/"` on Linux or `"xml:output\directory\"` on Windows), Google Test will create the XML file in that directory, named after the test executable (e.g. `foo_test.xml` for test program `foo_test` or `foo_test.exe`). If the file already exists (perhaps left over from a previous run), Google Test will pick a different name (e.g. `foo_test_1.xml`) to avoid overwriting it.
The report uses the format described here.  It is based on the `junitreport` Ant task and can be parsed by popular continuous build systems like [Jenkins](http://jenkins-ci.org/). Since that format was originally intended for Java, a little interpretation is required to make it apply to Google Test tests, as shown here:
``` <testsuites name="AllTests" ...>   <testsuite name="test_case_name" ...>     <testcase name="test_name" ...>       <failure message="..."/>       <failure message="..."/>       <failure message="..."/>     </testcase>   </testsuite> </testsuites> ```
* The root `<testsuites>` element corresponds to the entire test program.   * `<testsuite>` elements correspond to Google Test test cases.   * `<testcase>` elements correspond to Google Test test functions.
For instance, the following program
``` TEST(MathTest, Addition) { ... } TEST(MathTest, Subtraction) { ... } TEST(LogicTest, NonContradiction) { ... } ```
could generate this report:
``` <?xml version="1.0" encoding="UTF-8"?> <testsuites tests="3" failures="1" errors="0" time="35" name="AllTests">   <testsuite name="MathTest" tests="2" failures="1" errors="0" time="15">     <testcase name="Addition" status="run" time="7" classname="">       <failure message="Value of: add(1, 1)&#x0A; Actual: 3&#x0A;Expected: 2" type=""/>       <failure message="Value of: add(1, -1)&#x0A; Actual: 1&#x0A;Expected: 0" type=""/>     </testcase>     <testcase name="Subtraction" status="run" time="5" classname="">     </testcase>   </testsuite>   <testsuite name="LogicTest" tests="1" failures="0" errors="0" time="5">     <testcase name="NonContradiction" status="run" time="5" classname="">     </testcase>   </testsuite> </testsuites> ```
Things to note:
* The `tests` attribute of a `<testsuites>` or `<testsuite>` element tells how many test functions the Google Test program or test case contains, while the `failures` attribute tells how many of them failed.   * The `time` attribute expresses the duration of the test, test case, or entire test program in milliseconds.   * Each `<failure>` element corresponds to a single failed Google Test assertion.   * Some JUnit concepts don't apply to Google Test, yet we have to conform to the DTD. Therefore you'll see some dummy elements and attributes in the report. You can safely ignore these parts.
_Availability:_ Linux, Windows, Mac.
When running test programs under a debugger, it's very convenient if the debugger can catch an assertion failure and automatically drop into interactive mode. Google Test's _break-on-failure_ mode supports this behavior.
To enable it, set the `GTEST_BREAK_ON_FAILURE` environment variable to a value other than `0` . Alternatively, you can use the `--gtest_break_on_failure` command line flag.
_Availability:_ Linux, Windows, Mac.
Google Test can be used either with or without exceptions enabled.  If a test throws a C++ exception or (on Windows) a structured exception (SEH), by default Google Test catches it, reports it as a test failure, and continues with the next test method.  This maximizes the coverage of a test run.  Also, on Windows an uncaught exception will cause a pop-up window, so catching the exceptions allows you to run the tests automatically.
When debugging the test failures, however, you may instead want the exceptions to be handled by the debugger, such that you can examine the call stack when an exception is thrown.  To achieve that, set the `GTEST_CATCH_EXCEPTIONS` environment variable to `0`, or use the `--gtest_catch_exceptions=0` flag when running the tests.
**Availability**: Linux, Windows, Mac.
If you work on a project that has already been using another testing framework and is not ready to completely switch to Google Test yet, you can get much of Google Test's benefit by using its assertions in your existing tests.  Just change your `main()` function to look like:
``` #include "gtest/gtest.h"
int main(int argc, char** argv) {   ::testing::GTEST_FLAG(throw_on_failure) = true;   // Important: Google Test must be initialized.   ::testing::InitGoogleTest(&argc, argv);
... whatever your existing testing framework requires ... } ```
With that, you can use Google Test assertions in addition to the native assertions your testing framework provides, for example:
``` void TestFooDoesBar() {   Foo foo;   EXPECT_LE(foo.Bar(1), 100);     // A Google Test assertion.   CPPUNIT_ASSERT(foo.IsEmpty());  // A native assertion. } ```
If a Google Test assertion fails, it will print an error message and throw an exception, which will be treated as a failure by your host testing framework.  If you compile your code with exceptions disabled, a failed Google Test assertion will instead exit your program with a non-zero code, which will also signal a test failure to your test runner.
If you don't write `::testing::GTEST_FLAG(throw_on_failure) = true;` in your `main()`, you can alternatively enable this feature by specifying the `--gtest_throw_on_failure` flag on the command-line or setting the `GTEST_THROW_ON_FAILURE` environment variable to a non-zero value.
Death tests are _not_ supported when other test framework is used to organize tests.
_Availability:_ Linux, Windows, Mac; since v1.3.0.
If you have more than one machine you can use to run a test program, you might want to run the test functions in parallel and get the result faster.  We call this technique _sharding_, where each machine is called a _shard_.
Google Test is compatible with test sharding.  To take advantage of this feature, your test runner (not part of Google Test) needs to do the following:
1. Allocate a number of machines (shards) to run the tests.   1. On each shard, set the `GTEST_TOTAL_SHARDS` environment variable to the total number of shards.  It must be the same for all shards.   1. On each shard, set the `GTEST_SHARD_INDEX` environment variable to the index of the shard.  Different shards must be assigned different indices, which must be in the range `[0, GTEST_TOTAL_SHARDS - 1]`.   1. Run the same test program on all shards.  When Google Test sees the above two environment variables, it will select a subset of the test functions to run.  Across all shards, each test function in the program will be run exactly once.   1. Wait for all shards to finish, then collect and report the results.
Your project may have tests that were written without Google Test and thus don't understand this protocol.  In order for your test runner to figure out which test supports sharding, it can set the environment variable `GTEST_SHARD_STATUS_FILE` to a non-existent file path.  If a test program supports sharding, it will create this file to acknowledge the fact (the actual contents of the file are not important at this time; although we may stick some useful information in it in the future.); otherwise it will not create it.
Here's an example to make it clear.  Suppose you have a test program `foo_test` that contains the following 5 test functions: ``` TEST(A, V) TEST(A, W) TEST(B, X) TEST(B, Y) TEST(B, Z) ``` and you have 3 machines at your disposal.  To run the test functions in parallel, you would set `GTEST_TOTAL_SHARDS` to 3 on all machines, and set `GTEST_SHARD_INDEX` to 0, 1, and 2 on the machines respectively. Then you would run the same `foo_test` on each machine.
Google Test reserves the right to change how the work is distributed across the shards, but here's one possible scenario:
* Machine #0 runs `A.V` and `B.X`.   * Machine #1 runs `A.W` and `B.Y`.   * Machine #2 runs `B.Z`.
_Availability:_ Linux, Windows, Mac; since version 1.3.0.
Google Test's implementation consists of ~30 files (excluding its own tests).  Sometimes you may want them to be packaged up in two files (a `.h` and a `.cc`) instead, such that you can easily copy them to a new machine and start hacking there.  For this we provide an experimental Python script `fuse_gtest_files.py` in the `scripts/` directory (since release 1.3.0). Assuming you have Python 2.4 or above installed on your machine, just go to that directory and run ``` python fuse_gtest_files.py OUTPUT_DIR ```
and you should see an `OUTPUT_DIR` directory being created with files `gtest/gtest.h` and `gtest/gtest-all.cc` in it.  These files contain everything you need to use Google Test.  Just copy them to anywhere you want and you are ready to write tests.  You can use the [scripts/test/Makefile](../scripts/test/Makefile) file as an example on how to compile your tests against them.
Congratulations! You've now learned more advanced Google Test tools and are ready to tackle more complex testing tasks. If you want to dive even deeper, you can read the [Frequently-Asked Questions](V1_7_FAQ.md).
This page lists all documentation wiki pages for Google Test **(the SVN trunk version)** -- **if you use a released version of Google Test, please read the documentation for that specific version instead.**
* [Primer](V1_7_Primer.md) -- start here if you are new to Google Test.   * [Samples](V1_7_Samples.md) -- learn from examples.   * [AdvancedGuide](V1_7_AdvancedGuide.md) -- learn more about Google Test.   * [XcodeGuide](V1_7_XcodeGuide.md) -- how to use Google Test in Xcode on Mac.   * [Frequently-Asked Questions](V1_7_FAQ.md) -- check here before asking a question on the mailing list.
To contribute code to Google Test, read:
* [DevGuide](DevGuide.md) -- read this _before_ writing your first patch.   * [PumpManual](V1_7_PumpManual.md) -- how we generate some of Google Test's source files.

If you cannot find the answer to your question here, and you have read [Primer](V1_7_Primer.md) and [AdvancedGuide](V1_7_AdvancedGuide.md), send it to googletestframework@googlegroups.com.
First, let us say clearly that we don't want to get into the debate of which C++ testing framework is **the best**.  There exist many fine frameworks for writing C++ tests, and we have tremendous respect for the developers and users of them.  We don't think there is (or will be) a single best framework - you have to pick the right tool for the particular task you are tackling.
We created Google Test because we couldn't find the right combination of features and conveniences in an existing framework to satisfy _our_ needs.  The following is a list of things that _we_ like about Google Test.  We don't claim them to be unique to Google Test - rather, the combination of them makes Google Test the choice for us.  We hope this list can help you decide whether it is for you too.
* Google Test is designed to be portable: it doesn't require exceptions or RTTI; it works around various bugs in various compilers and environments; etc.  As a result, it works on Linux, Mac OS X, Windows and several embedded operating systems.   * Nonfatal assertions (`EXPECT_*`) have proven to be great time savers, as they allow a test to report multiple failures in a single edit-compile-test cycle.   * It's easy to write assertions that generate informative messages: you just use the stream syntax to append any additional information, e.g. `ASSERT_EQ(5, Foo(i)) << " where i = " << i;`.  It doesn't require a new set of macros or special functions.   * Google Test automatically detects your tests and doesn't require you to enumerate them in order to run them.   * Death tests are pretty handy for ensuring that your asserts in production code are triggered by the right conditions.   * `SCOPED_TRACE` helps you understand the context of an assertion failure when it comes from inside a sub-routine or loop.   * You can decide which tests to run using name patterns.  This saves time when you want to quickly reproduce a test failure.   * Google Test can generate XML test result reports that can be parsed by popular continuous build system like Hudson.   * Simple things are easy in Google Test, while hard things are possible: in addition to advanced features like [global test environments](V1_7_AdvancedGuide.md#global-set-up-and-tear-down) and tests parameterized by [values](V1_7_AdvancedGuide.md#value-parameterized-tests) or [types](V1_7_AdvancedGuide.md#typed-tests), Google Test supports various ways for the user to extend the framework -- if Google Test doesn't do something out of the box, chances are that a user can implement the feature using Google Test's public API, without changing Google Test itself.  In particular, you can:     * expand your testing vocabulary by defining [custom predicates](V1_7_AdvancedGuide.md#predicate-assertions-for-better-error-messages),     * teach Google Test how to [print your types](V1_7_AdvancedGuide.md#teaching-google-test-how-to-print-your-values),     * define your own testing macros or utilities and verify them using Google Test's [Service Provider Interface](V1_7_AdvancedGuide.md#catching-failures), and     * reflect on the test cases or change the test output format by intercepting the [test events](V1_7_AdvancedGuide.md#extending-google-test-by-handling-test-events).
We strive to minimize compiler warnings Google Test generates.  Before releasing a new version, we test to make sure that it doesn't generate warnings when compiled using its CMake script on Windows, Linux, and Mac OS.
Unfortunately, this doesn't mean you are guaranteed to see no warnings when compiling Google Test in your environment:
* You may be using a different compiler as we use, or a different version of the same compiler.  We cannot possibly test for all compilers.   * You may be compiling on a different platform as we do.   * Your project may be using different compiler flags as we do.
It is not always possible to make Google Test warning-free for everyone.  Or, it may not be desirable if the warning is rarely enabled and fixing the violations makes the code more complex.
If you see warnings when compiling Google Test, we suggest that you use the `-isystem` flag (assuming your are using GCC) to mark Google Test headers as system headers.  That'll suppress warnings from Google Test headers.
Underscore (`_`) is special, as C++ reserves the following to be used by the compiler and the standard library:
1. any identifier that starts with an `_` followed by an upper-case letter, and   1. any identifier that containers two consecutive underscores (i.e. `__`) _anywhere_ in its name.
User code is _prohibited_ from using such identifiers.
Now let's look at what this means for `TEST` and `TEST_F`.
Currently `TEST(TestCaseName, TestName)` generates a class named `TestCaseName_TestName_Test`.  What happens if `TestCaseName` or `TestName` contains `_`?
1. If `TestCaseName` starts with an `_` followed by an upper-case letter (say, `_Foo`), we end up with `_Foo_TestName_Test`, which is reserved and thus invalid.   1. If `TestCaseName` ends with an `_` (say, `Foo_`), we get `Foo__TestName_Test`, which is invalid.   1. If `TestName` starts with an `_` (say, `_Bar`), we get `TestCaseName__Bar_Test`, which is invalid.   1. If `TestName` ends with an `_` (say, `Bar_`), we get `TestCaseName_Bar__Test`, which is invalid.
So clearly `TestCaseName` and `TestName` cannot start or end with `_` (Actually, `TestCaseName` can start with `_` -- as long as the `_` isn't followed by an upper-case letter.  But that's getting complicated.  So for simplicity we just say that it cannot start with `_`.).
It may seem fine for `TestCaseName` and `TestName` to contain `_` in the middle.  However, consider this: ``` TEST(Time, Flies_Like_An_Arrow) { ... } TEST(Time_Flies, Like_An_Arrow) { ... } ```
Now, the two `TEST`s will both generate the same class (`Time_Files_Like_An_Arrow_Test`).  That's not good.
So for simplicity, we just ask the users to avoid `_` in `TestCaseName` and `TestName`.  The rule is more constraining than necessary, but it's simple and easy to remember.  It also gives Google Test some wiggle room in case its implementation needs to change in the future.
If you violate the rule, there may not be immediately consequences, but your test may (just may) break with a new compiler (or a new version of the compiler you are using) or with a new version of Google Test.  Therefore it's best to follow the rule.
In the early days, we said that you could install compiled Google Test libraries on `*`nix systems using `make install`. Then every user of your machine can write tests without recompiling Google Test.
This seemed like a good idea, but it has a got-cha: every user needs to compile his tests using the _same_ compiler flags used to compile the installed Google Test libraries; otherwise he may run into undefined behaviors (i.e. the tests can behave strangely and may even crash for no obvious reasons).
Why?  Because C++ has this thing called the One-Definition Rule: if two C++ source files contain different definitions of the same class/function/variable, and you link them together, you violate the rule.  The linker may or may not catch the error (in many cases it's not required by the C++ standard to catch the violation).  If it doesn't, you get strange run-time behaviors that are unexpected and hard to debug.
If you compile Google Test and your test code using different compiler flags, they may see different definitions of the same class/function/variable (e.g. due to the use of `#if` in Google Test). Therefore, for your sanity, we recommend to avoid installing pre-compiled Google Test libraries.  Instead, each project should compile Google Test itself such that it can be sure that the same flags are used for both Google Test and the tests.
(Answered by Trevor Robinson)
Load the supplied Visual Studio solution file, either `msvc\gtest-md.sln` or `msvc\gtest.sln`. Go through the migration wizard to migrate the solution and project files to Visual Studio 2008. Select `Configuration Manager...` from the `Build` menu. Select `<New...>` from the `Active solution platform` dropdown.  Select `x64` from the new platform dropdown, leave `Copy settings from` set to `Win32` and `Create new project platforms` checked, then click `OK`. You now have `Win32` and `x64` platform configurations, selectable from the `Standard` toolbar, which allow you to toggle between building 32-bit or 64-bit binaries (or both at once using Batch Build).
In order to prevent build output files from overwriting one another, you'll need to change the `Intermediate Directory` settings for the newly created platform configuration across all the projects. To do this, multi-select (e.g. using shift-click) all projects (but not the solution) in the `Solution Explorer`. Right-click one of them and select `Properties`. In the left pane, select `Configuration Properties`, and from the `Configuration` dropdown, select `All Configurations`. Make sure the selected platform is `x64`. For the `Intermediate Directory` setting, change the value from `$(PlatformName)\$(ConfigurationName)` to `$(OutDir)\$(ProjectName)`. Click `OK` and then build the solution. When the build is complete, the 64-bit binaries will be in the `msvc\x64\Debug` directory.
We haven't tested this ourselves, but Per Abrahamsen reported that he was able to compile and install Google Test successfully when using MinGW from Cygwin.  You'll need to configure it with:
`PATH/TO/configure CC="gcc -mno-cygwin" CXX="g++ -mno-cygwin"`
You should be able to replace the `-mno-cygwin` option with direct links to the real MinGW binaries, but we haven't tried that.
Caveats:
* There are many warnings when compiling.   * `make check` will produce some errors as not all tests for Google Test itself are compatible with MinGW.
We also have reports on successful cross compilation of Google Test MinGW binaries on Linux using [these instructions](http://wiki.wxwidgets.org/Cross-Compiling_Under_Linux#Cross-compiling_under_Linux_for_MS_Windows) on the WxWidgets site.
Please contact `googletestframework@googlegroups.com` if you are interested in improving the support for MinGW.
Due to some peculiarity of C++, it requires some non-trivial template meta programming tricks to support using `NULL` as an argument of the `EXPECT_XX()` and `ASSERT_XX()` macros. Therefore we only do it where it's most needed (otherwise we make the implementation of Google Test harder to maintain and more error-prone than necessary).
The `EXPECT_EQ()` macro takes the _expected_ value as its first argument and the _actual_ value as the second. It's reasonable that someone wants to write `EXPECT_EQ(NULL, some_expression)`, and this indeed was requested several times. Therefore we implemented it.
The need for `EXPECT_NE(NULL, ptr)` isn't nearly as strong. When the assertion fails, you already know that `ptr` must be `NULL`, so it doesn't add any information to print ptr in this case. That means `EXPECT_TRUE(ptr != NULL)` works just as well.
If we were to support `EXPECT_NE(NULL, ptr)`, for consistency we'll have to support `EXPECT_NE(ptr, NULL)` as well, as unlike `EXPECT_EQ`, we don't have a convention on the order of the two arguments for `EXPECT_NE`. This means using the template meta programming tricks twice in the implementation, making it even harder to understand and maintain. We believe the benefit doesn't justify the cost.
Finally, with the growth of Google Mock's [matcher](../../CookBook.md#using-matchers-in-google-test-assertions) library, we are encouraging people to use the unified `EXPECT_THAT(value, matcher)` syntax more often in tests. One significant advantage of the matcher approach is that matchers can be easily combined to form new matchers, while the `EXPECT_NE`, etc, macros cannot be easily combined. Therefore we want to invest more in the matchers than in the `EXPECT_XX()` macros.
Test runners tend to be tightly coupled with the build/test environment, and Google Test doesn't try to solve the problem of running tests in parallel.  Instead, we tried to make Google Test work nicely with test runners.  For example, Google Test's XML report contains the time spent on each test, and its `gtest_list_tests` and `gtest_filter` flags can be used for splitting the execution of test methods into multiple processes.  These functionalities can help the test runner run the tests in parallel.
It's difficult to write thread-safe code.  Most tests are not written with thread-safety in mind, and thus may not work correctly in a multi-threaded setting.
If you think about it, it's already hard to make your code work when you know what other threads are doing.  It's much harder, and sometimes even impossible, to make your code work when you don't know what other threads are doing (remember that test methods can be added, deleted, or modified after your test was written).  If you want to run the tests in parallel, you'd better run them in different processes.
Our original motivation was to be able to use Google Test in projects that disable exceptions.  Later we realized some additional benefits of this approach:
1. Throwing in a destructor is undefined behavior in C++.  Not using exceptions means Google Test's assertions are safe to use in destructors.   1. The `EXPECT_*` family of macros will continue even after a failure, allowing multiple failures in a `TEST` to be reported in a single run. This is a popular feature, as in C++ the edit-compile-test cycle is usually quite long and being able to fixing more than one thing at a time is a blessing.   1. If assertions are implemented using exceptions, a test may falsely ignore a failure if it's caught by user code: ``` try { ... ASSERT_TRUE(...) ... } catch (...) { ... } ``` The above code will pass even if the `ASSERT_TRUE` throws.  While it's unlikely for someone to write this in a test, it's possible to run into this pattern when you write assertions in callbacks that are called by the code under test.
The downside of not using exceptions is that `ASSERT_*` (implemented using `return`) will only abort the current function, not the current `TEST`.
Unfortunately, C++'s macro system doesn't allow us to use the same macro for both cases.  One possibility is to provide only one macro for tests with fixtures, and require the user to define an empty fixture sometimes:
``` class FooTest : public ::testing::Test {};
TEST_F(FooTest, DoesThis) { ... } ``` or ``` typedef ::testing::Test FooTest;
TEST_F(FooTest, DoesThat) { ... } ```
Yet, many people think this is one line too many. :-) Our goal was to make it really easy to write tests, so we tried to make simple tests trivial to create.  That means using a separate macro for such tests.
We think neither approach is ideal, yet either of them is reasonable. In the end, it probably doesn't matter much either way.
We like to use structs only when representing passive data.  This distinction between structs and classes is good for documenting the intent of the code's author.  Since test fixtures have logic like `SetUp()` and `TearDown()`, they are better defined as classes.
Our goal was to make death tests as convenient for a user as C++ possibly allows.  In particular:
* The runner-style requires to split the information into two pieces: the definition of the death test itself, and the specification for the runner on how to run the death test and what to expect.  The death test would be written in C++, while the runner spec may or may not be.  A user needs to carefully keep the two in sync. `ASSERT_DEATH(statement, expected_message)` specifies all necessary information in one place, in one language, without boilerplate code. It is very declarative.   * `ASSERT_DEATH` has a similar syntax and error-reporting semantics as other Google Test assertions, and thus is easy to learn.   * `ASSERT_DEATH` can be mixed with other assertions and other logic at your will.  You are not limited to one death test per test method. For example, you can write something like: ```     if (FooCondition()) {       ASSERT_DEATH(Bar(), "blah");     } else {       ASSERT_EQ(5, Bar());     } ``` If you prefer one death test per test method, you can write your tests in that style too, but we don't want to impose that on the users.  The fewer artificial limitations the better.   * `ASSERT_DEATH` can reference local variables in the current function, and you can decide how many death tests you want based on run-time information.  For example, ```     const int count = GetCount();  // Only known at run time.     for (int i = 1; i <= count; i++) {       ASSERT_DEATH({         double* buffer = new double[i];         ... initializes buffer ...         Foo(buffer, i)       }, "blah blah");     } ``` The runner-based approach tends to be more static and less flexible, or requires more user effort to get this kind of flexibility.
Another interesting thing about `ASSERT_DEATH` is that it calls `fork()` to create a child process to run the death test.  This is lightening fast, as `fork()` uses copy-on-write pages and incurs almost zero overhead, and the child process starts from the user-supplied statement directly, skipping all global and local initialization and any code leading to the given statement.  If you launch the child process from scratch, it can take seconds just to load everything and start running if the test links to many libraries dynamically.
Death tests (`EXPECT_DEATH`, etc) are executed in a sub-process s.t. the expected crash won't kill the test program (i.e. the parent process). As a result, any in-memory side effects they incur are observable in their respective sub-processes, but not in the parent process. You can think of them as running in a parallel universe, more or less.
If your class has a static data member:
``` // foo.h class Foo {   ...   static const int kBar = 100; }; ```
You also need to define it _outside_ of the class body in `foo.cc`:
``` const int Foo::kBar;  // No initializer here. ```
Otherwise your code is **invalid C++**, and may break in unexpected ways. In particular, using it in Google Test comparison assertions (`EXPECT_EQ`, etc) will generate an "undefined reference" linker error.
Google Test doesn't yet have good support for this kind of tests, or data-driven tests in general. We hope to be able to make improvements in this area soon.
Yes.
Each test fixture has a corresponding and same named test case. This means only one test case can use a particular fixture. Sometimes, however, multiple test cases may want to use the same or slightly different fixtures. For example, you may want to make sure that all of a GUI library's test cases don't leak important system resources like fonts and brushes.
In Google Test, you share a fixture among test cases by putting the shared logic in a base test fixture, then deriving from that base a separate fixture for each test case that wants to use this common logic. You then use `TEST_F()` to write tests using each derived fixture.
Typically, your code looks like this:
``` // Defines a base test fixture. class BaseTest : public ::testing::Test {   protected:    ... };
// Derives a fixture FooTest from BaseTest. class FooTest : public BaseTest {   protected:     virtual void SetUp() {       BaseTest::SetUp();  // Sets up the base fixture first.       ... additional set-up work ...     }     virtual void TearDown() {       ... clean-up work for FooTest ...       BaseTest::TearDown();  // Remember to tear down the base fixture                              // after cleaning up FooTest!     }     ... functions and variables for FooTest ... };
// Tests that use the fixture FooTest. TEST_F(FooTest, Bar) { ... } TEST_F(FooTest, Baz) { ... }
... additional fixtures derived from BaseTest ... ```
If necessary, you can continue to derive test fixtures from a derived fixture. Google Test has no limit on how deep the hierarchy can be.
For a complete example using derived test fixtures, see [sample5](../samples/sample5_unittest.cc).
You're probably using an `ASSERT_*()` in a function that doesn't return `void`. `ASSERT_*()` can only be used in `void` functions.
In Google Test, death tests are run in a child process and the way they work is delicate. To write death tests you really need to understand how they work. Please make sure you have read this.
In particular, death tests don't like having multiple threads in the parent process. So the first thing you can try is to eliminate creating threads outside of `EXPECT_DEATH()`.
Sometimes this is impossible as some library you must use may be creating threads before `main()` is even reached. In this case, you can try to minimize the chance of conflicts by either moving as many activities as possible inside `EXPECT_DEATH()` (in the extreme case, you want to move everything inside), or leaving as few things as possible in it. Also, you can try to set the death test style to `"threadsafe"`, which is safer but slower, and see if it helps.
If you go with thread-safe death tests, remember that they rerun the test program from the beginning in the child process. Therefore make sure your program can run side-by-side with itself and is deterministic.
In the end, this boils down to good concurrent programming. You have to make sure that there is no race conditions or dead locks in your program. No silver bullet - sorry!
The first thing to remember is that Google Test does not reuse the same test fixture object across multiple tests. For each `TEST_F`, Google Test will create a fresh test fixture object, _immediately_ call `SetUp()`, run the test, call `TearDown()`, and then _immediately_ delete the test fixture object. Therefore, there is no need to write a `SetUp()` or `TearDown()` function if the constructor or destructor already does the job.
You may still want to use `SetUp()/TearDown()` in the following cases:   * If the tear-down operation could throw an exception, you must use `TearDown()` as opposed to the destructor, as throwing in a destructor leads to undefined behavior and usually will kill your program right away. Note that many standard libraries (like STL) may throw when exceptions are enabled in the compiler. Therefore you should prefer `TearDown()` if you want to write portable tests that work with or without exceptions.   * The assertion macros throw an exception when flag `--gtest_throw_on_failure` is specified. Therefore, you shouldn't use Google Test assertions in a destructor if you plan to run your tests with this flag.   * In a constructor or destructor, you cannot make a virtual function call on this object. (You can call a method declared as virtual, but it will be statically bound.) Therefore, if you need to call a method that will be overriden in a derived class, you have to use `SetUp()/TearDown()`.
If the predicate function you use in `ASSERT_PRED*` or `EXPECT_PRED*` is overloaded or a template, the compiler will have trouble figuring out which overloaded version it should use. `ASSERT_PRED_FORMAT*` and `EXPECT_PRED_FORMAT*` don't have this problem.
If you see this error, you might want to switch to `(ASSERT|EXPECT)_PRED_FORMAT*`, which will also give you a better failure message. If, however, that is not an option, you can resolve the problem by explicitly telling the compiler which version to pick.
For example, suppose you have
``` bool IsPositive(int n) {   return n > 0; } bool IsPositive(double x) {   return x > 0; } ```
you will get a compiler error if you write
``` EXPECT_PRED1(IsPositive, 5); ```
However, this will work:
``` EXPECT_PRED1(*static_cast<bool (*)(int)>*(IsPositive), 5); ```
(The stuff inside the angled brackets for the `static_cast` operator is the type of the function pointer for the `int`-version of `IsPositive()`.)
As another example, when you have a template function
``` template <typename T> bool IsNegative(T x) {   return x < 0; } ```
you can use it in a predicate assertion like this:
``` ASSERT_PRED1(IsNegative*<int>*, -5); ```
Things are more interesting if your template has more than one parameters. The following won't compile:
``` ASSERT_PRED2(*GreaterThan<int, int>*, 5, 0); ```
as the C++ pre-processor thinks you are giving `ASSERT_PRED2` 4 arguments, which is one more than expected. The workaround is to wrap the predicate function in parentheses:
``` ASSERT_PRED2(*(GreaterThan<int, int>)*, 5, 0); ```
Some people had been ignoring the return value of `RUN_ALL_TESTS()`. That is, instead of
``` return RUN_ALL_TESTS(); ```
they write
``` RUN_ALL_TESTS(); ```
This is wrong and dangerous. A test runner needs to see the return value of `RUN_ALL_TESTS()` in order to determine if a test has passed. If your `main()` function ignores it, your test will be considered successful even if it has a Google Test assertion failure. Very bad.
To help the users avoid this dangerous bug, the implementation of `RUN_ALL_TESTS()` causes gcc to raise this warning, when the return value is ignored. If you see this warning, the fix is simple: just make sure its value is used as the return value of `main()`.
Due to a peculiarity of C++, in order to support the syntax for streaming messages to an `ASSERT_*`, e.g.
``` ASSERT_EQ(1, Foo()) << "blah blah" << foo; ```
we had to give up using `ASSERT*` and `FAIL*` (but not `EXPECT*` and `ADD_FAILURE*`) in constructors and destructors. The workaround is to move the content of your constructor/destructor to a private void member function, or switch to `EXPECT_*()` if that works. This section in the user's guide explains it.
C++ is case-sensitive. It should be spelled as `SetUp()`.  Did you spell it as `Setup()`?
Similarly, sometimes people spell `SetUpTestCase()` as `SetupTestCase()` and wonder why it's never called.
Google Test's failure message format is understood by Emacs and many other IDEs, like acme and XCode. If a Google Test message is in a compilation buffer in Emacs, then it's clickable. You can now hit `enter` on a message to jump to the corresponding source code, or use `C-x `` to jump to the next failure.
You don't have to. Instead of
``` class FooTest : public BaseTest {};
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
class BarTest : public BaseTest {};
TEST_F(BarTest, Abc) { ... } TEST_F(BarTest, Def) { ... } ```
you can simply `typedef` the test fixtures: ``` typedef BaseTest FooTest;
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
typedef BaseTest BarTest;
TEST_F(BarTest, Abc) { ... } TEST_F(BarTest, Def) { ... } ```
The Google Test output is meant to be a concise and human-friendly report. If your test generates textual output itself, it will mix with the Google Test output, making it hard to read. However, there is an easy solution to this problem.
Since most log messages go to stderr, we decided to let Google Test output go to stdout. This way, you can easily separate the two using redirection. For example: ``` ./my_test > googletest_output.txt ```
There are several good reasons:   1. It's likely your test needs to change the states of its global variables. This makes it difficult to keep side effects from escaping one test and contaminating others, making debugging difficult. By using fixtures, each test has a fresh set of variables that's different (but with the same names). Thus, tests are kept independent of each other.   1. Global variables pollute the global namespace.   1. Test fixtures can be reused via subclassing, which cannot be done easily with global variables. This is useful if many test cases have something in common.
You should try to write testable code, which means classes should be easily tested from their public interface. One way to achieve this is the Pimpl idiom: you move all private members of a class into a helper class, and make all members of the helper class public.
You have several other options that don't require using `FRIEND_TEST`:   * Write the tests as members of the fixture class: ``` class Foo {   friend class FooTest;   ... };
class FooTest : public ::testing::Test {  protected:   ...   void Test1() {...} // This accesses private members of class Foo.   void Test2() {...} // So does this one. };
TEST_F(FooTest, Test1) {   Test1(); }
TEST_F(FooTest, Test2) {   Test2(); } ```   * In the fixture class, write accessors for the tested class' private members, then use the accessors in your tests: ``` class Foo {   friend class FooTest;   ... };
class FooTest : public ::testing::Test {  protected:   ...   T1 get_private_member1(Foo* obj) {     return obj->private_member1_;   } };
TEST_F(FooTest, Test1) {   ...   get_private_member1(x)   ... } ```   * If the methods are declared **protected**, you can change their access level in a test-only subclass: ``` class YourClass {   ...  protected: // protected access for testability.   int DoSomethingReturningInt();   ... };
// in the your_class_test.cc file: class TestableYourClass : public YourClass {   ...  public: using YourClass::DoSomethingReturningInt; // changes access rights   ... };
TEST_F(YourClassTest, DoSomethingTest) {   TestableYourClass obj;   assertEquals(expected_value, obj.DoSomethingReturningInt()); } ```
We find private static methods clutter the header file.  They are implementation details and ideally should be kept out of a .h. So often I make them free functions instead.
Instead of: ``` // foo.h class Foo {   ...  private:   static bool Func(int n); };
// foo.cc bool Foo::Func(int n) { ... }
// foo_test.cc EXPECT_TRUE(Foo::Func(12345)); ```
You probably should better write: ``` // foo.h class Foo {   ... };
// foo.cc namespace internal {   bool Func(int n) { ... } }
// foo_test.cc namespace internal {   bool Func(int n); }
EXPECT_TRUE(internal::Func(12345)); ```
No. You can use a feature called [value-parameterized tests](V1_7_AdvancedGuide.md#Value_Parameterized_Tests) which lets you repeat your tests with different parameters, without defining it more than once.
To test a `foo.cc` file, you need to compile and link it into your unit test program. However, when the file contains a definition for the `main()` function, it will clash with the `main()` of your unit test, and will result in a build error.
The right solution is to split it into three files:   1. `foo.h` which contains the declarations,   1. `foo.cc` which contains the definitions except `main()`, and   1. `foo_main.cc` which contains nothing but the definition of `main()`.
Then `foo.cc` can be easily tested.
If you are adding tests to an existing file and don't want an intrusive change like this, there is a hack: just include the entire `foo.cc` file in your unit test. For example: ``` // File foo_unittest.cc
// The headers section ...
// Renames main() in foo.cc to make room for the unit test main() #define main FooMain
#include "a/b/foo.cc"
// The tests start here. ... ```
However, please remember this is a hack and should only be used as the last resort.
`ASSERT_DEATH(_statement_, _regex_)` (or any death assertion macro) can be used wherever `_statement_` is valid. So basically `_statement_` can be any C++ statement that makes sense in the current context. In particular, it can reference global and/or local variables, and can be:   * a simple function call (often the case),   * a complex expression, or   * a compound statement.
> Some examples are shown here:
``` // A death test can be a simple function call. TEST(MyDeathTest, FunctionCall) {   ASSERT_DEATH(Xyz(5), "Xyz failed"); }
// Or a complex expression that references variables and functions. TEST(MyDeathTest, ComplexExpression) {   const bool c = Condition();   ASSERT_DEATH((c ? Func1(0) : object2.Method("test")),                "(Func1|Method) failed"); }
// Death assertions can be used any where in a function. In // particular, they can be inside a loop. TEST(MyDeathTest, InsideLoop) {   // Verifies that Foo(0), Foo(1), ..., and Foo(4) all die.   for (int i = 0; i < 5; i++) {     EXPECT_DEATH_M(Foo(i), "Foo has \\d+ errors",                    ::testing::Message() << "where i is " << i);   } }
// A death assertion can contain a compound statement. TEST(MyDeathTest, CompoundStatement) {   // Verifies that at lease one of Bar(0), Bar(1), ..., and   // Bar(4) dies.   ASSERT_DEATH({     for (int i = 0; i < 5; i++) {       Bar(i);     }   },   "Bar has \\d+ errors");} ```
`googletest_unittest.cc` contains more examples if you are interested.
On POSIX systems, Google Test uses the POSIX Extended regular expression syntax (http://en.wikipedia.org/wiki/Regular_expression#POSIX_Extended_Regular_Expressions). On Windows, it uses a limited variant of regular expression syntax. For more details, see the [regular expression syntax](V1_7_AdvancedGuide.md#Regular_Expression_Syntax).
Google Test needs to be able to create objects of your test fixture class, so it must have a default constructor. Normally the compiler will define one for you. However, there are cases where you have to define your own:   * If you explicitly declare a non-default constructor for class `Foo`, then you need to define a default constructor, even if it would be empty.   * If `Foo` has a const non-static data member, then you have to define the default constructor _and_ initialize the const member in the initializer list of the constructor. (Early versions of `gcc` doesn't force you to initialize the const member. It's a bug that has been fixed in `gcc 4`.)
With the Linux pthread library, there is no turning back once you cross the line from single thread to multiple threads. The first time you create a thread, a manager thread is created in addition, so you get 3, not 2, threads. Later when the thread you create joins the main thread, the thread count decrements by 1, but the manager thread will never be killed, so you still have 2 threads, which means you cannot safely run a death test.
The new NPTL thread library doesn't suffer from this problem, as it doesn't create a manager thread. However, if you don't control which machine your test runs on, you shouldn't depend on this.
Google Test does not interleave tests from different test cases. That is, it runs all tests in one test case first, and then runs all tests in the next test case, and so on. Google Test does this because it needs to set up a test case before the first test in it is run, and tear it down afterwords. Splitting up the test case would require multiple set-up and tear-down processes, which is inefficient and makes the semantics unclean.
If we were to determine the order of tests based on test name instead of test case name, then we would have a problem with the following situation:
``` TEST_F(FooTest, AbcDeathTest) { ... } TEST_F(FooTest, Uvw) { ... }
TEST_F(BarTest, DefDeathTest) { ... } TEST_F(BarTest, Xyz) { ... } ```
Since `FooTest.AbcDeathTest` needs to run before `BarTest.Xyz`, and we don't interleave tests from different test cases, we need to run all tests in the `FooTest` case before running any test in the `BarTest` case. This contradicts with the requirement to run `BarTest.DefDeathTest` before `FooTest.Uvw`.
You don't have to, but if you like, you may split up the test case into `FooTest` and `FooDeathTest`, where the names make it clear that they are related:
``` class FooTest : public ::testing::Test { ... };
TEST_F(FooTest, Abc) { ... } TEST_F(FooTest, Def) { ... }
typedef FooTest FooDeathTest;
TEST_F(FooDeathTest, Uvw) { ... EXPECT_DEATH(...) ... } TEST_F(FooDeathTest, Xyz) { ... ASSERT_DEATH(...) ... } ```
If you use a user-defined type `FooType` in an assertion, you must make sure there is an `std::ostream& operator<<(std::ostream&, const FooType&)` function defined such that we can print a value of `FooType`.
In addition, if `FooType` is declared in a name space, the `<<` operator also needs to be defined in the _same_ name space.
Since the statically initialized Google Test singleton requires allocations on the heap, the Visual C++ memory leak detector will report memory leaks at the end of the program run. The easiest way to avoid this is to use the `_CrtMemCheckpoint` and `_CrtMemDumpAllObjectsSince` calls to not report any statically initialized heap objects. See MSDN for more details and additional heap check/debug routines.
You may get a number of the following linker error or warnings if you attempt to link your test project with the Google Test library when your project and the are not built using the same compiler settings.
* LNK2005: symbol already defined in object   * LNK4217: locally defined symbol 'symbol' imported in function 'function'   * LNK4049: locally defined symbol 'symbol' imported
The Google Test project (gtest.vcproj) has the Runtime Library option set to /MT (use multi-threaded static libraries, /MTd for debug). If your project uses something else, for example /MD (use multi-threaded DLLs, /MDd for debug), you need to change the setting in the Google Test project to match your project's.
To update this setting open the project properties in the Visual Studio IDE then select the branch Configuration Properties | C/C++ | Code Generation and change the option "Runtime Library".  You may also try using gtest-md.vcproj instead of gtest.vcproj.
`export CC=cc CXX=CC CXXFLAGS='-library=stlport4'`
If you write code that sniffs whether it's running in a test and does different things accordingly, you are leaking test-only logic into production code and there is no easy way to ensure that the test-only code paths aren't run by mistake in production.  Such cleverness also leads to [Heisenbugs](http://en.wikipedia.org/wiki/Unusual_software_bug#Heisenbug). Therefore we strongly advise against the practice, and Google Test doesn't provide a way to do it.
In general, the recommended way to cause the code to behave differently under test is [dependency injection](http://jamesshore.com/Blog/Dependency-Injection-Demystified.html). You can inject different functionality from the test and from the production code.  Since your production code doesn't link in the for-test logic at all, there is no danger in accidentally running it.
However, if you _really_, _really_, _really_ have no choice, and if you follow the rule of ending your test program names with `_test`, you can use the _horrible_ hack of sniffing your executable name (`argv[0]` in `main()`) to know whether the code is under test.
In C++, macros don't obey namespaces.  Therefore two libraries that both define a macro of the same name will clash if you `#include` both definitions.  In case a Google Test macro clashes with another library, you can force Google Test to rename its macro to avoid the conflict.
Specifically, if both Google Test and some other code define macro `FOO`, you can add ```   -DGTEST_DONT_DEFINE_FOO=1 ``` to the compiler flags to tell Google Test to change the macro's name from `FOO` to `GTEST_FOO`. For example, with `-DGTEST_DONT_DEFINE_TEST=1`, you'll need to write ```   GTEST_TEST(SomeTest, DoesThis) { ... } ``` instead of ```   TEST(SomeTest, DoesThis) { ... } ``` in order to define a test.
Currently, the following `TEST`, `FAIL`, `SUCCEED`, and the basic comparison assertion macros can have alternative names. You can see the full list of covered macros [here](http://www.google.com/codesearch?q=if+!GTEST_DONT_DEFINE_\w%2B+package:http://googletest\.googlecode\.com+file:/include/gtest/gtest.h). More information can be found in the "Avoiding Macro Name Clashes" section of the README file.
Yes.
The rule is **all test methods in the same test case must use the same fixture class**. This means that the following is **allowed** because both tests use the same fixture class (`::testing::Test`).
``` namespace foo { TEST(CoolTest, DoSomething) {   SUCCEED(); } }  // namespace foo
namespace bar { TEST(CoolTest, DoSomething) {   SUCCEED(); } }  // namespace foo ```
However, the following code is **not allowed** and will produce a runtime error from Google Test because the test methods are using different test fixture classes with the same test case name.
``` namespace foo { class CoolTest : public ::testing::Test {};  // Fixture foo::CoolTest TEST_F(CoolTest, DoSomething) {   SUCCEED(); } }  // namespace foo
namespace bar { class CoolTest : public ::testing::Test {};  // Fixture: bar::CoolTest TEST_F(CoolTest, DoSomething) {   SUCCEED(); } }  // namespace foo ```
If you try to build Google Test's Xcode project with Xcode 4.0 or later, you may encounter an error message that looks like "Missing SDK in target gtest\_framework: /Developer/SDKs/MacOSX10.4u.sdk". That means that Xcode does not support the SDK the project is targeting. See the Xcode section in the [README](../../README.MD) file on how to resolve this.
If you cannot find the answer to your question in this FAQ, there are some other resources you can use:
1. read other [wiki pages](http://code.google.com/p/googletest/w/list),   1. search the mailing list [archive](http://groups.google.com/group/googletestframework/topics),   1. ask it on [googletestframework@googlegroups.com](mailto:googletestframework@googlegroups.com) and someone will answer it (to prevent spam, we require you to join the [discussion group](http://groups.google.com/group/googletestframework) before you can post.).
Please note that creating an issue in the [issue tracker](http://code.google.com/p/googletest/issues/list) is _not_ a good way to get your answer, as it is monitored infrequently by a very small number of people.
When asking a question, it's helpful to provide as much of the following information as possible (people cannot help you if there's not enough information in your question):
* the version (or the revision number if you check out from SVN directly) of Google Test you use (Google Test is under active development, so it's possible that your problem has been solved in a later version),   * your operating system,   * the name and version of your compiler,   * the complete command line flags you give to your compiler,   * the complete compiler error messages (if the question is about compilation),   * the _actual_ code (ideally, a minimal but complete program) that has the problem you encounter.

_Google C++ Testing Framework_ helps you write better C++ tests.
No matter whether you work on Linux, Windows, or a Mac, if you write C++ code, Google Test can help you.
So what makes a good test, and how does Google C++ Testing Framework fit in? We believe:   1. Tests should be _independent_ and _repeatable_. It's a pain to debug a test that succeeds or fails as a result of other tests.  Google C++ Testing Framework isolates the tests by running each of them on a different object. When a test fails, Google C++ Testing Framework allows you to run it in isolation for quick debugging.   1. Tests should be well _organized_ and reflect the structure of the tested code.  Google C++ Testing Framework groups related tests into test cases that can share data and subroutines. This common pattern is easy to recognize and makes tests easy to maintain. Such consistency is especially helpful when people switch projects and start to work on a new code base.   1. Tests should be _portable_ and _reusable_. The open-source community has a lot of code that is platform-neutral, its tests should also be platform-neutral.  Google C++ Testing Framework works on different OSes, with different compilers (gcc, MSVC, and others), with or without exceptions, so Google C++ Testing Framework tests can easily work with a variety of configurations.  (Note that the current release only contains build scripts for Linux - we are actively working on scripts for other platforms.)   1. When tests fail, they should provide as much _information_ about the problem as possible. Google C++ Testing Framework doesn't stop at the first test failure. Instead, it only stops the current test and continues with the next. You can also set up tests that report non-fatal failures after which the current test continues. Thus, you can detect and fix multiple bugs in a single run-edit-compile cycle.   1. The testing framework should liberate test writers from housekeeping chores and let them focus on the test _content_.  Google C++ Testing Framework automatically keeps track of all tests defined, and doesn't require the user to enumerate them in order to run them.   1. Tests should be _fast_. With Google C++ Testing Framework, you can reuse shared resources across tests and pay for the set-up/tear-down only once, without making tests depend on each other.
Since Google C++ Testing Framework is based on the popular xUnit architecture, you'll feel right at home if you've used JUnit or PyUnit before. If not, it will take you about 10 minutes to learn the basics and get started. So let's go!
_Note:_ We sometimes refer to Google C++ Testing Framework informally as _Google Test_.
To write a test program using Google Test, you need to compile Google Test into a library and link your test with it.  We provide build files for some popular build systems: `msvc/` for Visual Studio, `xcode/` for Mac Xcode, `make/` for GNU make, `codegear/` for Borland C++ Builder, and the autotools script (deprecated) and `CMakeLists.txt` for CMake (recommended) in the Google Test root directory.  If your build system is not on this list, you can take a look at `make/Makefile` to learn how Google Test should be compiled (basically you want to compile `src/gtest-all.cc` with `GTEST_ROOT` and `GTEST_ROOT/include` in the header search path, where `GTEST_ROOT` is the Google Test root directory).
Once you are able to compile the Google Test library, you should create a project or build target for your test program.  Make sure you have `GTEST_ROOT/include` in the header search path so that the compiler can find `"gtest/gtest.h"` when compiling your test.  Set up your test project to link with the Google Test library (for example, in Visual Studio, this is done by adding a dependency on `gtest.vcproj`).
If you still have questions, take a look at how Google Test's own tests are built and use them as examples.
When using Google Test, you start by writing _assertions_, which are statements that check whether a condition is true. An assertion's result can be _success_, _nonfatal failure_, or _fatal failure_. If a fatal failure occurs, it aborts the current function; otherwise the program continues normally.
_Tests_ use assertions to verify the tested code's behavior. If a test crashes or has a failed assertion, then it _fails_; otherwise it _succeeds_.
A _test case_ contains one or many tests. You should group your tests into test cases that reflect the structure of the tested code. When multiple tests in a test case need to share common objects and subroutines, you can put them into a _test fixture_ class.
A _test program_ can contain multiple test cases.
We'll now explain how to write a test program, starting at the individual assertion level and building up to tests and test cases.
Google Test assertions are macros that resemble function calls. You test a class or function by making assertions about its behavior. When an assertion fails, Google Test prints the assertion's source file and line number location, along with a failure message. You may also supply a custom failure message which will be appended to Google Test's message.
The assertions come in pairs that test the same thing but have different effects on the current function. `ASSERT_*` versions generate fatal failures when they fail, and **abort the current function**. `EXPECT_*` versions generate nonfatal failures, which don't abort the current function. Usually `EXPECT_*` are preferred, as they allow more than one failures to be reported in a test. However, you should use `ASSERT_*` if it doesn't make sense to continue when the assertion in question fails.
Since a failed `ASSERT_*` returns from the current function immediately, possibly skipping clean-up code that comes after it, it may cause a space leak. Depending on the nature of the leak, it may or may not be worth fixing - so keep this in mind if you get a heap checker error in addition to assertion errors.
To provide a custom failure message, simply stream it into the macro using the `<<` operator, or a sequence of such operators. An example: ``` ASSERT_EQ(x.size(), y.size()) << "Vectors x and y are of unequal length";
for (int i = 0; i < x.size(); ++i) {   EXPECT_EQ(x[i], y[i]) << "Vectors x and y differ at index " << i; } ```
Anything that can be streamed to an `ostream` can be streamed to an assertion macro--in particular, C strings and `string` objects. If a wide string (`wchar_t*`, `TCHAR*` in `UNICODE` mode on Windows, or `std::wstring`) is streamed to an assertion, it will be translated to UTF-8 when printed.
These assertions do basic true/false condition testing. | **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_TRUE(`_condition_`)`;  | `EXPECT_TRUE(`_condition_`)`;   | _condition_ is true | | `ASSERT_FALSE(`_condition_`)`; | `EXPECT_FALSE(`_condition_`)`;  | _condition_ is false |
Remember, when they fail, `ASSERT_*` yields a fatal failure and returns from the current function, while `EXPECT_*` yields a nonfatal failure, allowing the function to continue running. In either case, an assertion failure means its containing test fails.
_Availability_: Linux, Windows, Mac.
This section describes assertions that compare two values.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| |`ASSERT_EQ(`_expected_`, `_actual_`);`|`EXPECT_EQ(`_expected_`, `_actual_`);`| _expected_ `==` _actual_ | |`ASSERT_NE(`_val1_`, `_val2_`);`      |`EXPECT_NE(`_val1_`, `_val2_`);`      | _val1_ `!=` _val2_ | |`ASSERT_LT(`_val1_`, `_val2_`);`      |`EXPECT_LT(`_val1_`, `_val2_`);`      | _val1_ `<` _val2_ | |`ASSERT_LE(`_val1_`, `_val2_`);`      |`EXPECT_LE(`_val1_`, `_val2_`);`      | _val1_ `<=` _val2_ | |`ASSERT_GT(`_val1_`, `_val2_`);`      |`EXPECT_GT(`_val1_`, `_val2_`);`      | _val1_ `>` _val2_ | |`ASSERT_GE(`_val1_`, `_val2_`);`      |`EXPECT_GE(`_val1_`, `_val2_`);`      | _val1_ `>=` _val2_ |
In the event of a failure, Google Test prints both _val1_ and _val2_ . In `ASSERT_EQ*` and `EXPECT_EQ*` (and all other equality assertions we'll introduce later), you should put the expression you want to test in the position of _actual_, and put its expected value in _expected_, as Google Test's failure messages are optimized for this convention.
Value arguments must be comparable by the assertion's comparison operator or you'll get a compiler error.  We used to require the arguments to support the `<<` operator for streaming to an `ostream`, but it's no longer necessary since v1.6.0 (if `<<` is supported, it will be called to print the arguments when the assertion fails; otherwise Google Test will attempt to print them in the best way it can. For more details and how to customize the printing of the arguments, see this Google Mock [recipe](../../googlemock/docs/CookBook.md#teaching-google-mock-how-to-print-your-values).).
These assertions can work with a user-defined type, but only if you define the corresponding comparison operator (e.g. `==`, `<`, etc).  If the corresponding operator is defined, prefer using the `ASSERT_*()` macros because they will print out not only the result of the comparison, but the two operands as well.
Arguments are always evaluated exactly once. Therefore, it's OK for the arguments to have side effects. However, as with any ordinary C/C++ function, the arguments' evaluation order is undefined (i.e. the compiler is free to choose any order) and your code should not depend on any particular argument evaluation order.
`ASSERT_EQ()` does pointer equality on pointers. If used on two C strings, it tests if they are in the same memory location, not if they have the same value. Therefore, if you want to compare C strings (e.g. `const char*`) by value, use `ASSERT_STREQ()` , which will be described later on. In particular, to assert that a C string is `NULL`, use `ASSERT_STREQ(NULL, c_string)` . However, to compare two `string` objects, you should use `ASSERT_EQ`.
Macros in this section work with both narrow and wide string objects (`string` and `wstring`).
_Availability_: Linux, Windows, Mac.
The assertions in this group compare two **C strings**. If you want to compare two `string` objects, use `EXPECT_EQ`, `EXPECT_NE`, and etc instead.
| **Fatal assertion** | **Nonfatal assertion** | **Verifies** | |:--------------------|:-----------------------|:-------------| | `ASSERT_STREQ(`_expected\_str_`, `_actual\_str_`);`    | `EXPECT_STREQ(`_expected\_str_`, `_actual\_str_`);`     | the two C strings have the same content | | `ASSERT_STRNE(`_str1_`, `_str2_`);`    | `EXPECT_STRNE(`_str1_`, `_str2_`);`     | the two C strings have different content | | `ASSERT_STRCASEEQ(`_expected\_str_`, `_actual\_str_`);`| `EXPECT_STRCASEEQ(`_expected\_str_`, `_actual\_str_`);` | the two C strings have the same content, ignoring case | | `ASSERT_STRCASENE(`_str1_`, `_str2_`);`| `EXPECT_STRCASENE(`_str1_`, `_str2_`);` | the two C strings have different content, ignoring case |
Note that "CASE" in an assertion name means that case is ignored.
`*STREQ*` and `*STRNE*` also accept wide C strings (`wchar_t*`). If a comparison of two wide strings fails, their values will be printed as UTF-8 narrow strings.
A `NULL` pointer and an empty string are considered _different_.
_Availability_: Linux, Windows, Mac.
See also: For more string comparison tricks (substring, prefix, suffix, and regular expression matching, for example), see the [Advanced Google Test Guide](V1_7_AdvancedGuide.md).
To create a test:   1. Use the `TEST()` macro to define and name a test function, These are ordinary C++ functions that don't return a value.   1. In this function, along with any valid C++ statements you want to include, use the various Google Test assertions to check values.   1. The test's result is determined by the assertions; if any assertion in the test fails (either fatally or non-fatally), or if the test crashes, the entire test fails. Otherwise, it succeeds.
``` TEST(test_case_name, test_name) {  ... test body ... } ```
`TEST()` arguments go from general to specific. The _first_ argument is the name of the test case, and the _second_ argument is the test's name within the test case. Both names must be valid C++ identifiers, and they should not contain underscore (`_`). A test's _full name_ consists of its containing test case and its individual name. Tests from different test cases can have the same individual name.
For example, let's take a simple integer function: ``` int Factorial(int n); // Returns the factorial of n ```
A test case for this function might look like: ``` // Tests factorial of 0. TEST(FactorialTest, HandlesZeroInput) {   EXPECT_EQ(1, Factorial(0)); }
// Tests factorial of positive numbers. TEST(FactorialTest, HandlesPositiveInput) {   EXPECT_EQ(1, Factorial(1));   EXPECT_EQ(2, Factorial(2));   EXPECT_EQ(6, Factorial(3));   EXPECT_EQ(40320, Factorial(8)); } ```
Google Test groups the test results by test cases, so logically-related tests should be in the same test case; in other words, the first argument to their `TEST()` should be the same. In the above example, we have two tests, `HandlesZeroInput` and `HandlesPositiveInput`, that belong to the same test case `FactorialTest`.
_Availability_: Linux, Windows, Mac.
If you find yourself writing two or more tests that operate on similar data, you can use a _test fixture_. It allows you to reuse the same configuration of objects for several different tests.
To create a fixture, just:   1. Derive a class from `::testing::Test` . Start its body with `protected:` or `public:` as we'll want to access fixture members from sub-classes.   1. Inside the class, declare any objects you plan to use.   1. If necessary, write a default constructor or `SetUp()` function to prepare the objects for each test. A common mistake is to spell `SetUp()` as `Setup()` with a small `u` - don't let that happen to you.   1. If necessary, write a destructor or `TearDown()` function to release any resources you allocated in `SetUp()` . To learn when you should use the constructor/destructor and when you should use `SetUp()/TearDown()`, read this [FAQ entry](V1_7_FAQ.md#should-i-use-the-constructordestructor-of-the-test-fixture-or-the-set-uptear-down-function).   1. If needed, define subroutines for your tests to share.
When using a fixture, use `TEST_F()` instead of `TEST()` as it allows you to access objects and subroutines in the test fixture: ``` TEST_F(test_case_name, test_name) {  ... test body ... } ```
Like `TEST()`, the first argument is the test case name, but for `TEST_F()` this must be the name of the test fixture class. You've probably guessed: `_F` is for fixture.
Unfortunately, the C++ macro system does not allow us to create a single macro that can handle both types of tests. Using the wrong macro causes a compiler error.
Also, you must first define a test fixture class before using it in a `TEST_F()`, or you'll get the compiler error "`virtual outside class declaration`".
For each test defined with `TEST_F()`, Google Test will:   1. Create a _fresh_ test fixture at runtime   1. Immediately initialize it via `SetUp()` ,   1. Run the test   1. Clean up by calling `TearDown()`   1. Delete the test fixture.  Note that different tests in the same test case have different test fixture objects, and Google Test always deletes a test fixture before it creates the next one. Google Test does not reuse the same test fixture for multiple tests. Any changes one test makes to the fixture do not affect other tests.
As an example, let's write tests for a FIFO queue class named `Queue`, which has the following interface: ``` template <typename E> // E is the element type. class Queue {  public:   Queue();   void Enqueue(const E& element);   E* Dequeue(); // Returns NULL if the queue is empty.   size_t size() const;   ... }; ```
First, define a fixture class. By convention, you should give it the name `FooTest` where `Foo` is the class being tested. ``` class QueueTest : public ::testing::Test {  protected:   virtual void SetUp() {     q1_.Enqueue(1);     q2_.Enqueue(2);     q2_.Enqueue(3);   }
// virtual void TearDown() {}
Queue<int> q0_;   Queue<int> q1_;   Queue<int> q2_; }; ```
In this case, `TearDown()` is not needed since we don't have to clean up after each test, other than what's already done by the destructor.
Now we'll write tests using `TEST_F()` and this fixture. ``` TEST_F(QueueTest, IsEmptyInitially) {   EXPECT_EQ(0, q0_.size()); }
TEST_F(QueueTest, DequeueWorks) {   int* n = q0_.Dequeue();   EXPECT_EQ(NULL, n);
n = q1_.Dequeue();   ASSERT_TRUE(n != NULL);   EXPECT_EQ(1, *n);   EXPECT_EQ(0, q1_.size());   delete n;
n = q2_.Dequeue();   ASSERT_TRUE(n != NULL);   EXPECT_EQ(2, *n);   EXPECT_EQ(1, q2_.size());   delete n; } ```
The above uses both `ASSERT_*` and `EXPECT_*` assertions. The rule of thumb is to use `EXPECT_*` when you want the test to continue to reveal more errors after the assertion failure, and use `ASSERT_*` when continuing after failure doesn't make sense. For example, the second assertion in the `Dequeue` test is `ASSERT_TRUE(n != NULL)`, as we need to dereference the pointer `n` later, which would lead to a segfault when `n` is `NULL`.
When these tests run, the following happens:   1. Google Test constructs a `QueueTest` object (let's call it `t1` ).   1. `t1.SetUp()` initializes `t1` .   1. The first test ( `IsEmptyInitially` ) runs on `t1` .   1. `t1.TearDown()` cleans up after the test finishes.   1. `t1` is destructed.   1. The above steps are repeated on another `QueueTest` object, this time running the `DequeueWorks` test.
_Availability_: Linux, Windows, Mac.
_Note_: Google Test automatically saves all _Google Test_ flags when a test object is constructed, and restores them when it is destructed.
`TEST()` and `TEST_F()` implicitly register their tests with Google Test. So, unlike with many other C++ testing frameworks, you don't have to re-list all your defined tests in order to run them.
After defining your tests, you can run them with `RUN_ALL_TESTS()` , which returns `0` if all the tests are successful, or `1` otherwise. Note that `RUN_ALL_TESTS()` runs _all tests_ in your link unit -- they can be from different test cases, or even different source files.
When invoked, the `RUN_ALL_TESTS()` macro:   1. Saves the state of all  Google Test flags.   1. Creates a test fixture object for the first test.   1. Initializes it via `SetUp()`.   1. Runs the test on the fixture object.   1. Cleans up the fixture via `TearDown()`.   1. Deletes the fixture.   1. Restores the state of all Google Test flags.   1. Repeats the above steps for the next test, until all tests have run.
In addition, if the text fixture's constructor generates a fatal failure in step 2, there is no point for step 3 - 5 and they are thus skipped. Similarly, if step 3 generates a fatal failure, step 4 will be skipped.
_Important_: You must not ignore the return value of `RUN_ALL_TESTS()`, or `gcc` will give you a compiler error. The rationale for this design is that the automated testing service determines whether a test has passed based on its exit code, not on its stdout/stderr output; thus your `main()` function must return the value of `RUN_ALL_TESTS()`.
Also, you should call `RUN_ALL_TESTS()` only **once**. Calling it more than once conflicts with some advanced Google Test features (e.g. thread-safe death tests) and thus is not supported.
_Availability_: Linux, Windows, Mac.
You can start from this boilerplate: ``` #include "this/package/foo.h" #include "gtest/gtest.h"
namespace {
// The fixture for testing class Foo. class FooTest : public ::testing::Test {  protected:   // You can remove any or all of the following functions if its body   // is empty.
FooTest() {     // You can do set-up work for each test here.   }
virtual ~FooTest() {     // You can do clean-up work that doesn't throw exceptions here.   }
// If the constructor and destructor are not enough for setting up   // and cleaning up each test, you can define the following methods:
virtual void SetUp() {     // Code here will be called immediately after the constructor (right     // before each test).   }
virtual void TearDown() {     // Code here will be called immediately after each test (right     // before the destructor).   }
// Objects declared here can be used by all tests in the test case for Foo. };
// Tests that the Foo::Bar() method does Abc. TEST_F(FooTest, MethodBarDoesAbc) {   const string input_filepath = "this/package/testdata/myinputfile.dat";   const string output_filepath = "this/package/testdata/myoutputfile.dat";   Foo f;   EXPECT_EQ(0, f.Bar(input_filepath, output_filepath)); }
// Tests that Foo does Xyz. TEST_F(FooTest, DoesXyz) {   // Exercises the Xyz feature of Foo. }
}  // namespace
int main(int argc, char **argv) {   ::testing::InitGoogleTest(&argc, argv);   return RUN_ALL_TESTS(); } ```
The `::testing::InitGoogleTest()` function parses the command line for Google Test flags, and removes all recognized flags. This allows the user to control a test program's behavior via various flags, which we'll cover in [AdvancedGuide](V1_7_AdvancedGuide.md). You must call this function before calling `RUN_ALL_TESTS()`, or the flags won't be properly initialized.
On Windows, `InitGoogleTest()` also works with wide strings, so it can be used in programs compiled in `UNICODE` mode as well.
But maybe you think that writing all those main() functions is too much work? We agree with you completely and that's why Google Test provides a basic implementation of main(). If it fits your needs, then just link your test with gtest\_main library and you are good to go.
In addition, if you define your tests in a static library, add `/OPT:NOREF` to your main program linker options. If you use MSVC++ IDE, go to your .exe project properties/Configuration Properties/Linker/Optimization and set References setting to `Keep Unreferenced Data (/OPT:NOREF)`. This will keep Visual C++ linker from discarding individual symbols generated by your tests from the final executable.
There is one more pitfall, though. If you use Google Test as a static library (that's how it is defined in gtest.vcproj) your tests must also reside in a static library. If you have to have them in a DLL, you _must_ change Google Test to build into a DLL as well. Otherwise your tests will not run correctly or will not run at all. The general conclusion here is: make your life easier - do not write your tests in libraries!
Congratulations! You've learned the Google Test basics. You can start writing and running Google Test tests, read some [samples](V1_7_Samples.md), or continue with [AdvancedGuide](V1_7_AdvancedGuide.md), which describes many more useful Google Test features.
Google Test is designed to be thread-safe.  The implementation is thread-safe on systems where the `pthreads` library is available.  It is currently _unsafe_ to use Google Test assertions from two threads concurrently on other systems (e.g. Windows).  In most tests this is not an issue as usually the assertions are done in the main thread. If you want to help, you can volunteer to implement the necessary synchronization primitives in `gtest-port.h` for your platform.

<b>P</b>ump is <b>U</b>seful for <b>M</b>eta <b>P</b>rogramming.
Template and macro libraries often need to define many classes, functions, or macros that vary only (or almost only) in the number of arguments they take. It's a lot of repetitive, mechanical, and error-prone work.
Variadic templates and variadic macros can alleviate the problem. However, while both are being considered by the C++ committee, neither is in the standard yet or widely supported by compilers.  Thus they are often not a good choice, especially when your code needs to be portable. And their capabilities are still limited.
As a result, authors of such libraries often have to write scripts to generate their implementation. However, our experience is that it's tedious to write such scripts, which tend to reflect the structure of the generated code poorly and are often hard to read and edit. For example, a small change needed in the generated code may require some non-intuitive, non-trivial changes in the script. This is especially painful when experimenting with the code.
Pump (for Pump is Useful for Meta Programming, Pretty Useful for Meta Programming, or Practical Utility for Meta Programming, whichever you prefer) is a simple meta-programming tool for C++. The idea is that a programmer writes a `foo.pump` file which contains C++ code plus meta code that manipulates the C++ code. The meta code can handle iterations over a range, nested iterations, local meta variable definitions, simple arithmetic, and conditional expressions. You can view it as a small Domain-Specific Language. The meta language is designed to be non-intrusive (s.t. it won't confuse Emacs' C++ mode, for example) and concise, making Pump code intuitive and easy to maintain.
* The implementation is in a single Python script and thus ultra portable: no build or installation is needed and it works cross platforms.   * Pump tries to be smart with respect to [Google's style guide](http://code.google.com/p/google-styleguide/): it breaks long lines (easy to have when they are generated) at acceptable places to fit within 80 columns and indent the continuation lines correctly.   * The format is human-readable and more concise than XML.   * The format works relatively well with Emacs' C++ mode.
The following Pump code (where meta keywords start with `$`, `[[` and `]]` are meta brackets, and `$$` starts a meta comment that ends with the line):
``` $var n = 3     $$ Defines a meta variable n. $range i 0..n  $$ Declares the range of meta iterator i (inclusive). $for i [[                $$ Meta loop. // Foo$i does blah for $i-ary predicates. $range j 1..i template <size_t N $for j [[, typename A$j]]> class Foo$i { $if i == 0 [[   blah a; ]] $elif i <= 2 [[   blah b; ]] $else [[   blah c; ]] };
]] ```
will be translated by the Pump compiler to:
``` // Foo0 does blah for 0-ary predicates. template <size_t N> class Foo0 {   blah a; };
// Foo1 does blah for 1-ary predicates. template <size_t N, typename A1> class Foo1 {   blah b; };
// Foo2 does blah for 2-ary predicates. template <size_t N, typename A1, typename A2> class Foo2 {   blah b; };
// Foo3 does blah for 3-ary predicates. template <size_t N, typename A1, typename A2, typename A3> class Foo3 {   blah c; }; ```
In another example,
``` $range i 1..n Func($for i + [[a$i]]); $$ The text between i and [[ is the separator between iterations. ```
will generate one of the following lines (without the comments), depending on the value of `n`:
``` Func();              // If n is 0. Func(a1);            // If n is 1. Func(a1 + a2);       // If n is 2. Func(a1 + a2 + a3);  // If n is 3. // And so on... ```
We support the following meta programming constructs:
| `$var id = exp` | Defines a named constant value. `$id` is valid util the end of the current meta lexical block. | |:----------------|:-----------------------------------------------------------------------------------------------| | `$range id exp..exp` | Sets the range of an iteration variable, which can be reused in multiple loops later.          | | `$for id sep [[ code ]]` | Iteration. The range of `id` must have been defined earlier. `$id` is valid in `code`.         | | `$($)`          | Generates a single `$` character.                                                              | | `$id`           | Value of the named constant or iteration variable.                                             | | `$(exp)`        | Value of the expression.                                                                       | | `$if exp [[ code ]] else_branch` | Conditional.                                                                                   | | `[[ code ]]`    | Meta lexical block.                                                                            | | `cpp_code`      | Raw C++ code.                                                                                  | | `$$ comment`    | Meta comment.                                                                                  |
**Note:** To give the user some freedom in formatting the Pump source code, Pump ignores a new-line character if it's right after `$for foo` or next to `[[` or `]]`. Without this rule you'll often be forced to write very long lines to get the desired output. Therefore sometimes you may need to insert an extra new-line in such places for a new-line to show up in your output.
``` code ::= atomic_code* atomic_code ::= $var id = exp     | $var id = [[ code ]]     | $range id exp..exp     | $for id sep [[ code ]]     | $($)     | $id     | $(exp)     | $if exp [[ code ]] else_branch     | [[ code ]]     | cpp_code sep ::= cpp_code | empty_string else_branch ::= $else [[ code ]]     | $elif exp [[ code ]] else_branch     | empty_string exp ::= simple_expression_in_Python_syntax ```
You can find the source code of Pump in [scripts/pump.py](../scripts/pump.py). It is still very unpolished and lacks automated tests, although it has been successfully used many times. If you find a chance to use it in your project, please let us know what you think!  We also welcome help on improving Pump.
You can find real-world applications of Pump in [Google Test](http://www.google.com/codesearch?q=file%3A\.pump%24+package%3Ahttp%3A%2F%2Fgoogletest\.googlecode\.com) and [Google Mock](http://www.google.com/codesearch?q=file%3A\.pump%24+package%3Ahttp%3A%2F%2Fgooglemock\.googlecode\.com).  The source file `foo.h.pump` generates `foo.h`.
* If a meta variable is followed by a letter or digit, you can separate them using `[[]]`, which inserts an empty string. For example `Foo$j[[]]Helper` generate `Foo1Helper` when `j` is 1.   * To avoid extra-long Pump source lines, you can break a line anywhere you want by inserting `[[]]` followed by a new line. Since any new-line character next to `[[` or `]]` is ignored, the generated code won't contain this new line.
If you're like us, you'd like to look at some Google Test sample code.  The [samples folder](../samples) has a number of well-commented samples showing how to use a variety of Google Test features.
* [Sample #1](../samples/sample1_unittest.cc) shows the basic steps of using Google Test to test C++ functions.   * [Sample #2](../samples/sample2_unittest.cc) shows a more complex unit test for a class with multiple member functions.   * [Sample #3](../samples/sample3_unittest.cc) uses a test fixture.   * [Sample #4](../samples/sample4_unittest.cc) is another basic example of using Google Test.   * [Sample #5](../samples/sample5_unittest.cc) teaches how to reuse a test fixture in multiple test cases by deriving sub-fixtures from it.   * [Sample #6](../samples/sample6_unittest.cc) demonstrates type-parameterized tests.   * [Sample #7](../samples/sample7_unittest.cc) teaches the basics of value-parameterized tests.   * [Sample #8](../samples/sample8_unittest.cc) shows using `Combine()` in value-parameterized tests.   * [Sample #9](../samples/sample9_unittest.cc) shows use of the listener API to modify Google Test's console output and the use of its reflection API to inspect test results.   * [Sample #10](../samples/sample10_unittest.cc) shows use of the listener API to implement a primitive memory leak checker.

This guide will explain how to use the Google Testing Framework in your Xcode projects on Mac OS X. This tutorial begins by quickly explaining what to do for experienced users. After the quick start, the guide goes provides additional explanation about each step.
Here is the quick guide for using Google Test in your Xcode project.
1. Download the source from the [website](http://code.google.com/p/googletest) using this command: `svn checkout http://googletest.googlecode.com/svn/trunk/ googletest-read-only`   1. Open up the `gtest.xcodeproj` in the `googletest-read-only/xcode/` directory and build the gtest.framework.   1. Create a new "Shell Tool" target in your Xcode project called something like "UnitTests"   1. Add the gtest.framework to your project and add it to the "Link Binary with Libraries" build phase of "UnitTests"   1. Add your unit test source code to the "Compile Sources" build phase of "UnitTests"   1. Edit the "UnitTests" executable and add an environment variable named "DYLD\_FRAMEWORK\_PATH" with a value equal to the path to the framework containing the gtest.framework relative to the compiled executable.   1. Build and Go
The following sections further explain each of the steps listed above in depth, describing in more detail how to complete it including some variations.
Currently, the gtest.framework discussed here isn't available in a tagged release of Google Test, it is only available in the trunk. As explained at the Google Test [site](http://code.google.com/p/googletest/source/checkout">svn), you can get the code from anonymous SVN with this command:
``` svn checkout http://googletest.googlecode.com/svn/trunk/ googletest-read-only ```
Alternatively, if you are working with Subversion in your own code base, you can add Google Test as an external dependency to your own Subversion repository. By following this approach, everyone that checks out your svn repository will also receive a copy of Google Test (a specific version, if you wish) without having to check it out explicitly. This makes the set up of your project simpler and reduces the copied code in the repository.
To use `svn:externals`, decide where you would like to have the external source reside. You might choose to put the external source inside the trunk, because you want it to be part of the branch when you make a release. However, keeping it outside the trunk in a version-tagged directory called something like `third-party/googletest/1.0.1`, is another option. Once the location is established, use `svn propedit svn:externals _directory_` to set the svn:externals property on a directory in your repository. This directory won't contain the code, but be its versioned parent directory.
The command `svn propedit` will bring up your Subversion editor, making editing the long, (potentially multi-line) property simpler. This same method can be used to check out a tagged branch, by using the appropriate URL (e.g. `http://googletest.googlecode.com/svn/tags/release-1.0.1`). Additionally, the svn:externals property allows the specification of a particular revision of the trunk with the `-r_##_` option (e.g. `externals/src/googletest -r60 http://googletest.googlecode.com/svn/trunk`).
Here is an example of using the svn:externals properties on a trunk (read via `svn propget`) of a project. This value checks out a copy of Google Test into the `trunk/externals/src/googletest/` directory.
``` [Computer:svn] user$ svn propget svn:externals trunk externals/src/googletest http://googletest.googlecode.com/svn/trunk ```
The next step is to build and add the gtest.framework to your own project. This guide describes two common ways below.
* **Option 1** --- The simplest way to add Google Test to your own project, is to open gtest.xcodeproj (found in the xcode/ directory of the Google Test trunk) and build the framework manually. Then, add the built framework into your project using the "Add->Existing Framework..." from the context menu or "Project->Add..." from the main menu. The gtest.framework is relocatable and contains the headers and object code that you'll need to make tests. This method requires rebuilding every time you upgrade Google Test in your project.   * **Option 2** --- If you are going to be living off the trunk of Google Test, incorporating its latest features into your unit tests (or are a Google Test developer yourself). You'll want to rebuild the framework every time the source updates. to do this, you'll need to add the gtest.xcodeproj file, not the framework itself, to your own Xcode project. Then, from the build products that are revealed by the project's disclosure triangle, you can find the gtest.framework, which can be added to your targets (discussed below).
To start writing tests, make a new "Shell Tool" target. This target template is available under BSD, Cocoa, or Carbon. Add your unit test source code to the "Compile Sources" build phase of the target.
Next, you'll want to add gtest.framework in two different ways, depending upon which option you chose above.
* **Option 1** --- During compilation, Xcode will need to know that you are linking against the gtest.framework. Add the gtest.framework to the "Link Binary with Libraries" build phase of your test target. This will include the Google Test headers in your header search path, and will tell the linker where to find the library.   * **Option 2** --- If your working out of the trunk, you'll also want to add gtest.framework to your "Link Binary with Libraries" build phase of your test target. In addition, you'll  want to add the gtest.framework as a dependency to your unit test target. This way, Xcode will make sure that gtest.framework is up to date, every time your build your target. Finally, if you don't share build directories with Google Test, you'll have to copy the gtest.framework into your own build products directory using a "Run Script" build phase.
Since the unit test executable is a shell tool, it doesn't have a bundle with a `Contents/Frameworks` directory, in which to place gtest.framework. Instead, the dynamic linker must be told at runtime to search for the framework in another location. This can be accomplished by setting the "DYLD\_FRAMEWORK\_PATH" environment variable in the "Edit Active Executable ..." Arguments tab, under "Variables to be set in the environment:". The path for this value is the path (relative or absolute) of the directory containing the gtest.framework.
If you haven't set up the DYLD\_FRAMEWORK\_PATH, correctly, you might get a message like this:
``` [Session started at 2008-08-15 06:23:57 -0600.]   dyld: Library not loaded: @loader_path/../Frameworks/gtest.framework/Versions/A/gtest     Referenced from: /Users/username/Documents/Sandbox/gtestSample/build/Debug/WidgetFrameworkTest     Reason: image not found ```
To correct this problem, got to the directory containing the executable named in "Referenced from:" value in the error message above. Then, with the terminal in this location, find the relative path to the directory containing the gtest.framework. That is the value you'll need to set as the DYLD\_FRAMEWORK\_PATH.
Now, when you click "Build and Go", the test will be executed. Dumping out something like this:
``` [Session started at 2008-08-06 06:36:13 -0600.] [==========] Running 2 tests from 1 test case. [----------] Global test environment set-up. [----------] 2 tests from WidgetInitializerTest [ RUN      ] WidgetInitializerTest.TestConstructor [       OK ] WidgetInitializerTest.TestConstructor [ RUN      ] WidgetInitializerTest.TestConversion [       OK ] WidgetInitializerTest.TestConversion [----------] Global test environment tear-down [==========] 2 tests from 1 test case ran. [  PASSED  ] 2 tests.
The Debugger has exited with status 0.   ```
Unit testing is a valuable way to ensure your data model stays valid even during rapid development or refactoring. The Google Testing Framework is a great unit testing framework for C and C++ which integrates well with an Xcode development environment.

This guide will explain how to use the Google Testing Framework in your Xcode projects on Mac OS X. This tutorial begins by quickly explaining what to do for experienced users. After the quick start, the guide goes provides additional explanation about each step.
Here is the quick guide for using Google Test in your Xcode project.
1. Download the source from the [website](http://code.google.com/p/googletest) using this command: `svn checkout http://googletest.googlecode.com/svn/trunk/ googletest-read-only`   1. Open up the `gtest.xcodeproj` in the `googletest-read-only/xcode/` directory and build the gtest.framework.   1. Create a new "Shell Tool" target in your Xcode project called something like "UnitTests"   1. Add the gtest.framework to your project and add it to the "Link Binary with Libraries" build phase of "UnitTests"   1. Add your unit test source code to the "Compile Sources" build phase of "UnitTests"   1. Edit the "UnitTests" executable and add an environment variable named "DYLD\_FRAMEWORK\_PATH" with a value equal to the path to the framework containing the gtest.framework relative to the compiled executable.   1. Build and Go
The following sections further explain each of the steps listed above in depth, describing in more detail how to complete it including some variations.
Currently, the gtest.framework discussed here isn't available in a tagged release of Google Test, it is only available in the trunk. As explained at the Google Test [site](http://code.google.com/p/googletest/source/checkout">svn), you can get the code from anonymous SVN with this command:
``` svn checkout http://googletest.googlecode.com/svn/trunk/ googletest-read-only ```
Alternatively, if you are working with Subversion in your own code base, you can add Google Test as an external dependency to your own Subversion repository. By following this approach, everyone that checks out your svn repository will also receive a copy of Google Test (a specific version, if you wish) without having to check it out explicitly. This makes the set up of your project simpler and reduces the copied code in the repository.
To use `svn:externals`, decide where you would like to have the external source reside. You might choose to put the external source inside the trunk, because you want it to be part of the branch when you make a release. However, keeping it outside the trunk in a version-tagged directory called something like `third-party/googletest/1.0.1`, is another option. Once the location is established, use `svn propedit svn:externals _directory_` to set the svn:externals property on a directory in your repository. This directory won't contain the code, but be its versioned parent directory.
The command `svn propedit` will bring up your Subversion editor, making editing the long, (potentially multi-line) property simpler. This same method can be used to check out a tagged branch, by using the appropriate URL (e.g. `http://googletest.googlecode.com/svn/tags/release-1.0.1`). Additionally, the svn:externals property allows the specification of a particular revision of the trunk with the `-r_##_` option (e.g. `externals/src/googletest -r60 http://googletest.googlecode.com/svn/trunk`).
Here is an example of using the svn:externals properties on a trunk (read via `svn propget`) of a project. This value checks out a copy of Google Test into the `trunk/externals/src/googletest/` directory.
``` [Computer:svn] user$ svn propget svn:externals trunk externals/src/googletest http://googletest.googlecode.com/svn/trunk ```
The next step is to build and add the gtest.framework to your own project. This guide describes two common ways below.
* **Option 1** --- The simplest way to add Google Test to your own project, is to open gtest.xcodeproj (found in the xcode/ directory of the Google Test trunk) and build the framework manually. Then, add the built framework into your project using the "Add->Existing Framework..." from the context menu or "Project->Add..." from the main menu. The gtest.framework is relocatable and contains the headers and object code that you'll need to make tests. This method requires rebuilding every time you upgrade Google Test in your project.   * **Option 2** --- If you are going to be living off the trunk of Google Test, incorporating its latest features into your unit tests (or are a Google Test developer yourself). You'll want to rebuild the framework every time the source updates. to do this, you'll need to add the gtest.xcodeproj file, not the framework itself, to your own Xcode project. Then, from the build products that are revealed by the project's disclosure triangle, you can find the gtest.framework, which can be added to your targets (discussed below).
To start writing tests, make a new "Shell Tool" target. This target template is available under BSD, Cocoa, or Carbon. Add your unit test source code to the "Compile Sources" build phase of the target.
Next, you'll want to add gtest.framework in two different ways, depending upon which option you chose above.
* **Option 1** --- During compilation, Xcode will need to know that you are linking against the gtest.framework. Add the gtest.framework to the "Link Binary with Libraries" build phase of your test target. This will include the Google Test headers in your header search path, and will tell the linker where to find the library.   * **Option 2** --- If your working out of the trunk, you'll also want to add gtest.framework to your "Link Binary with Libraries" build phase of your test target. In addition, you'll  want to add the gtest.framework as a dependency to your unit test target. This way, Xcode will make sure that gtest.framework is up to date, every time your build your target. Finally, if you don't share build directories with Google Test, you'll have to copy the gtest.framework into your own build products directory using a "Run Script" build phase.
Since the unit test executable is a shell tool, it doesn't have a bundle with a `Contents/Frameworks` directory, in which to place gtest.framework. Instead, the dynamic linker must be told at runtime to search for the framework in another location. This can be accomplished by setting the "DYLD\_FRAMEWORK\_PATH" environment variable in the "Edit Active Executable ..." Arguments tab, under "Variables to be set in the environment:". The path for this value is the path (relative or absolute) of the directory containing the gtest.framework.
If you haven't set up the DYLD\_FRAMEWORK\_PATH, correctly, you might get a message like this:
``` [Session started at 2008-08-15 06:23:57 -0600.]   dyld: Library not loaded: @loader_path/../Frameworks/gtest.framework/Versions/A/gtest     Referenced from: /Users/username/Documents/Sandbox/gtestSample/build/Debug/WidgetFrameworkTest     Reason: image not found ```
To correct this problem, got to the directory containing the executable named in "Referenced from:" value in the error message above. Then, with the terminal in this location, find the relative path to the directory containing the gtest.framework. That is the value you'll need to set as the DYLD\_FRAMEWORK\_PATH.
Now, when you click "Build and Go", the test will be executed. Dumping out something like this:
``` [Session started at 2008-08-06 06:36:13 -0600.] [==========] Running 2 tests from 1 test case. [----------] Global test environment set-up. [----------] 2 tests from WidgetInitializerTest [ RUN      ] WidgetInitializerTest.TestConstructor [       OK ] WidgetInitializerTest.TestConstructor [ RUN      ] WidgetInitializerTest.TestConversion [       OK ] WidgetInitializerTest.TestConversion [----------] Global test environment tear-down [==========] 2 tests from 1 test case ran. [  PASSED  ] 2 tests.
The Debugger has exited with status 0.   ```
Unit testing is a valuable way to ensure your data model stays valid even during rapid development or refactoring. The Google Testing Framework is a great unit testing framework for C and C++ which integrates well with an Xcode development environment.
Contributing to Nanopb development ==================================
Reporting issues and requesting features ----------------------------------------
Feel free to report any issues you see or features you would like to see in the future to the Github issue tracker. Using the templates below is preferred:
* [Report a bug](https://github.com/nanopb/nanopb/issues/new?body=**Steps%20to%20reproduce%20the%20issue**%0a%0a1.%0a2.%0a3.%0a%0a**What%20happens?**%0A%0A**What%20should%20happen?**&labels=Type-Defect) * [Request a feature](https://github.com/nanopb/nanopb/issues/new?body=**What%20should%20the%20feature%20do?**%0A%0A**In%20what%20situation%20would%20the%20feature%20be%20useful?**&labels=Type-Enhancement)
Requesting help ---------------
If there is something strange going on, but you do not know if it is actually a bug in nanopb, try asking first on the [discussion forum](https://groups.google.com/forum/#!forum/nanopb).
Pull requests -------------
Pull requests are welcome!
If it is not obvious from the commit message, please indicate the same information as you would for an issue report:
* What functionality it fixes/adds. * How can the problem be reproduced / when would the feature be useful.

Nanopb - Protocol Buffers for Embedded Systems ==============================================
[![Build Status](https://travis-ci.org/nanopb/nanopb.svg?branch=master)](https://travis-ci.org/nanopb/nanopb)
Nanopb is a small code-size Protocol Buffers implementation in ansi C. It is especially suitable for use in microcontrollers, but fits any memory restricted system.
* **Homepage:** https://jpa.kapsi.fi/nanopb/ * **Documentation:** https://jpa.kapsi.fi/nanopb/docs/ * **Downloads:** https://jpa.kapsi.fi/nanopb/download/ * **Forum:** https://groups.google.com/forum/#!forum/nanopb

Using the nanopb library ------------------------ To use the nanopb library, you need to do two things:
1. Compile your .proto files for nanopb, using protoc. 2. Include pb_encode.c, pb_decode.c and pb_common.c in your project.
The easiest way to get started is to study the project in "examples/simple". It contains a Makefile, which should work directly under most Linux systems. However, for any other kind of build system, see the manual steps in README.txt in that folder.

Using the Protocol Buffers compiler (protoc) -------------------------------------------- The nanopb generator is implemented as a plugin for the Google's own protoc compiler. This has the advantage that there is no need to reimplement the basic parsing of .proto files. However, it does mean that you need the Google's protobuf library in order to run the generator.
If you have downloaded a binary package for nanopb (either Windows, Linux or Mac OS X version), the 'protoc' binary is included in the 'generator-bin' folder. In this case, you are ready to go. Simply run this command:
generator-bin/protoc --nanopb_out=. myprotocol.proto
However, if you are using a git checkout or a plain source distribution, you need to provide your own version of protoc and the Google's protobuf library. On Linux, the necessary packages are protobuf-compiler and python-protobuf. On Windows, you can either build Google's protobuf library from source or use one of the binary distributions of it. In either case, if you use a separate protoc, you need to manually give the path to nanopb generator:
protoc --plugin=protoc-gen-nanopb=nanopb/generator/protoc-gen-nanopb ...

Running the tests ----------------- If you want to perform further development of the nanopb core, or to verify its functionality using your compiler and platform, you'll want to run the test suite. The build rules for the test suite are implemented using Scons, so you need to have that installed. To run the tests:
cd tests     scons
This will show the progress of various test cases. If the output does not end in an error, the test cases were successful.
Note: Mac OS X by default aliases 'clang' as 'gcc', while not actually supporting the same command line options as gcc does. To run tests on Mac OS X, use: "scons CC=clang CXX=clang". Same way can be used to run tests with different compilers on any platform.
**IMPORTANT NOTE**
**NCCL1 is no longer maintained/updated and has been replaced by NCCL2, available at**
**http://developer.nvidia.com/nccl.**
Optimized primitives for collective multi-GPU communication.
NCCL (pronounced "Nickel") is a stand-alone library of standard collective communication routines, such as all-gather, reduce, broadcast, etc., that have been optimized to achieve high bandwidth over PCIe. NCCL supports an arbitrary number of GPUs installed in a single node and can be used in either single- or multi-process (e.g., MPI) applications. [This blog post](https://devblogs.nvidia.com/parallelforall/fast-multi-gpu-collectives-nccl/) provides details on NCCL functionality, goals, and performance.
At present, the library implements the following collectives: - all-reduce - all-gather - reduce-scatter - reduce - broadcast
These collectives are implemented using ring algorithms and have been optimized primarily for throughput. For best performance, small collectives should be batched into larger operations whenever possible. Small test binaries demonstrating how to use each of the above collectives are also provided.
NCCL requires at least CUDA 7.0 and Kepler or newer GPUs. Best performance is achieved when all GPUs are located on a common PCIe root complex, but multi-socket configurations are also supported.
Note: NCCL may also work with CUDA 6.5, but this is an untested configuration.
To build the library and tests.
```shell $ cd nccl $ make CUDA_HOME=<cuda install path> test ```
Test binaries are located in the subdirectories nccl/build/test/{single,mpi}.
```shell $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:./build/lib $ ./build/test/single/all_reduce_test Error: must specify at least data size in bytes!
Tests nccl AllReduce with user supplied arguments.     Usage: all_reduce_test <data size in bytes> [number of GPUs] [GPU 0] [GPU 1] ...
$ ./build/test/single/all_reduce_test 10000000 # Using devices #   Device  0 ->  0 [0x0a] GeForce GTX TITAN X #   Device  1 ->  1 [0x09] GeForce GTX TITAN X #   Device  2 ->  2 [0x06] GeForce GTX TITAN X #   Device  3 ->  3 [0x05] GeForce GTX TITAN X
To install, run `make PREFIX=<install dir> install` and add `<instal dir>/lib` to your `LD_LIBRARY_PATH`.
NCCL follows the MPI collectives API fairly closely. Before any collectives can be called, a communicator object must be initialized on each GPU. On a single-process machine, all GPUs can be conveniently initialized using `ncclCommInitAll`. For multi-process applications (e.g., with MPI), `ncclCommInitRank` must be called for each GPU. Internally `ncclCommInitRank` invokes a synchronization among all GPUs, so these calls must be invoked in different host threads (or processes) for each GPU. A brief single-process example follows, for an MPI example see test/mpi/mpi_test.cu. For details about the API see nccl.h.
```c #include <nccl.h>
typedef struct {   double* sendBuff;   double* recvBuff;   int size;   cudaStream_t stream; } PerThreadData;
int main(int argc, char* argv[]) {   int nGPUs;   cudaGetDeviceCount(&nGPUs);   ncclComm_t* comms = (ncclComm_t*)malloc(sizeof(ncclComm_t)*nGPUs);   ncclCommInitAll(comms, nGPUs); // initialize communicator                                 // One communicator per process
PerThreadData* data;
... // Allocate data and issue work to each GPU's       // perDevStream to populate the sendBuffs.
for(int i=0; i<nGPUs; ++i) {     cudaSetDevice(i); // Correct device must be set                       // prior to each collective call.     ncclAllReduce(data[i].sendBuff, data[i].recvBuff, size,         ncclDouble, ncclSum, comms[i], data[i].stream);   }
... // Issue work into data[*].stream to consume buffers, etc. } ```
NCCL is provided under the [BSD licence](LICENSE.txt). All source code and accompanying documentation is copyright (c) 2015-2016, NVIDIA CORPORATION. All rights reserved.
Thank you for your interest in this project! Please refer to the following sections on how to contribute code and bug reports.
At the moment, this project is run in the spare time of a single person ([Wenzel Jakob](http://rgl.epfl.ch/people/wjakob)) with very limited resources for issue tracker tickets. Thus, before submitting a question or bug report, please take a moment of your time and ensure that your issue isn't already discussed in the project documentation provided at [http://pybind11.readthedocs.org/en/latest](http://pybind11.readthedocs.org/en/latest).
Assuming that you have identified a previously unknown problem or an important question, it's essential that you submit a self-contained and minimal piece of code that reproduces the problem. In other words: no external dependencies, isolate the function(s) that cause breakage, submit matched and complete C++ and Python snippets that can be easily compiled and run on my end.
* Make a new branch for every feature you're working on. * Make small and clean pull requests that are easy to review but make sure they   do add value by themselves. * Add tests for any new functionality and run the test suite (``make pytest``)   to ensure that no existing features break. * This project has a strong focus on providing general solutions using a   minimal amount of code, thus small pull requests are greatly preferred.
pybind11 is provided under a BSD-style license that can be found in the ``LICENSE`` file. By using, distributing, or contributing to this project, you agree to the terms and conditions of this license.
Make sure you've completed the following steps before submitting your issue -- thank you!
1. Check if your question has already been answered in the [FAQ](http://pybind11.readthedocs.io/en/latest/faq.html) section. 2. Make sure you've read the [documentation](http://pybind11.readthedocs.io/en/latest/). Your issue may be addressed there. 3. If those resources didn't help and you only have a short question (not a bug report), consider asking in the [Gitter chat room](https://gitter.im/pybind/Lobby). 4. If you have a genuine bug report or a more complex question which is not answered in the previous items (or not suitable for chat), please fill in the details below. 5. Include a self-contained and minimal piece of code that reproduces the problem. If that's not possible, try to make the description as clear as possible.
*After reading, remove this checklist and the template text in parentheses below.*
(Provide a short description, state the expected behavior and what actually happens.)
(The code should be minimal, have no external dependencies, isolate the function(s) that cause breakage. Submit matched and complete C++ and Python snippets that can be easily compiled and run to diagnose the issue.)
![pybind11 logo](https://github.com/pybind/pybind11/raw/master/docs/pybind11-logo.png)
[![Documentation Status](https://readthedocs.org/projects/pybind11/badge/?version=master)](http://pybind11.readthedocs.org/en/master/?badge=master) [![Documentation Status](https://readthedocs.org/projects/pybind11/badge/?version=stable)](http://pybind11.readthedocs.org/en/stable/?badge=stable) [![Gitter chat](https://img.shields.io/gitter/room/gitterHQ/gitter.svg)](https://gitter.im/pybind/Lobby) [![Build Status](https://travis-ci.org/pybind/pybind11.svg?branch=master)](https://travis-ci.org/pybind/pybind11) [![Build status](https://ci.appveyor.com/api/projects/status/riaj54pn4h08xy40?svg=true)](https://ci.appveyor.com/project/wjakob/pybind11)
**pybind11** is a lightweight header-only library that exposes C++ types in Python and vice versa, mainly to create Python bindings of existing C++ code. Its goals and syntax are similar to the excellent [Boost.Python](http://www.boost.org/doc/libs/1_58_0/libs/python/doc/) library by David Abrahams: to minimize boilerplate code in traditional extension modules by inferring type information using compile-time introspection.
The main issue with Boost.Pythonand the reason for creating such a similar projectis Boost. Boost is an enormously large and complex suite of utility libraries that works with almost every C++ compiler in existence. This compatibility has its cost: arcane template tricks and workarounds are necessary to support the oldest and buggiest of compiler specimens. Now that C++11-compatible compilers are widely available, this heavy machinery has become an excessively large and unnecessary dependency.
Think of this library as a tiny self-contained version of Boost.Python with everything stripped away that isn't relevant for binding generation. Without comments, the core header files only require ~4K lines of code and depend on Python (2.7 or 3.x, or PyPy2.7 >= 5.7) and the C++ standard library. This compact implementation was possible thanks to some of the new C++11 language features (specifically: tuples, lambda functions and variadic templates). Since its creation, this library has grown beyond Boost.Python in many ways, leading to dramatically simpler binding code in many common situations.
Tutorial and reference documentation is provided at [http://pybind11.readthedocs.org/en/master](http://pybind11.readthedocs.org/en/master). A PDF version of the manual is available [here](https://media.readthedocs.org/pdf/pybind11/master/pybind11.pdf).
- Functions accepting and returning custom data structures per value, reference, or pointer - Instance methods and static methods - Overloaded functions - Instance attributes and static attributes - Arbitrary exception types - Enumerations - Callbacks - Iterators and ranges - Custom operators - Single and multiple inheritance - STL data structures - Iterators and ranges - Smart pointers with reference counting like ``std::shared_ptr`` - Internal references with correct reference counting - C++ classes with virtual (and pure virtual) methods can be extended in Python
- Python 2.7, 3.x, and PyPy (PyPy2.7 >= 5.7) are supported with an   implementation-agnostic interface.
- It is possible to bind C++11 lambda functions with captured variables. The   lambda capture data is stored inside the resulting Python function object.
- pybind11 uses C++11 move constructors and move assignment operators whenever   possible to efficiently transfer custom data types.
- It's easy to expose the internal storage of custom data types through   Pythons' buffer protocols. This is handy e.g. for fast conversion between   C++ matrix classes like Eigen and NumPy without expensive copy operations.
- pybind11 can automatically vectorize functions so that they are transparently   applied to all entries of one or more NumPy array arguments.
- Python's slice-based access and assignment operations can be supported with   just a few lines of code.
- Everything is contained in just a few header files; there is no need to link   against any additional libraries.
- Binaries are generally smaller by a factor of at least 2 compared to   equivalent bindings generated by Boost.Python. A recent pybind11 conversion   of PyRosetta, an enormous Boost.Python binding project,   [reported](http://graylab.jhu.edu/RosettaCon2016/PyRosetta-4.pdf) a binary   size reduction of **5.4x** and compile time reduction by **5.8x**.
- When supported by the compiler, two new C++14 features (relaxed constexpr and   return value deduction) are used to precompute function signatures at compile   time, leading to smaller binaries.
- With little extra effort, C++ types can be pickled and unpickled similar to   regular Python objects.
1. Clang/LLVM 3.3 or newer (for Apple Xcode's clang, this is 5.0.0 or newer) 2. GCC 4.8 or newer 3. Microsoft Visual Studio 2015 Update 3 or newer 4. Intel C++ compiler 16 or newer (15 with a [workaround](https://github.com/pybind/pybind11/issues/276)) 5. Cygwin/GCC (tested on 2.5.1)
This project was created by [Wenzel Jakob](http://rgl.epfl.ch/people/wjakob). Significant features and/or improvements to the code were contributed by Jonas Adler, Sylvain Corlay, Trent Houliston, Axel Huebl, @hulucc, Sergey Lyskov Johan Mabille, Tomasz Misko, Dean Moldovan, Ben Pritchard, Jason Rhinelander, Boris Schling, Pim Schellart, Ivan Smirnov, and Patrick Stewart.
pybind11 is provided under a BSD-style license that can be found in the ``LICENSE`` file. By using, distributing, or contributing to this project, you agree to the terms and conditions of this license.
This is simply clang's Python bindings (clang.cindex) ported to Python 3. Please see http://llvm.org/svn/llvm-project/cfe/trunk/bindings/python/ for the original project.
Common Lisp [Markdown][] -> html converter, using [esrap][] for parsing, and grammar based on [peg-markdown][].
Currently a bit slow and uses lots of RAM for large documents (particularly when using the top-level `doc` parser instead of reading documents as a sequence of `block`s), but seems to handle the tests from [peg-markdown] reasonably well.
todo:
* clean up API * figure out how to automate testing (closure-html + `tree-equal`? need some way to normalize whitespace though), and add tests * optimize grammar * optimize esrap
[markdown]: http://daringfireball.net/projects/markdown/ [esrap]: https://github.com/nikodemus/esrap [peg-markdown]: https://github.com/jgm/peg-markdown [peg/leg]: http://piumarta.com/software/peg/peg.1.html
* If `3bmd:*smart-quotes*` is non-`NIL` while parsing, some extra patterns will be recognized and converted as follows (outside code blocks):     * `'`single quoted strings`'` -> `&lsquo;` ... `&rsquo;` like &lsquo;single quoted string&rsquo;       (with slightly ugly heuristics to avoid contractions)     * other single quotes `'` -> `&apos;` &apos;     * `"`double quoted strings`"` -> `&ldquo;` ... `&rdquo;`, like &ldquo;double quoted string&rdquo;     * ellipsis `...` or `. . .` -> `&hellip;`, &hellip;     * en dash `--` -> `&ndash;`, &ndash;     * em dash `---` -> `&mdash;`, &mdash;     * left right arrow `<->` -> `&harr;`, &harr;     * left arrow `<-` -> `&larr;`, &larr;     * right arrow `->` -> `&rarr;`, &rarr;     * left right double arrow `<=>` -> `&hArr`, &hArr;     * left double arrow `<=` -> `&lArr;`, &lArr;     * right double arrow `=>` -> `&rArr;`, &rArr;
* Loading `3bmd-ext-wiki-links.asd` adds support for parsing simple [[]] style wiki links:      If `3bmd-wiki:*wiki-links*` is non-`NIL` while parsing, wiki links of the form `[[foo]]` or `[[foo|...]]` will be parsed, where `...` is one or more optional args separated by `|` characters.     By default, wiki links will just print the `foo` part as normal text. To integrate into an actual wiki, users should bind `3bmd-wiki:*wiki-processor*` during printing, and define a method on `3bmd-wiki:process-wiki-link` that specializes on the value of `3bmd-wiki:*wiki-processor*` to create an HTML link from the `foo` and arguments. (API subject to change.)
* Loading `3bmd-ext-code-blocks.asd` adds support for github style fenced code blocks, with `colorize` support:       If `3bmd-code-blocks:*code-blocks*` is non-`NIL` while parsing, in addition to normal indented verbatim blocks, ```` ``` ```` can be used to delimit blocks of code:
```         This block doesn't specify a language for colorization         ```     or
```lisp         ;;; this block will be colorized as Common Lisp         (defun foo (bar)           (list bar))         ```
Language names ignore case and whitespace, so `Common Lisp` and `commonlisp` are treated the same, see `3bmd:*colorize-name-map*` for full list of supported language names, or add names to that to recognize a custom colorize `coloring-type`.     If a language name is not specified after the opening ```` ``` ````, `3bmd-code-blocks:*code-blocks-default-colorize*` can be set to one of the keywords naming a `coloring-type` recognized by `colorize` to specify a default, otherwise the block will not be colorized.
* Loading `3bmd-ext-definition-lists.asd` adds support for parsing PHP Markdown Extra style definition lists      If `3bmd-definition-lists:*definition-lists*` is non-`NIL` while parsing, the following definition list will be recognized (see <http://michelf.ca/projects/php-markdown/extra/#def-list>):
Term         : definition
* Loading `3bmd-ext-tables.asd` adds support for parsing PHP Markdown Extra style tables      If `3bmd-tables:*tables*` is non-`NIL` while parsing, the following will be recognized as tables (see <http://michelf.ca/projects/php-markdown/extra/#table>):
| Content Cell  | Content Cell  |         | Content Cell  | Content Cell  |
| First Header  | Second Header |         | ------------- | ------------- |         | Content Cell  | Content Cell  |         | Content Cell  | Content Cell  |
| Name | Description          |         | ------------- | ----------- |         | Help      | Display the help window.|         | Close     | Closes a window     |
| Left-Aligned  | Center Aligned  | Right Aligned |         | :------------ |:---------------:| -----:|         | col 3 is      | some wordy text | $1600 |         | col 2 is      | centered        |   $12 |         | zebra stripes | are neat        |    $1 |
The following simplified table style is not supported, because it is ambiguous, especially, without heading:
```     First Header  | Second Header     ------------- | -------------     Content Cell  | Content Cell     Content Cell  | Content Cell     ```
As contributors and maintainers of this project, we pledge to respect all people who  contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities.
We are committed to making participation in this project a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion.
Examples of unacceptable behavior by participants include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.
Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this  Code of Conduct. Project maintainers who do not follow the Code of Conduct may be removed  from the project team.
Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by  opening an issue or contacting one or more of the project maintainers.
This Code of Conduct is adapted from the Contributor Covenant  (http:contributor-covenant.org), version 1.0.0, available at  http://contributor-covenant.org/version/1/0/0/
<div align="center"> <img src="https://user-images.githubusercontent.com/9893806/29490594-f18fa890-84f5-11e7-9fd4-d9e366b1dc64.gif"> </div>
Currently, there exist thousands of biological databases containing terabytes of publicly available data.  So much data scattered in so many locations impedes unified and comprehensive data-driven approaches to biological discovery.
Create an artificial intelligence daemon that is constantly unifying and organizing the world's biological information by intelligently integrating it into self-similar data modules grouped by biological themes and subthemes (e.g., theme: brain cancer; subthemes: glioblastoma (GBM), astrocytoma, medulloblastoma, ... ; sub-subthemes: primary GBM, pineal astrocytic tumor, brain stem glioma, ...).
The biological data-verse is expanding every day, with new experimental data published daily.  Biology is done in many different model organisms (e.g., human, mouse, rat, etc.), with many different next-generation sequencing types (e.g, ChIP-seq, RNA-seq, etc.), in many different cell lines (e.g., K562, NHEK, etc.), focusing on many different transcription factors, epigenetic modifications, etc.  Multidimensionally integrating all this information is essential to data-driven discovery (e.g., [cancer cures could already exist in big data](https://www.fastcompany.com/3063530/cancer-cures-could-already-exist-in-big-data)).   Specifically, pairing ostensibly unrelated datasets (e.g., from different organisms, NGS types, age groups, cell lines, etc.) can inform and contribute deeper understanding of a variety of biological questions ranging from cancer to aging.
`Biochat` aims at providing an interactive workbench for biological databases (e.g., [Gene Expression Omnibus (GEO)](https://www.ncbi.nlm.nih.gov/geo/), [miRBase](http://www.mirbase.org/), [TCGA](https://cancergenome.nih.gov/), [Human Epigenome Atlas](https://www.genboree.org/epigenomeatlas/index.rhtml), etc.) to learn to communicate with each other by matching and pairing similar data records across the biological data-verse.  `Biochat`'s mission is to fundamentally transform how people perform biological data science by unifying it, going from thousands of scattered database silos (that act as storage repositories) to 1 intelligent centralized framework (that acts as an AI to integrate large-scale data), thereby opening doors to more biological breakthroughs based on existing data.  `Biochat` is written in Common Lisp and operates based on efficient categorization and pairing of similar items (e.g., words that describe ostensibly unrelated data records) into groups.  It is basically the high performance computing (HPC) data science equivalent of the chemistry saying "like dissolves like."
Here is a sample run from `Biochat` using record #10 as input from the Gene Expression Omnibus (GEO) database:
``` #S(GEO-REC    :ID 10    :TITLE "Type 1 diabetes gene expression profiling"    :SUMMARY "Examination of spleen and thymus of type 1 diabetes nonobese diabetic (NOD) mouse, four NOD-derived diabetes-resistant congenic strains and two nondiabetic control strains."    :ORGANISM "Mus musculus") ```
Here is the output using two separate approaches (`vec-closest-recs` and `tree-closest-recs`, both discussed in the section [How it works](https://github.com/Bohdan-Khomtchouk/Biochat#how-it-works)):
``` B42> (subseq (vec-closest-recs (? *geo-db* 0)) 0 3) (#S(GEO-REC      :ID 5167      :TITLE "Type 2 diabetic obese patients: visceral adipose tissue CD14+ cells"      :SUMMARY "Analysis of visceral adipose tissue CD14+ cells isolated from obese, type 2 diabetic patients. Obesity is marked by changes in the immune cell composition of adipose tissue. Results provide insight into the molecular basis of proinflammatory cytokine production in obesity-linked type 2 diabetes."      :ORGANISM "Homo sapiens")   #S(GEO-REC      :ID 4191      :TITLE "NZM2410-derived lupus susceptibility locus Sle2c1: peritoneal cavity B cells"      :SUMMARY "Analysis of peritoneal cavity B cells (B1a) and splenic B (sB) cells from B6.Sle2c1 mice. Sle2 induces expansion of the B1a cell compartment, a B cell defect consistently associated with lupus. Results provide insight into molecular mechanisms underlying susceptibility to lupus in the NZM2410 model."      :ORGANISM "Mus musculus")   #S(GEO-REC      :ID 437      :TITLE "Heart transplants"      :SUMMARY "Examination of immunologic tolerance induction achieved in cardiac allografts from BALB/c to C57BL/6 mice by daily intraperitoneal injection of anti-CD80 and anti-CD86 monoclonal antibodies (mAbs)."      :ORGANISM "Mus musculus"))
B42> (subseq (tree-closest-recs (? *geo-db* 0)) 0 3) (#S(GEO-REC     :ID 471     :TITLE "Malaria resistance"     :SUMMARY "Examination of molecular basis of malaria resistance. Spleens from malaria resistant recombinant congenic strains AcB55 and AcB61 compared with malaria susceptible A/J mice."     :ORGANISM "Mus musculus")  #S(GEO-REC     :ID 4258     :TITLE "THP-1 macrophage-like cells response to W-Beijing Mycobacterium tuberculosis strains: time course"     :SUMMARY "Temporal analysis of macrophage-like THP-1 cell line infected by Mycobacterium tuberculosis (Mtb) W-Beijing strains and H37Rv. Mtb W-Beijing sublineages are highly virulent, prevalent and genetically diverse. Results provide insight into host macrophage immune response to Mtb W-Beijing strains."     :ORGANISM "Homo sapiens")  #S(GEO-REC     :ID 4966     :TITLE "Active tuberculosis: peripheral blood mononuclear cells"     :SUMMARY "Analysis of PBMCs isolated from patients with active pulmonary tuberculosis (PTB) and latent TB infection (LTBI). Results provide insight into identifying potential biomarkers that can distinguish individuals with PTB from LTBI."     :ORGANISM "Homo sapiens")) ```
Record #10 ("Type 1 diabetes gene expression profiling") is a mouse diabetes record from spleen and thymus, which are organs where immunological tolerance is frequently studied.  Even though no explicit mention of "immunological tolerance" is made in record #10, `Biochat` correctly pairs it with record #437 (where "immunological tolerance" is explicitly stated in the Summary).  Likewise, record #10 is nicely paired with record #5167 ("Type 2 diabetic obese patients: visceral adipose tissue CD14+ cells"), which is from a different model organism (human) but involves an immunological study (CD14+ cells) from diabetic patient samples.
The data is obtained by web scraping using the project [crawlik](https://github.com/vseloved/crawlik), which should be cloned from Github prior to loading `Biochat`. The crawled data from GEO is stored as text files in <a href="https://github.com/Bohdan-Khomtchouk/Biochat/tree/master/data/GEO/GEO_records">data/GEO/GEO_records</a> directory & in memory in the variable `*geo-db*`. Here's an example record:
``` TITLE Na,K-ATPase alpha 1 isoform reduced expression effect on hearts
SUMMARY Expression profiling of hearts from 8 to 16 week old adult males lacking one copy of the Na,K-ATPase alpha 1 isoform.  Na,K-ATPase alpha 1 isoform expression is reduced by half in heterozygous null mutants.  Results provide insight into the role of the Na,K-ATPase alpha 1 isoform in the heart.
ORGANISM Mus musculus ```
The purpose of this tool is to find related/similar records using different approaches. This is implemented in the generic function `geo-group` that processes the database into a number of groups of related records. It has a number of methods:
1. Match based on the same histone (the list of known histones is read from a <a href="https://github.com/Bohdan-Khomtchouk/Biochat/blob/master/data/GEO/histones.txt">text file</a>). 2. Match based on the same organism. 3. Synonym based on the synonyms obtained from the biological [PubData](https://github.com/Bohdan-Khomtchouk/PubData) wordnet database (read from a <a href="https://github.com/Bohdan-Khomtchouk/Biochat/blob/master/data/GEO/pubdata-wordnet.json">JSON file</a>). 4. Other possible simple match methods may be implemented.
Another approach to matching is via vector space representations. Each record is transformed into a vector using the pre-calculated vectors for each word in its description (either all fields, or just summary, or summary + title). The vectors used are [PubMed vectors](https://drive.google.com/open?id=0BzMCqpcgEJgiUWs0ZnU0NlFTam8).
The combination of individual word vectors may be performed in several ways. The most straightforward approach (implemented in the library) is direct aggregation, in which a document vector is a normalized sum of vectors for its words. Additional weighting may be applied to words from different parts of the document (summary, title, ...). Another possible aggregation approach is to use [doc2vec](https://cs.stanford.edu/~quocle/paragraph_vector.pdf) PV-DM algorithm. The function `text-vec` produces an aggregated document vector from individual PubMed vectors.
The obtained document vectors may be matched using various similarity measures. The most common are cosine similarity (`cos-sim`) and Euclidian distance-based similarity (`euc-sim`). Unlike `geo-group`, vector-space modeling results in a continuous space, in which it is unclear how to separate individual groups of related vectors. That's why an alternative approach is taken: arrange record vectors in terms of proximity to a given record. This is done with the functions:
- `vec-closest-recs` that sorts the aggregated document vectors directly with the similarity measure (`cos-sim`, `euc-sim`, etc.) - `tree-closest-recs` finds the closest records based on the pre-calculated hierarchical clustering (performed with the UPGMA algorithm using the cosine similarity measure). The results of clustering are stored in the <a href="https://github.com/Bohdan-Khomtchouk/Biochat/blob/master/data/GEO/GEO-tree-cos.lisp">text file</a>.
We apply the "like dissolves like" principle to teach data files to learn to talk to each other (quite literally).  In order to talk, data must first be able to find each other in space (not a trivial task, considering that there are thousands of bioinformatics databases out there... see how we've tackled this problem with <a href="https://github.com/Bohdan-Khomtchouk/PubData">PubData</a>).  So how, for example, is an RNA-seq dataset supposed to find its potentially related ChIP-seq dataset (e.g., according to some combination of similar cell type, histone mark, sequencing details, etc.)?  Through metadata, of course!  However, for the datasets to meet each other via a similar metadata footprint requires sophisticated NLP strategies to introduce them.  Once the datasets meet, we can let the conversations (i.e., integrative bioinformatics analyses) begin!  Hence the name: `Biochat`.
Our ultimate goal is to make integrative multi-omics a lot easier (and more fun) through artificial intelligence (AI).  Right now, we are barely scratching the surface with NLP.  Thus, we are currently implementing novel neural network approaches to help us teach data to talk to each other (stay tuned!).
So far, here is what has been completed in `Biochat`:
* [x] Scrape [GEO](https://www.ncbi.nlm.nih.gov/geo/), then extract the title, summary, etc. from each entry (entry example: <https://www.ncbi.nlm.nih.gov/sites/GDSbrowser?acc=GDS4303>) * [x] Store all this structured metadata in a database (currently, in-memory representation is sufficient) * [x] Teach an algorithm to match similar groups (e.g., if organism is "Mus musculus", i.e. mouse) then group them together (which is easy), but also be able to spot "leukemia" as a cancer type, so group it together with other cancer types
Stages of the development of matching algorithm:
* [x] Direct matching on a per-word or per-phrase basis * [x] Similarity matching using vector space modeling with word vectors from <https://github.com/cambridgeltl/BioNLP-2016> and the [doc2vec approach](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)
Additionally to having Quicklisp you'll need to clone [crawlik](https://github.com/vseloved/crawlik) into the home directory.
To use PubMed word vectors, `(pushnew :use-pubmed *features*)` before loading the system `biochat`.
You are welcome to:
* submit suggestions and bug-reports at: <https://github.com/Bohdan-Khomtchouk/Biochat/issues> * send a pull request on: <https://github.com/Bohdan-Khomtchouk/Biochat> * compose an e-mail to: <bohdan@stanford.edu>
Please note that this project is released with a [Contributor Code of Conduct](CONDUCT.md). By participating in this project you agree to abide by its terms.
This software is thanks to the amazing work done by MANY people in the open source community of biological databases (GEO, PubMed, etc.)
The work on `Biochat` was done by [Bohdan B. Khomtchouk, Ph.D.](https://about.me/bohdankhomtchouk) and [Vsevolod Dyomkin](https://vseloved.github.io/).
Biochats is a collection of procedures to group records by similarity based on their free text description and other meta information. The records are obtained from the datasets of biological experiment data, such as GDS and GSE. The data is collected using web scraping.
Similarity, in the context of dataset descriptions, is not a well-defined concept, as the dataset record contains a number of fields, including free-form text descriptive ones such as the title, summary, and experiment design, as well as more structured fields like the sample organism or platform. Besides, from the point of view of a researcher, different notions of similarity may be relevant. For instance, sometimes only datasets for a particular group of organisms are of interest. A more nuanced case is when only experiments that target a particular histone (which may be mentioned in the text summary but is not indicated in a special field) are requested. That's why the Biochats project aims to provide a flexible toolset suitable for experimenting with different similarity measures and their parameters, as well as supplemental filtering based on additional parameters.
In the context of Biochats, a similarity measure is a function of 2 records that returns a number in the interval [0,1] signifying the degree of similarity (the closer to 1 - the more similar). The magnitude of the similarity doesn't have any particular meaning, the only requirement is that records considered more similar should have a larger value of similarity. So, similarity values obtained by different similarity measures can't be compared.
Currently, in Biochats, two principal approaches to similarity measurement are:
- bag-of-words-based similarity - distributed representation based similarity
In the bag-of-words (or token-based) approach, each record's textual description is transformed into a (sparse) vector of the size equal to the size of the vocabulary. The transformation is performed by tokenization of the text, and then assigning to the element of the document vector representing each token some weight value.
The BoW similarity measures include the variants of TF-IDF [1]: vanilla one and BM25 [2].
The TF and IDF vocabularies are calculated from the whole record set using the tokens from the record's title, summary, and design description. TF count for each document is calculated as a ratio of token count by the document's length. IDF count is calculated using the standard log weighting (`log(record count / token frequency)`).
Both TF-IDF and BM25 similarity measures calculations use the stored weights. The similarity value of two records is calculated as a ratio of the sum of all TF-IDF weights of the tokens present in both record's text descriptions divided by the product of the L2-norms of the TF-IDF vectors of each record.
The difference between the measures is that, in BM25, instead of the plain TF-IDF, the following formula is used: `(k + 1) * tf * idf / (k + tf)`, where `k` is the BM25 parameter, the default value of which is chosen to be 1.2.
Another approach to document representation implemented in Biochats is based on vector space models that use dense low-dimensional (vector size: 100-300) word vectors and combine them in some way into a same dimensional document vector. There are 2 approaches to obtaining the document vectors: by simple aggregation of the pre-calculated word vectors and by constructing the vector using an ML algorithm - see Paragraph vectors [3] or Skip Thought vectors [4]. In Biochats, we chose to implement the aggregation approach using the PubMed word vectors [5] calculated with the word2vec algorithm [6]. This is due to the availability of high-quality pre-trained vectors, lack of training data for the successful application of the doc2vec approaches, and the empirical results showing that simple word vectors aggregation performs not worse on short texts [7].
The similarity measures based on document vectors implemented in Biochats perform the comparison using the following algorithms:
- cosine similarity and smoothed cosine similarity [8]   (5 is chosen as the default smoothing factor) - Euclidian distance-based similarity. The formula for calculating the   similarity score in the interval [0,1] is the following:   `1/(nrm2(v1 - v2) + 1)`, where `nrm2` is the L2-norm - combined cosine/Euclidian distance similarity that uses the square   root of the product of both measures
The main application of Biochats is sorting the records database according to the similarity to a selected record. The sorted output may be additionally filtered based on a set of criteria:
- retain only records for a selected organism or group of organisms - retain only records that mention a particular histone [9]
[1]: http://www.tfidf.com/ [2]: https://dl.acm.org/citation.cfm?id=1704810 [3]: https://cs.stanford.edu/~quocle/paragraph_vector.pdf [4]: https://arxiv.org/abs/1506.06726 [5]: http://bio.nlplab.org/ [6]: https://arxiv.org/abs/1301.3781 [7]: https://arxiv.org/pdf/1607.00570.pdf [8]: http://www.benfrederickson.com/distance-metrics/ [9]: https://en.wikipedia.org/wiki/Histone
MIT License
Copyright (c) 2017 Bohdan Khomtchouk and Vsevolod Dyomkin
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
This is a fork of arnesi utilities suite (http://common-lisp.net/project/bese/arnesi.html), which seems to be orphaned.
It includes some fixes to ```call/cc``` to better handle special variables.
The project's initial concept is by [Bohdan Khomtchouk](http://bohdankhomtchouk.com):
> a 24/7 artificial intelligence system that's using NLP techniques to pair, organize, and group together different biological datasets, such that you could query based on a set of keywords (e.g., "cancer", "leukemia", "mouse"), and it would return to you datasets that are most like each other and most deserving of being considered integratively (i.e., analyzing both or three together could unlock an interesting medical result that could not otherwise be found by analyzing just one dataset alone)
The plan for the first version is:
* [x] Scrape [GEO](https://www.ncbi.nlm.nih.gov/geo/), then extract the title, summary, etc. from each entry (entry example: <https://www.ncbi.nlm.nih.gov/sites/GDSbrowser?acc=GDS4303>) * [ ] Store all this structured metadata in a database * [ ] Teach an algorithm to match similar groups (e.g., if organism is "Mus musculus", i.e. mouse) then group them together (which is easy), but also be able to spot "leukemia" as a cancer type, so group it together with other cancer types
Stages of the development of matching algorithm:
* [ ] Direct matching on a per-word or per-phase basis * [ ] Similarity matching using vector space modeling. Using word vectors from <https://github.com/cambridgeltl/BioNLP-2016> and the [doc2vec approach](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)
Additionally to having Quicklisp you'll need to clone [crawlik](https://github.com/vseloved/crawlik) to `~/common-lisp/`.
cl-jupyter ==========  An enhanced interactive Shell for Common Lisp (based on the Jupyter protocol)  ```  cl-jupyter: an enhanced interactive Common Lisp Shell (Version 0.7 - Ipython protocol v.5.0) --> (C) 2014-2015 Frederic Peschanski (cf. LICENSE)                                  __________                                        /         /.            .-----------------.       /_________/ |           /                 / |      |         | |          /+================+\ |      | |====|  | |          ||cl-jupyter      || |      |         | |          ||                || |      | |====|  | |          ||* (fact 5)      || |      |         | |          ||120             || |      |   ___   | |          ||                || |      |  |166|  | |          ||                ||/@@@    |   ---   | |          \+================+/    @   |_________|./.                               @           ..  ....'          ..................@      __.'. '  ''              /oooooooooooooooo//      ///                      /................//      /_/                       ------------------                           ```  **Important** : this is beta-quality software, expect (and please report) some bugs...   ## Requirements ##  To try cl-jupyter you need :   - a Common lisp implementation, for now     - either SBCL 1.2.x or above (with native threads enabled)     - or Clozure CL 1.10 or above (with native threads enabled) ...     - ECL is planned, for other implementations please fill an issue.   - Quicklisp (cf. http://www.quicklisp.org)   - Python 3.x (cf. http://www.python.org)   - Jupyter (a.k.a. IPython 4.x) or IPython 3.x (cf. http://www.jupyter.org)  ## Quick install ##  Please run the installation script :      python3 ./install-cl-jupyter.py  By default, cl-jupyter assumes SBCL as the default lisp implementation. Using CCL instead requires the following command line:      python3 ./install-cl-jupyter.py  --lisp=ccl  **Note**: cl-jupyter seems to work better with CCL on MacOS (but on Linux everything's fine with SBCL).  As an optional step, you can pre-install the quicklisp dependencies to avoid a veeeerrrry long first startup.    - using SBCL          sbcl --load ./cl-jupyter.lisp    - using CCL          ccl --load ./cl-jupyter.lisp  ## Running cl-jupyter  The console mode is a simple REPL that is useful to check that cl-jupyter is working.  ### Console mode   - for Jupyter          jupyter console --kernel=lisp   - for IPython 3.x          ipython3 console --kernel=lisp  ### Notebooks  The real interest of cl-jupyter is its use conjointly  with the Jupyter notebook frontend. For a try, type:    - for Jupyter          jupyter notebook    - for IPython 3.x          ipython3 notebook  The file [about-cl-jupyter.ipynb](https://github.com/fredokun/cl-jupyter/blob/master/about-cl-jupyter.ipynb) is an example of a Lisp-based notebook.  The file [about-cl-jupyter.pdf](https://github.com/fredokun/cl-jupyter/blob/master/about-cl-jupyter.pdf) is a printable PDF version of this notebook that can be generated by the Jupyter `nbconvert` tool.  ----   ... have fun !
-*- markdown -*-
A Common Lisp implementation of the MessagePack (http://msgpack.org/) serialization/deserialization format, implemented according to http://wiki.msgpack.org/display/MSGPACK/Format+specification.
Depends on `flexi-streams` and `babel`. Floating point values are supported only on SBCL currently.
Status: first draft encoder and decoder implemented, added extensions for some Lisp data types (see below), simple tests.
This translates to `NIL` in Lisp directly, but see `C2` (`False`) below, too.
On encoding this can be achieved via `:false`; when this is encountered during decoding, `NIL` is returned to Lisp as long `*use-false*` is kept `NIL`.
The previous version used the bytes `#xC4`, `#xC5`, `#xC6`, and `#xC7` to encode a 'pure' cons (a cons whose `CDR` is not a cons, symbols, symbols as a number (via a lookup table), and rationals.
As these encodings are no longer allowed by the MSGPACK specification this functionality has been removed; you can use `*EXTENDED-TYPES*` to achieve similar things, though.
MSGPACK allows for a range of "Extended Types"; these consist of one of the bytes `#xC7` to `#xC9` resp. `#xD4` to `#xD8`, a one-byte _type number_, and an array of bytes for the data (which can optionally be interpreted as an integer ID).
A simple use case is eg. to identify pieces of data across a messagepack-RPC channel (like eg. http://github.com/neovim/neovim does):
(defparameter *my-type-list*       (messagepack:define-extension-types         '(:numeric           0           Buffer           Window           Tabpage           ...)))
(defparameter *my-lookup-table*       (make-array 10 :adjustable t :initial-element nil))
(let ((messagepack:*extended-types* *my-type-list*))           (messagepack:*lookup-table* *my-lookup-table*)       (messagepack:decode-stream stream))
Now receiving an reply with an item of extended type 0 will automatically build an instance of the class `BUFFER`, and the `ID` slot will be filled with the received ID, so that passing that instance to another query can be converted into a matching messagepack _extended type_ element.
This provides type-safe communication across this RPC link.
The classes don't have to be defined ahead of time; the call to DEFINE-EXTENSION-TYPES will create their definition if needed.
Please remember that only the _id_ gets transmitted; if you want to get the _same_ object (with _same_ as in `EQ`), you'll need to make sure that the correct object is looked up again; this is what `*LOOKUP-TABLE*` above is for. Remember to bind that per RPC-connection to avoid duplicate IDs, and to invalidate it if the remote process changes!
For more advanced usage `CL-MESSAGEPACK` provides a base class `EXTENSION-TYPE` that can be used to define classes with more slots:
(defclass type1 (cl-messagepack:extension-type)        ( slots... ))
Please note that *encoding* is currently limited to the `#xC7` byte, and therefore imposes a 255 byte limit for the byte array.
Copy the `cl-messagepack` directory to the `local-projects` directory of your Quicklisp install, then
(require :cl-messagepack)     (fiveam:run! 'mpk-tests::cl-messagepack-tests)
in a REPL (tested under SBCL and CCL under Linux x64).
[![Build Status](https://travis-ci.org/vseloved/cl-nlp.png?branch=master)](https://travis-ci.org/vseloved/cl-nlp) [![Documentation Status](https://readthedocs.org/projects/cl-nlp/badge/?version=latest)](https://readthedocs.org/projects/cl-nlp/?badge=latest)
Eventually, CL-NLP will provide a comprehensive and extensible set of tools to solve natural language processing problems in Common Lisp.
The goals of the project include the following:
- support for constructing arbitrary NLP pipelines on top of it - support for easy and fast experimentation and development of new models and approaches - serve as a good framework for teaching NLP concepts
It comprises of a number of utility/horizontal and end-user/vertical modules that implement the basic functions and provide a way to add own extensions and models.
The utility layer includes:
- tools for transforming raw natural language text, as well as various corpora   into a form suitable for further processing - basic support for language modelling - support for a number of linguistic concepts - support for working with machine learning models and a number of training algorithms
The end-user layer will provide:
- POS taggers - constituency parsers - dependency parsers - other stuff (will be added step-by-step, suggestions are welcome)
The project has already reached a stage of usefulness for the primary author: for instance, it supports my current language modelling experiments by providing easy access to treebanks and other utilities.
Yet, it is far from being production-ready. So, if you want to use it for production tasks, expect to bleed on the bleeding edge.
Otherwise, if you want to contribute to developing the toolkit, you're very welcome. Here are a few write-ups to give you the sense of the project and to help get started:
- [Writing a POS tagger with CL-NLP](docs/user-guide/examples/eng-pos-tagger.md) - [NLTK series](http://lisp-univ-etc.blogspot.com/search/label/nltk) -   to be continued, by the way... - [CL-NLP Style Guide](docs/user-guide/getting-started.md#coding-style-guidelines)
You'll also, probably, need to track the latest version of [RUTILS][RUTILS] from git.
For CL-NLP to reach v.0.1 that may be considered suitable for limited use by non-contributors, the following things should be finished (work-in-progress):
- implement a comprehensive test-suite and fix all bugs encountered in the process - describe available models and their quality metrics
- [RUTILS][RUTILS] - [Closure XML](http://common-lisp.net/project/cxml/) - [DRAKMA](http://weitz.de/drakma/) - [ZIP](http://common-lisp.net/project/zip/) - [USERIAL](http://nklein.com/software/unet/userial/)
For development:
- [SHOULD-TEST](http://github.com/vseloved/should-test)
The license of CL-NLP is Apache 2.0.
Specific models may have different license due to the limitations of the dataset they are built with. Please see a `<model>.license` file accompanying each model for details.
(c) 2013-2014, Vsevolod Dyomkin <vseloved@gmail.com>
[RUTILS]:http://github.com/vseloved/rutils
The API is made up of generic functions for performing various operations, like `tokenize`, `stem`, `lemmatize`, `tag`, `parse`, `classify`, etc.
Concrete algorithms are implemented as methods, specialized on various classes, like `porter-stemmer`, `db-lemmatizer` or `avg-perceptron`. If the instances of these classes require configuration or internal state, they may be created in the usual way (with `make-instance`).
Otherwise there are corresponding singletons for accessing the default instance: `<porter-stemmer>`, `<metaphone>`, `<damlev-distance>`.
`calculate-distance`
- `edit-distance` - `damlev-distance` - `hamming-distance`
`generate-variants`
- `edit-distance` - `damlev-distance` - `hamming-distance`
`tokenize`
- `regex-tokenizer`
`split-sentences`
- `rule-based-splitter` - `token-based-splitter`
`phonetic-transform`
- `db-IPA` - `db-X-SAMPA` - `metaphone` - `double-metaphone` - `metaphone3` - `soundex` - `phonix`
`stem`
- `porter-stemmer`
`lemmatize`
- `db-lemmatizer`
`pos-tag`
- `baseline-tagger` - `hmm-tagger` - `greedy-ap-tagger`
`parse`
- `cky-parser` - `link-grammar-parser`
`deps`
- `greedy-ap-deps-parser`
`classify`
`train`
- `character-language-model`
- `trained-ngram-model` - `db-nram-model` - `network-ngram-model`
- `ngram-freq` - `ngram-prob`
- `naive-bayes-classifier`
- `svm-classifier`
CL-NLP is a Modern NLP toolkit built using Common Lisp.
CL-NLP aims to provide a comprehensive and extensible set of tools to solve natural language processing problems in Common Lisp.
The goals of the project include the following:
- support for constructing arbitrary NLP pipelines on top of it - support for easy and fast experimentation and development of new models and   approaches - serve as a good framework for teaching NLP concepts
It comprises of a number of utility/horizontal and end-user/vertical modules that implement the basic functions and provide a way to add own extensions and models.
The utility layer includes:
- tools for transforming raw natural language text, as well as various corpora   into a form suitable for further processing - basic support for language modelling - support for a number of linguistic concepts - support for working with machine learning models and a number of training   algorithms
The end-user layer will provide:
- POS taggers - constituency parsers - dependency parsers - other stuff (will be added step-by-step, suggestions are welcome)
OK, let's get started with the NLTK book. Its first chapter tries to impress the reader with how simple it is to accomplish some neat things with texts using it. Actually, the underlying algorithms that allow to achieve these results are mostly quite basic. We'll discuss them in this post and the code for the first part of the chapter can be found in [nltk/ch1-1.lisp](https://github.com/vseloved/cl-nlp/blob/master/nltk/ch1-1.lisp).
For the purpose of this demonstration we'll need several texts which can be downloaded from [NLTK data](http://nltk.org/nltk_data/). Namely, we'll use the following 5 texts:
- Moby Dick (can be found inside Project Gutenberg) - Sense and Sensibility (likewise from Project Gutenberg) - The Book of Genesis - Inaugural Address Corpus (this one comes as a collection of separate   texts, that you'll need to cat together into one file) - NPS Chat Corpus
These texts are in `nltk/data/` directory in `CL-NLP`.
NLTK guys have created a special `Text` class and have defined all the operations in this chapter as its methods. We'll employ a slightly simpler approach and implement them as ordinary functions. Yet we'll also have a special-purpose `text` class to cache reusable results of long-running operations, like tokenization.
NLTK> (load-nltk-texts "data/")     #<MOBY [Moby Dick by Herman... 1242986>     #<SENSE [Sense and Sensibili... 673019>     #<GENESIS In the beginning God... 188665>     ...
As you've already guessed, we've just loaded all the texts. The number in the last column is each text's character count.
Now they are stored in `*texts*` hash-table. This is how we can access an individual text and name them for future usage:
(defparameter *sense* (get# :sense *texts*))
(`get#` is one of the shorthand functions for operating on hash-tables defined in [rutils](https://github.com/vseloved/rutils/blob/master/core/packages.lisp))
Now we have a variable pointing to "Sense and Sensibility". If we examine it, this is what we'll see:
NLTK> (describe *sense*)     #<SENSE [Sense and Sensibili... 673019>       [standard-object]     Slots with :INSTANCE allocation:       NAME         = :SENSE       RAW          = "[Sense and Sensibility by Jane Austen 1811]..       WORDS        = #<unbound slot>       CTXS         = #<unbound slot>       TRANSITIONS  = #<unbound slot>       DISPERSION   = #<unbound slot>
As you see, there are some unbound slots in this structure: `words` will hold every word in the text after tokenization, `ctxs` will be a table of contexts for each word with their probabilities. By analogy, `transitons` will be a table of transition probabilities between words. Finally, `dispersion` will be a table of indices of word occurences in text. We'll use a lazy initialization strategy for them by defining `slot-unbound` CLOS methods, that will be called on first access to each slot. For example, here's how `words` is initialized:
(defmethod slot-unbound (class (obj text) (slot (eql 'words)))       (with-slots (raw words) obj         (format t "~&Tokenizing text...~%")         (prog1 (setf words (mapcan #`(cons "" (tokenize <word-tokenizer> %))                                    (tokenize <paragraph-splitter> raw)))           (format t "Number of words: ~A~%" (length words)))))
First we split the raw text in paragraphs, because we'd like to preserve paragraph information. Splitting is slightly involved as paragraphs are separated by double newlines, while single newlines end every line in the text, and we have to distinguish this. We insert pillcrow signs paragraph boundaries. Then we tokenize the paragraphs into separate words (real words, punctuation marks, symbols, etc).
NB. I consider tokenization the crucial function of the NLP toolkit, and we'll explore it in more detail in one of the future posts.
OK, now we are ready to start churning out examples from the first chapter.
The first one finds occurences of certain words in the text. NLTK guys perform the search on the tokenized texts. But I think, it's quite OK to do it on raw strings with regexes. This has an added benefit of preserving text structure.
NLTK> (concordance *moby* "monstrous")     Displaying 11 of 11 matches         former, one was of a most monstrous size. ...  This came towards                    "Touching that monstrous bulk of the whale or ork we h                          array of monstrous clubs and spears.  Some were      you gazed, and wondered what monstrous      has survived the flood; most monstrous                                   monstrous fable, or still worse and mor                            Of the Monstrous Pictures of Whales.             In connexion with the monstrous pictures of whales, I am stro     o enter upon those still more monstrous stories of them     ave been rummaged out of this monstrous      Whale-Bones; for Whales of a monstrous size are
With `:pass-newlines` on we can get the output similar to NLTK's. Let's try one of the homework tasks:
NLTK> (concordance *genesis* "lived" :pass-newlines t)     Displaying 75 of 75 matches     t from Yahweh's presence, and lived in the land of Nod, east of      when they were created. Adam lived one hundred thirty years, and     ...
Now let's try similarity. Here we won't do without proper tokenization.
NLTK> (similar *moby* "monstrous")     Building word contexts...     Tokenizing text...     Number of words: 267803     Number of unique words: 19243     ("mystifying" "subtly" "maddens" "impalpable" "modifies" "vexatious" "candid"      "exasperate" "doleful" "delightfully" "trustworthy" "domineering" "abundant"      "puzzled" "untoward" "contemptible" "gamesome" "reliable" "mouldy"      "determined")
NLTK> (similar *sense* "monstrous")     Building word contexts...     Tokenizing text...     Number of words: 146926     Number of unique words: 6783     ("amazingly" "vast" "heartily" "extremely" "remarkably" "great" "exceedingly"      "sweet" "very" "so" "good" "a" "as")
We mostly get the same words as NLTK's result, but with a slightly different ordering. It turns out, that the reason for this is very simple. The function `similar` matches words based on the contexts, where they occur. According to the famous quote by John Rupert Firth:
> You shall know a word by the company it keeps
But if we look at context overlap between various words from our list we'll see that the similarity relation between all these words is extremely weak: the decision is based on the match of a single context in which both words appeared in text. In fact, all the listed words are similar to the same extent.
NLTK> (common-contexts *moby* "monstrous" "loving")     ("most_and")     NLTK> (common-contexts *moby* "monstrous" "mystifying")     ("most_and")     NLTK> (apply #'common-contexts *moby* (similar *moby* "monstrous"))     ("most_and")
Actually, the next NLTK example is, probably, the best context overlap you can get from those texts:
NLTK> (common-contexts *sense* "monstrous" "very")     ("am_glad" "be_glad" "a_pretty" "is_pretty" "a_lucky")
Now let's draw a dispersion plot of the words from inaugural corpus. This task may seem difficult to approach at first, because the authors use a Python library `matplotlib` for drawing the graph. Fortunately, there's a language-agnostic tool to achieve similar goals, which is called `gnuplot`. There is a couple of Lisp wrapper libraries for it, and the actual code you need to write to drive it amounts to 2 lines (not counting the code to format the data for consumption). There are, actually, numerous language-agnostic tools on the Unix platform  don't forget to look for them when you have such kind of specific need :)
![gnuplot dispersion graph with cl-nlp](http://img.photobucket.com/albums/v473/pufpuf/dispersion_zps7447117e.jpg)
The next problem in this part also seems pretty hard. And, in fact, it is extremely hard if framed correctly  to generate a meaningful text based on some other text. But the example solves an easier task to generate _a somewhat_ meaningful text. And the approach taken to solve it is a very simple one  it is the baseline method in this area and is based on Markov chains. There was even a famous mock with Markov chains in the times of Usenet called [Mark V. Shaney](http://en.wikipedia.org/wiki/Mark_V_Shaney). Markov models have one principal parameter  _order_. Mark V. Shaney was an order 2 chain.
Let's try to generate something with it:
NLTK> (princ (generate *genesis* :order 2 :n 93))     Building prefix transitions index of length 2...     Number of prefixes: 14326     In the marsh grass . Behold , the male and female . Of these , and that Jacob obeyed his father . I will return to the earth was dry . God set them in the earth . Noah built an altar there , and put me in the pit ; and that which was our father ' s hand , then the handmaids and their sin is very grievous in your flesh for an everlasting covenant between God and every man to see the nakedness of his flock and keep it .
And what if we raise the order?
NLTK> (princ (generate *genesis* :order 3 :n 93))     Building prefix transitions index of length 3...     Number of prefixes: 28206     In the beginning God created the large sea creatures , and every bird , whatever moves on the earth . He stayed yet another seven days , and sent over that which he had gained in Paddan Aram . Esau saw that the interpretation was good , he said to them , they conspired against him to kill him . They took captive all their little ones , and for days and years ; and let it divide the waters from the waters . God said to the younger , and his seed
The text starts to resemble the original more and more. Also you may notice, that the text will always start with "In". That's because Genesis isn't split in paragraphs, and our generation starts from paragraph beginnings, of which there's only one here.
OK, this seems to work, but with probabilities you never know for sure... ;)
Now, we're left with very simple tasks. Let's just do them:
NLTK> (length (text-words *genesis*))     44671
In the book they had a slightly different number: 44764. This is because of the different tokenization scheme. The differences can be seen in the next snippet (we have a cleaner version for this use case :)
NLTK> (take 20 (sort (remove-duplicates (text-words *genesis*)                                             :test 'string=)                          'string<))     ("!" "\"" "'" "(" ")" "," "-" "." ":" ";" "?" "A" "Abel" "Abida" "Abimael"  "Abimelech" "About" "Abraham" "Abram" "Accad")
What about the vocabulary size? Well, once again very similar to the NLTK number (2789).
NLTK> (length (remove-duplicates (text-words *genesis*) :test 'string=))     2634
Now, let's look for words:
NLTK> (count "smote" (text-words *genesis*) :test 'string=)     0
Hmm... What about some other word?
NLTK> (count "Abraham" (text-words *genesis*) :test 'string=)     134
This seems to work. What's the problem with `"smote"`? Turns out, there's no such word in the Genesis text: at least the examination of the text doesn't show any traces of it. Looks like we've found a bug in the book :)
(defun percentage (count total)       (/ (* 100.0 count) total))     NLTK> (with-slots (words) *inaugural*             (percentage (count "a" words :test 'string=) (length words)))     1.4597242
(defun lexical-diversity (text)       (with-slots (words) text         (/ (float (length words))            (length (remove-duplicates words :test 'string=)))))     NLTK> (lexical-diversity *genesis*)     16.959377     NLTK> (lexical-diversity *chat*)     6.9837084
Interestingly, the results for `*chat*` corpus differ from the NLTK ones, although they are calculated based on tokens, provided in the corpus and not extracted by our tokenization algorithms. This text is special, because it is extracted from the XML-structured document, which also contains the full tokenization. To use it we swap `words` in `*chat*` corpus:
NLTK> (setf (text-words *chat*)                 (mapcar #'token-word                         (flatten (mapcar #'text-tokenized                                          (corpus-texts ncorp:+nps-chat-corpus+)))))
But first we need to get the corpus and extract the data from it  see `corpora/nps-chat.lisp` for details.
And, finally, we can examine the Brown Corpus.
Genre        |  Tokens  |  Types  |  Lexical Diversity     --------------------+----------+---------+--------------------     PRESS-REPORTAGE     |  100554  |  14393  |    7.0     PRESS-EDITORIAL     |  61604   |  9889   |    6.2     PRESS-REVIEWS       |  40704   |  8625   |    4.7     RELIGION            |  39399   |  6372   |    6.2     SKILL-AND-HOBBIES   |  82345   |  11934  |    6.9     POPULAR-LORE        |  110299  |  14502  |    7.6     BELLES-LETTRES      |  173096  |  18420  |    9.4     MISCELLANEOUS-GOVER |  70117   |  8180   |    8.6     LEARNED             |  181888  |  16858  |   10.8     FICTION-GENERAL     |  68488   |  9301   |    7.4     FICTION-MYSTERY     |  57169   |  6981   |    8.2     FICTION-SCIENCE     |  14470   |  3232   |    4.5     FICTION-ADVENTURE   |  69342   |  8873   |    7.8     FICTION-ROMANCE     |  70022   |  8451   |    8.3     HUMOR               |  21695   |  5016   |    4.3
OK, seems like we're done with this chapter. So far there was no rocket science involved, but it was interesting...
So, what are the interesting bits we haven't discussed?
First, let's look at a small optimization trick for calculating `lexical-diversity`. Our initial variant uses a library function `remove-duplicates` which is highly inefficient for this case.
NLTK> (time (lexical-diversity *chat*))     Evaluation took:       9.898 seconds of real time       9.888618 seconds of total run time (9.888618 user, 0.000000 system)       99.91% CPU       23,687,560,947 processor cycles       229,392 bytes consed
What we'd like to do is something similar to the Python's version which puts everything in a set and calculates its size. A set is easily represented with a hash-table:
(defun uniq (list &key raw case-insensitive)       "Return only unique elements from LIST either as a new list        or as hash-table if RAW is set. Can be CASE-INSENSITIVE."       (let ((uniqs (make-hash-table :test (if case-insensitive 'equalp 'equal))))         (dolist (elt list)           (set# elt uniqs t))         (if raw uniqs (ht-keys uniqs))))
Here's the time of the same calculation using `uniq`:
NLTK> (time (lexical-diversity *chat*))     Evaluation took:       0.014 seconds of real time       0.012001 seconds of total run time (0.012001 user, 0.000000 system)       85.71% CPU       33,396,336 processor cycles       613,568 bytes consed
A 1000x speed increase!
Now, let's return to text generation. It is accomplished with the following loop (a simplified version):
(loop :for i :from 1 :to length :do       (let ((r (random 1.0))             (total 0))         (dotable (word prob                   (or (get# prefix transitions)                       ;; no continuation - start anew                       (prog1 (get# (setf prefix initial-prefix) transitions)                         ;; add period unless one is already there                         (unless (every #'period-char-p (car rez))                           (push "." rez)                           (incf i)))))           (when (> (incf total prob) r)             (push word rez)             (setf prefix (cons word (butlast prefix)))             (return)))))
On each iteration it places all possible continuations of the current prefix on a segment from 0 to 1 and generates a random number that points to one of the variants. If there's no continuation it starts anew.
NLTK book, actually, uses a slightly more complicated model: first, it builds a probability distribution on top of the transition frequencies and then generated the text from the probabilities. As of now I don't see why this is needed and if it makes any difference in the results.
And, finally, here's how we draw the dispersion plot:
(defun plot-dispersion (words file)       "Plot WORDS dispersion data from FILE."       (cgn:start-gnuplot)       (cgn:format-gnuplot "set title \"Lexical Dispersion Plot\"")       (cgn:format-gnuplot "plot \"~A\" using 1:2:yticlabels(3) title \"\"" file))
It's just 1 line of `gnuplot` code, actually, but we also need to prepare the data in a tab-separated text file:
(defun dump-data (words dispersion-table)       "Dump data from DISPERSION-TABLE for WORDS into a temporary file        and return its name."       (let ((filename (fmt "/tmp/~A" (gensym))))         (with-out-file (out filename)           (format out "0~t0~t~%")           (doindex (i word words)             (dolist (idx (get# word dispersion-table))               (format out "~A~t~A~t~A~%" idx (1+ i) word)))           (format out "0~t~A~t~%" (1+ (length words))))         filename))
To wrap up, we've seen a demonstration of a lot of useful tools for text processing, and also discussed how they can be built. Among all of them I want to outline the utility of a seemingly simplistic `concordance` that is actually kind of a `grep` tool that is indispensable for any text exploration. I even used it a couple of times debugging issues in more complex functions from this pack.
Most of the remaining parts of the first chapter of NLTK book serve as an introduction to Python in the context of text processing. I won't translate that to Lisp, because there're much better resources explaining how to use Lisp properly. First and foremost I'd refer anyone interested to the appropriate chapters of [Practical Common Lisp](http://gigamonkeys.com/book):
- [List Processing](http://gigamonkeys.com/book/they-called-it-lisp-for-a-reason-list-processing.html) - [Collections](http://gigamonkeys.com/book/collections.html) - [Variables](http://gigamonkeys.com/book/variables.html) - [Macros: Standard Control Constructs](http://gigamonkeys.com/book/macros-standard-control-constructs.html)
It's only worth noting that Lisp has a different notion of lists, than Python. Lisp's lists are linked lists, while Python's are essentially vectors. Lisp also has vectors as a separate data-structure, and it also has multidimensional arrays (something Python mostly lacks). And the set of Lisp's list operations is somewhat different from Python's. List is the default sequence data-structure, but you should understand its limitations and know, when to switch to vectors (when you will have a lot of elements and often access them at random). Also Lisp doesn't provide Python-style syntactic sugar for slicing and dicing lists, although all the operations are there in the form of functions. The only thing which isn't easily reproducible in Lisp is assigning to a slice:
>>> sent[1:9] = ['Second', 'Third']     >>> sent     ['First', 'Second', 'Third', 'Last']
There's `replace` but it can't shrink a sequence:
CL-USER> (defvar sent '(1 2 3 4 5 6 7 8 9 0))     CL-USER> (replace sent '("Second" "Third") :start1 1 :end1 9)     (1 "Second" "Third" 4 5 6 7 8 9 0)
So, the only part worth discussing here is statistics.
Let's start with a __frequency distribution__. We have already used something similar in the previous part for text generation, but it was very basic and tailored to the task. Now, it's time to get into some serious language modeling and discuss a more general-purpose implementation.
Such modeling is accomplished via collecting of large amounts of statistical data about words and their sequences appearances in texts. These sequences are called __ngrams__. In a nutshell, you can think of ngrams distribution as a table mapping ngram sequences to numbers.
(defclass ngrams ()       ((order :initarg :order :reader ngrams-order)        (count :reader ngrams-count)        (max-freq :reader ngrams-max-freq)        (min-freq :reader ngrams-min-freq)        (total-freq :reader ngrams-total-freq)))
The crucial parameter of this class is `order` which defines the length of a sequence. In practice, ngrams of order from 1 to 5 may be used.
`ngrams` is an abstract class. In Lisp you don't have to somehow specify this property, you just don't implement methods for it. The simplest `ngrams` implementation  `table-ngrams`  uses an in-memory hash-table as a store. You can get ngram frequency and "probability" (the maximum likelihood estimation) from it, as well as log of probability which is used more often in calculations, because it allows to avoid the problem of floating point rounding errors occurring when multiplying probabilities which are rather small values.
NLTK> (freq (text-bigrams *moby*) "The whale")     Indexing bigrams...     Number of bigrams: 116727     14     NLTK> (logprob (text-bigrams *moby*) "The whale")     -14.255587
So how do we get bigrams of Moby Dick? For that we just have to count all of them in text (this is a simplified version  some additional processing for sentence start/ends is needed):
(defun index-ngrams (order words &key ignore-case)       (make 'table-ngrams :order order             :table             (let ((ht (make-hash-table :test (if ignore-case 'equalp 'equal))))               (do ((tail words (rest tail)))                    ((shorter? tail order))                 (incf (get# (if (= order 1)                                 (car tail)                                 (sub tail 0 order))                             ht 0)))               ht)))
`table-ngrams` will be useful for simple experimentation and prototyping, like we do in our NLTK examples.
NLTK> (defvar *1grams* (text-ugrams *moby*))     Indexing unigrams...     Number of unigrams: 19244     NLTK> (freq *1grams* "whale")     906     NLTK> (take 50 (vocab *1grams* :order-by '>))     ("," "the" "<S>" "</S>" "." "of" "and" "-" "a" "to" ";" "in" "\"" "that" "'"  "his" "it" "I" "!" "s" "is" "he" "with" "was" "as" "all" "for" "this" "at"  "by" "but" "not" "him" "from" "be" "on" "?" "so" "whale" "one" "you" "had"  "have" "there" "But" "or" "were" "now" "which" "me")
The strings `"<S>"` and `"</S>"` here denote special symbols for sentence start and end.
Here's a cumulative plot of them:
![Cumulative Frequency Plot for 50 Most Frequent Words in Moby Dick](http://img.photobucket.com/albums/v473/pufpuf/ccounts_zpsbc41c690.png)
And here's just the counts graph:
![Frequency Plot for 50 Most Frequent Words in Moby Dick](http://img.photobucket.com/albums/v473/pufpuf/counts_zpsa3d96079.png)
And, finally, here's hapaxes:
NLTK> (take 50 (hapaxes (text-ugrams *moby*)))     ("orphan" "retracing" "sheathed" "padlocks" "dirgelike" "Buoyed" "liberated"  "Till" "Ixion" "closing" "suction" "halfspent" "THEE" "ESCAPED" "ONLY"  "Epilogue" "thrill" "etherial" "intercept" "incommoding" "tauntingly"  "backwardly" "coincidings" "ironical" "intermixingly" "whelmings" "inanimate"  "animate" "lookouts" "infatuation" "Morgana" "Fata" "gaseous" "mediums"  "bewildering" "bowstring" "mutes" "voicelessly" "THUS" "grapple"  "unconquering" "comber" "foregone" "bullied" "uncracked" "unsurrendered"  "Diving" "flume" "dislodged" "buttress")
The next Python feature showcased here is __list comprehensions__. The idea behind them is to resemble theoretical-set notation in list definition. There's no such thing out-of-the box in Lisp (although you can implement an even closer to set-notation variant in [just 24 lines](http://lisp-univ-etc.blogspot.com/2013/01/real-list-comprehensions-in-lisp.html)), and the general approach is to favor functional style filtering with variants of `map` and `remove-if`.
NLTK> (sort (remove-if #`(<= (length %) 15)                            (uniq (text-words *moby*)))                 'string<)     ("CIRCUMNAVIGATION" "Physiognomically" "apprehensiveness" "cannibalistically" "characteristically" "circumnavigating" "circumnavigation" "circumnavigations" "comprehensiveness" "hermaphroditical" "indiscriminately" "indispensableness" "irresistibleness" "physiognomically" "preternaturalness" "responsibilities" "simultaneousness" "subterraneousness" "supernaturalness" "superstitiousness" "uncomfortableness" "uncompromisedness" "undiscriminating" "uninterpenetratingly")     NLTK> (sort (remove-if #`(or (<= (length %) 7)                                  (<= (freq (text-ugrams *chat*) %) 7))                        (vocab (text-ugrams *chat*)))                 'string<)     ("20sUser104" <... another 130 users ...> "Question" "actually" "anything" "computer" "everyone" "football" "innocent" "listening" "remember" "seriously" "something" "talkcity_adults" "thinking" "together" "watching")
In NLTK variant all users are removed from the corpus with some pre-processing.
But to be useful for real-world scenarios ngrams have to be large, really large (on the orders of tens of gigabytes of data for trigrams). This means that you won't be able to simply store them in memory and will have to use some external storage: a general-purpose data-store, like the relational database or a special-purpose software.
One such ngrams service that is available on the internet is [Microsoft Web N-gram Services](http://web-ngram.research.microsoft.com/). If you have a developer token you can query it over HTTP. The service only returns log-probabilities and also log-conditional-probabilities and runs really slow, but it is capable of serving batch requests, i.e. return probabilities for several ngrams at once. The implementation of `ngrams` interface for such service is provided in [contrib/ms-ngrams.lisp](https://github.com/vseloved/cl-nlp/blob/master/src/contrib/ms-ngrams.lisp).
We have already encountered conditional probabilities in the previous part. They have the following relationship with regular (so called, "joint") probabilities (for bigrams):
p(A,B) = p(B|A) * p(A)     where P(A,B) is a joint probability and P(B|A) is the conditional one
I.e. they can be calculated from current ngrams plus the ngrams of preceding order. So, this operation is performed not on a single `ngrams` object, but on a pair of such objects. And they serve an important role we'll see below. But first we need to talk about language models.
A __language model__ is, basically, a collection of ngrams of different orders. Combining these ngrams we're able to obtain some other measures beyond a simple frequency value or probability estimate. The biggest added value of such model is in smoothing capabilities that it implements. The problem smoothing solves is that you'll almost never be able to have all possible ngrams in your data-store  there's just too many of them and the language users keep adding more. But it's very nasty to get 0 probability for some ngram. The language model allows to find a balance between the number of ngrams you have to store and the possibility to get meaningful probability numbers for any ngram. This is achieved with various smoothing techniques: interpolation and discounting. Some of the smoothing methods are:
- +1 smoothing - Kneser-Ney smoothing - and Stupid backoff
A good general compilation of various smoothing methods is assembled in [this presentation](http://courses.washington.edu/ling570/fei_fall09/10_26_Smoothing.pdf).
Let's look at the simplified implementation of scoring a sentence with the Stupid Backoff model:
(defmethod logprob ((model language-model) (sentence list))       (with-slots (order) model         (let ((rez 0)               (s (append (cons "<S>" sentence) (list "</S>"))))           (when (shorter? s order)             (return-from logprob (logprob (get-ngrams (length s) model) s)))           ;; start of the sentence: p(A|<S>) * p(B|<S>,A) * ...           (do ((i 2 (1+ i)))                ((= i order))             (incf rez (cond-logprob model (sub s 0 i))))           ;; middle of the sentence           (do ((tail s (rest tail)))                ((shorter? tail order))             (incf rez (cond-logprob model (sub tail 0 order))))           rez)))
Eventually, the language model is able to return the estimated probability of any sequence of words, not limited to the maximum order of ngram in it. This is usually calculated using the Markov assumption with the following formula (for a bigram language model):
p(s) = p(A) * p(B|A) * p(C|A,B) * p(D|B,C) * ... * p(Z|X,Y)     where s = A B ... Z
NLTK> (defvar *moby-lm2* (make-lm 'stupid-backoff-lm                                       :1g (text-ugrams *moby*)                                       :2g (text-bigrams *moby*)))     NLTK> (prob *moby-lm2* "This is a test sentence.")     6.139835e-20
That was, by the way, the probability of an unseen sentence with the word "sentence" completely missing from vocabulary.
NLTK> (prob *moby-lm2* '("<S>" "Moby" "Dick" "." "</S>"))     5.0842726e-9     NLTK> (float (prob (text-bigrams *moby*) '("Moby" "Dick")))     3.0310222e-4
As you see, it's much more likely to encounter the sentence "Moby Dick." in this text, although not so likely as the phrase "Moby Dick". :)
Also such model is able to generate random texts just like we did in the previous part. But because of the smoothing capability it's much more general, i.e. it can generate sequences with any word from the vocabulary, even the phrases unseen before. At the same time it's much more computationally expensive, because now generating each new word takes `O(vocabulary size)` while it was `O(average number of words following any particular word)`.
NLTK> (princ (generate *genesis* :order 2 :n 93))     burial to judged eaten sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung sprung foreign longed them ought up Temanites Aran earth earth blessings surface surface surface surface surface surface surface surface surface floated Darkness Now homage earth Now In princes said vengeance It passed said divide In beginning earth Asenath said re The peaceful kind Calah said blameless mistress Chaldees said hunter said middle surface surface surface surface yonder earth rib said said smoking smoking smoking
And, as you see, this example totally doesn't resemble the one in the previous part. Is this a bug? No, just a trick that is played with us because we aren't following the basic math principles.  In the Stupid Backoff model the probabilities don't add up to 1 and the conditional probability of an unseen ngrams may be larger than the largest probability of any recorded one! This is the reason we get to produce sequences of repeated words. This problem is much less obvious for the trigram model, although the text remains a complete gibberish.
NLTK> (princ (generate *genesis* :order 3 :n 93))      brink time wagons fourth Besides south darkness listen foreigner Stay possessor lentils backwards be call dignity Kenizzites tar witness strained Yes appear colts bodies Reuel burn inheritance Galeed Hadar money touches conceal mighty foreigner spices Set pit straw son hurry yoke numbered gutters Dedan honest drove Magdiel Nod life assembly your Massa iniquity Tola still fifteen ascending wilderness everywhere shepherd harm bore Elah Jebusites Assyria butler Euphrates sinners gave Nephilim Stay garments find lifted communing closed Ir lights doing weeping shortly disobedience possessions drank peoples fifteen bless talked songs lamb far Shaveh heavens
What this example shows us are at least two things:
- we should always check that mathematical properties of our models   still hold as we tweak them - although the major use-case for language model is scoring, you can   get a feel of how good it will perform by looking at the texts it   generates
This is another interesting and useful NLP problem with a very elegant baseline solution, which is explained in this [article](http://tdunning.blogspot.com/2008/03/surprise-and-coincidence.html). Hopefully, we'll get back to it in more detail in the future chapters. And for now here's the results of implementing the algorithm from the article:
NLTK> (collocations *inaugural*)     (("United" "States") ("fellow" "citizens") ("four" "years") ("years" "ago")      ("Federal" "Government") ("General" "Government") ("American" "people")      ("Vice" "President") ("Old" "World") ("Almighty" "God") ("Fellow" "citizens")      ("Chief" "Magistrate") ("Chief" "Justice") ("God" "bless") ("go" "forward")      ("every" "citizen") ("Indian" "tribes") ("public" "debt") ("one" "another")      ("foreign" "nations") ("political" "parties") ("State" "governments")      ("National" "Government") ("United" "Nations") ("public" "money")      ("national" "life") ("beloved" "country") ("upon" "us") ("fellow" "Americans")      ("Western" "Hemisphere"))
I'm surprised at how similar they are to NLTK's considering that I didn't look at their implementation. In fact, they are the same up to the difference in the list of __stopwords__ (the dirty secret of every NLP application :) The code for collocation extraction function can be found in [core/measures.lisp](https://github.com/vseloved/cl-nlp/blob/master/src/core/measures.lisp).
Ngrams are also sometimes used for individual characters to build Character language models. And here's another usage from NLTK  for counting word lengths.
NLTK> (defvar *moby-lengths*                   (index-ngrams 1 (mapcar #'length (text-words *moby*))))     NLTK> (vocab *moby-lengths*)     (1 4 2 6 8 9 11 5 7 3 10 12 13 14 16 15 17 18 20)     NLTK> (ngrams-pairs *moby-lengths*)     ((1 . 58368) (4 . 42273) (2 . 35726) (6 . 17111) (8 . 9966) (9 . 6428)      (11 . 1873) (5 . 26595) (7 . 14399) (3 . 49633) (10 . 3528) (12 . 1053)      (13 . 567) (14 . 177) (16 . 22) (15 . 70) (17 . 12) (18 . 1) (20 . 1))     NLTK> (ngrams-max-freq *moby-lengths*)     58368     NLTK> (freq *moby-lengths* 3)     49633
Language modeling is really the foundation of any serious NLP work. Having access to ngrams expands your possibilities immensely, but the problem with them is that moving from prototype to production implementation becomes tricky due to the problems of collecting a representative data-set and consequently efficiently storing it. Yet, there are solutions: the [Google Books Ngrams](http://storage.googleapis.com/books/ngrams/books/datasetsv2.html) and [Google Web1T](http://googleresearch.blogspot.com/2006/08/all-our-n-gram-are-belong-to-you.html) are an example of web-scale ngrams data-set, and there's also special-purpose software for storing large ngrams corpora and obtaining language models from them. The notable examples are [BerkeleyLM](http://code.google.com/p/berkeleylm/) and [KenLM](http://kheafield.com/code/kenlm/).
Let's return to start of chapter 2 and explore the tools needed to easily and efficiently work with various linguistic resources.
What are the most used and useful corpora? This is a difficult question to answer because different problems will likely require specific annotations and often a specific corpus. There are even special conferences dedicated to corpus linguistics.
Here's a list of the most well-known general-purpose corpora:
- Brown Corpus - one of the first big corpora and the only one in the   list really easily accessible - we've already worked with it   in the first chapter - Penn Treebank - Treebank is a corpus of sentences annotated with their   constituency parse trees so that they can be used to train and evaluate parsers - Reuters Corpus (not to be confused with the ApteMod version provided with NLTK) - British National Corpus (BNC) - a really huge corpus, but, unfortunately,   not freely available
Another very useful resource which isn't structured specifically as academic corpora mentioned above, but at the same time has other dimensions of useful connections and annotations is **Wikipedia**. And there's being a lot of interesting linguistic research performed with it.
Besides there are two additional valuable language resources that can't be classified as text corpora at all, but rather as language databases: **WordNet** and **Wiktionary**. We have already discussed `CL-NLP` interface to Wordnet. And we'll touch working with Wiktionary in this part.
All of the text corpora we'll encounter come as a set of files which use some format, either custom or standard (like XML). So to be able to access this data we'll need to implement reading and processing of individual files and assembling these files into groups. Besides, as some corpora are really large (for instance a zipped instance of the Reuters corpus amounts to 1.5+ Gb), it is also useful to be able to process the data one text at a time not detaining them in memory. All this defines a rather simple protocol for corpora processing.
A `corpus` is just a list of texts, that can be arbitrary grouped.
(defstruct corpus       desc texts groups)
A `text` has a `name` and several representations: basic texts may have a raw, a cleaned-up and a tokenized one. We'll also see texts with other representations, like the parse trees for treebanks - we'll use structure inheritance to describe them.
(defstruct text       name raw clean tokens)
The protocol itself comprises of 3 operations:
(defgeneric read-corpus (type path))
(defgeneric read-corpus-file (type source))
(defgeneric map-corpus (type path fn))
`read-corpus` creates a corpus object, and it uses `read-corpus-file` to read individual files and return their contents in multiple forms, potentially needed for further processing. `map-corpus` calls function `fn` with every `text` produced from calling `read-corpus-file` on a corpus in arbitrary order. This function works more like `maphash` than `mapcar`, because it doesn't collect the results of applying `fn`.
The methods of these functions are usually boring. For text-based formats we implement `read-corpus-file` by reading each file's text either in whole or line-by-line with the `dolines` macro, performing tokenization and some post-processing. For XML-based variants we may use SAX processing with Closure XML library.
Let's look at the NPS Chat corpus that is provided with NLTK. It has a rather simple XML format. The entries are called `Post`s and have the following structure:
<Post class="Emotion" user="10-19-30sUser2">10-19-30sUser11 lol         <terminals>             <t pos="NNP" word="10-19-30sUser11"/>             <t pos="UH" word="lol"/>         </terminals>     </Post>
We process each file by calling `cxml:parse` with an instance of the `nps-chat-sax` class.
(defmethod read-corpus-file ((type (eql :nps-chat)) source)       (cxml:parse source (make 'nps-chat-sax)))
For this object we'll specialize the parser methods. It will also serve as a storage for state of processing as SAX parsing operates with callbacks that don't have access to the current context besides access to the parser object.
(defclass nps-chat-sax (sax:sax-parser-mixin)       ((texts :initform nil)        (tokens :initform nil)        (classes :initform nil)        (users :initform nil)        (cur-tag :initform nil)        (cur-tokens :initform nil)))
`read-corpus-file` will return a list of each post's contents, tokens, as well as the list of posts' classes and users, which are indicated in the meta attributes. Technically these values will be produced by the `sax:end-document` method that is called at the end of SAX processing:
(defmethod sax:end-document ((sax nps-chat-sax))       (with-slots (texts tokens users classes) sax         (values nil  ;; raw text isn't useful for this corpus                 (reverse texts)                 (reverse tokens)                 (reverse classes)                 (reverse users))))
In `sax:start-element` method we store the current tag and record attributes of each post or tokens, depending on the element.
(defmethod sax:start-element ((sax nps-chat-sax)                                   namespace-uri local-name qname attributes)       (with-slots (classes users cur-tokens cur-tag) sax         (case (setf cur-tag (mkeyw local-name))           (:post (push (attr "class" attributes) classes)                  (push (attr "user" attributes) users))           (:t (push (make-token :word (attr "word" attributes)                                 :tag (mkeyw (attr "pos" attributes)))                     cur-tokens)))))
In `sax:characters` we record current post's text:
(defmethod sax:characters ((sax nps-chat-sax) data)       (with-slots (cur-tag texts) sax         (when (eql :terminals cur-tag)           (push data texts))))
And in `sax:end-element` we dump current tokens:
(defmethod sax:end-element ((sax nps-chat-sax) namespace-uri                                 local-name qname)       (when (eql :terminals (mkeyw local-name))         (with-slots (tokens cur-tokens) sax           (push (reverse cur-tokens) tokens)           (setf cur-tokens nil))))
If you have used SAX parsing in some other language, like Python, you should immediately recognize this approach and see how it can translated to that language almost line-by-line.
A slightly more complex processing is required for the Reuters corpus. The reason for that is that unlike with the Chat corpus that we assumed to be inside a filesystem directory, it's not always reasonable to extract this corpus as it's big and also is stored in two-level zip archive with individual archives packed inside another big archive. Extracting all of them is, obviously, tedious.
For such corpus it makes sense to resort to using `map-corpus`. Here's a definition of its method for this corpus:
(defmethod map-corpus ((type (eql :reuters)) path fn)       (zip:with-zipfile (zip path)         (zip:do-zipfile-entries (name entry zip)           (unless (char= #\/ (last-char name))             (with-zipped-zip (in entry :raw t)               (mv-bind (_ text tokens __ ___ headline byline dateline)                   (read-corpus-file :reuters in)                 (declare (ignore _ __ ___))                 (funcall fn (make-reuters-text                              :name name                              :clean text                              :tokens tokens                              :headline headline                              :byline byline                              :dateline dateline))))))))
It relies on `read-corpus-file` which processes individual XML documents just like we saw early for the NPS Chat corpus. But the documents are fed into it not by `fad:walk-directory`, but with the help of the utilities, provided by David Lichteblau's excellent `zip` library.
(zip:with-zipfile (zip path)       (zip:do-zipfile-entries (name entry zip)         (unless (char= #\/ (last-char name))           (with-zipped-zip (in entry :raw t)
In this snippet we open the zip file at `path` in `with-zipfile` and iterate over its entries with `do-zipfile-entries`. These are usual Lisp patterns to handle such kinds of resources. Yet inside the zip file we find another layer of zip archives. To remove unnecessary hassle and boilerplate I've added an additional macro `with-zipped-zip`. It has to some extent to replicate the functionality of `with-zipfile`, but it should take the data from the contents of one of the entries of the already open zip file. Another twist is that it optionally gives the possibility to access the raw unzipped binary stream, not yet converted to a text representation - this is useful for CXML which can work with such streams efficiently.
(defmacro with-zipped-zip ((name stream zipfile-entry                                        &key (external-format :utf-8) raw)                                &body body)       (with-gensyms (zipstream v end entry entries zip x n)         ;; here we transform the archives contents into an input stream         ;; and then read it         `(flex:with-input-from-sequence               (,zipstream (zip:zipfile-entry-contents ,zipfile-entry))             (let ((,v (make-array (zip:zipfile-entry-size ,zipfile-entry)                                   :element-type '(unsigned-byte 8))))               (read-sequence ,v ,zipstream)
;; here we look for the central directory header               ;; and move to it in the stream               (if-it (search #(80 75 5 6) ,v :from-end t)                      (file-position ,zipstream it)                      (error "end of central directory header not found"))
;; here we create a corresponding zipfile object for the entry               (let* ((,end (zip::make-end-header ,zipstream))                      (,n (zip::end/total-files ,end))                      (,entries (make-hash-table :test #'equal))                      (,zip (zip::make-zipfile                             :stream ,zipstream                             :entries ,entries                             :external-format ,external-format)))                 (file-position ,zipstream                                (zip::end/central-directory-offset ,end))
;; and here we read individual entries from the archive                 (dotimes (,x ,n)                   (let ((,entry (zip::read-entry-object ,zipstream                                                         ,external-format)))                     (set# (zip:zipfile-entry-name ,entry) ,entries ,entry)))
;; finally, we're able to access entries in the same manner                 ;; as we'll do for the ordinary archive                 (do-entries (,name ,stream ,zip                              :external-format ,external-format :raw ,raw)                   ,@body))))))
As you see, this macro uses a lot of `zip`'s internal symbols, as it implements the similar function to the one which the library does, but not anticipated by its author...
Let's see how it works:
NLP> (map-corpus :reuters "Reuters.zip"                      #`(print (text-name %)))     "Reuters/Eng Lang_Disk 1/19960824.zip/12536newsML.xml"     "Reuters/Eng Lang_Disk 1/19960824.zip/12537newsML.xml"     ...
The Penn Treebank is a very important corpus which is also not easy to obtain: you have to order a CD from Linguistic Data Consortium (LDC) and pay more than 1.5 thousand dollars for it. Yet, there are 2 workarounds:
- NLTK data provides 5% of the treebank, so you can use it for   experimenting with the data format - There's a more recent corpus OntoNotes which includes the Penn   Treebank, and you also should obtain it from LDC, but it costs only   50$ (I've learned about its existence on StackOverflow, ordered it   and it indeed has a treebank inside, as well as a lot of other   useful linguistic annotations; the only thing I'm not sure about is   whether it is an exact copy of the Penn Treebank)
Let's see how to load the NLTK's treebank. The obvious thing about treebanks is that they are basically Lisp code, so it should be very easy to parse the data with Lisp. The only catch is that the treebank doesn't obey Lisp's formatting rules for strings and doesn't distinguish special characters like quote and pipe. So the task is to properly handle all that.
In `CL-NLP` we have several utilities for dealing with trees: the macros `dotree` and `doleaves` which execute arbitrary code for each subtree or leafin a tree for side-effects, and their counterpart functions `maptree` and `mapleaves` that allow to create isomorphic tree structures by applying a function to all tree's nodes or leaf nodes.
So, reading a treebanked tree will be performed in 2 steps:
- first, we prepare the tree for loading by properly escaping everything:
(defun prepare-tree-for-reading (string)           (strjoin " " (mapcar #`(cond-it                                    ((char= #\( (char % 0))                                     (cond-it                                       ((member (sub % 1)                                                '("." "," ";" ":" "#" "''" "``")                                                :test 'string=)                                        (fmt "(|~A|" (sub % 1))))                                       ((position #\| %)                                        (fmt "(|~A\\|~A|"                                             (sub % 1 it) (sub % (1+ it))))                                       (t %)))                                    ((position #\) %)                                     (if (zerop it)                                         %                                         (fmt "\"~A\"~A" (sub % 0 it) (sub % it))))                                    (t (fmt "\"~A\"" %)))                                (split-sequence-if #`(member % +white-chars+)                                                   string :remove-empty-subseqs t)))
- and then we `read` the tree with the Lisp reader and separately   collect its tokens:
(defmethod read-corpus-file ((type (eql :treebank)) file)           (let ((raw (string-trim +white-chars+ (read-file file))))             (with-input-from-string (in (prepare-tree-for-reading raw))               (loop                  :for tree := (car (read in nil)) :while tree                  :collect raw :into raws                  :collect tree :into trees                  :collect (let ((pos 0)                                 toks)                             (dotree (subtree tree)                               (when (and (listp subtree)                                          (single (cdr subtree))                                          (atom (cadr subtree)))                                 (let ((word (second subtree)))                                   (push (make-token                                          :beg pos                                          :end (1- (incf pos (1+ (length word))))                                          :word word                                          :tag (first subtree))                                         toks))))                             (reverse toks))                  :into tokens                  :finally                  (return (values (strjoin #\Newline raws)                                  (mapcar #`(strjoin #\Space                                                     (mapcar #'token-word %))                                          tokens)                                  tokens                                  trees))))))
Most of the other corpora will use formats similar to the Brown, Reuters Corpus, or Penn Treebank, so their readers may easily be defined by analogy. Besides, the implementations of `read-corpus` methods assume a certain way to present the corpus to the library: in a filesystem directory, in a zipfile etc. Certainly, the corpora may come in different form, but it will take just a couple of lines of code changed to re-purpose the methods to handle a different representation
Working with some other collections of documents presented in the NLTK book, like Project Gutenberd collection of famous literary texts in public domain or Inaugural speeches collection is just trivial - you can see how it's done in our implementation of Chapter 1.
For instance, if we have Project Gutenberg collection in some directory `dir`, we can process it by using the following pattern:
(fad:walk-directory      dir      #`(let ((text (string-trim +white-chars (read-file %))))          ... do some processing on the raw text of the corpus ...          ))
Unlike most of academic corpora that are not so easy to obtain Wikipedia and Wiktionary without a hassle give you access to full dumps of their data in various formats: SQL, XML and text. For instance, we can obtain the latest dump of English Wiktionary from <http://dumps.wikimedia.org/enwiktionary/>.
I found it the most convenient to process them using the same XML SAX parsing approach that was utilized for the Reuters and NPS Chat corpora.  The difference for them is that inside the XML documents a special Mediawiki markup is used to add metadata. It is, in fact, a heroic feat to parse this markup, because it doesn't have a clear, precise spec - it's real spec is the PHP code of the Wikipedia's parser,- and different people tend to (ab)use different variations of annotations to express the same or similar things, as well as just to use the markup in an untidy manner. I call such documents semi-structured compared to unstructured raw text and structured XML markup.  Still, there's a lot of value in this annotation, because of their crowdsourced nature that allows to capture much more information than in most centralized efforts. Basically, there are 2 ways to work with Mediawiki markup: using regexes or implementing the complete parser.
Below is a snippet of code, that uses the regex-based approach to extract some information from the English Wiktionary - English word definitions.  In Wiktionary markup the definitions are inside each language's section (denoted with `==Lang==` marker, where `Lang` can be `English` or some other language). The definitions themselves are placed on their own lines and start with one of these markers: `#`, `#:`, `#*`, `#*:`, `#*::`, `* [[`.
(defvar *defs* (list))
(defclass word-collector (sax:sax-parser-mixin)       ((title :accessor title :initform nil)        (tag :accessor tag :initform nil)        (text :accessor text :initform ())        (itemcount :accessor itemcount :initform 0)        (tagcount :accessor tagcount :initform 0)))
(defmethod sax:end-element ((sax word-collector)                                 namespace-uri local-name qname)       (with-slots (title tag text) sax         (when (string= "text" local-name)           (let ((lang-marker "==English==")                 (whole-text (strjoin "" (reverse text))))             (when-it (search lang-marker whole-text)               (let ((start (+ it (length lang-marker))))                 (dolist (line (split-sequence                                #\Newline (sub whole-text start                                               (re:scan "[^=]==[^=]" whole-text                                                        :start start))))                   (when (some #`(starts-with % line)                               '("# " "#: " "#* " "#*: " "#*:: " "* [["))                     (push (clean-words line) *defs*)                     (incf (itemcount sax))))))))))))
(defun clean-words (line)       "Return a list of downcased words (only alpha-chars or hyphens        in the middle) found in LINE."       (mapcar #`(string-downcase (string-trim "-" %))               (remove-if #`(or (blankp %)                                (loop :for char :across % :do                                  (unless (or (alpha-char-p char)                                              (char= #\- char))                                    (return t))))                          (re:split +punctuation+ (raw-text line)))))
(defun raw-text (line)       "Return LINE without special-purpose Wiktionary chars."       (re:regex-replace-all "({[^}]+})|(\\[\\[)|(\\]\\])|('''?)"                             (sub line (1+ (position #\Space line)))                             ""))
As the task is clearly defined and limited - extract just the text of definitions - it is possible to use regexes here:
- one regex to spot the interesting lines - another one to filter out all the unnecessary markup.
Now, as we can already load and play with our corpora let's take a look at some NLTK examples.
First, let's examine the Brown corpus. Here are its categories:
NLP> (ht-keys (corpus-groups *brown*))     (:PRESS-REPORTAGE :PRESS-EDITORIAL :PRESS-REVIEWS :RELIGION      :SKILL-AND-HOBBIES :POPULAR-LORE :BELLES-LETTRES      :MISCELLANEOUS-GOVERNMENT-HOUSE-ORGANS :LEARNED :FICTION-GENERAL      :FICTION-MYSTERY :FICTION-SCIENCE :FICTION-ADVENTURE :FICTION-ROMANCE      :HUMOR)
As you see, there is no "news" category which is mentioned in the NLTK example. Probably, what they refer to is `:press-reportage`.
NLP> (take 9 (mapcar #'token-word                          (flatten (mapcar #'text-tokenized                                           (get# :press-reportage                                                 (corpus-groups *brown*))))))     ("The" "Fulton" "County" "Grand" "Jury" "said" "Friday" "an" "investigation")
NLP> (take 9 (mapcar #'token-word                          (flatten                           (mapcar #'text-tokenized                                   (remove-if-not #`(string= "cg22" (text-name %))                                                  (corpus-texts *brown*))))))     ("Does" "our" "society" "have" "a" "runaway" "," "uncontrollable" "growth")
NLP> (setf *print-length* 3)     NLP> (mapcan #`(ncorpus::sentences-from-tokens (text-tokenized %))                  (get# :press-reportage (corpus-groups *brown*)))     ((#<The/at 0..3> #<Fulton/np-tl 4..10> #<County/nn-tl 11..17> ...)      (#<The/at 166..169> #<jury/nn 170..174> #<further/rbr 175..182> ...)      (#<The/at 409..412> #<September-October/np 413..430> #<term/nn 431..435> ...)      ...)
The function `sentences-from-tokens` here operates under the assumption, that every token with `.` tag is ending a sentence, and it splits the sentences on one or more such tokens.
The presented code may seam much more elaborate, than the NLTK version:
>>> brown.words(categories='news')     ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]     >>> brown.words(fileids=['cg22'])     ['Does', 'our', 'society', 'have', 'a', 'runaway', ',', ...]     >>> brown.sents(categories=['news', 'editorial', 'reviews'])     [['The', 'Fulton', 'County'...], ['The', 'jury', 'further'...], ...]
Yet, it should be understood, that it is easy to add a ton of various utility accessors, like it is done in NLTK, but they will inevitable make the code more complex and harder to maintain. And the question is, how frequently are they going to be used and what we will miss anyway? Coding such utilities is very pleasant and easy using the functional style, as shown above, so they are left outside of the scope of `cl-nlp`, at least until proven essential...
(NB. Don't forget to set `*print-length*` back to `nil`).
Next, we'll be once again looking at frequency distributions. First, we need to build an ngram index from Brown corpus words in "news" category. In chapter 1 we've already done a very similar thing:
NLP> (index-ngrams           1 (mapcar #'token-word                     (flatten (mapcar #'text-tokenized                                      (get# :press-reportage                                            (corpus-groups *brown*))))))     #<TABLE-NGRAMS order:1 count:14395 outcomes:108130 {101C2B57E3}>     NLP> (defvar *news-1grams* *)  ;; * is the previous returned value     NLP> (dolist (m '("can" "could" "may" "might" "must" "will"))            (format t "~A: ~A " m (freq *news-1grams* m)))     can: 93 could: 86 may: 66 might: 38 must: 50 will: 389
Funny, some numbers don't add up to what there's in NLTK:
can: 94 could: 87 may: 93 might: 38 must: 53 will: 389
Well, we can double-check them from a different direction:
NLP> (length (remove-if-not                   #`(string= "can" %)                   (mapcar #'token-word                           (flatten (mapcar #'text-tokenized                                            (get# :press-reportage                                                  (corpus-groups *brown*)))))))     93
Looks like our calculation is precise.
Next is conditional frequency distribution, but we'll leave this topic for the next part that is fully dedicated to that.
So far so good. We have examined common approaches to handling various corpora. There are, basically, 2 main things you need to do with them: load & parse and filter for some interesting information. The loading for most corpora will be performed either with some regexes on raw strings, with XML SAX parsing, or using the Lisp reader. And for filtering Lisp offers a great versatile toolset of higher-order functions: `mapcar`, `remove-if-not`, `position`, and `reduce` - to name a few.
What is a conditional frequency distribution? From a statistical point of view, it is a function of 2 arguments - a condition and a concrete outcome - producing an integer result that is a frequency of the outcome's occurence under the condition. The simplest variant of such function is a table.
